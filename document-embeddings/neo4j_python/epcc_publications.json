{
    "59ef3cbb-d704-4146-a563-7e811d5aa37d": {
        "id": "59ef3cbb-d704-4146-a563-7e811d5aa37d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/using-machine-learning-to-reduce-ensembles-of-geological-models-for-oil-and-gas-exploration(59ef3cbb-d704-4146-a563-7e811d5aa37d).html",
        "abstract": "Exploration using borehole drilling is a key activity in determining the most appropriate locations for the petroleum industry to develop oil fields. However, estimating the amount of Oil In Place (OIP) relies on computing with a very significant number of geological models, which, due to the ever increasing capability to capture and refine data, is becoming infeasible. As such, data reduction techniques are required to reduce this set down to a smaller, yet still fully representative ensemble. In this paper we explore different approaches to identifying the key grouping of models, based on their most important features, and then using this information select a reduced set which we can be confident fully represent the overall model space. The result of this work is an approach which enables us to describe the entire state space using only 0.5\\% of the models, along with a series of lessons learnt. The techniques that we describe are not only applicable to oil and gas exploration, but also more generally to the HPC community as we are forced to work with reduced data-sets due to the rapid increase in data collection capability.",
        "title": "Using machine learning to reduce ensembles of geological models for oil and gas exploration",
        "keywords": "",
        "authors": [
            {
                "name": "Anna Roubickova",
                "uuid": "15afd39e-b81e-4522-8dc6-2da955254911"
            },
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "af5e5e63-34cb-45da-8459-bed6d5e0bbc3": {
        "id": "af5e5e63-34cb-45da-8459-bed6d5e0bbc3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/machine-learning-for-gas-and-oil-exploration(af5e5e63-34cb-45da-8459-bed6d5e0bbc3).html",
        "abstract": "Drilling boreholes for gas and oil extraction is an expensive process and profitability strongly depends on characteristics of the subsurface. As profitability is a key success factor, companies in the industry utilise well logs to explore the subsurface beforehand. These well logs contain various characteristics of the rock around the borehole, which allow petrophysicists to determine the expected amount of contained hydrocarbon. However, these logs are often incomplete and, as a consequence, the subsequent analyses cannot exploit the full potential of the well logs.<br/><br/>In this paper we demonstrate that Machine Learning can be applied to fill in the gaps and estimate missing values. We investigate how the amount of training data influences the accuracy of prediction and how to best design regression models (Gradient Boosting and neural network) to obtain optimal results. We then explore the models' predictions both quantitatively, tracking the prediction error, and qualitatively, capturing the evolution of the measured and predicted values for a given property with depth. Combining the findings has enabled us to develop a predictive model that completes the well logs, increasing their quality and potential commercial value.",
        "title": "Machine Learning for Gas and Oil Exploration",
        "keywords": "",
        "authors": [
            {
                "name": "Anna Roubickova",
                "uuid": "15afd39e-b81e-4522-8dc6-2da955254911"
            },
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "f4bd3215-2223-4fc9-9e08-f8839d285821": {
        "id": "f4bd3215-2223-4fc9-9e08-f8839d285821",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/machine-learning-on-crays-to-optimise-petrophysical-workflows-in-oil-and-gas-exploration(f4bd3215-2223-4fc9-9e08-f8839d285821).html",
        "abstract": "The oil and gas industry is awash with sub-surface data, which is used to characterize the rock and fluid properties beneath the seabed. This in turn drives commercial decision making and exploration, but the industry currently relies upon highly manual workflows when processing data. A key question is whether this can be improved using machine learning to complement the activities of petrophysicists searching for hydrocarbons. In this paper we present work done using supervised machine learning with a general aim of decreasing the petrophysical interpretation time down from over 7 days to 7 minutes. We describe the use of mathematical models that have been trained using raw well log data, for completing each of the four stages of a petrophysical interpretation workflow, along with initial data cleaning. We explore how the predictions from these models compare against the interpretations of human petrophysicists, along with numerous options and techniques that were used to optimise the prediction of our models. Some popular machine learning framework are unable to take full advantage of modern HPC machines, and we explore our solutions. The result of this work is the ability, for the first time, to use machine learning for the entire petrophysical workflow.",
        "title": "Machine learning on Crays to optimise petrophysical workflows in oil and gas exploration",
        "keywords": "",
        "authors": [
            {
                "name": "Anna Roubickova",
                "uuid": "15afd39e-b81e-4522-8dc6-2da955254911"
            },
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "a9682a06-d159-4d00-9f92-f9a27f0bb385": {
        "id": "a9682a06-d159-4d00-9f92-f9a27f0bb385",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/defoe-a-sparkbased-toolbox-for-analysing-digital-historical-textual-data(a9682a06-d159-4d00-9f92-f9a27f0bb385).html",
        "abstract": "This work presents <i>defoe</i>, a new scalable and portable digital eScience toolbox that enables historical research. It allows for running text mining queries across large datasets, such as historical newspapers and books in parallel via <i>Apache Spark</i>. It handles queries against collections that comprise several XML schemas and physical representations. The proposed tool has been successfully evaluated using five different large-scale historical text datasets and two HPC environments, as well as on desktops. Results shows that <i>defoe</i> allows researchers to query multiple datasets in parallel from a single command-line interface and in a consistent way, without any HPC environment-specific requirements.",
        "title": "<i>defoe</i>: A Spark-based Toolbox for Analysing Digital Historical Textual Data",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Anna Roubickova",
                "uuid": "15afd39e-b81e-4522-8dc6-2da955254911"
            },
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "542f87b8-cb92-4c39-9be9-aeae04e09eb4": {
        "id": "542f87b8-cb92-4c39-9be9-aeae04e09eb4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-technologies-required-for-fusing-hpc-and-realtime-data-to-support-urgent-computing(542f87b8-cb92-4c39-9be9-aeae04e09eb4).html",
        "abstract": "The use of High Performance Computing (HPC) to compliment urgent decision making in the event of disasters is an important future potential use of supercomputers. However, the usage modes involved are rather different from how HPC has been used traditionally. As such, there are many obstacles that need to be overcome, not least the unbounded wait times in the batch system queues, to make the use of HPC in disaster response practical. In this paper, we present how the VESTEC project plans to overcome these issues and develop a working prototype of an urgent computing control system. We describe the requirements for such a system and analyse the different technologies available that can be leveraged to successfully build such a system. We finally explore the design of the VESTEC system and discuss ongoing challenges that need to be addressed to realise a production level system.",
        "title": "The Technologies Required for Fusing HPC and Real-Time Data to Support Urgent Computing",
        "keywords": "",
        "authors": [
            {
                "name": "Rupert Nash",
                "uuid": "f171552c-1aec-414e-a571-901bba2f6cb2"
            },
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "b868ffbd-a11f-4e70-a611-bb49ebc18cfa": {
        "id": "b868ffbd-a11f-4e70-a611-bb49ebc18cfa",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-role-of-interactive-supercomputing-in-using-hpc-for-urgent-decision-making(b868ffbd-a11f-4e70-a611-bb49ebc18cfa).html",
        "abstract": "Technological advances are creating exciting new opportunities that have the potential to move HPC well beyond traditional computational workloads. In this paper we focus on the potential for HPC to be instrumental in responding to disasters such as wildfires, hurricanes, extreme flooding, earthquakes, tsunamis, winter weather conditions, and accidents. Driven by the VESTEC EU funded H2020 project, our research looks to prove HPC as a tool not only capable of simulating disasters once they have happened, but also one which is able to operate in a responsive mode, supporting disaster response teams making urgent decisions in real-time. Whilst this has the potential to revolutionise disaster response, it requires the ability to drive HPC interactively, both from the user's perspective and also based upon the arrival of data. As such interactivity is a critical component in enabling HPC to be exploited in the role of supporting disaster response teams so that urgent decision makers can make the correct decision first time, every time.",
        "title": "The role of interactive super-computing in using HPC for urgent decision making",
        "keywords": "",
        "authors": [
            {
                "name": "Rupert Nash",
                "uuid": "f171552c-1aec-414e-a571-901bba2f6cb2"
            },
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "14918ae3-1fcd-4aba-9638-b4e3d7afbfc4": {
        "id": "14918ae3-1fcd-4aba-9638-b4e3d7afbfc4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/polnet(14918ae3-1fcd-4aba-9638-b4e3d7afbfc4).html",
        "abstract": "<p>In this article, we present PolNet, an open-source software tool for the study of blood flow and cell-level biological activity during vessel morphogenesis. We provide an image acquisition, segmentation, and analysis protocol to quantify endothelial cell polarity in entire in vivo vascular networks. In combination, we use computational fluid dynamics to characterize the hemodynamics of the vascular networks under study. The tool enables, to our knowledge for the first time, a network-level analysis of polarity and flow for individual endothelial cells. To date, PolNet has proven invaluable for the study of endothelial cell polarization and migration during vascular patterning, as demonstrated by two recent publications. Additionally, the tool can be easily extended to correlate blood flow with other experimental observations at the cellular/molecular level. We release the source code of our tool under the Lesser General Public License.</p>",
        "title": "PolNet",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rupert Nash",
                "uuid": "f171552c-1aec-414e-a571-901bba2f6cb2"
            }
        ]
    },
    "b639c4b3-4cb0-40ee-95c9-351543ded452": {
        "id": "b639c4b3-4cb0-40ee-95c9-351543ded452",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-24th-international-conference-on-discrete-simulation-of-fluid-dynamics-in-edinburgh-scotland(b639c4b3-4cb0-40ee-95c9-351543ded452).html",
        "abstract": "",
        "title": "The 24th International Conference on Discrete Simulation of Fluid Dynamics in Edinburgh, Scotland",
        "keywords": "",
        "authors": [
            {
                "name": "Rupert Nash",
                "uuid": "f171552c-1aec-414e-a571-901bba2f6cb2"
            },
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "f6f953a8-774e-424a-8dfd-0c94491660b3": {
        "id": "f6f953a8-774e-424a-8dfd-0c94491660b3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/modeling-patientspecific-magnetic-drug-targeting-within-the-intracranial-vasculature(f6f953a8-774e-424a-8dfd-0c94491660b3).html",
        "abstract": "",
        "title": "Modeling Patient-Specific Magnetic Drug Targeting Within the Intracranial Vasculature",
        "keywords": "",
        "authors": [
            {
                "name": "Rupert Nash",
                "uuid": "f171552c-1aec-414e-a571-901bba2f6cb2"
            }
        ]
    },
    "12f0ad3a-a476-46c2-9f79-16870238fe9e": {
        "id": "12f0ad3a-a476-46c2-9f79-16870238fe9e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/coupling-of-latticeboltzmann-solvers-with-suspended-particles-using-the-mpi-intercommunication-framework(12f0ad3a-a476-46c2-9f79-16870238fe9e).html",
        "abstract": "The MPI intercommunication framework was used for coupling of two lattice-Boltzmann solvers with suspended particles, which model advection and diffusion respectively of these particles in a carrier fluid. Simulation domain was divided into two parts, one with advection and diffusion, and the other with diffusion only (no macroscopic flow). Particles were exchanged between these domains at their common boundary by a direct process to process communication. By analysing weak and strong scaling, it was shown that the linear scaling characteristics of the lattice-Boltzmann solvers were not compromised by their coupling.",
        "title": "Coupling of lattice-Boltzmann solvers with suspended particles using the MPI intercommunication framework",
        "keywords": "",
        "authors": [
            {
                "name": "Rupert Nash",
                "uuid": "f171552c-1aec-414e-a571-901bba2f6cb2"
            }
        ]
    },
    "b9ff1f7f-97ce-4713-bf00-46cb6e20a706": {
        "id": "b9ff1f7f-97ce-4713-bf00-46cb6e20a706",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/role-of-correlations-in-the-collective-behavior-of-microswimmer-suspensions(b9ff1f7f-97ce-4713-bf00-46cb6e20a706).html",
        "abstract": "<p>In this Letter, we study the collective behavior of a large number of self-propelled microswimmers immersed in a fluid. Using unprecedentedly large-scale lattice Boltzmann simulations, we reproduce the transition to bacterial turbulence. We showthat, even well belowthe transition, swimmersmove in a correlated fashion that cannot be described by a mean-field approach. We develop a novel kinetic theory that captures these correlations and is nonperturbative in the swimmer density. To provide an experimentally accessible measure of correlations, we calculate the diffusivity of passive tracers and reveal its nontrivial density dependence. The theory is in quantitative agreement with the lattice Boltzmann simulations and captures the asymmetry between pusher and puller swimmers below the transition to turbulence.</p>",
        "title": "Role of Correlations in the Collective Behavior of Microswimmer Suspensions",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rupert Nash",
                "uuid": "f171552c-1aec-414e-a571-901bba2f6cb2"
            }
        ]
    },
    "7f280ffc-ce8f-45ad-aacd-c00bbf0aad6e": {
        "id": "7f280ffc-ce8f-45ad-aacd-c00bbf0aad6e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/weighted-decomposition-in-highperformance-latticeboltzmann-simulations(7f280ffc-ce8f-45ad-aacd-c00bbf0aad6e).html",
        "abstract": "<p>Obtaining a good load balance is a significant challenge in scaling up lattice-Boltzmann simulations of realistic sparse problems to the exascale. Here we analyze the effect of weighted decomposition on the performance of the HemeLB lattice-Boltzmann simulation environment, when applied to sparse domains. Prior to domain decomposition, we assign wall and in/outlet sites with increased weights which reflect their increased computational cost. We combine our weighted decomposition with a second optimization, which is to sort the lattice sites according to a space filling curve. We tested these strategies on a sparse bifurcation and very sparse aneurysm geometry, and find that using weights reduces calculation load imbalance by up to 85%, although the overall communication overhead is higher than some of our runs.</p>",
        "title": "Weighted Decomposition in High-Performance Lattice-Boltzmann Simulations",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rupert Nash",
                "uuid": "f171552c-1aec-414e-a571-901bba2f6cb2"
            }
        ]
    },
    "4764cf0a-85e5-401e-90b9-9f5b5f5456f6": {
        "id": "4764cf0a-85e5-401e-90b9-9f5b5f5456f6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/computer-simulations-reveal-complex-distribution-of-haemodynamic-forces-in-a-mouse-retina-model-of-angiogenesis(4764cf0a-85e5-401e-90b9-9f5b5f5456f6).html",
        "abstract": "There is currently limited understanding of the role played by haemodynamic forces on the processes governing vascular development. One of many obstacles to be overcome is being able to measure those forces, at the required resolution level, on vessels only a few micrometres thick. In this paper, we present an in silico method for the computation of the haemodynamic forces experienced by murine retinal vasculature (a widely used vascular development animal model) beyond what is measurable experimentally. Our results show that it is possible to reconstruct high-resolution three-dimensional geometrical models directly from samples of retinal vasculature and that the lattice-Boltzmann algorithm can be used to obtain accurate estimates of the haemodynamics in these domains. We generate flow models from samples obtained at postnatal days (P) 5 and 6. Our simulations show important differences between the flow patterns recovered in both cases, including observations of regression occurring in areas where wall shear stress (WSS) gradients exist. We propose two possible mechanisms to account for the observed increase in velocity and WSS between P5 and P6: (i) the measured reduction in typical vessel diameter between both time points and (ii) the reduction in network density triggered by the pruning process. The methodology developed herein is applicable to other biomedical domains where microvasculature can be imaged but experimental flow measurements are unavailable or difficult to obtain.",
        "title": "Computer simulations reveal complex distribution of haemodynamic forces in a mouse retina model of angiogenesis",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rupert Nash",
                "uuid": "f171552c-1aec-414e-a571-901bba2f6cb2"
            }
        ]
    },
    "7694a226-d92a-4045-8b98-75f731875a6d": {
        "id": "7694a226-d92a-4045-8b98-75f731875a6d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/choice-of-boundary-condition-for-latticeboltzmann-simulation-of-moderatereynoldsnumber-flow-in-complex-domains(7694a226-d92a-4045-8b98-75f731875a6d).html",
        "abstract": "Modeling blood flow in larger vessels using lattice-Boltzmann methods comes with a challenging set of constraints: a complex geometry with walls and inlets and outlets at arbitrary orientations with respect to the lattice, intermediate Reynolds (Re) number, and unsteady flow. Simple bounce-back is one of the most commonly used, simplest, and most computationally efficient boundary conditions, but many others have been proposed. We implement three other methods applicable to complex geometries [Guo, Zheng, and Shi, Phys. Fluids 14, 2007 (2002); Bouzidi, Firdaouss, and Lallemand, Phys. Fluids 13, 3452 (2001); Junk and Yang, Phys. Rev. E 72, 066701 (2005)] in our open-source application hemelb. We use these to simulate Poiseuille and Womersley flows in a cylindrical pipe with an arbitrary orientation at physiologically relevant Re number (1\u2013300) and Womersley (4\u201312) numbers and steady flow in a curved pipe at relevant Dean number (100\u2013200) and compare the accuracy to analytical solutions. We find that both the Bouzidi-Firdaouss-Lallemand (BFL) and Guo-Zheng-Shi (GZS) methods give second-order convergence in space while simple bounce-back degrades to first order. The BFL method appears to perform better than GZS in unsteady flows and is significantly less computationally expensive. The Junk-Yang method shows poor stability at larger Re number and so cannot be recommended here. The choice of collision operator (lattice Bhatnagar-Gross-Krook vs multiple relaxation time) and velocity set (D3Q15 vs D3Q19 vs D3Q27) does not significantly affect the accuracy in the problems studied.",
        "title": "Choice of boundary condition for lattice-Boltzmann simulation of moderate-Reynolds-number flow in complex domains",
        "keywords": "",
        "authors": [
            {
                "name": "Rupert Nash",
                "uuid": "f171552c-1aec-414e-a571-901bba2f6cb2"
            }
        ]
    },
    "7bb4ae02-f55e-45bf-9bfe-0ad321402665": {
        "id": "7bb4ae02-f55e-45bf-9bfe-0ad321402665",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/impact-of-blood-rheology-on-wall-shear-stress-in-a-model-of-the-middle-cerebral-artery(7bb4ae02-f55e-45bf-9bfe-0ad321402665).html",
        "abstract": "<p>Perturbations to the homeostatic distribution of mechanical forces exerted by blood on the endothelial layer have been correlated with vascular pathologies, including intracranial aneurysms and atherosclerosis. Recent computational work suggests that, in order to correctly characterize such forces, the shear-thinning properties of blood must be taken into account. To the best of our knowledge, these findings have never been comparedagainst experimentally observed pathological thresholds. In thiswork, we apply the three-band diagram (TBD) analysis due to Gizzi et al. (Gizzi et al. 2011 Three-band decomposition analysis of wall shear stress in pulsatile flows. Phys. Rev. E 83, 031902. (doi: 10.1103/PhysRevE.83.031902)) to assess the impact of the choice of blood rheology model on acomputational model of the right middle cerebral artery. Our results showthat, in themodel under study, the differences between thewall shear stress predicted by a Newtonian model and thewell-known Carreau-Yasuda generalized Newtonian model are only significant if the vascular pathology under study is associated with a pathological threshold in the range 0.94-1.56 Pa, where the results of the TBD analysis of the rheology models considered differs. Otherwise, we observe no significant differences.</p>",
        "title": "Impact of blood rheology on wall shear stress in a model of the middle cerebral artery",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rupert Nash",
                "uuid": "f171552c-1aec-414e-a571-901bba2f6cb2"
            }
        ]
    },
    "6482870f-2c06-4f9b-8f4a-f049070a00db": {
        "id": "6482870f-2c06-4f9b-8f4a-f049070a00db",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/proceedings-of-the-7th-international-conference-on-pgas-programming-models(6482870f-2c06-4f9b-8f4a-f049070a00db).html",
        "abstract": "The 7th edition of the International Conference on Partitioned Global Address Space languages took place in Edinburgh on the 3rd and 4th October 2013. The conference brought together over 60 attendees from across the globe: leading researchers and scientists from North America, Europe and Japan addressed a wide range of topics relevant to PGAS languages and exascale computing.<br/><br/>These proceedings collate the papers that were accepted for publication. The first section of the proceedings is dedicated to the research papers, which represent substantial bodies of work and progress beyond the state-of-the art. The subsequent section contains the \"hot\" category: these are shorter papers that introduce work in progress. The proceedings conclude with the poster submissions.",
        "title": "Proceedings of the 7th International Conference on PGAS Programming Models",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "4381df14-5878-4d8d-86b8-c3046b99fa80": {
        "id": "4381df14-5878-4d8d-86b8-c3046b99fa80",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/guidelines-for-the-use-and-interpretation-of-assays-for-monitoring-autophagy-3rd-edition(4381df14-5878-4d8d-86b8-c3046b99fa80).html",
        "abstract": "",
        "title": "Guidelines for the use and interpretation of assays for monitoring autophagy (3rd edition)",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Xu Guo",
                "uuid": "0150939e-12bd-44ca-881b-36e8463aee37"
            }
        ]
    },
    "32a1a505-b74f-4560-8cca-21eded1928e3": {
        "id": "32a1a505-b74f-4560-8cca-21eded1928e3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hybrid-large-eddy-simulation-for-loworder-discontinuous-galerkin-methods-using-an-explicit-filter(32a1a505-b74f-4560-8cca-21eded1928e3).html",
        "abstract": "In this paper we present a simple, easily implemented and effective approach for explicitly-filtered Large Eddy Simulation with a Discontinuous Galerkin (DG) discretision for velocity. DG formulations are often desirable due to their stability and increased accuracy, however this can come at greater computational expense due to the additional degrees of freedom in the velocity field. Additionally, data output can also be an issue, due to the increased storage<br/>requirements. Here we present a hybrid approach, based upon the construction of an approximation of the velocity shear tensor using information from a projected Continuous Galerkin (CG) version of the discontinuous velocity field.<br/>The resulting turbulence algorithm is implemented within Fluidity, an open-source computational fluid dynamics solver. The model is then validated with a well known test case, and shown to agree favourably with published results. Comparisons are also made between the CG/DG hybrid LES with DG-only LES, which demonstrate the superior computational performance of the hybrid model.",
        "title": "Hybrid Large Eddy Simulation for Low-order Discontinuous Galerkin Methods Using an Explicit Filter",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "66f44d1e-5f9c-417d-8ba8-b719c87896e0": {
        "id": "66f44d1e-5f9c-417d-8ba8-b719c87896e0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-architecture-for-high-performance-computing-and-data-systems-using-byteaddressable-persistent-memory(66f44d1e-5f9c-417d-8ba8-b719c87896e0).html",
        "abstract": "Non-volatile and byte-addressable memory technology with\nperformance close to main memory has the potential to revolutionise\ncomputing systems in the near future. Such memory technology provides\nthe potential for extremely large memory regions (i.e. &gt; 3TB per server),\nvery high performance I/O, and new ways of storing and sharing data for\napplications and workflows. This paper proposes hardware and system\nsoftware architectures that have been designed to exploit such memory\nfor High Performance Computing and High Performance Data Analytics\nsystems, along with descriptions of how applications could benet from\nsuch hardware, and initial performance results on a system with Intel\nOptane DC Persistent Memory.",
        "title": "An Architecture for High Performance Computing and Data Systems using Byte-Addressable Persistent Memory",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "a3684683-9ee6-40e2-b547-a773e2bfff61": {
        "id": "a3684683-9ee6-40e2-b547-a773e2bfff61",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/norns-extending-slurm-to-support-datadriven-workflows-through-asynchronous-data-staging(a3684683-9ee6-40e2-b547-a773e2bfff61).html",
        "abstract": "As HPC systems move into the Exascale era, parallel file systems are struggling to keep up with the I/O requirements from data-intensive problems. While the inclusion of burst buffers has helped to alleviate this by improving I/O performance, it has also increased the complexity of the I/O hierarchy by adding additional storage layers each with its own semantics. This forces users to explicitly manage data movement between the different storage layers, which, coupled with the lack of interfaces to communicate data dependencies between jobs in a data-driven workflow, prevents resource schedulers from optimizing these<br/>transfers to benefit the cluster\u2019s overall performance. This paper proposes several extensions to job schedulers, prototyped using the Slurm scheduling system, to enable users to appropriately express the data dependencies between the different phases in their processing workflows. It also introduces a new service for asynchronous data staging called NORNS that coordinates with the job scheduler to orchestrate data transfers to achieve better resource utilization. Our evaluation shows that a workflow-aware Slurm exploits node-local storage more effectively, reducing the filesystem I/O contention and improving job running times",
        "title": "NORNS: Extending Slurm to Support Data-Driven Workflows through Asynchronous Data Staging",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "c20330d8-675d-45a4-828f-59eeac064ab6": {
        "id": "c20330d8-675d-45a4-828f-59eeac064ab6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/developing-fluidity-for-highfidelity-coastal-modelling(c20330d8-675d-45a4-828f-59eeac064ab6).html",
        "abstract": "This paper outlines work undertaken to improve the performance of Fluidity for both general computational fluid dynamics and tidal modelling problems. Optimising the general computational structure of Fluidity, along with work to improve the data decomposition and parallel load balance enabled simulations to be run over 3x faster than with the original code, even at scale. This changes the level of detail that fluids problems can be studied with Fluidity, and impacts upon research that examines high Reynolds number, turbulent flows \u2013 particularly in areas such as engineering aerodynamics, wind energy, marine energy, and environmental/pollution modelling.",
        "title": "Developing Fluidity for high-fidelity coastal modelling",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "00807d1c-b95f-449a-8aaf-7e95d8fb6e45": {
        "id": "00807d1c-b95f-449a-8aaf-7e95d8fb6e45",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-early-evaluation-of-intels-optane-dc-persistent-memory-module-and-its-impact-on-highperformance-scientific-applications(00807d1c-b95f-449a-8aaf-7e95d8fb6e45).html",
        "abstract": "Memory and I/O performance bottlenecks in supercomputing sim- ulations are two key challenges that need to be addressed on the road to Exascale. The recently released byte-addressable persistent non-volatile memory technology from Intel, DCPMM, promises to be an exciting opportunity to break with the status quo, with unprecedented levels of capacity at near-DRAM speeds. In this paper, we explore the potential of DCPMM in the context of high- performance scientific computing using two distinct applications in terms of outright performance, efficiency and usability for both its Memory and App Direct modes. In Memory mode, we show that it is possible to achieve equivalent performance and better efficiency for a CASTEP simulation that struggles with memory capacity limitations on conventional DRAM-only systems without needing to introduce any changes to the application. For IFS, we demonstrate that using a distributed object-store over the NVRAM devices reduces the data contention created in weather forecasting data producer-consumer workflows. In addition to presenting the impact on two applications, we also present results for achievable memory bandwidth performance using STREAM.",
        "title": "An Early Evaluation of Intel\u2019s Optane DC Persistent Memory Module and its Impact on High-Performance Scientific Applications",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            },
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "3c84c01e-3bac-44bf-a4aa-191a31f3f2c9": {
        "id": "3c84c01e-3bac-44bf-a4aa-191a31f3f2c9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/evaluating-the-arm-ecosystem-for-high-performance-computing(3c84c01e-3bac-44bf-a4aa-191a31f3f2c9).html",
        "abstract": "In recent years, Arm-based processors have arrived on the HPC scene, offering an alternative the existing status quo, which was largely dominated by x86 processors. In this paper, we evaluate the Arm ecosystem, both the hardware offering and the software stack that is available to users, by benchmarking a production HPC platform that uses Marvell\u2019s ThunderX2 processors. We investigate the performance of complex scientific applications across multiple nodes, and we also assess the maturity of the software stack and the ease of use from a users\u2019 perspective. This papers finds that the performance across our benchmarking applications is generally as good as, or better, than that of well-established platforms, and we can conclude from our experience that there are no major hurdles that might hinder wider adoption of this ecosystem within the HPC community.",
        "title": "Evaluating the Arm Ecosystem for High Performance Computing",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Andrew Turner",
                "uuid": "7f157976-5a16-428d-a95e-42f5f7c33e17"
            },
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            },
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "476d7b17-f393-4a14-b7b1-57a0c09dcc17": {
        "id": "476d7b17-f393-4a14-b7b1-57a0c09dcc17",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/compressible-navierstokes-analysis-of-floating-wind-turbine-rotor-aerodynamics(476d7b17-f393-4a14-b7b1-57a0c09dcc17).html",
        "abstract": "<p>The unsteady aerodynamics of floating offshore wind turbine rotors is more complex than that of fixed-bottom turbine rotors, due to additional rigid-body motion components enabled by the lack of rigid foundations; it is still unclear if low-fidelity aerodynamic models, such as the blade element momentum theory, provide sufficiently reliable input for floating turbine design requiring load data for a wide range of operating conditions. High-fidelity Navies-Stokes CFD has the potential to improve the understanding of FOWT rotor aerodynamics, and support the improvement of lower-fidelity aerodynamic analysis models. To accomplish these aims, this study uses an in-house compressible Navier-Stokes code and the NREL FAST engineering code to analyze the unsteady flow regime of the NREL 5 MW rotor pitching with amplitude of 4<sup>o</sup> and frequency of 0.2 Hz, and compares all results to those obtained with a commercial incompressible code and FAST in a previous independent study. The level of agreement of CFD and engineering analyses in each of these two studies is found to be quantitatively similar, but the peak rotor power of the compressible flow analysis is about 20 % higher than that of the incompressible analysis. This is possibly due to compressibility effects, as the instantaneous local Mach number is found to be higher than 0.4. Validation of the compressible flow analysis set-up, using an absolute frame formulation and low-speed preconditioning, is based on the analysis of the steady and yawed flow past the NREL Phase VI rotor.</p>",
        "title": "Compressible Navier-Stokes analysis of floating wind turbine rotor aerodynamics",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "482428fc-d630-4107-8ac7-d7658cf8cefa": {
        "id": "482428fc-d630-4107-8ac7-d7658cf8cefa",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/networked-carbon-markets-permissionless-innovation-with-distributed-ledgers(482428fc-d630-4107-8ac7-d7658cf8cefa).html",
        "abstract": "The purpose of this chapter is to outline the most important questions identified in relation to the connecting of carbon markets through the application of distributed ledger (DL) technologies, and share the authors\u2019 current thoughts on those questions.",
        "title": "Networked Carbon Markets: Permissionless Innovation with Distributed Ledgers?",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "72876950-2709-4deb-b308-fdca101b8705": {
        "id": "72876950-2709-4deb-b308-fdca101b8705",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/symposium-on-experiences-of-porting-and-optimising-code-for-xeon-phi-processors(72876950-2709-4deb-b308-fdca101b8705).html",
        "abstract": "",
        "title": "Symposium on experiences of porting and optimising code for Xeon Phi processors",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "bebd98bc-feef-43dc-a869-699963ca41a8": {
        "id": "bebd98bc-feef-43dc-a869-699963ca41a8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/exploiting-the-performance-benefits-of-storage-class-memory-for-hpc-and-hpda-workflows(bebd98bc-feef-43dc-a869-699963ca41a8).html",
        "abstract": "Byte-addressable storage class memory (SCM) is an upcoming technology that will transform the memory and storage hierarchy of HPC systems by dramatically reducing the latency gap between DRAM and persistent storage. In this paper, we discuss general SCM characteristics, including the different hardware configurations and data access mechanisms SCM is likely to provide. We outline the performance challenges I/O requirements place on traditional scientific workflows and present how data access through SCM can have a beneficial impact on the performance of such workflows, in particular those with large scale data dependencies. We describe the system software components that are required to enabled workflow and data aware resource allocation scheduling in order to optimise both system throughput and time to solution for individual applications; these include a data scheduler and data movers. We also present an illustration of the performance improvement potential of the technology, based on initial workflow performance benchmarks with I/O dependencies.",
        "title": "Exploiting the Performance Benefits of Storage Class Memory for HPC and HPDA Workflows",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            },
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "6a95748b-b64b-42fe-b0fb-7e4ed452305b": {
        "id": "6a95748b-b64b-42fe-b0fb-7e4ed452305b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/load-balance-and-parallel-io-optimising-cosa-for-scale(6a95748b-b64b-42fe-b0fb-7e4ed452305b).html",
        "abstract": "This paper describes steps taken to optimise COSA for large scale parallel simulations.  Optimising the general computational structure of Fluidity, along with work to improve the data decomposition and parallel load balance enabled simulations to be run over 3x faster than with the original code, even at scale.",
        "title": "Load balance and Parallel I/O: Optimising COSA for scale",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "eb036c2f-2f8c-43f4-b61a-bc829d095436": {
        "id": "eb036c2f-2f8c-43f4-b61a-bc829d095436",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/resource-requirement-specification-for-novel-dataaware-and-workflowenabled-hpc-job-schedulers(eb036c2f-2f8c-43f4-b61a-bc829d095436).html",
        "abstract": "Technological advancements in computer architectures and the ever-increasing scope of what may be described as a hybrid HPC architecture have not been followed by relevant changes in the way jobs are described to HPC job schedulers. In this WiP, we aim to introduce an augmented job resource request (JRR) specification to be adapted by existing job scheduler implementations and used to more accurately describe the resource requirements of a job to HPC schedulers. The ultimate aim of this work is to both improve the performance of individual applications by improving the utilization of novel resources as they become available, as well as to enable the more efficient scheduling of jobs and workflows on future HPC systems.",
        "title": "Resource requirement specification for novel data-aware and workflow-enabled HPC job schedulers",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "f83b89b7-371f-44b7-ac6b-975e146e0342": {
        "id": "f83b89b7-371f-44b7-ac6b-975e146e0342",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/load-balance-and-parallel-io-optimising-cosa-for-large-simulations(f83b89b7-371f-44b7-ac6b-975e146e0342).html",
        "abstract": "This paper presents the optimisation of the parallel functionalities of the Navier-Stokes Computational Fluid Dynamics research code COSA, a finite volume structured multi-block code featuring a steady solver, a general purpose time-domain solver, and a frequency-domain harmonic balance solver for the rapid solution of unsteady periodic flows. The optimisation focuses on improving the scalability of the parallel input/output functionalities of the code and developing an effective and user-friendly load balancing approach. Both features are paramount for using COSA efficiently for large-scale production simulations using tens of thousands of computational cores.  The efficiency enhancements resulting from optimising the parallel I/O functionality and addressing load balance issues has provided up to a four times performance improvement for unbalanced simulations, and two times performance improvements for balanced simulations.",
        "title": "Load balance and Parallel I/O: Optimising COSA for large simulations",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "2d67c450-0c2f-4de5-8d95-d24807b5b177": {
        "id": "2d67c450-0c2f-4de5-8d95-d24807b5b177",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/adapting-and-optimising-fluidity-for-highfidelity-coastal-modelling(2d67c450-0c2f-4de5-8d95-d24807b5b177).html",
        "abstract": "Work undertaken to improve the performance of Fluidity, an open-source finite-element computational fluid dynamics solver from Imperial College London, for both general computational fluid dynamics and tidal modelling problems is outlined. Optimising the general computational structure of Fluidity, along with work to improve the data decomposition and parallel load balancing enabled simulations to be run over three times faster than with the original code, even when using thousands of computational cores. This changes the level of detail at which fluids problems can be studied with Fluidity, and impacts upon research that examines high Reynolds number turbulent flows. This is of particular relevance in areas such as engineering aerodynamics, wind energy, marine energy, and environmental or pollution modelling.",
        "title": "Adapting and optimising Fluidity for high-fidelity coastal modelling",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "86bcdc9c-3f9f-4808-b315-fbab552c46a8": {
        "id": "86bcdc9c-3f9f-4808-b315-fbab552c46a8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/looplevel-parallelism(86bcdc9c-3f9f-4808-b315-fbab552c46a8).html",
        "abstract": "",
        "title": "Loop-level Parallelism",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "22ec5e9a-6ba6-4a5a-8d6b-3c1a9961a191": {
        "id": "22ec5e9a-6ba6-4a5a-8d6b-3c1a9961a191",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/networked-carbon-markets(22ec5e9a-6ba6-4a5a-8d6b-3c1a9961a191).html",
        "abstract": "Carbon markets are key components in the climate change mitigation response, enabling a price to be placed on carbon emissions. Connecting these markets has the potential to allow a more integrated, efficient, and globally consistent price on carbon which will promote greater confidence in the market, investment and, ultimately, help foster new technology development through climate finance.<br/><br/>The challenge to connecting carbon markets is that each individual carbon market has its own legal and regulatory framework and its own rules for assigning and accounting for the carbon units traded. This presents significant legal and political hurdles that rule out a single, global, carbon market being established. An alternative, \u2018bottom-up\u2019 solution, to enable carbon trading between a range of markets without forcing legal and regulatory homogeneous standardisation and conformity on those markets, would be a more practical way to connect them.<br/><br/>One candidate technology to facilitate such connection, is the \u2018Distributed Ledger\u2019 (DL), which provides the combination of a distributed database with public/private key encryption and a decentralised infrastructure. This potentially allows for innovative solutions to data sharing, or transaction management application areas, making it a good first-order match to the emerging requirements for an interoperable carbon market infrastructure.<br/><br/>To meet the objectives of the Paris Agreement, a solution needs to be found that facilitates a global-scale distributed infrastructure, which allows a diverse set of markets and participants to utilise and exploit it. The established literature on innovation and technology diffusion gives guidance on this issue, but no ability to predict success.<br/><br/>The purpose of this White Paper, therefore, is to outline the most important questions identified in relation to the connecting of carbon markets through the application of DL technologies, and outline the authors\u2019 current thoughts on those questions.",
        "title": "Networked Carbon Markets",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "0510d891-3919-4526-b538-c5054ba09a25": {
        "id": "0510d891-3919-4526-b538-c5054ba09a25",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/beatbox--hpc-simulation-environment-for-biophysically-and-anatomically-realistic-cardiac-electrophysiology(0510d891-3919-4526-b538-c5054ba09a25).html",
        "abstract": "The BeatBox simulation environment combines flexible script language user interface with the robust computational tools, in order to setup cardiac electrophysiology in-silico experiments without re-coding at low-level, so that cell excitation, tissue/anatomy models, stimulation protocols may be included into a BeatBox script, and simulation run either sequentially or in parallel (MPI) without re-compilation. BeatBox is a free software written in C language to be run on a Unix-based platform. It provides the whole spectrum of multi scale tissue modelling from 0-dimensional individual cell simulation, 1-dimensional fibre, 2-dimensional sheet and 3-dimensional slab of tissue, up to anatomically realistic whole heart simulations, with run time measurements including cardiac re-entry tip/filament tracing, ECG, local/global samples of any variables, etc. BeatBox solvers, cell, and tissue/anatomy models repositories are extended via robust and flexible interfaces, thus providing an open framework for new developments in the field. In this paper we give an overview of the BeatBox current state, together with a description of the main computational methods and MPI parallelisation approaches.",
        "title": "BeatBox - HPC simulation environment for biophysically and anatomically realistic cardiac electrophysiology",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "86e57fa0-4d08-4f14-9921-0e3eeaf3560d": {
        "id": "86e57fa0-4d08-4f14-9921-0e3eeaf3560d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/monitoring-and-evaluating-io-performance-of-hpc-systems(86e57fa0-4d08-4f14-9921-0e3eeaf3560d).html",
        "abstract": "In this extended abstract, we describe our work, as part of the NEXTGenIO project, around system-wide monitoring of workloads and I/O on large HPC systems. Several factors mean that monitoring at this level is a difficult problem: there should be little or no performance limiting overhead associated with monitoring; the system consists of a multitude of components, which each have different monitoring interfaces; and the large number of users, jobs and applications means that the amount of data that is collected from monitoring is not trivial. In this abstract, we describe how we aim to address this challenge in NEXTGenIO.",
        "title": "Monitoring and evaluating I/O performance of HPC systems",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "bf82c022-1cab-44a9-a485-419d66b7dd80": {
        "id": "bf82c022-1cab-44a9-a485-419d66b7dd80",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/experiences-porting-production-codes-to-xeon-phi-processors(bf82c022-1cab-44a9-a485-419d66b7dd80).html",
        "abstract": "This paper outlines our experiences with porting a number of production simulation codes to the Xeon Phi co-processor. Large scale production simulation codes present a challenge for optimisation on any platform, and can be even more problematic for accelerator hardware as the codes contain language operations or functionality that are hard to get good performance from on novel hardware. We present the challenges we have experienced porting two large FORTRAN production codes: GS2 and CP2K. We discuss the strategies, which have proven useful or otherwise, for obtaining good performance on Xeon Phi. We also discuss the reasons why achieving good performance for large-scale codes is problematic.",
        "title": "Experiences Porting Production Codes to Xeon Phi Processors",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            },
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "55cf4435-4393-44b6-9213-9979c1aef4ed": {
        "id": "55cf4435-4393-44b6-9213-9979c1aef4ed",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/lu-factorisation-on-xeon-and-xeon-phi-processors(55cf4435-4393-44b6-9213-9979c1aef4ed).html",
        "abstract": "This paper outlines the parallelisation and vectorisation methods we have used to port a LU decomposition library to the Xeon Phi co-processor. We ported a LU factorisation algorithm, which utilizes the Gaussian elimination method to perform the decomposition, using Intel LEO directives, OpenMP 4.0 directives, Intel's Cilk array notation, and vectorisation directives. We compare the performance achieved with these different methods, investigate the cost of data transfer on the overall time to solution, and analyse the impact of these optimization and parallelisation techniques on code running on the host processors as well. The results show that performance can be improved on the Xeon Phi by optimising the memory operations, and that Cilk array notation can benefit this benchmark on standard processors but do not have the same impact on the Xeon Phi co-processor. We have also demonstrated cases where the Xeon Phi will compute our implementations faster than we can run them on a node of a HPC system, and that our implementations are not as efficient as the LU factorisation implemented in the mkl library.",
        "title": "LU Factorisation on Xeon and Xeon Phi Processors",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "bf25b8bb-89b3-4e46-a4b7-986ac173b43d": {
        "id": "bf25b8bb-89b3-4e46-a4b7-986ac173b43d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/optimising-performance-through-unbalanced-decompositions(bf25b8bb-89b3-4e46-a4b7-986ac173b43d).html",
        "abstract": "When significant communication costs arise in the solution of multidimensional problems on parallel computers, optimal performance cannot always be achieved by perfectly balancing the computational load across cores. Modest sacrifices in the computational load balance may facilitate substantial overall performance improvements by achieving large savings in the costs associated with communications. This general approach is illustrated by application to GS2, an initial value gyrokinetic simulation code developed to study low-frequency turbulence in magnetized plasma. GS2 is parallelised using MPI with the simulation domain decomposed across tasks. The optimal domain decomposition is non-trivial, and is complicated by the fact that several domain decompositions are needed and that these do not all optimise at the chosen task count. Application to GS2, of the novel approach outlined in this paper, has improved performance by up to 17% for a representative simulation. Similar strategies may be beneficial in a broader class of problems.",
        "title": "Optimising Performance Through Unbalanced Decompositions",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            }
        ]
    },
    "094301c6-e1fd-4a2d-849f-6b6308d2625c": {
        "id": "094301c6-e1fd-4a2d-849f-6b6308d2625c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/stepping-up(094301c6-e1fd-4a2d-849f-6b6308d2625c).html",
        "abstract": "Computational simulation is an important research tool for modern scientists. There are a range of different scales of high performance computing (HPC) resources available to scientists, from laptop and desktop machines, to small institutional clusters, to national HPC resources, and the largest parallel computers in the world. This paper outlines the challenges that developers and users face moving from small scale computational resources to larger scale parallel machines. We present an overview of various research efforts to improve performance on large scale systems to enable users and developers to gain an understanding of the performance issues often encountered by simulation codes.",
        "title": "Stepping Up",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "ba8f79a2-1766-4ce8-b8e5-791ed28eaa90": {
        "id": "ba8f79a2-1766-4ce8-b8e5-791ed28eaa90",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mdmp-managed-data-message-passing(ba8f79a2-1766-4ce8-b8e5-791ed28eaa90).html",
        "abstract": "MDMP is a parallel programming approach de- signed to provide users with an easy way to add parallelism to programs, optimise scientific simulation algorithms, and providing optimised communications to MPI-based programs without requiring them to be re-written from scratch. MDMP uses directives to allow users to specify what communications should take place in the code, and then implements those communications in an optimal manner using both the information provided by the user and data collected from instrumenting the code and gathering information on the data to be communicated at runtime. In this paper we outline the basic concepts and functionality of MDMP and discuss the performance that can be achieved using our prototype implementation of MDMP a range of benchmark cases.",
        "title": "MDMP: Managed Data Message Passing",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "2042147f-e544-4175-a4ed-e48d4a823429": {
        "id": "2042147f-e544-4175-a4ed-e48d4a823429",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/optimised-hybrid-parallelisation-of-a-cfd-code-on-many-core-architectures(2042147f-e544-4175-a4ed-e48d4a823429).html",
        "abstract": "Reliable aerodynamic and aeroelastic design of wind turbines, aircraft wings and turbomachinery blades increasingly relies on the use of high-fidelity Navier-Stokes Computational Fluid Dynamics codes to predict the strongly nonlinear periodic flows associated with structural vibrations and periodically vary- ing farfield boundary conditions. On a single computer core, the harmonic balance solution of the Navier-Stokes equations has been shown to significantly reduce the analysis runtime with respect to the conventional time-domain approach. The problem size of realistic simulations, however, requires high- performance computing. The Computational Fluid Dynamics COSA code features a novel harmonic balance Navier-Stokes solver which has been previously parallelised using both a pure MPI implementation and a hybrid MPI/OpenMP implementa- tion. This paper presents the recently completed optimisation of both parallelisations. The achieved performance improvements of both parallelisations highlight the effectiveness of the adopted parallel optimisation strategies. Moreover, a comparative analysis of the optimal performance of these two architectures in terms of runtime and power consumption using some of the current common HPC architectures highlights the reduction of both aspects achievable by using the hybrid parallelisation with emerging many-core architectures.",
        "title": "Optimised Hybrid Parallelisation of a CFD Code on Many Core Architectures",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "20ac4d7b-b1fe-4c92-aee7-3249243f6df2": {
        "id": "20ac4d7b-b1fe-4c92-aee7-3249243f6df2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/turbulent-navierstokes-analysis-of-an-oscillating-wing-in-a-powerextraction-regime-using-the-shear-stress-transport-turbulence-model(20ac4d7b-b1fe-4c92-aee7-3249243f6df2).html",
        "abstract": "",
        "title": "Turbulent navier-stokes analysis of an oscillating wing in a power-extraction regime using the shear stress transport turbulence model",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "b3f6a452-6d22-485c-b0a5-41ab304d6a79": {
        "id": "b3f6a452-6d22-485c-b0a5-41ab304d6a79",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-epcc-openacc-benchmark-suite(b3f6a452-6d22-485c-b0a5-41ab304d6a79).html",
        "abstract": "OpenACC is a relatively new standard, first released in November 2011, which brings directives-based programming to accelerators such as NVidia or AMD GPUs, Intel MICs or other devices which can accelerate computational kernels. The use of accelerators as part of a heterogeneous multi-core system is one likely path towards exa-scale technologies. Programming models for such systems are highly likely to be directives-based as programmers will expect systems tools and compilers to make sensible choices about when and where to offload certain computational kernels dependent on a knowledge of the system.<br/><br/>In this work, we present a benchmark suite for OpenACC to compare systems and compilers. This suite provides three levels of benchmark ranging from low level data movement such as time taken to copy data to and from a device, through basic BLAS-type mathematical kernels such as DGEMM, ATAX and 2DCONV, to demonstration applications such as SEISMO, a 2D seismological simulation code. Each benchmark included is representative of operations commonly found in scientific computing.<br/><br/>To demonstrate the operation of the benchmark suite, we provide results obtained from the most recently released compilers from industry (CAPS, PGI, Cray) and academia (ULL). Our results show how a programmer can make an informed choice about which compiler would give best performance on their system. Alternatively, a programmer could use a single compiler but run the benchmarks on various systems to give an idea which system will best suit their application. This latter point is especially important where a choice of hardware is available, it may not be obvious which device is the best choice for a particular application without testing a range of devices.<br/><br/>We also envisage usage by compiler writers who can use our benchmarks to provide an independent reference source for the code they produce. Given the relative youth of the standard and implementations of that standard, it is important for compiler writers to be able to benchmark their compilers using externally provided codes.",
        "title": "The EPCC OpenACC Benchmark Suite",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            }
        ]
    },
    "978282ce-35ed-403e-bced-66a9545aaee1": {
        "id": "978282ce-35ed-403e-bced-66a9545aaee1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/investigation-in-to-the-optimal-3d-fft-strategy-for-quantum-mechanical-codes(978282ce-35ed-403e-bced-66a9545aaee1).html",
        "abstract": "We will present an analysis of 3D FFT methods scaling from matrices of 1283 to 10243. We will show how the performance is limited by the memory, so larger systems can only be on multiple nodes, necessitating the use of network interconnect and discuss the implications of using small FFTs limited to single nodes and the associated profitability of performing the same calculation multiple times to avoid network communication. This will be of particular importance to GPU implementations of software packages in order to reduce the requirement of moving data on and off GPU accelerators.<br/><br/>We will discuss our investigation into the optimal construction of 3D FFTs by using either a 3D FFT library function call or using multiple 1D FFTs. We will also consider the equivalent GPU directives by using cu-FFT library calls. Critically, the performance of 3D FFTs relies heavily on the performance of the all-to-all communications of a particular architecture.<br/><br/>Finally we will discuss a case study of FFT performance in CASTEP, in its current format and also by using data replication to reduce communication of FFT routines across nodes. Performance can be boosted by distributing small FFT calculations on processes (16 cores on HECToR), then nodes (two processes, with a total of 32 cores) and finally by blades (4 nodes with 128 cores). We discuss the benefits for various simulations in CASTEP of using fewer processes and minimising the use of the interconnect of HECToR.",
        "title": "Investigation in to the optimal 3D FFT strategy for Quantum Mechanical Codes",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Antonia Collis",
                "uuid": "2289f0e7-8c0a-4791-b3c1-2024bd519fc4"
            }
        ]
    },
    "d94e813e-a46e-478c-9208-d6ffe011911c": {
        "id": "d94e813e-a46e-478c-9208-d6ffe011911c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/optimising-performance-through-unbalanced-decompositions(d94e813e-a46e-478c-9208-d6ffe011911c).html",
        "abstract": "GS2 is an initial value gyrokinetic simulation code developed to study low-frequency turbulence in magnetized plasma. It is parallelised using MPI with the simulation domain decomposed across tasks. The optimal domain decomposition is non-trivial, and complicated by the different requirements of the linear and non-linear parts of the calculations. GS2 users currently choose a data layout, and are guided towards processor counts that are efficient for linear calculations. These choices can, however, lead to data decompositions that are relatively inefficient for the non-linear calculations. We have analysed the performance impact of the data decompositions on the non-linear calculation, and the communications required for those calculations. This has helped us to optimise the decomposition algorithm by using slightly imbalanced data layouts for the non-linear calculations whilst maintaining the existing decompositions for the linear calculations. With the imbalanced layouts we completely eliminate communications for parts of the non-linear simulation.",
        "title": "Optimising Performance Through Unbalanced Decompositions",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            }
        ]
    },
    "e285747c-4ed2-47f7-a706-5b1fe7723caf": {
        "id": "e285747c-4ed2-47f7-a706-5b1fe7723caf",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mdmp-managed-data-message-passing(e285747c-4ed2-47f7-a706-5b1fe7723caf).html",
        "abstract": "MDMP is a new parallel programming approach that aims to provide users with an easy way to add parallelism to programs, optimise the message passing costs of traditional scientific simulation algorithms, and enable existing MPI-based parallel programs to be optimised and extended without requiring the whole code to be re-written from scratch. MDMP utilises a directives based approach to enable users to specify what communications should take place in the code, and then implements those communications for the user in an optimal manner using both the information provided by the user and data collected from instrumenting the code and gathering information on the data to be communicated. This work will present the basic concepts and functionality of MDMP and discuss the performance that can be achieved using our prototype implementation of MDMP on some model scientific simulation applications.",
        "title": "MDMP: Managed Data Message Passing",
        "keywords": "Types of Association to Advance Collegiate Schools of Business (AACSB) Subject Areas",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "2391b861-490b-424d-8f0c-ba163f10e8cb": {
        "id": "2391b861-490b-424d-8f0c-ba163f10e8cb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-comparison-of-the-performance-of-xml-and-relational-databases-for-the-gridsafe-project(2391b861-490b-424d-8f0c-ba163f10e8cb).html",
        "abstract": "",
        "title": "A Comparison of the Performance of XML and Relational Databases for the Grid-SAFE project",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Stephen Booth",
                "uuid": "b1fdf0bf-ae1e-4b47-94f6-a488f8d2f14c"
            }
        ]
    },
    "b27e0a4b-0f4a-4ad7-b2ec-db29d096cc47": {
        "id": "b27e0a4b-0f4a-4ad7-b2ec-db29d096cc47",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/gridsafe(b27e0a4b-0f4a-4ad7-b2ec-db29d096cc47).html",
        "abstract": "",
        "title": "Grid-SAFE",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "dd510a39-43c7-4360-ac65-d61d3086ec96": {
        "id": "dd510a39-43c7-4360-ac65-d61d3086ec96",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/benchmarking-of-cloud-infrastructure-for-high-performance-computing(dd510a39-43c7-4360-ac65-d61d3086ec96).html",
        "abstract": "",
        "title": "Benchmarking of Cloud Infrastructure for High Performance Computing",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "c0db4a82-0579-48db-884d-f8f3578195ff": {
        "id": "c0db4a82-0579-48db-884d-f8f3578195ff",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/planned-alltoallv-a-clustered-approach(c0db4a82-0579-48db-884d-f8f3578195ff).html",
        "abstract": "",
        "title": "Planned AlltoAllv a clustered approach",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Stephen Booth",
                "uuid": "b1fdf0bf-ae1e-4b47-94f6-a488f8d2f14c"
            }
        ]
    },
    "b411f880-0eec-4a87-a06a-3ddfec06d881": {
        "id": "b411f880-0eec-4a87-a06a-3ddfec06d881",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/3d-ffts-on-hpcx-ibm-vs-fftw(b411f880-0eec-4a87-a06a-3ddfec06d881).html",
        "abstract": "Fast Fourier Transforms (FFTs) are an essential part of many scientic codes: from Molecular Dynamics to Climate Modelling. It is, therefore, evident that HPCx requires effcient methods forperforming FFTs and related calculations. This study compares the performance of the two main FFT libraries on HPCx: IBM's ESSL/PESSL and FFTW. Both serial and parallel (distributed-memory only) 3D complex-to-complex FFT routines are investigated, and the performance of the two different libraries is investigated.<br/>In general, the ESSL and FFTW serial 3D FFT routines are comparable. For parallel FFTs, the PESSL library is, in general, slightly faster, however, FFTW has better parallel effciency. FFTW measured plans are extremely expensive to compute and only give a modest improvement in performance over estimated plans.<br/>Some further comments are made about the overall performance of HPCx, and its impact of the use of FFT library routines.",
        "title": "3D FFTs on HPCx (IBM vs FFTW)",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Gavin Pringle",
                "uuid": "66f4ae16-ad0a-4ab4-ae37-5f844ed07fae"
            }
        ]
    },
    "204904e8-4920-4348-8ac1-d72d2e7e5018": {
        "id": "204904e8-4920-4348-8ac1-d72d2e7e5018",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/single-sided-communications-on-hpcx(204904e8-4920-4348-8ac1-d72d2e7e5018).html",
        "abstract": "Single sided communications allow for data transfer without the need for matching send and received operations between processes. This can improve the performance of various types of scientific codes. This report compares the performance of LAPI and MPI-2 single sided communication functions on HPCx. Only the basic Put and Get functions are benchmarked. These functions are tested using a simple ping-pong benchmark, timing the communication, and recording the amount of data sent. In general LAPI has a better performance for small messages, and MPI-2 outperforms LAPI for large messages.",
        "title": "Single sided communications on HPCx",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "07651186-03de-4820-a542-51c1e3e9171c": {
        "id": "07651186-03de-4820-a542-51c1e3e9171c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/lapi-on-hps(07651186-03de-4820-a542-51c1e3e9171c).html",
        "abstract": "LAPI is an IBM-specic communication library that performs single-sided operation. This library was well profiled on Phase 1 of the HPCx system. Phase 2 of HPCx is now in service, using newer hardware and software than Phase 1. This report aims to capture the performance characteristics of LAPI, compare it to MPI's performance, and investigate whether we can improve performance by tuning the default runtime environment.",
        "title": "LAPI on HPS",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "13e935d6-da9b-4b52-b8e6-6a7a4f074f71": {
        "id": "13e935d6-da9b-4b52-b8e6-6a7a4f074f71",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/planned-alltoallv-a-cluster-approach(13e935d6-da9b-4b52-b8e6-6a7a4f074f71).html",
        "abstract": "The MPI AlltoAllv operation is generally based on a large number of point-to-point messages being sent by all the processes in the communication. This report aims to discover whether this process can be optimised for a<br/>clustered architecture by collating the data from all the processors within a node into a shared memory segment and then sending all the data for one node using a single message. This planned method has the potential to decrease overheads by greatly reducing the number of messages sent, and therefore diminishing latency, of the AlltoAllv call. We compare the performance of the planned AlltoAllv with that of the standard MPI AlltoAllv on a number of clustered architectures, and find that for a standard benchmark the planned AlltoAllv can perform considerably better than the MPI version, but for a more realistic benchmark the performance benet is not as great.",
        "title": "Planned AlltoAllv: A Cluster Approach",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Stephen Booth",
                "uuid": "b1fdf0bf-ae1e-4b47-94f6-a488f8d2f14c"
            }
        ]
    },
    "9b5d8da5-aa4b-49de-9062-9f934db7c617": {
        "id": "9b5d8da5-aa4b-49de-9062-9f934db7c617",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/communications-on-sp7-and-sp9(9b5d8da5-aa4b-49de-9062-9f934db7c617).html",
        "abstract": "IBM's communications libraries on HPCx, LAPI and MPI, have recently received a software update, Service Pack 7. This report re-evaluates the performance of both communication libraries in light of this update, and also assesses the impact of a future update (Service Pack 9) on the LAPI library. We nd that the Service Pack 7 update signicantly improves the performance of both communication libraries.",
        "title": "Communications on SP7 and SP9",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "a4935d67-9ff9-49c3-bcc3-8419d3709792": {
        "id": "a4935d67-9ff9-49c3-bcc3-8419d3709792",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/terascaling-techniques-on-hpcx(a4935d67-9ff9-49c3-bcc3-8419d3709792).html",
        "abstract": "",
        "title": "Terascaling techniques on HPCx",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Stephen Booth",
                "uuid": "b1fdf0bf-ae1e-4b47-94f6-a488f8d2f14c"
            }
        ]
    },
    "95430290-30c4-47bd-aa08-55bd38c355a4": {
        "id": "95430290-30c4-47bd-aa08-55bd38c355a4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/unified-parallel-c-upc-on-hpcx(95430290-30c4-47bd-aa08-55bd38c355a4).html",
        "abstract": "UPC is an alternative to MPI and OpenMP parallelisation. It is an extension of C that aims to simulate a shared memory environment, hiding the details of parallelisation from the user. This document outlines the basic concepts<br/>of UPC, and explores what functionality is available on HPCx. It then goes on to analyse the performance of UPC against IBM's MPI and LAPI on HPCx. Both IBM's UPC offering, and an open-source (Berkeley) UPC compiler are evaluated.",
        "title": "Unified Parallel C: UPC on HPCx",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "aa523583-b54d-45b7-bd16-dd43959798dd": {
        "id": "aa523583-b54d-45b7-bd16-dd43959798dd",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/euforia-hpc-massive-parallelisation-for-fusion-community(aa523583-b54d-45b7-bd16-dd43959798dd).html",
        "abstract": "One of the central tasks of EUFORIA is to port, parallelise, and optimise fusion simulation codes, developed at individual research institutes in Europe. There are three supercomputer centres involved in the project located at Barcelona, Edinburgh, and Helsinki. For some of the fusion codes simply porting them to one of the supercomputers represents a major advancement in the use of the codes, as they until now have mainly been used by a small user community, or even exclusively by the author of the code. Also, where codes currently can only use one processor (i. e. are serial) providing any parallel functionality can be of major benefit to the code and the code owner(s). Many of the simulation codes for edge and core transport modelling of fusion plasma using high performance computing are estimated to currently require weeks or months of execution time to simulate science at a scale required to model the new fusion reactor ITER, and therefore these codes have to be optimised to run as fast as possible and parallelised in such a way that computer resources are used as effectively as possible. During the first fifteen month of the project, we have successfully ported eleven fusion codes to the supercomputers in Barcelona, Edinburgh and Helsinki. The installation procedure, library requirements and runtime scripts have been documented for each code, and deposited in the EUFORIA software repository and code revision system. Following this a number of these codes have been chosen for code optimisation and improvements in parallelisation and this paper outlines the experience that we have had with some of these codes, the performance improvements achieved, and the techniques used.",
        "title": "EUFORIA HPC: Massive Parallelisation for Fusion Community",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Adam Carter",
                "uuid": "81a2c418-fc7e-45ff-9e65-dbec6893a46c"
            },
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            }
        ]
    },
    "5053ae7f-2bad-41ae-90fe-84c294d18cd1": {
        "id": "5053ae7f-2bad-41ae-90fe-84c294d18cd1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-european-infrastructure-for-fusion-simulations(5053ae7f-2bad-41ae-90fe-84c294d18cd1).html",
        "abstract": "he Integrated Tokamak Modelling Task Force (ITM-TF) is developing an infrastructure where the validation needs, as being formulated in terms of multi-device data access and detailed physics comparisons aiming for inclusion of synthetic diagnostics in the simulation chain, are key components. A device independent approach to data transport and a standardized approach to data management (data structures, naming, and access) is being developed in order to allow cross validation between different fusion devices using a single toolset. The effort is focused on ITER plasmas and ITER scenario development on current fusion device. The modeling tools are, however, aimed for general use and can be promoted in other areas of modelling as well. Extensive work has already gone into the development of standardized descriptions of the data (Consistent Physical Objects) providing initial steps towards a complete fusion modelling ontology. The longer term aim is a complete simulation platform which is expected to last and be extended in different ways for the coming 30 years. The technical underpinning is therefore of vital importance. In particular, the platform needs to be extensible and open-ended to be able to take full advantage of not only today's most advanced technologies but also be able to marshal future developments. A full level comprehensive prediction of ITER physics rapidly becomes expensive in terms of computing resources and may cover a range of computing paradigms. The simulation framework therefore needs to be able to use both grid and HPC computing facilities. Hence, data access and code coupling technologies are required to be available for a heterogeneous, possibly distributed, environment. The developments in this area are pursued in a separate project - EUFORIA (EU Fusion for ITER Applications). The current status of ITM-TF and EUFORIA is presented and discussed.",
        "title": "A European Infrastructure for Fusion Simulations",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "efb3269c-80d2-4916-9004-9c354e7bb21f": {
        "id": "efb3269c-80d2-4916-9004-9c354e7bb21f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/high-performance-computing-tools-for-the-integrated-tokamak-modelling-project(efb3269c-80d2-4916-9004-9c354e7bb21f).html",
        "abstract": "Fusion Modelling and Simulation are very challenging and the High Performance Computing issues are addressed here. Toolset for jobs launching and scheduling, data communication and visualization have been developed by the EUFORIA project and used with a plasma edge simulation code.",
        "title": "High Performance Computing tools for the Integrated Tokamak Modelling project",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "51cfc7c6-acd6-4824-9e2a-c5c02773440e": {
        "id": "51cfc7c6-acd6-4824-9e2a-c5c02773440e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sharedmemory-distributedmemory-and-mixedmode-parallelisation-of-a-cfd-simulation-code(51cfc7c6-acd6-4824-9e2a-c5c02773440e).html",
        "abstract": "This paper presents some different approaches to the parallelisation of a harmonic balance Navier-Stokes solver for unsteady aerodynamics. Such simulation codes can require very large amounts of computational resource for realistic simulations, and therefore can benefit significantly from parallelisation. The simulation code addressed in this paper can undertake different modes of aerodynamic simulation and includes both harmonic balance and time domain solvers. These different modes have performance characteristics which can affect any potential parallelisation, as can the specifics of the problem being simulated. Therefore, three different techniques have been used for the parallelisation, shared-memory, distributed-memory, and a combination of the two\u2014a hybrid or mixed-mode parallelisation. These different techniques attempt to address the different performance requirements associated with the types of simulation the code can be used for and provide the level of computational resources required for significant simulation problems. We discuss the different parallelisations and the performance they exhibit on a range of computational resources.",
        "title": "Shared-memory, distributed-memory, and mixed-mode parallelisation of a CFD simulation code",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "6ebdb00b-0b6d-486b-b230-e24d6bf0dca6": {
        "id": "6ebdb00b-0b6d-486b-b230-e24d6bf0dca6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/on-the-parallelization-of-a-harmonic-balance-compressible-navierstokes-solver-for-wind-turbine-aerodynamics(6ebdb00b-0b6d-486b-b230-e24d6bf0dca6).html",
        "abstract": "The paper discusses the parallelization of a novel explicit harmonic balance Navier-Stokes solver for wind turbine unsteady aerodynamics. For large three-dimensional problems, the use of a standard MPI parallelization based on the geomet ric domain decomposition of the physical domain may require an excessive degree of partitioning with respect to that needed when the same aerodynamic analysis is performed with the time-domain solver. This occurrence may penalize the parallel efficiency of the harmonic balance solver due to excessive communication among MPI processes to transfer halo data. In the caseof the harmonic balance analysis, the necessity of further grid<br/>partitioning may arise because the memory requirement of each block is higher than for the time-domain analysis: it is that of the time-domain analysis multiplied by a variable proportional to the number of complex harmonics used to represent the sought periodic flow field. A hybrid multi-level parallelization paradigm for explicit harmonic balance Navier-Stokes solvers is presented, which makes use of both distributed and shared memory parallelization technologies, and removes the need for further domain decomposition with respect to the case of the time-domain an<br/>alysis. The discussed parallelization approaches are tested on the multigrid harmonic balance solver being developed by the authors, considering various computational configurations for the CFD analysis of the unsteady flow field past the airfoil of a wind tubine blade in yawed wind",
        "title": "On the Parallelization of a Harmonic Balance Compressible Navier-Stokes Solver for Wind Turbine Aerodynamics",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "077eadf4-bc27-45e6-abdd-1b48b26d7e7d": {
        "id": "077eadf4-bc27-45e6-abdd-1b48b26d7e7d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/easy-use-of-high-performance-computers-for-fusion-simulations(077eadf4-bc27-45e6-abdd-1b48b26d7e7d).html",
        "abstract": "Fusion Modelling and Simulation are very challenging and the high performance computing issues are addressed here. Based on the framework developed by the European Integrated Tokamak Modelling project and on the EUFORIA infrastructure, a tool solving nicely these difficulties has been developed for the end users and applied to several fusion simulation cases. The first part recalls the issues with GRID and high performance computing, while the second part presents the solutions and the tool for developing easily a GRID/HPC actor. The last part reports the use of this tool in MHD equilibrium and plasma edge simulations.",
        "title": "Easy use of high performance computers for fusion simulations",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            }
        ]
    },
    "4c3af42b-0881-46dd-94f0-2fde20354c6f": {
        "id": "4c3af42b-0881-46dd-94f0-2fde20354c6f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/high-performance-io(4c3af42b-0881-46dd-94f0-2fde20354c6f).html",
        "abstract": "Parallelisation, serial optimisation, compiler tuning, and many more techniques are used to optimise and improve the performance scaling of parallel programs. One area which is frequently not optimised is file I/O. This is because it is often not considered to be key to the performance of a program and also because it is traditionally difficult to optimise and very machine specific. However, in the current era of Peta- and Exascale computing it is no longer possible to ignore I/O performance as it can significantly limit the scaling of many codes when executing on very large numbers of processors or cores. Furthermore, as producing data is the main purpose of most simulation codes any work that can be undertaken to provide improved performance of I/0 can be applicable to a very large range of simulation codes, and provide them with improved functionality (i.e. the ability to produce more data).This paper describes some of the issues surrounding I/O, the technology that is commonly deployed to provide I/O on HPC machines and the software libraries available to programmers to undertake I/O. The performance of all these aspects of I/O on a range of HPC systems were investigated by the authors and a represented in this paper to motivate the discussions in the paper.",
        "title": "High Performance I/O",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            },
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            }
        ]
    },
    "70faf45c-8658-4c99-9c56-4558223da112": {
        "id": "70faf45c-8658-4c99-9c56-4558223da112",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/parallel-optimisation-strategies-for-fusion-codes(70faf45c-8658-4c99-9c56-4558223da112).html",
        "abstract": "We have previously documented the on-going work in the EUFORIA project to parallelise and optimise European fusion simulation codes. This involves working with a wide range of codes to try and address any performance and scaling issues that these codes have. However, as no two simulation codes are exactly the same, it is very hard to apply exactly the same approach to optimising a disparate range of codes. Indeed, the codes investigated range in terms of performance and ability from well-optimised, highly parallelised codes, to serial or poorly performing codes. After analysing, optimising, and parallelising a range of codes it is, actually, possible to discern a number of distinct optimisation techniques or approaches/strategies that can be used to improve the performance or scaling of a parallel simulation code. This paper outlines the distinct approaches that we have identified, highlighting their benefits and drawbacks, giving an overview of the type of work that is often attempted for fusion simulation code optimisation. performing codes. After analysing, optimising, parallelising, and scaling a range of codes it is, actually, possible to discern a number of distinctoptimisation techniques or approaches/strategies that can be used to improve the performance or scaling of a parallel simulation code. This paper outlines the distinct approaches that we have identified, highlighting their benefits and drawbacks, giving an overview of the type of work that is often attempted for fusion simulation code optimisation.",
        "title": "Parallel Optimisation Strategies for Fusion Codes",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Stephen Booth",
                "uuid": "b1fdf0bf-ae1e-4b47-94f6-a488f8d2f14c"
            },
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            },
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            }
        ]
    },
    "db31ec56-599e-4696-9792-2697a6656aa7": {
        "id": "db31ec56-599e-4696-9792-2697a6656aa7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/evaluating-performance-on-a-shared-cloud(db31ec56-599e-4696-9792-2697a6656aa7).html",
        "abstract": "",
        "title": "Evaluating Performance on a Shared Cloud",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "492e3a0c-e7d0-4a7d-88d0-e05ce763056d": {
        "id": "492e3a0c-e7d0-4a7d-88d0-e05ce763056d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/transparent-access-to-scientific-and-commercial-clouds-from-the-kepler-workflow-engine(492e3a0c-e7d0-4a7d-88d0-e05ce763056d).html",
        "abstract": "This paper describes the architecture for transparently using several different Cloud Resources from with the graphical Kepler Worklfow environment. This architecture was proven to work by implementing and using it in practice within the FP7 project EUFORIA. The clouds supported are the Open Source cloud environment OpenNEbula (ONE) and the commercial Amazon Elastic Compute Cloud (EC2).<br/><br/>Subsequently, these clouds are compared regarding their cost-effectiveness, which covers a performance examination but also the comparison of the commercial against a scientific cloud provider.",
        "title": "Transparent Access to Scientific and Commercial Clouds from the Kepler Workflow Engine",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "7dda6a2d-b32a-475f-b55c-52941749ce45": {
        "id": "7dda6a2d-b32a-475f-b55c-52941749ce45",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cloud-computing-for-scientific-simulation-and-high-performance-computing(7dda6a2d-b32a-475f-b55c-52941749ce45).html",
        "abstract": "This chapter describes experiences using Cloud infrastructures for scientific computing, both for serial and parallel computing. Amazon's High Performance Computing (HPC) Cloud computing resources were compared to traditional HPC resources to quantify performance as well as assessing the complexity and cost of using the Cloud. Furthermore, a shared Cloud infrastructure is compared to standard desktop resources for scientific simulations. Whilst this is only a small scale evaluation these Cloud offerings, it does allow some conclusions to be drawn, particularly that the Cloud can currently not match the parallel performance of dedicated HPC machines for large scale parallel programs but can match the serial performance of standard computing resources for serial and small scale parallel programs. Also, the shared Cloud infrastructure cannot match dedicated computing resources for low level benchmarks, although for an actual scientific code, performance is comparable.",
        "title": "Cloud computing for scientific simulation and high performance computing",
        "keywords": "",
        "authors": [
            {
                "name": "William Jackson",
                "uuid": "93234ad3-2825-4091-978f-b486d5465d21"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "19e251c8-d9b9-463f-a73a-7fa7efbe4988": {
        "id": "19e251c8-d9b9-463f-a73a-7fa7efbe4988",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cityflow-enabling-quality-of-service-in-the-internet(19e251c8-d9b9-463f-a73a-7fa7efbe4988).html",
        "abstract": "<p>In this paper, we propose an OpenFlow enabled Internet infrastructure, using virtual path slicing in an end-to-end path, so that any user connected to an OpenFlow network is dynamically allocated a corresponding right of way. This approach allows an interference-free path, from other traffic, between any two endpoints, on multiple autonomous systems, for a given application flow (e.g., WebHD Video Streaming). Additionally, we propose and implement an end-to-end quality of service framework for the Future Internet and extend the virtual path slice engine to support future Internet technologies such as OpenFlow. The proposed framework is evaluated in distinct multiple autonomous scenarios for a city with a population of 1 million inhabitants, emulating xDSL (Digital Subscriber Line), LTE (Long-Term Evolution) and Fibre networking scenarios. The obtained results confirm the suitability of the proposed architecture between multiple autonomous systems, considering both data and control traffic scalability, as well as resilience and failure recovery. Furthermore, challenges and solutions for experimentation in a large-scale testbed are described.</p>",
        "title": "CityFlow, enabling quality of service in the Internet",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Adam Carter",
                "uuid": "81a2c418-fc7e-45ff-9e65-dbec6893a46c"
            },
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            },
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Charaka Palansuriya",
                "uuid": "fa7ecedb-db73-44ce-9703-b55c93331e57"
            }
        ]
    },
    "f6183ea4-a69a-4ab7-b4c9-065894108e1a": {
        "id": "f6183ea4-a69a-4ab7-b4c9-065894108e1a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/what-is-the-best-or-most-relevant-global-minimum-for-nanoclusters-predicting-comparing-and-recycling-cluster-structures-with-waspn(f6183ea4-a69a-4ab7-b4c9-065894108e1a).html",
        "abstract": "<p>To address the question posed in the title, we have created, and now report details of, an open-access database of cluster structures with a web-assisted interface and toolkit as part of the WASP@N project. The database establishes a map of connectivities within each structure, the information about which is coded and kept as individual labels, called hashkeys, for the nanoclusters. These hashkeys are the basis for structure comparison within the database, and for establishing a map of connectivities between similar structures (topologies). The database is successfully used as a key element in a data-mining study of (MX)<sub>12</sub> clusters of three binary compounds (LiI, SrO and GaAs) of which the database has no prior knowledge. The structures are assessed on the energy landscapes determined by the corresponding bulk interatomic potentials. Global optimisation, using a Lamarckian genetic algorithm, is used to search for low lying minima on the same energy landscape to confirm that the data-mined structures form a representative sample of the landscapes, with only very few structures missing from the close energy neighbourhood of the respective global minima.</p>",
        "title": "What is the best or most relevant global minimum for nanoclusters? Predicting, comparing and recycling cluster structures with WASP@N",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Adam Carter",
                "uuid": "81a2c418-fc7e-45ff-9e65-dbec6893a46c"
            },
            {
                "name": "Malcolm Illingworth",
                "uuid": "6ea1f03e-f39e-48a4-8867-a27c471920fa"
            }
        ]
    },
    "3d85561f-dfcc-4c95-9c76-ad3233e17423": {
        "id": "3d85561f-dfcc-4c95-9c76-ad3233e17423",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/waspn-database-of-published-atomic-structures-of-nanoclusters(3d85561f-dfcc-4c95-9c76-ad3233e17423).html",
        "abstract": "The WASP@N database has an associated web front-end for submitting and searching structures. The database is coupled to an HPC system which can compute and verify properties of the submitted structures and store this information back into the database.",
        "title": "WASP@N Database of published atomic structures of nanoclusters",
        "keywords": "",
        "authors": [
            {
                "name": "Adam Carter",
                "uuid": "81a2c418-fc7e-45ff-9e65-dbec6893a46c"
            }
        ]
    },
    "f314164b-e79c-4306-97c4-ad5465323cd2": {
        "id": "f314164b-e79c-4306-97c4-ad5465323cd2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cityflow(f314164b-e79c-4306-97c4-ad5465323cd2).html",
        "abstract": "<p>CityFlow is an EU FP7 project, aiming to create a set of multi-autonomous-system OpenFlow experiments on the OFELIA infrastructure to emulate a city of one million inhabitants. In this demo, we demonstrate all of the key components of the CityFlow experimentation stack working together.</p>",
        "title": "CityFlow",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Adam Carter",
                "uuid": "81a2c418-fc7e-45ff-9e65-dbec6893a46c"
            },
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            }
        ]
    },
    "821a8c85-47c7-4acc-9762-e9a13781607e": {
        "id": "821a8c85-47c7-4acc-9762-e9a13781607e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/aspectratio-scaling-and-the-stiffness-exponent--for-ising-spin-glasses(821a8c85-47c7-4acc-9762-e9a13781607e).html",
        "abstract": "",
        "title": "Aspect-Ratio Scaling and the Stiffness Exponent \u03b8 for Ising Spin Glasses",
        "keywords": "",
        "authors": [
            {
                "name": "Adam Carter",
                "uuid": "81a2c418-fc7e-45ff-9e65-dbec6893a46c"
            }
        ]
    },
    "f7c03f98-fafb-4554-aeaa-057e57d6719a": {
        "id": "f7c03f98-fafb-4554-aeaa-057e57d6719a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/preparing-scientific-application-software-for-exascale-computing(f7c03f98-fafb-4554-aeaa-057e57d6719a).html",
        "abstract": "",
        "title": "Preparing Scientific Application Software for Exascale Computing",
        "keywords": "",
        "authors": [
            {
                "name": "Adam Carter",
                "uuid": "81a2c418-fc7e-45ff-9e65-dbec6893a46c"
            }
        ]
    },
    "c3f9781b-f835-4b83-ae6b-dd47e8a8ef7c": {
        "id": "c3f9781b-f835-4b83-ae6b-dd47e8a8ef7c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/prace-deci-distributed-european-computing-initiative-minisymposium(c3f9781b-f835-4b83-ae6b-dd47e8a8ef7c).html",
        "abstract": "",
        "title": "PRACE DECI (Distributed European Computing Initiative) Minisymposium",
        "keywords": "",
        "authors": [
            {
                "name": "Adam Carter",
                "uuid": "81a2c418-fc7e-45ff-9e65-dbec6893a46c"
            },
            {
                "name": "Christopher Johnson",
                "uuid": "a8de15a3-eda9-4534-8b2d-a922f57bd7f9"
            },
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "226a8090-ec64-4190-9cce-b46e1a3cfc00": {
        "id": "226a8090-ec64-4190-9cce-b46e1a3cfc00",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mastering-parallel-programming-with-r(226a8090-ec64-4190-9cce-b46e1a3cfc00).html",
        "abstract": "About This Book<br/>Create R programs that exploit the computational capability of your cloud platforms and computers to the fullest<br/>Become an expert in writing the most efficient and highest performance parallel algorithms in R<br/>Get to grips with the concept of parallelism to accelerate your existing R programs<br/>Who This Book Is For<br/>This book is for R programmers who want to step beyond its inherent single-threaded and restricted memory limitations and learn how to implement highly accelerated and scalable algorithms that are a necessity for the performant processing of Big Data. No previous knowledge of parallelism is required. This book also provides for the more advanced technical programmer seeking to go beyond high level parallel frameworks.<br/><br/>What You Will Learn<br/>Create and structure efficient load-balanced parallel computation in R, using R's built-in parallel package<br/>Deploy and utilize cloud-based parallel infrastructure from R, including launching a distributed computation on Hadoop running on Amazon Web Services (AWS)<br/>Get accustomed to parallel efficiency, and apply simple techniques to benchmark, measure speed and target improvement in your own code<br/>Develop complex parallel processing algorithms with the standard Message Passing Interface (MPI) using RMPI, pbdMPI, and SPRINT packages<br/>Build and extend a parallel R package (SPRINT) with your own MPI-based routines<br/>Implement accelerated numerical functions in R utilizing the vector processing capability of your Graphics Processing Unit (GPU) with OpenCL<br/>Understand parallel programming pitfalls, such as deadlock and numerical instability, and the approaches to handle and avoid them<br/>Build a task farm master-worker, spatial grid, and hybrid parallel R programs<br/>In Detail<br/>R is one of the most popular programming languages used in data science. Applying R to big data and complex analytic tasks requires the harnessing of scalable compute resources.<br/><br/>Mastering Parallel Programming with R presents a comprehensive and practical treatise on how to build highly scalable and efficient algorithms in R. It will teach you a variety of parallelization techniques, from simple use of R's built-in parallel package versions of lapply(), to high-level AWS cloud-based Hadoop and Apache Spark frameworks. It will also teach you low level scalable parallel programming using RMPI and pbdMPI for message passing, applicable to clusters and supercomputers, and how to exploit thousand-fold simple processor GPUs through ROpenCL. By the end of the book, you will understand the factors that influence parallel efficiency, including assessing code performance and implementing load balancing; pitfalls to avoid, including deadlock and numerical instability issues; how to structure your code and data for the most appropriate type of parallelism for your problem domain; and how to extract the maximum performance from your R code running on a variety of computer systems.<br/><br/>Style and approach<br/>This book leads you chapter by chapter from the easy to more complex forms of parallelism. The author's insights are presented through clear practical examples applied to a range of different problems, with comprehensive reference information for each of the R packages employed. The book can be read from start to finish, or by dipping in chapter by chapter, as each chapter describes a specific parallel approach and technology, so can be read as a standalone.",
        "title": "Mastering Parallel Programming with R",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Eilidh Troup",
                "uuid": "b76bc187-bfcc-43bf-8af0-d9302dfc1ee3"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "225bfd48-ff05-487f-9e38-66f95722109a": {
        "id": "225bfd48-ff05-487f-9e38-66f95722109a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/practical-evaluation-of-seek-and-openbis-for-biological-data-management-in-synthsys-second-report(225bfd48-ff05-487f-9e38-66f95722109a).html",
        "abstract": "The objective of this joint project between University Information Services (IS) and the School of Biological Sciences (SBS) is to evaluate the provision of Biological Data Management systems and their integration with University Research Data Management solutions. The long-term aim is to comply with the University and Funder data mandates, while also adding value to ongoing research in SBS and the wider University. The benefits from streamlining data management would help to balance the School and user investment in establishing and adopting data management systems.",
        "title": "Practical evaluation of SEEK and OpenBIS for biological data management in SynthSys; second report",
        "keywords": "",
        "authors": [
            {
                "name": "Eilidh Troup",
                "uuid": "b76bc187-bfcc-43bf-8af0-d9302dfc1ee3"
            }
        ]
    },
    "26abac82-3e6d-49d0-a135-cc52054d8439": {
        "id": "26abac82-3e6d-49d0-a135-cc52054d8439",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/practical-evaluation-of-seek-and-openbis-for-biological-data-management-in-synthsys-first-report(26abac82-3e6d-49d0-a135-cc52054d8439).html",
        "abstract": "The project evaluated two existing data management systems for a small set of users, who represent diverse needs within the SynthSys Centre, in order to inform wider adoption for biological research.",
        "title": "Practical evaluation of SEEK and OpenBIS for biological data management in SynthSys; first report.",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Eilidh Troup",
                "uuid": "b76bc187-bfcc-43bf-8af0-d9302dfc1ee3"
            }
        ]
    },
    "0ae45529-79ad-4c2a-a00a-3463d3979cd3": {
        "id": "0ae45529-79ad-4c2a-a00a-3463d3979cd3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sprint-v107-software-release(0ae45529-79ad-4c2a-a00a-3463d3979cd3).html",
        "abstract": "New in version 1.0.7:<br/>\u2022 SPRINT now works with Linux (Fedora, Debian) running OpenMPI in addition to running on MPICH on Linux and OpenMPI and MPICH on Mac OS X as in release 1.0.6.<br/>\u2022 A bug that could cause a seg fault error has been fixed in pcor().<br/>\u2022 The psvm() method has been removed until it can be changed to meet CRAN guidelines.",
        "title": "SPRINT v1.0.7 Software Release",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Eilidh Troup",
                "uuid": "b76bc187-bfcc-43bf-8af0-d9302dfc1ee3"
            },
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "bcf6fb25-5123-4f69-8603-24940636e337": {
        "id": "bcf6fb25-5123-4f69-8603-24940636e337",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sprint-v106-software-release(bcf6fb25-5123-4f69-8603-24940636e337).html",
        "abstract": "Latest Software Release: SPRINT 1.0.6 - June 2014<br/>This update:<br/>- compatible with R version 3.0.x<br/>- supports Open MPI in addition to MPICH<br/>SPRINT is currently not available via CRAN, we have no access to a hardware configuration running the Solaris operating system and cannot adapt SPRINT for that platform as is required by CRAN.",
        "title": "SPRINT v1.0.6 Software Release",
        "keywords": "",
        "authors": [
            {
                "name": "Eilidh Troup",
                "uuid": "b76bc187-bfcc-43bf-8af0-d9302dfc1ee3"
            },
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "0961357c-f0fb-4cdc-93a1-ced3583519b7": {
        "id": "0961357c-f0fb-4cdc-93a1-ced3583519b7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/using-sprint-and-parallelised-functions-for-analysis-of-large-data-on-multicore-mac-and-hpc-platforms(0961357c-f0fb-4cdc-93a1-ced3583519b7).html",
        "abstract": "Keywords: HPC, Big Data, Genomics, SPRINT, Parallelisation<br/>We here present computation performance (CPU time, memory requirements) increases we can obtain in<br/>the analysis of large biological (or other) data sets through use of the SPRINT package (www.r-sprint.org).<br/>With the arrival of \u201cbig data\u201d (microarrays, screens, next-generation sequencing) in the life sciences, standard analyses of these data for regular users of R now run into severe issues of computation time or computer memory. Many projects (including parallelisation efforts of the R core) offer R packages and functions that allow programming of solutions for large-scale analysis problems. However, these usually require familiarity with HPC programming as well as sufficient and funded time to employ, which is feasible for one-off analysis problems but impractical for common analysis methods.<br/>To make High Performance Computing (HPC) solutions available to R users without HPC experience, we started development on the SPRINT package in 2008. It allows these users straightforward use of already implemented parallelised versions of many relevant R functions on multi-core Macs as well as large-scale clusters/HPC platforms like the UK\u2019s HECToR or ARCHER (we have also tested on Amazon Elastic Compute Cloud). In addition to addressing speed-critical problems, we also address memory-critical problems.<br/>We will here introduce recent upgrades to SPRINT, discuss for regular R users how to use SPRINT and for users with HPC background how our parallelisation strategies are particularly aimed at problems that go beyond \u2018simple\u2019 task farming. We outline case examples for use of SPRINT as well as performance and limitations of our approach in context of biological high-throughput data (although most individual functions are generically usable for other larger data sets).<br/>Based on our needs and those we established in R user surveys, we currently support parallelised versions [1] of original [2] functions (our function names add prefix \u2018p\u2019, apart from pmaxt, which is based on mt.maxT) that are essential in clustering, classification and non-parametric statistics when applied to very large data sets: pstringdistmatrix, pboot, papply, pcor, ppam, prandomForest, pmaxt, pRP, psvm.<br/>References<br/>[1] Publications of our function implementations can be found on www.r-sprint.org -&gt; Publications<br/>[2] Source citations for these packages can be found on www.r-sprint.org -&gt; Overview and R functions",
        "title": "Using SPRINT and parallelised functions for analysis of large data on multi-core Mac and HPC platforms",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Eilidh Troup",
                "uuid": "b76bc187-bfcc-43bf-8af0-d9302dfc1ee3"
            },
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "8a7bb575-598a-4d19-865b-aef832bd9015": {
        "id": "8a7bb575-598a-4d19-865b-aef832bd9015",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sprint-v105-software-release(8a7bb575-598a-4d19-865b-aef832bd9015).html",
        "abstract": "<br/>This update:<br/>- Adds pstringdistmatrix(), which computes (in this version) the Hamming distance between any strings (e.g. nucleotide bases, Next Gen Sequencing short reads).<br/>- Makes SPRINT compliant with MPI3 (and the latest version of the mpich package)<br/>- Provides simplified installation instructions<br/>- Other bug fixes and updates (see User Guide)<br/>- NOTE: This version is currently not compatible with R version 3 and higher, as we have yet to test this fully.<br/>SPRINT version 1.0.5 is not available from CRAN or R-Forge at this time, as package submission guidelines have changed with the newly released R 3.0.x.",
        "title": "SPRINT v1.0.5 Software Release",
        "keywords": "",
        "authors": [
            {
                "name": "Eilidh Troup",
                "uuid": "b76bc187-bfcc-43bf-8af0-d9302dfc1ee3"
            },
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "74f0ffe4-ccab-45b1-af92-635c14c22c52": {
        "id": "74f0ffe4-ccab-45b1-af92-635c14c22c52",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/strengths-and-limitations-of-period-estimation-methods-for-circadian-data(74f0ffe4-ccab-45b1-af92-635c14c22c52).html",
        "abstract": "<p>A key step in the analysis of circadian data is to make an accurate estimate of the underlying period. There are many different techniques and algorithms for determining period, all with different assumptions and with differing levels of complexity. Choosing which algorithm, which implementation and which measures of accuracy to use can offer many pitfalls, especially for the non-expert. We have developed the BioDare system, an online service allowing data-sharing (including public dissemination), data-processing and analysis. Circadian experiments are the main focus of BioDare hence performing period analysis is a major feature of the system. Six methods have been incorporated into BioDare: Enright and Lomb-Scargle periodograms, FFT-NLLS, mFourfit, MESA and Spectrum Resampling. Here we review those six techniques, explain the principles behind each algorithm and evaluate their performance. In order to quantify the methods' accuracy, we examine the algorithms against artificial mathematical test signals and model-generated mRNA data. Our re-implementation of each method in Java allows meaningful comparisons of the computational complexity and computing time associated with each algorithm. Finally, we provide guidelines on which algorithms are most appropriate for which data types, and recommendations on experimental design to extract optimal data for analysis.</p>",
        "title": "Strengths and limitations of period estimation methods for circadian data",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Eilidh Troup",
                "uuid": "b76bc187-bfcc-43bf-8af0-d9302dfc1ee3"
            }
        ]
    },
    "c0119730-e92d-4600-b674-dadaf1c9b88b": {
        "id": "c0119730-e92d-4600-b674-dadaf1c9b88b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sprint-v105-software-release(c0119730-e92d-4600-b674-dadaf1c9b88b).html",
        "abstract": "SPRINT (Simple Parallel R INTerface) is a parallel framework for R. It provides a High Performance Computing (HPC) harness which allow R scripts to run on HPC clusters. SPRINT contains a library of selected R functions that have been parallelized. Functions are named after the original R function with the added prefix 'p', i.e. the parallel version of cor() in SPRINT is called pcor(). Call to the parallel R functions are included directly in standard R scripts.<br/><br/>This update:<br/>- Adds pstringdistmatrix(), which computes (in this version) the Hamming distance between any strings (e.g. nucleotide bases, Next Gen Sequencing short reads).<br/>- Makes SPRINT compliant with MPI3 (and the latest version of the mpich package)<br/>- Provides simplified installation instructions<br/>- Other bug fixes and updates (see User Guide)",
        "title": "SPRINT v1.0.5 Software Release",
        "keywords": "",
        "authors": [
            {
                "name": "Eilidh Troup",
                "uuid": "b76bc187-bfcc-43bf-8af0-d9302dfc1ee3"
            },
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "160dfe73-a4a2-49ce-93af-9ad3b615300b": {
        "id": "160dfe73-a4a2-49ce-93af-9ad3b615300b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sprint-v104-software-release(160dfe73-a4a2-49ce-93af-9ad3b615300b).html",
        "abstract": "SPRINT (Simple Parallel R INTerface) is a parallel framework for R. It provides a High Performance Computing (HPC) harness which allow R scripts to run on HPC clusters. SPRINT contains a library of selected R functions that have been parallelized. Functions are named after the original R function with the added prefix 'p', i.e. the parallel version of cor() in SPRINT is called pcor(). Call to the parallel R functions are included directly in standard R scripts.<br/><br/>This update includes bug fixes and Apple OSX installation instructions. You can now run SPRINT on your Intel Mac.",
        "title": "SPRINT v1.0.4 Software Release",
        "keywords": "",
        "authors": [
            {
                "name": "Eilidh Troup",
                "uuid": "b76bc187-bfcc-43bf-8af0-d9302dfc1ee3"
            },
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "59e5c784-85d7-4e6a-9da8-09820be3af8d": {
        "id": "59e5c784-85d7-4e6a-9da8-09820be3af8d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-biodare-data-repository(59e5c784-85d7-4e6a-9da8-09820be3af8d).html",
        "abstract": "BioDare, an integrated data analysis and sharing resource for dynamic biological systems, <br/><br/>by Zielinski, Moore, Troup, Beaton, Adams, Halliday, Millar.<br/><br/>2016 overview: BioDare returns immediate value to any user who uploads data, directly justifying the time that they spend in describing and organising their data. This makes BioDare unusual among biological data management systems. It is entirely typical that this immediate value is highly targeted, to users who require specialised analysis of rhythmic data. In addition, it facilitates data sharing and public dissemination, which give value in the much longer term. <br/><br/>2011 summary: BioDare, was developed to store, share and analyse rhythmic time series data. Currently it stores more than 70000 time series with over 9 million time points. The repository supports the description and processing of data from various experimental techniques, as well as literature data. It allows searching and aggregation of data from independent experiments and subsequent visualisation of not only original data but also processed data (averaged, normalized, detrended). BioDare also performs data analysis by executing period analysis routines via web services, including FFT-NLLS, mFourfit and the ROBuST spectrum resampling method. BioDare was designed initially to support the ROBuST project [opening to ROBuST users in 2009], and was extended for SynthSys and TiMet projects. It is highly relevant to other similar research, worldwide. The data infrastructure team is following a staged process to open the data repository and associated web services for analysis of rhythmic data to external users. Six potential beta-testing locations were recruited and visited in Jan-Feb 2011. Requirements specified by these betatesters have been progressively included in the system, in some cases over multiple rounds of interaction. Further beta-test users were recruited in the summer of 2011. We expect to open the system to additional users in the Spring of 2012, and to make the system public within the year.<br/><br/>2016 update. <br/>BioDare was made public as proposed and additional external users were recruited at scientific conferences in 2012-2014, including the UK circadian clock clubs, Gordon conferences on Chronobiology and GARNET data management workshops. <br/><br/>BioDare's data analysis was transformed to support public use. First SynthSys, then in 2015 the UK Centre for Mammalian Synthetic Biology provided upgraded computer servers. Both the original analysis methods and four further rhythm analysis methods were refactored to native Java, greatly enhancing compute speed and stability, in part through a collaborative project with Edinburgh's supercomputing centre EPCC (see Zielinski et al. 2014 for detailed method evaluation and user guidance).<br/><br/>The detailed experimental metadata required from users now supports a very powerful search method, which aggregates data from multiple labs and experiments. <br/>Data visualisation is more flexible, with many secondary data series (normalised, de-trended, averages, error bars, etc) pre-computed for rapid graphical display.<br/>Any data displayed can be downloaded as a numerical spreadsheet, to reproduce exactly the online graphs.<br/><br/>As of February 2015, BioDare held over 41 million data points, in 232,844 timeseries, from 2,344 experiments. The 10 largest user labs were from UK, USA, Chile and Sweden. The largest single user lab by experiments works on circadian clocks in mouse cell and tissue cultures, at MRC LMB, Cambridge UK. The largest user lab by timeseries is from the original ROBuST project, working on plant circadian clocks. (see Flis et al. 2015).<br/><br/>Partial cost recovery started in 2014: heavy users of data analysis functions pay an annual subscription. To encourage data sharing, users who release their BioDare data for public dissemination gain \"analysis credits\", which can fully support their usage costs.",
        "title": "The Biodare Data Repository",
        "keywords": "",
        "authors": [
            {
                "name": "Eilidh Troup",
                "uuid": "b76bc187-bfcc-43bf-8af0-d9302dfc1ee3"
            }
        ]
    },
    "9c841944-6404-4815-81c1-b01d36a71cea": {
        "id": "9c841944-6404-4815-81c1-b01d36a71cea",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/its-all-about-data-movement-optimising-fpga-data-access-to-boost-performance(9c841944-6404-4815-81c1-b01d36a71cea).html",
        "abstract": "The use of reconfigurable computing, and FPGAs in particular, to accelerate computational kernels has the potential to be of great benefit to scientific codes and the HPC community in general. However, whilst recent advanced in FPGA tooling have made the physical act of programming reconfigurable architectures much more accessible, in order to gain good performance the entire algorithm must be rethought and recast in a dataflow style. Reducing the cost of data movement for all computing devices is critically important, and in this paper we explore the most appropriate techniques for FPGAs. We do this by exploring the optimisations of an existing FPGA implementation of an atmospheric model's advection scheme. Taking an FPGA code that was over four times slower than running on the CPU, mainly due to data movement overhead, we describe the profiling and optimisation strategies adopted to significantly reduce the runtime and bring the performance of our FPGA kernels to a much more practical level for real-world use. The result of this work is a set of techniques, steps, and lessons learnt that we have found significantly improve the performance of FPGA based HPC codes and that others can adopt in their own codes to achieve similar improvements.",
        "title": "It's all about data movement: Optimising FPGA data access to boost performance",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "669388db-cb2a-4b8c-8b2d-4b383344d3b8": {
        "id": "669388db-cb2a-4b8c-8b2d-4b383344d3b8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/high-level-programming-abstractions-for-leveraging-hierarchical-memories-with-microcore-architectures(669388db-cb2a-4b8c-8b2d-4b383344d3b8).html",
        "abstract": "Micro-core architectures combine many low memory, low power computing cores together in a single package. These are attractive for use as accelerators but due to limited on-chip memory and multiple levels of memory hierarchy, the way in which programmers offload kernels needs to be carefully considered. In this paper we use Python as a vehicle for exploring the semantics and abstractions of higher level programming languages to support the offloading of computational kernels to these devices. By moving to a pass by reference model, along with leveraging memory kinds, we demonstrate the ability to easily and efficiently take advantage of multiple levels in the memory hierarchy, even ones that are not directly accessible to the micro-cores. Using a machine learning benchmark, we perform experiments on both Epiphany-III and MicroBlaze based micro-cores, demonstrating the ability to compute with data sets of arbitrarily large size. To provide context of our results, we explore the performance and power efficiency of these technologies, demonstrating that whilst these two micro-core technologies are competitive within their own embedded class of hardware, there is still a way to go to reach HPC class GPUs.",
        "title": "High level programming abstractions for leveraging hierarchical memories with micro-core architectures",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "e0e24d1d-26ec-4c45-ae95-b38c567be955": {
        "id": "e0e24d1d-26ec-4c45-ae95-b38c567be955",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ipregel-strategies-to-deal-with-an-extreme-form-of-irregularity-in-vertexcentric-graph-processing(e0e24d1d-26ec-4c45-ae95-b38c567be955).html",
        "abstract": "Over the last decade, the vertex-centric programming model has attracted significant attention in the world of graph processing, resulting in the emergence of a number of vertex-centric frameworks. Its simple programming interface, where computation is expressed from a vertex point of view, offers both ease of programming to the user and inherent parallelism for the underlying framework to leverage. However, vertex-centric programs represent an extreme form of irregularity, both inter and intra core. This is because they exhibit a variety of challenges from a workload that may greatly vary across supersteps, through fine-grain synchronisations, to memory accesses that are unpredictable both in terms of quantity and location. In this paper, we explore three optimisations which address these irregular challenges; a hybrid combiner carefully coupling lock-free and lock-based combinations, the partial externalisation of vertex structures to improve locality and the shift to an edge-centric representation of the workload. We also assess the suitability of more traditional optimisations such as dynamic load-balancing and software prefetching. The optimisations were integrated into the iPregel vertex-centric framework, enabling the evaluation of each optimisation in the context of graph processing across three general purpose benchmarks common in the vertex-centric community, each run on four publicly available graphs covering all orders of magnitude from a million to a billion edges. The result of this work is a set of techniques which we believe not only provide a significant performance improvement in vertex-centric graph processing, but are also applicable more generally to irregular applications.",
        "title": "iPregel: Strategies to Deal with an Extreme Form of Irregularity in Vertex-Centric Graph Processing",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "347bad01-6161-4473-8598-e0202ba62419": {
        "id": "347bad01-6161-4473-8598-e0202ba62419",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/eithne-a-framework-for-benchmarking-microcore-accelerators(347bad01-6161-4473-8598-e0202ba62419).html",
        "abstract": "Running existing HPC benchmarks as-is on micro-core architectures is at best difficult and most often impossible as they have a number of architectural features that makes them significantly different from traditional CPUs : tiny amounts on-chip RAM (c. 32KB), low-level knowledge specific to each device (including the host / device communications interface), limited communications bandwidth and complex or no device debugging environment. In order to compare and contrast different the micro-core architectures, a benchmark framework is required to abstract much of this complexity.<br/><br/>The modular Eithne framework supports the comparison of a number of micro-core architectures. The framework separates the actual benchmark from the details of how this is executed on the different technologies. <br/><br/>The framework was evaluated by running the LINPACK benchmark on the Adapteva Epiphany, PicoRV32 (RISC-V) and Orca soft-cores, NXP RV32M1, ARM Cortex-A9, and Xilinx MicroBlaze soft-core, and comparing resulting performance and power consumption.",
        "title": "Eithne: A framework for benchmarking micro-core accelerators",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "5a68f358-5159-4c2c-9da6-e445f3072fa5": {
        "id": "5a68f358-5159-4c2c-9da6-e445f3072fa5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/modelling-the-earths-geomagnetic-environment-on-cray-machines-using-petsc-and-slepc(5a68f358-5159-4c2c-9da6-e445f3072fa5).html",
        "abstract": "The British Geological Survey's global geomagnetic model, Model of the Earth's Magnetic Environment (MEME), is an important tool for calculating the strength and direction of the Earth's magnetic field, which is continually in flux. Whilst the ability to collect data from ground based observation sites and satellites has grown rapidly, the memory bound nature of the original code has proved a significant limitation in modelling problem sizes required by modern science. In this paper we describe work done replacing the bespoke, sequential, eigen-solver with that of the PETSc/SLEPc package for solving the system of normal equations. Adopting PETSc/SLEPc also required fundamental changes in how we built and distributed the data structures and as such we describe an approach for building symmetric matrices that provides good load balance and avoids the need for close co-ordination between the processes or replication of work. We also study the memory bound nature of the code from an irregular memory accesses perspective and combine detailed profiling with software cache prefetching to significantly optimise this. Performance and scaling characteristics are explored on ARCHER, a Cray XC30, where we achieved a speed up for the solver of 294 times by replacing the model's bespoke approach with SLEPc.",
        "title": "Modelling the earth\u2019s geomagnetic environment on Cray machines using PETSc and SLEPc",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "59d39d63-5bde-4135-987e-41ba19f91e84": {
        "id": "59d39d63-5bde-4135-987e-41ba19f91e84",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/extended-abstract-type-oriented-programming-for-task-based-parallelism(59d39d63-5bde-4135-987e-41ba19f91e84).html",
        "abstract": "",
        "title": "Extended Abstract: Type oriented programming for task based parallelism",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "5951d1bd-4ab9-40d2-8d63-45cd942c25b9": {
        "id": "5951d1bd-4ab9-40d2-8d63-45cd942c25b9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/exploring-the-acceleration-of-the-met-office-nerc-cloud-model-using-fpgas(5951d1bd-4ab9-40d2-8d63-45cd942c25b9).html",
        "abstract": "The use of Field Programmable Gate Arrays (FPGAs) to accelerate computational kernels has the potential to be great benefit to scientific codes and the HPC community in general. With the recent developments in FPGA programming technology, the ability to port kernels is becoming far more accessible. However, to gain reasonable performance from this technology it is not enough to simple transfer a code onto the FPGA, instead the algorithm must be rethought and recast in a data-flow style to suit the target architecture. In this paper we describe the porting, via HLS, of one of the most computationally intensive kernels of the Met Office NERC Cloud model (MONC), an atmospheric model used by climate and weather researchers, onto an FPGA. We describe in detail the steps taken to adapt the algorithm to make it suitable for the architecture and the impact this has on kernel performance. Using a PCIe mounted FPGA with on-board DRAM, we consider the integration on this kernel within a larger infrastructure and explore the performance characteristics of our approach in contrast to Intel CPUs that are popular in modern HPC machines, over problem sizes involving very large grids. The result of this work is an experience report detailing the challenges faced and lessons learnt in porting this complex computational kernel to FPGAs, as well as exploring the role that FPGAs can play and their fundamental limits in accelerating traditional HPC workloads.",
        "title": "Exploring the acceleration of the Met Office NERC Cloud model using FPGAs",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "d1281e20-33a6-423a-bea9-2f5760641268": {
        "id": "d1281e20-33a6-423a-bea9-2f5760641268",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/modelling-the-earths-geomagnetic-environment-on-cray-machines-using-petsc-and-slepc(d1281e20-33a6-423a-bea9-2f5760641268).html",
        "abstract": "The British Geological Survey's global geomagnetic model, Model of the Earth's Magnetic Environment (MEME), is an important tool for calculating the earth's magnetic field, which is continually in flux. Whilst the ability to collect data from ground based observation sites and satellites has grown rapidly, the memory bound nature of the code has proved a significant limitation in modelling problem sizes required by modern science. In this paper we describe work done replacing the bespoke, sequential, eigen-solver with that of the SLEPc package for solving the system of normal equations. This work had a dual purpose, to break through the memory limit of the code, and thus support the modelling of much larger systems, by supporting execution on distributed machines, and to improve performance. But when adopting SLEPc it was not just the solving of the normal equations, but also fundamentally how we build and distribute the data structures. We describe an approach for building symmetric matrices in a way that provides good load balance and avoids the need for close co-ordination between the processes or replication of work. We also study the memory bound nature of the code from an irregular memory accesses perspective and combine detailed profiling with software cache prefetching to significantly optimise this. Performance and scaling characteristics are explored on ARCHER, a Cray XC30, both comparing the new model's SLEPc approach against the previous model's bespoke solver, and also considering much larger system sizes up to 100,000 model coefficients. Some of the challenges of modelling systems of this large scale are explored, and mitigations including hybrid MPI+OpenMP along with the use of iterative solvers are also considered. The result of this work is a modern MEME model that is not only capable of simulating problem sizes demanded by state of the art geomagnetism but also acts as further evidence to the utility of the SLEPc libary.",
        "title": "Modelling the earth\u2019s geomagnetic environment on Cray machines using PETSc and SLEPc",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "0dd22e2a-0b9c-400a-b8d8-47254383bd25": {
        "id": "0dd22e2a-0b9c-400a-b8d8-47254383bd25",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/machine-learning-on-crays-to-optimise-petrophysical-workflows-in-oil-and-gas-exploration(0dd22e2a-0b9c-400a-b8d8-47254383bd25).html",
        "abstract": "The oil and gas industry is awash with sub-surface data, which is used to characterize the rock and fluid properties beneath the seabed. This in turn drives commercial decision making and exploration, but the industry currently relies upon highly manual workflows when processing data. A key question is whether this can be improved using machine learning to complement the activities of petrophysicists searching for hydrocarbons. In this paper we present work done, in collaboration with Rock Solid Images (RSI), using supervised machine learning on a Cray XC30 to train models that streamline the manual data interpretation process. With a general aim of decreasing the petrophysical interpretation time down from over 7 days to 7 minutes, in this paper we describe the use of mathematical models that have been trained using raw well log data, for completing each of the four stages of a petrophysical interpretation workflow, along with initial data cleaning. We explore how the predictions from these models compare against the interpretations of human petrophysicists, along with numerous options and techniques that were used to optimise the prediction of our models. The power provided by modern supercomputers such as Cray machines is crucial here, but some popular machine learning framework are unable to take full advantage of modern HPC machines. As such we will also explore the suitability of the machine learning tools we have used, and describe steps we took to work round their limitations. The result of this work is the ability, for the first time, to use machine learning for the entire petrophysical workflow. Whilst there are numerous challenges, limitations and caveats, we demonstrate that machine learning has an important role to play in the processing of sub-surface data.",
        "title": "Machine learning on Crays to optimise petrophysical workflows in oil and gas exploration",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "c0020f21-a61a-4541-86c0-63dd73626930": {
        "id": "c0020f21-a61a-4541-86c0-63dd73626930",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ipregel-vertexcentric-programmability-vs-memory-efficiency-and-performance-why-choose(c0020f21-a61a-4541-86c0-63dd73626930).html",
        "abstract": "The vertex-centric programming model, designed to improve the programmability in graph processing application writing, has attracted great attention over the years. Multiple shared memory frameworks that have implemented the vertex-centric interface all expose a common tradeoff: programmability against memory efficiency and performance.<br/><br/>Our approach consists in preserving vertex-centric programmability, while implementing optimisations missing from Femto-Graph, developing new ones and designing these so they are transparent to a user\u2019s application code, hence not impacting programmability. We therefore implemented our own shared memory vertex-centric framework iPregel, relying on in-memory storage and synchronous execution. In this paper, we evaluate it against FemtoGraph, whose characteristics are identical, but also an asynchronous counterpart GraphChi and the vertex-subset-centric framework Ligra. Our experiments include three of the most popular vertex-centric benchmark applications over 4 real-world publicly accessible graphs, which cover all orders of magnitude between a million to a billion edges. We then measure the execution time and the peak memory usage. Finally, we evaluate the programmability of each framework by comparing it against the original Pregel, Google\u2019s closed-source implementation that started the whole area of vertex-centric programming.<br/><br/>Experiments demonstrate that iPregel, like FemtoGraph, does not sacrifice vertex-centric programmability for additional performance and memory efficiency optimisations, which contrasts with GraphChi and Ligra. Sacrificing vertex-centric programmability allowed the latter to benefit from substantial performance and memory efficiency gains. However, experiments demonstrate that iPregel is up to 2,300 times faster than FemtoGraph, as well as generating a memory footprint up to 100 times smaller. These results greatly change the situation; Ligra and GraphChi are up to 17,000 and 700 times faster than FemtoGraph but, when comparing against iPregel, this maximum speed-up drops to 10. Furthermore, on PageRank, it is iPregel that proves to be the fastest overall. When it comes to memory efficiency, the same observation applies; Ligra and GraphChi are 100 and 50 times lighter than FemtoGraph, but iPregel nullifies these benefits: it provides the same memory efficiency as Ligra and even proves to be 3 to 6 times lighter than GraphChi on average. In other words, iPregel demonstrates that preserving vertex-centric programmability is not incompatible with a competitive performance and memory efficiency.",
        "title": "iPregel: Vertex-Centric Programmability vs Memory Efficiency and Performance, Why Choose?",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "c730f255-8b39-48ee-ba3e-1a1cee56c3aa": {
        "id": "c730f255-8b39-48ee-ba3e-1a1cee56c3aa",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/massively-parallel-parcelbased-simulation-of-moist-convection(c730f255-8b39-48ee-ba3e-1a1cee56c3aa).html",
        "abstract": "We discuss recent progress on an essentially Lagrangian model of moist convection. In this Moist-Parcel-In-Cell (MPIC) model, parcels represent both the thermodynamic and the dynamical properties of the flow. The parcels have a finite volume and carry part of the circulation and thermodynamic attributes (liquid water potential temperature and total water content). The representation of parcel properties is fully Lagrangian, but an efficient grid-based solver calculates parcel advection velocities.<br/><br/>The Lagrangian approach of MPIC has a number of advantages: thermodynamic properties and their corre- lations are naturally conserved, and the amount of mixing between parcels can be explicitly controlled. MPIC also lends itself well to parallelisation, because most of the communication required between processors is local, and an efficient solver is available where global communication is required.<br/>A massively parallel version of MPIC which uses the framework of the Met Office NERC Cloud (MONC) model has recently been developed. This version will make it possible to simulate realistic clouds in a fully Lagrangian framework. Here, we present the adaptations we have made to MPIC, and in particular its dynamical core, to facilitate such simulations, and discuss the steps we are taking to include microphysics. We also show scaling results of the new code for up to 50,000 compute cores.",
        "title": "Massively parallel parcel-based simulation of moist convection",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "9c5edc54-4108-4fe2-8d53-5bdef001be18": {
        "id": "9c5edc54-4108-4fe2-8d53-5bdef001be18",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/driving-asynchronous-distributed-tasks-with-events(9c5edc54-4108-4fe2-8d53-5bdef001be18).html",
        "abstract": "Open-source matters, not just to the current cohort of HPC users but also to potential new HPC communities, such as machine learning, themselves often rooted in open-source. Many of these potential new workloads are, by their very nature, far more asynchronous and unpredictable than traditional HPC codes and open-source solutions must be found to enable new communities of developers to easily take advantage of large scale parallel machines. Task-based models have the potential to help here, but many of these either entirely abstract the user from the distributed nature of their code, placing emphasis on the runtime to make important decisions concerning scheduling and locality, or require the programmer to explicitly combine their task based code with a distributed memory technology such as MPI, which adds considerable complexity. In this paper we describe a new approach where the programmer still splits their code up into distinct tasks, but is explicitly aware of the distributed nature of the machine and drives interactions between tasks via events. This provides the best of both worlds; the programmer is able to direct important aspects of parallelism whilst still being abstracted from the low level mechanism of how this parallelism is achieved. We demonstrate our approach via two use-cases, the Graph500 BFS benchmark and in-situ data analytics of MONC, an atmospheric model. For both applications we demonstrate considerably improved performance at large core counts and the result of this work is an approach and open-source library which is readily applicable to a wide range of codes.",
        "title": "Driving asynchronous distributed tasks with events",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "9a791c0d-0ff3-444e-a916-e6682f923caa": {
        "id": "9a791c0d-0ff3-444e-a916-e6682f923caa",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/leveraging-mpi-rma-to-optimise-haloswapping-communications-in-monc-on-cray-machines(9a791c0d-0ff3-444e-a916-e6682f923caa).html",
        "abstract": "Remote Memory Access (RMA), also known as single\u2010sided communications, provides a way for reading and writing directly into the memory of other processes without having to issue explicit message passing style communication calls. Previous studies have concluded that MPI RMA can provide increased communication performance over traditional MPI Point to Point (P2P), but these are based on synthetic benchmarks rather than real\u2010world codes. In this work, we replace the existing non\u2010blocking P2P communication calls in the Met Office NERC Cloud model, a mature code for modeling the atmosphere, with MPI RMA. We describe our approach in detail and discuss the options taken for correctness and performance. Experiments are performed on ARCHER, a Cray XC30, and Cirrus, an SGI ICE machine. We demonstrate on ARCHER that, by using RMA, we can obtain between a 5% and 10% reduction in communication time at each timestep on up to 32768 cores, which over the entirety of a run (with many timesteps) results in a significant improvement in performance compared to P2P on the Cray. However, RMA is not a silver bullet, and there are challenges when integrating RMA calls into existing codes: important optimizations are necessary to achieve good performance and library support is not universally mature, as is the case on Cirrus. In this paper, we discuss, in the context of a real\u2010world code, the lessons learned converting P2P to RMA, explore performance and scaling challenges, and contrast alternative RMA synchronization approaches in detail.",
        "title": "Leveraging MPI RMA to optimise halo-swapping communications in MONC on Cray machines",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "ef141dc2-5beb-4fc4-b411-294e1f4e4ff5": {
        "id": "ef141dc2-5beb-4fc4-b411-294e1f4e4ff5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/leveraging-mpi-rma-to-optimise-haloswapping-communications-in-monc-on-cray-machines(ef141dc2-5beb-4fc4-b411-294e1f4e4ff5).html",
        "abstract": "Remote Memory Access (RMA), also known as single sided communications, provides a way for reading and writing directly into the memory of other processes without having to issue explicit message passing style communication calls. Previous studies have concluded that MPI RMA can provide increased communication performance over traditional MPI Point to Point (P2P) but these are based on synthetic benchmarks rather than real world codes. In this work, we replace the existing non-blocking P2P communication calls in the Met Office NERC Cloud model, a mature code for modelling the atmosphere, with MPI RMA. We describe our approach in detail and discuss the options taken for correctness and performance. Experiments are performed on ARCHER, a Cray XC30 and Cirrus, an SGI ICE machine. We demonstrate on ARCHER that by using RMA we can obtain between a 10-20\\% reduction in communication time at each timestep on up to 32768 cores, which over the entirety of a run (with many timesteps) results in a significant improvement in performance compared to P2P on the Cray. However, RMA is not a silver bullet and there are challenges when integrating RMA calls into existing codes: important optimisations are necessary to achieve good performance and library support is not universally mature, as is the case on Cirrus. In this paper we discuss, in the context of a real world code, the lessons learned converting P2P to RMA, explore performance and scaling challenges, and contrast alternative RMA synchronisation approaches in detail.",
        "title": "Leveraging MPI RMA to optimise halo-swapping communications in MONC on Cray machines",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "4647364a-0e9d-49fd-b57b-5bec212a57ff": {
        "id": "4647364a-0e9d-49fd-b57b-5bec212a57ff",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/epython-an-implementation-of-python-enabling-accessible-programming-of-microcore-architectures(4647364a-0e9d-49fd-b57b-5bec212a57ff).html",
        "abstract": "",
        "title": "ePython: An Implementation of Python Enabling Accessible Programming of Micro-Core Architectures",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "04e17585-407a-47c4-86d2-0b052e77852f": {
        "id": "04e17585-407a-47c4-86d2-0b052e77852f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/event-driven-asynchronous-tasks-edat(04e17585-407a-47c4-86d2-0b052e77852f).html",
        "abstract": "In task based models, by rethinking parallelism in the paradigm of tasks one reduces synchronisation and decouples the management of parallelism from computation. However existing models typically rely on shared memory, where the programmer expresses input and output dependencies of tasks based upon variables. To then execute these over large scale distributed memory machines requires complex support in the runtime system which the programmer has no control over. We propose an alternative approach where the programmer still works with the concept of tasks but is explicitly aware of the distributed nature of their code and drives interactions through events. Tasks are scheduled and depend upon a number of events arriving, which may originate from tasks running remotely or locally, before they can execute. Events are explicitly \u201cfired\u201d to a target by the programmer with an associated identifier, which is used to match up dependencies, and optionally contain data which tasks can process. This enables the programmer to write large-scale task based codes, still abstracted from the mechanism of parallelism but with a general understanding of how their system is interacting which is useful for optimisation such as locality. Furthermore, as the entire state of the code can be expressed as outstanding events and scheduled tasks, this enables ACID compliance which provides resilience. Our approach works especially well for parallel codes that contain irregular communication patterns, such as in-situ data analytics, and can be applied incrementally to existing MPI based codes to break apart the bulk synchronous nature of the communications.",
        "title": "Event Driven Asynchronous Tasks (EDAT)",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "ca5a318a-773f-4a28-9d36-d7a812701f88": {
        "id": "ca5a318a-773f-4a28-9d36-d7a812701f88",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-directorycache-for-leveraging-the-efficient-use-of-distributed-memory-by-taskbased-runtime-systems(ca5a318a-773f-4a28-9d36-d7a812701f88).html",
        "abstract": "",
        "title": "A directory/cache for leveraging the efficient use of distributed memory by task-based runtime systems",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "c9ffb865-caf0-4a95-9e94-c5bb9b57aae4": {
        "id": "c9ffb865-caf0-4a95-9e94-c5bb9b57aae4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/leveraging-slepc-in-modeling-the-earths-magnetic-environment(c9ffb865-caf0-4a95-9e94-c5bb9b57aae4).html",
        "abstract": "",
        "title": "Leveraging SLEPc in modeling the earth's magnetic environment",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "1930de8b-bed0-48ba-99b8-91711383b42a": {
        "id": "1930de8b-bed0-48ba-99b8-91711383b42a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/leveraging-hierarchical-memories-for-microcore-architectures(1930de8b-bed0-48ba-99b8-91711383b42a).html",
        "abstract": "",
        "title": "Leveraging hierarchical memories for micro-core architectures",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "c1ed6f6a-3d2c-41fa-8e37-16bbfb8da2c3": {
        "id": "c1ed6f6a-3d2c-41fa-8e37-16bbfb8da2c3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-comparison-of-techniques-for-solving-the-poisson-equation-in-cfd(c1ed6f6a-3d2c-41fa-8e37-16bbfb8da2c3).html",
        "abstract": "CFD is a ubiquitous technique central to much of computational simulation such as that required by aircraft design. Solving of the Poisson equation occurs frequently in CFD and there are a number of possible approaches one may leverage. The dynamical core of the MONC atmospheric model is one example of CFD which requires the solving of the Poisson equation to determine pressure terms. Traditionally this aspect of the model has been very time consuming and-so it is important to consider how we might reduce the runtime cost.<br/><br/>In this paper we survey the different approaches implemented in MONC to perform the pressure solve. Designed to take advantage of large scale, modern, HPC machines, we are concerned with the computation and communication behaviour of the available techniques and in this text we focus on direct FFT and indirect iterative methods. In addition to describing the implementation of these techniques we illustrate on up to 32768 processor cores of a Cray XC30 both the performance and scalability of our approaches. Raw runtime is not the only measure so we also make some comments around the stability and accuracy of solution. The result of this work are a number of techniques, optimised for large scale HPC systems, and an understanding of which is most appropriate in different situations.<br/>",
        "title": "A comparison of techniques for solving the Poisson equation in CFD",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "ff9e36d6-b2dc-4793-bacb-fa34d243c4e0": {
        "id": "ff9e36d6-b2dc-4793-bacb-fa34d243c4e0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/monc--highly-scalable-cloud-modelling-on-the-latest-supercomputers(ff9e36d6-b2dc-4793-bacb-fa34d243c4e0).html",
        "abstract": "The Met Office NERC Cloud model (MONC) is a community code that has been developed in collaboration with EPCC and the Met Office for the modelling of clouds and atmospheric flows at large scale. We routinely run MONC on 32,768 cores and the highly modular, pluggable architecture of this model supports great flexibility of use. Data analytics is critically important and, because of the very large raw data sizes, an in-situ approach has been adopted where the raw data is analysed as it is computed. This model also forms the basis of a public engagement activity which will be discussed.",
        "title": "MONC - highly scalable cloud modelling on the latest supercomputers",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "bb89386e-f843-4cad-b912-0256eb319e66": {
        "id": "bb89386e-f843-4cad-b912-0256eb319e66",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/offloading-python-kernels-to-microcore-architectures(bb89386e-f843-4cad-b912-0256eb319e66).html",
        "abstract": "Micro-core architectures combine many low memory, low power computing cores together in a single package. These can be used as a co-processor or standalone but due to limited on-chip memory and esoteric nature of the hardware, writing efficient parallel codes for them is challenging. We previously developed ePython, a low memory (24Kb) implementation of Python supporting the rapid development of parallel Python codes and education for these architectures. In this poster we present our work on an offload abstraction to support the use of micro-cores as an accelerator. Programmers decorate specific functions in their Python code, running under any Python interpreter on the host, with our underlying technology then responsible for the low-level data movement, scheduling and execution of kernels on the micro-cores. Aimed at education and fast prototyping, a machine learning code for detecting lung cancer, where computational kernels are offloaded to micro-cores, is used to illustrate the approach.",
        "title": "Offloading Python kernels to micro-core architectures",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "aeb6c757-9358-4385-83c1-980a6b29fa56": {
        "id": "aeb6c757-9358-4385-83c1-980a6b29fa56",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/directorycache-api-for-sharing-data-in-distributed-memory-systems(aeb6c757-9358-4385-83c1-980a6b29fa56).html",
        "abstract": "The transition to the Exascale predicts the appearance of more complex architectures. Such systems may have a huge number of multi-core nodes, deep memory hierarchies and complex interconnect topologies. Efficiently programming them requires new adequate programming models and currently, the task-based models are perceived as a very promising candidate to start with; they abstract the notion of parallelism from the application developer and offer better perspectives for efficiently exploiting heterogeneous architectures. One of the tasks defined in the INTERTWinE project funded by the European Commission is the definition of a common, generic API for a directory/cache service for task-based runtime systems (like OmpSs, StarPU, etc.). The main purpose of the directory/cache is to provide a set of services that allow task-based runtime systems to efficiently run distributed applications, while being able to consistently manage data stored in distributed memory or in local caches. The directory/cache API allows the task-based runtimes to be completely independent from the physical representation of data and from the type of storage used, facilitating the access through the same interface to an extendable list of memory segment implementations (GASPI, MPI, etc). Moreover, applications may also use the directory/cache API directly. In this poster we try to highlight some of the relevant aspects related to the resulted directory/cache API and the architectural concept.",
        "title": "Directory/Cache API for Sharing Data in Distributed Memory Systems",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "e34ecef6-6126-44bb-9a58-6e507fa719b2": {
        "id": "e34ecef6-6126-44bb-9a58-6e507fa719b2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mpi-rma-as-a-directorycache-interoperability-layer(e34ecef6-6126-44bb-9a58-6e507fa719b2).html",
        "abstract": "It is widely accepted that for codes to take advantage of exa-scale systems, programmers will need to work at different level of parallelism. Inevitably this will involve combining different programming technologies in a code and these interoperating together. An example of this is task based models, which work well in shared memory, but to scale these out to distributed memory machines requires the combination of other technologies such as MPI. We have developed a directory/cache which can be integrated with higher level programming language runtimes and enables transparent (to the end user) interoperability between shared memory and distributed memory technologies such as task based models and MPI. \n\nThe directory/cache presents a single, unified global view of memory to users, abstracting them from the underlying complexity of how memory is physically distributed across nodes and issues such as the uneven decomposition of data. Internally MPI RMA is used as the underlying transport layer, the ubiquity and predictable performance of MPI RMA meant that this was a natural choice. We illustrate how this RMA transport layer has been implemented and several recent features from MPI version 3 standard that we rely upon to support transparent data movement. Abstraction can come at a cost to performance, to understand this a benchmark (block Cholesky matrix factorisation) has been developed and we present performance &amp; scaling results in comparison to direct passive and active target synchronisation MPI RMA implementations. This benchmark is also used to briefly illustrate how the directory/cache might be used in code.",
        "title": "MPI RMA as a directory/cache interoperability layer",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "42338fea-de77-4727-a107-e4f74d2147ef": {
        "id": "42338fea-de77-4727-a107-e4f74d2147ef",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/in-situ-data-analytics-for-highly-scalable-cloud-modelling-on-cray-machines(42338fea-de77-4727-a107-e4f74d2147ef).html",
        "abstract": "MONC is a highly scalable modelling tool for the investigation of atmospheric flows, turbulence, and cloud microphysics. Typical simulations produce very large amounts of raw data, which must then be analysed for scientific investigation. For performance and scalability reasons, this analysis and subsequent writing to disk should be performed in situ on the data as it is generated; however, one does not wish to pause the computation whilst analysis is carried out. In this paper, we present the analytics approach of MONC, where cores of a node are shared between computation and data analytics. By asynchronously sending their data to an analytics core, the computational cores can run continuously without having to pause for data writing or analysis. We describe our IO server framework and analytics workflow, which is highly asynchronous, along with solutions to challenges that this approach raises and the performance implications of some common configuration choices. The result of this work is a highly scalable analytics approach, and we illustrate on up to 32 768 computational cores of a Cray XC30 that there is minimal performance impact on the runtime when enabling data analytics in MONC and also investigate the performance and suitability of our approach on the KNL.",
        "title": "In situ data analytics for highly scalable cloud modelling on Cray machines",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "2ae292de-13ab-4a6e-ac8a-7b066f80c126": {
        "id": "2ae292de-13ab-4a6e-ac8a-7b066f80c126",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/insitu-data-analytics-for-highly-scalable-cloud-modelling-on-cray-machines(2ae292de-13ab-4a6e-ac8a-7b066f80c126).html",
        "abstract": "MONC is a highly scalable modelling tool for the investigation of atmospheric flows, turbulence, and cloud microphysics. Typical simulations produce very large amounts of raw data, which must then be analysed for scientific investigation. For performance and scalability reasons, this analysis and subsequent writing to disk should be performed in situ on the data as it is generated; however, one does not wish to pause the computation whilst analysis is carried out. In this paper, we present the analytics approach of MONC, where cores of a node are shared between computation and data analytics. By asynchronously sending their data to an analytics core, the computational cores can run continuously without having to pause for data writing or analysis. We describe our IO server framework and analytics workflow, which is highly asynchronous, along with solutions to challenges that this approach raises and the performance implications of some common configuration choices. The result of this work is a highly scalable analytics approach, and we illustrate on up to 32 768 computational cores of a Cray XC30 that there is minimal performance impact on the runtime when enabling data analytics in MONC and also investigate the performance and suitability of our approach on the KNL.",
        "title": "In-situ data analytics for highly scalable cloud modelling on Cray machines",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "6b67b679-34ca-4dd0-9e22-9c2a5d075c15": {
        "id": "6b67b679-34ca-4dd0-9e22-9c2a5d075c15",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/porting-the-microphysics-model-casim-to-gpu-and-knl-cray-machines(6b67b679-34ca-4dd0-9e22-9c2a5d075c15).html",
        "abstract": "CASIM is a microphysics scheme which calculates the interaction between moisture droplets in the atmosphere and forms a critical part of weather and climate modelling codes. However the calculations involved are computationally intensive and so investigating whether CASIM can take advantage of novel hardware architectures and the likely increase in performance this might afford makes sense. In this paper we  present work done in porting CASIM to GPUs via the directive driven OpenACC and also modifying CASIM to take advantage of the Knights Landing (KNL) processor using OpenMP. Due to the design, models extracting out specific computational kernels for offload to the GPU proved suboptimal and instead the entire scheme was ported over to the GPU. We consider the suitability and maturity of OpenACC for this approach as well as important optimisations that were identified. Enabling CASIM to take advantage of the KNL was significantly easier, but still required careful experimentation to understand the best design and configuration. The performance of both versions of CASIM, in comparison to the latest generation of CPUs is discussed, before identifying lessons learnt about the suitability of CASIM and other similar models for these architectures. The result of this work are versions of CASIM which show promising performance benefits when utilising both GPUs and KNLs and enable the communities to take advantage of these technologies, in addition to general techniques that can be applied to other similar weather and climate models.",
        "title": "Porting the microphysics model CASIM to GPU and KNL Cray machines",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "32ba3523-fb3f-48e9-8d03-fb500fa81d00": {
        "id": "32ba3523-fb3f-48e9-8d03-fb500fa81d00",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/type-oriented-parallel-programming-for-exascale(32ba3523-fb3f-48e9-8d03-fb500fa81d00).html",
        "abstract": "Whilst there have been great advances in HPC hardware and software in recent years, the languages and models that we use to program these machines have remained much more static. This is not from a lack of effort, but instead by virtue of the fact that the foundation that many programming languages are built on is not sufficient for the level of expressivity required for parallel work. The result is an implicit trade-off between programmability and performance which is made worse due to the fact that, whilst many scientific users are experts within their own fields, they are not HPC experts.<br/><br/>Type oriented programming looks to address this by encoding the complexity of a language via the type system. Most of the language functionality is contained within a loosely coupled type library that can be flexibly used to control many aspects such as parallelism. Due to the high level nature of this approach there is much information available during compilation which can be used for optimisation and, in the absence of type information, the compiler can apply sensible default options thus supporting both the expert programmer and novice alike.<br/><br/>We demonstrate that, at no performance or scalability penalty when running on up to 8196 cores of a Cray XE6 system, codes written in this type oriented manner provide improved programmability. The programmer is able to write simple, implicit parallel, HPC code at a high level and then explicitly tune by adding additional type information if required.",
        "title": "Type oriented parallel programming for Exascale",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "3b55ed53-6bbd-4bbf-b089-c23e2c7ba6b7": {
        "id": "3b55ed53-6bbd-4bbf-b089-c23e2c7ba6b7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/epython-an-implementation-of-python-for-the-manycore-epiphany-coprocessor(3b55ed53-6bbd-4bbf-b089-c23e2c7ba6b7).html",
        "abstract": "The Epiphany is a many-core, low power, low on-chip memory architecture and one can very cheaply gain access to a number of parallel cores which is beneficial for HPC education and prototyping. The very low power nature of these architectures also means that there is potential for their use in future HPC machines, however there is a high barrier to entry in programming them due to the associated complexities and immaturity of supporting tools. <br/><br/>In this paper we present our work on ePython, a subset of Python for the Epiphany and similar many-core co-processors. Due to the limited on-chip memory per core we have developed a new Python interpreter and this, combined with additional support for parallelism, has meant that novices can take advantage of Python to very quickly write parallel codes on the Epiphany and explore concepts of HPC using a smaller scale parallel machine. The high level nature of Python opens up new possibilities on the Epiphany, we examine a computationally intensive Gauss-Seidel code from the programmability and performance perspective, discuss running Python hybrid on both the host CPU and Epiphany, and interoperability between a full Python interpreter on the CPU and ePython on the Epiphany. The result of this work is support for developing Python on the Epiphany, which can be applied to other similar architectures, that the community have already started to adopt and use to explore concepts of parallelism and HPC.",
        "title": "ePython: An implementation of Python for the many-core Epiphany coprocessor",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "aa2dfb95-d0d2-48b5-9f13-071b59073393": {
        "id": "aa2dfb95-d0d2-48b5-9f13-071b59073393",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/on-processing-extreme-data(aa2dfb95-d0d2-48b5-9f13-071b59073393).html",
        "abstract": "",
        "title": "On Processing Extreme Data",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "e62f209a-aa8f-42d1-90d6-21e0a7a4799d": {
        "id": "e62f209a-aa8f-42d1-90d6-21e0a7a4799d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/report-on-the-state-of-the-art-of-worldwide-codesign-centres(e62f209a-aa8f-42d1-90d6-21e0a7a4799d).html",
        "abstract": "The HPC community have set themselves the target of reaching exa-scale performance by 2020. It is not a question of whether this target will be met, but instead whether or not an exa-scale machine can be programmed and used effectively to perform science at a scale never before attainable. There are many challenges in many different areas to overcome if the community are to scale their current scientific codes up to the exa-flop level and one of the approaches to solving this is through the use of co-design, where interdisciplinary teams work together to solve a specific problem.<br/><br/>However this development methodology is still relatively immature and in this report we gather the opinions of co-design from those in the HPC field, consider the positive and negative impact of such an approach, survey how co-design is currently being used and make some recommendations about how European projects might more effectively take advantage of this methodology to help solve the exa-scale challenge.",
        "title": "Report on the state of the art of worldwide co-design centres",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "ffcbe0f1-4265-4e27-a830-a02aefb942d6": {
        "id": "ffcbe0f1-4265-4e27-a830-a02aefb942d6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/type-oriented-parallel-programming-for-exascale(ffcbe0f1-4265-4e27-a830-a02aefb942d6).html",
        "abstract": "Whilst there have been great advances in HPC hardware and software in recent years, the languages and models that we use to program these machines have remained much more static. This is not from a lack of effort, but instead by virtue of the fact that the foundation that many programming languages are built on is not sufficient for the level of expressivity required for parallel work. The result is an implicit trade-off between programmability and performance which is made worse due to the fact that, whilst many scientific users are experts within their own fields, they are not HPC experts. <br/><br/>Type oriented programming looks to address this by encoding the complexity of a language via the type system. Most of the language functionality is contained within a loosely coupled type library that can be flexibly used to control many aspects such as parallelism. Due to the high level nature of this approach there is much information available during compilation which can be used for optimisation and, in the absence of type information, the compiler can apply sensible default options thus supporting both the expert programmer and novice alike. <br/><br/>We demonstrate that, at no performance or scalability penalty when running on up to 8196 cores of a Cray XE6 system, codes written in this type oriented manner provide improved programmability. The programmer is able to write simple, implicit parallel, HPC code at a high level and then explicitly tune by adding additional type information if required.",
        "title": "Type oriented parallel programming for Exascale",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "91bcbd2f-7992-4ef9-a0d9-99a1543ffeb7": {
        "id": "91bcbd2f-7992-4ef9-a0d9-99a1543ffeb7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/applying-type-oriented-programming-to-the-pgas-memory-model(91bcbd2f-7992-4ef9-a0d9-99a1543ffeb7).html",
        "abstract": "The Partitioned Global Address Space memory model has been popularised by a number of languages and applications. However this abstraction can often result in the programmer having to rely on some in built choices and with this implicit parallelism, with little assistance by the programmer, the scalability and performance of the code heavily depends on the compiler and choice of application.<br/><br/>We propose an approach, type oriented programming, where all aspects of parallelism are encoded via types and the type system. The type information associated by the programmer will determine, for instance, how an array is allocated, partitioned and distributed. With this rich, high level of information the compiler can generate an efficient target executable. If the programmer wishes to omit detailed type information then the compiler will rely on well documented and safe default behaviour which can be tuned at a later date with the addition of types. <br/><br/>The type oriented parallel programming language Mesham, which follows the PGAS memory model, is presented. We illustrate how, if so wished, with the use of types one can tune all parameters and options associated with this PGAS model in a clean and consistent manner without rewriting large portions of code. An FFT case study is presented and considered both in terms of programmability and performance - the latter we demonstrate by a comparison with an existing FFT solver.",
        "title": "Applying Type Oriented Programming to the PGAS Memory Model",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "2ca86dee-8799-42ca-b738-8251366a5659": {
        "id": "2ca86dee-8799-42ca-b738-8251366a5659",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-directive-based-hybrid-met-office-nerc-cloud-model(2ca86dee-8799-42ca-b738-8251366a5659).html",
        "abstract": "Large Eddy Simulation is a critical modelling tool for the investigation of atmospheric flows, turbulence and cloud microphysics. The models used by the UK atmospheric research community are homogeneous and the latest model, MONC, is designed to run on substantial HPC systems with very high CPU core counts. In order to future proof these codes it is worth investigating other technologies and architectures which might support the communities running their codes at the exa-scale.<br/><br/>In this paper we present a hybrid version of MONC, where the most computationally intensive aspect is offloaded to the GPU while the rest of the functionality runs concurrently on the CPU. Developed using the directive driven OpenACC, we consider the suitability and maturity of this technology to modern Fortran scientific codes as well general software engineering techniques which aid this type of porting work. The performance of our hybrid model at scale is compared against the CPU version before considering other tuning options and making a comparison between the energy usage of the homo- and hetero-geneous versions. The result of this work is a promising hybrid model that shows performance benefits of our approach when the GPU has a significant computational workload which can not only be applied to the MONC model but also other weather and climate simulations in use by the community.",
        "title": "A directive based hybrid met office NERC cloud model",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "e78fb3d1-e173-4051-b63b-ee0d1fb9713a": {
        "id": "e78fb3d1-e173-4051-b63b-ee0d1fb9713a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-hybrid-approach-for-extreme-scalability-when-solving-linear-systems(e78fb3d1-e173-4051-b63b-ee0d1fb9713a).html",
        "abstract": "Iterative methods for solving large sparse systems of linear equations are widely used in many HPC applications. Extreme scaling of these methods can be difficult, however, since global synchronisation to form dot products is typically required at every iteration.<br/><br/>To try to overcome this limitation we propose a hybrid approach, where the solution space is partitioned up into blocks. The solving of these blocks occurs at two levels; interblock communication is performed synchronously and intrablock asynchronously. Following this approach it is possible to completely separate the concerns involved at the block and intra block level, allowing one to choose a highly optimised (parallel) internal block solver and an asynchronous method operating at the global level. Using this approach one can achieve extreme scalability - when the limits of conventional solvers start to be reached the system can be partitioned into one or more blocks, each operating with the same conventional solver but at a high level employing asynchronous block Jacobi or some other multisplitting technique.<br/><br/>Our block framework has been built to use PETSc, a popular scientific suite for solving sparse linear systems, as the synchronous interblock solver, and we demonstrate results on up to 32768 cores of a Cray XE6 system.",
        "title": "A hybrid approach for extreme scalability when solving linear systems",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "8981fca6-7b1c-4355-aef7-303acd4b9d22": {
        "id": "8981fca6-7b1c-4355-aef7-303acd4b9d22",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-typeoriented-graph500-benchmark(8981fca6-7b1c-4355-aef7-303acd4b9d22).html",
        "abstract": "<p>Data intensive workloads have become a popular use of HPC in recent years and the question of how data scientists, who might not be HPC experts, can effectively program these machines is important to address. Whilst using models such as Partitioned Global Address Space (PGAS) is attractive from a simplicity point of view, the abstractions that these impose upon the programmer can impact performance. We propose an approach, type-oriented programming, where all aspects of parallelism are encoded via types and the type system which allows for the programmer to write simple PGAS data intensive HPC codes and then, if they so wish, tune the fundamental aspects by modifying type information. This paper considers the suitability of using type-oriented programming, with the PGAS memory model, in data intensive workloads. We compare a type-oriented implementation of the Graph500 benchmark against MPI reference implementations both in terms of programmability and performance, and evaluate how orienting their parallel codes around types can assist in the data intensive HPC field.</p>",
        "title": "A type-oriented Graph500 benchmark",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "8f85bc9e-5e6c-4fc4-9d01-33f41dee5ea4": {
        "id": "8f85bc9e-5e6c-4fc4-9d01-33f41dee5ea4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-highly-scalable-met-office-nerc-cloud-model(8f85bc9e-5e6c-4fc4-9d01-33f41dee5ea4).html",
        "abstract": "Large Eddy Simulation is a critical modelling tool for scien- tists investigating atmospheric flows, turbulence and cloud microphysics. Within the UK, the principal LES model used by the atmospheric research community is the Met Office Large Eddy Model (LEM). The LEM was originally devel- oped in the late 1980s using computational techniques and assumptions of the time, which means that the it does not scale beyond 512 cores. In this paper we present the Met Office NERC Cloud model, MONC, which is a re-write of the existing LEM. We discuss the software engineering and architectural decisions made in order to develop a flexible, extensible model which the community can easily customise for their own needs. The scalability of MONC is evaluated, along with numerous additional customisations made to fur- ther improve performance at large core counts. The result of this work is a model which delivers to the community signifi- cant new scientific modelling capability that takes advantage of the current and future generation HPC machines.",
        "title": "A highly scalable Met Office NERC Cloud model",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "09295fab-061c-4a75-8712-88303cad3aca": {
        "id": "09295fab-061c-4a75-8712-88303cad3aca",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/epython--a-tiny-python-implementation-for-microcore-architectures(09295fab-061c-4a75-8712-88303cad3aca).html",
        "abstract": "ePython is a 24Kb implementation of Python that we have developed, specifically targetting highly parallel micro-core architectures. The main version here is optimised for the Epiphany architecture, but can be easily ported to other technologies by providing an updated runtime. The technology supports all the imperative aspects of the language, with full memory management, garbage collection and support for parallelism (message passing, shared memory and task based.) See the README file for more information about building ePython and running codes under it. The examples directory provides numerous code snippets that can be run under the interpreter.",
        "title": "ePython - a tiny Python implementation for micro-core architectures",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            }
        ]
    },
    "cc1566da-1176-4aab-b9c5-06acf77d9799": {
        "id": "cc1566da-1176-4aab-b9c5-06acf77d9799",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/met-office-nerc-cloud-model-monc(cc1566da-1176-4aab-b9c5-06acf77d9799).html",
        "abstract": "Source code for the Met Office NERC Cloud model (MONC) which is an atmospheric model used to study clouds and turbulent flows. It has been shown to scale to over 32768 compute cores and includes both the simulation (computation of raw data prognostic fields) and in-situ data analytics to then convert these to diagnostics. A variety of sample test-cases are included and the README file describes, in detail, how to compile and run the model.",
        "title": "Met Office NERC Cloud model (MONC)",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Brown",
                "uuid": "d0fe7a8b-6e4f-409f-a5b2-cb1cfe31ce36"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "601fd53b-05b2-49b0-b166-4e99de86cd19": {
        "id": "601fd53b-05b2-49b0-b166-4e99de86cd19",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/parallel-computing-on-the-road-to-exascale(601fd53b-05b2-49b0-b166-4e99de86cd19).html",
        "abstract": "As predicted by Gordon E. Moore in 1965, the performance of computer processors increased at an exponential rate. Nevertheless, the increases in computing speeds of single processor machines were eventually curtailed by physical constraints. This led to the development of parallel computing, and whilst progress has been made in this field, the complexities of parallel algorithm design, the deficiencies of the available software development tools and the complexity of scheduling tasks over thousands and even millions of processing nodes represent a major challenge to the construction and use of more powerful parallel systems.<br/><br/>This book presents the proceedings of the biennial International Conference on Parallel Computing (ParCo2015), held in Edinburgh, Scotland, in September 2015. Topics covered include computer architecture and performance, programming models and methods, as well as applications. The book also includes two invited talks and a number of mini-symposia.<br/><br/>Exascale computing holds enormous promise in terms of increasing scientific knowledge acquisition and thus contributing to the future well-being and prosperity of mankind. A number of innovative approaches to the development and use of future high-performance and high-throughput systems are to be found in this book, which will be of interest to all those whose work involves the handling and processing of large amounts of data.",
        "title": "Parallel Computing: On the Road to Exascale",
        "keywords": "",
        "authors": [
            {
                "name": "Christopher Sawyer",
                "uuid": "180e24e2-c3fb-4b0e-ae6e-778a5208b847"
            },
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            }
        ]
    },
    "53463c71-a595-4721-a7e8-2dd9d0e0a6b7": {
        "id": "53463c71-a595-4721-a7e8-2dd9d0e0a6b7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/oxidative-dna-damage-may-not-mediate-niinduced-genotoxicity-in-marine-mussels(53463c71-a595-4721-a7e8-2dd9d0e0a6b7).html",
        "abstract": "<p>Nickel (Ni) is a known carcinogenic and mutagenic compound and an important contaminant of aquatic environments. Ni toxicity and its potential impact on aquatic organisms are, however, not well understood. This study used an integrated approach to evaluate genotoxic effects, tissue-specific accumulation and transcriptional profiles of key genes in mussels, Mytilus galloprovincialis, exposed to a range of concentrations of Ni. The genotoxic effects assessed were total and oxidative DNA damage (DNA strand breaks measured using the enzyme modified comet assay), and induction of micronuclei (MN; clastogenic and/or aneugenic effects) using haemocytes as the target cells. Six genes (pgp, mt10, mt20, sod, hsp70 and gst) were selected for transcriptional analysis in the gills based on their key role in the stress response. Following exposure to sublethal concentrations of Ni (0-3600\u03bcgL<sup>-1</sup>) for 5 days, mussel haemocytes showed significant genotoxicity at &gt;1800\u03bcgL<sup>-1</sup> (4-fold increase for DNA strand breaks and 3-fold increase for MN induction). There was no significant difference between buffer (control) and enzyme treatments which target oxidised DNA bases (formamidopyrimidine glycosylase or endonuclease IIII). This suggested that, in haemocytes, oxidative DNA damage is not a major mechanism for Ni-induced genotoxicity. The expression of mt20 and gst genes in gill was up-regulated at genotoxic concentrations, whilst pgp expression was markedly up-regulated, particularly at 18\u03bcgL<sup>-1</sup> Ni (19-fold increase). Pearson's correlation analysis revealed significant associations between % tail DNA and MN induction in haemocytes (r=0.88, p&lt;0.05), and between Ni accumulation in foot (r=0.47, p&lt;0.05) and digestive gland (r=0.41, p&lt;0.05) and induction of MN in the haemocytes. Our results are the first to suggest that Ni-induced genotoxicity in mussel haemocytes may not be a result of oxidative DNA damage, and that multixenobiotic resistance (MXR) may play an important role in Ni detoxification in this species.</p>",
        "title": "Oxidative DNA damage may not mediate Ni-induced genotoxicity in marine mussels",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Andrew Turner",
                "uuid": "7f157976-5a16-428d-a95e-42f5f7c33e17"
            }
        ]
    },
    "d0dfbfbc-cd43-4cb5-8a99-aa5302fcab56": {
        "id": "d0dfbfbc-cd43-4cb5-8a99-aa5302fcab56",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/molecular-structure-of-trimethylphosphinegallane-me3p-center-dot-gah3-gasphase-electron-diffraction-singlecrystal-xray-diffraction-and-quantum-chemical-studiest(d0dfbfbc-cd43-4cb5-8a99-aa5302fcab56).html",
        "abstract": "<p>The structure of the gallane adduct Me3P.GaH3 in the vapour and crystalline states has been investigated. The gas-phase electron-diffraction (GED) pattern has been analysed using the SARACEN method to determine the most reliable structure of the gaseous molecule. Salient structural parameters (r(h1) structure) were found to be: r(Ga-H) 159.0(11), (Ga-P) 244.3(6), r(P-C) 184.0(2), r(C-H) 108.3(7) pm; H-Ga-P 98.4(12) and Ga-P-C 117.7(3)degrees. The structure of a single crystal At 150 K shows that the adduct retains the same monomeric unit in the crystalline phase, with dimensions generally close to those of the gaseous molecule and an eclipsed conformation of the C3PGaH3 skeleton. The results are discussed and analysed in the light of quantum chemical calculations and of the properties of related adducts of Group 13 metal hydrides.</p>",
        "title": "Molecular structure of trimethylphosphine-gallane, Me3P center dot GaH3: gas-phase electron diffraction, single-crystal X-ray diffraction, and quantum chemical studiest",
        "keywords": "",
        "authors": [
            {
                "name": "Andrew Turner",
                "uuid": "7f157976-5a16-428d-a95e-42f5f7c33e17"
            }
        ]
    },
    "0371fc01-9281-4e5f-9d50-a14c7f7a473f": {
        "id": "0371fc01-9281-4e5f-9d50-a14c7f7a473f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/barriers-to-racemization-in-c3symmetric-complexes-containing-the-hydrotris2mercapto1ethylimidazolylborate-tmet-ligand(0371fc01-9281-4e5f-9d50-a14c7f7a473f).html",
        "abstract": "<p>The tripodal ligands hydrotris(N-ethyl-2-mercaptoimidazol-1-yl)borate (NaTmEt) (1) and hydrotris(N-benzyl-2mercaptoimidazol-1-yl)borate (NaTmBn) (2), analogues of the hydrotris(N-methyl-2-mercaptoimidazol-1 -yl)borate ligand (Tm) containing alternative nitrogen substituents, have been employed to examine the racemization of their C-3 symmetric complexes with both four- and six-coordinate metals. The ligands react at room temperature with metal halides to provide C-3-symmetric metal complexes. The syntheses of the four-coordinate complexes [(TmZnCl)-Zn-Et] (3), [(TmCdBr)-Cd-Et] (4), [(TmHgCl)-Hg-Et] (5), [(TmCuPPh3)-Cu-Et] (6), [(TmAgPPh3)-Ag-Et] (7), and [(TmZnCl)-Zn-Bn] (8) are reported. The six-coordinate complexes [(TmRu)-Ru-Et(p-cymene)]Cl (9), [(TmRu)-Ru-Et(p-cymene)]PF6 (10), and [(TmMn)-Mn-Et(CO)(3)] (11) were also synthesized. The X-ray crystal structures of 3, 4, 6, and 9 are reported. The diastereotopic nature of the ethyl and benzyl hydrogen atoms in the ligands allows the enantiomeric forms of these complexes to be distinguished by H-1 NMR spectroscopy. Variable-temperature (VT) 1H NMR spectra have thus been used to investigate the energies of the racemization processes occurring in these chiral complexes. In solvents the activation energies to racemization for the four-coordinate complexes lay in the range of 53-77 kJ mol(-1). In non-donor solvents the energies are reduced and a dissociative mechanism is therefore implicated. No interconversion could be observed by VT NMR for the six-coordinate complexes in any solvent. To further explore the racemization mechanisms ab initio density functional theory calculations have been conducted on the ground- and transition-state structures of representative six-coordinate [Mn(I)] and four-coordinate [Zn(II)] complexes following a proposed nondissociative mechanism of racemization. The calculated energy barriers to racemization are 163 and 121 U mol-1, respectively. It is concluded that the low-energy racemization of substitution-labile four-coordinate complexes occurs via a dissociative mechanism, while substitution-inert six-coordinate complexes experience a significantly higher barrier to racemization. Whether this is due to the operation of a dissociative mechanism with a higher activation barrier or to a nondissociative mechanism remains unknown.</p>",
        "title": "Barriers to racemization in C-3-symmetric complexes containing the hydrotris(2-mercapto-1-ethylimidazolyl)borate (Tm-Et) Ligand",
        "keywords": "",
        "authors": [
            {
                "name": "Andrew Turner",
                "uuid": "7f157976-5a16-428d-a95e-42f5f7c33e17"
            }
        ]
    },
    "ff4ae176-d2ca-4236-8169-c094df4fb95f": {
        "id": "ff4ae176-d2ca-4236-8169-c094df4fb95f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/inor-121ch-bond-functionalization-directed-by-asymmetric-pd-nhc-complexes(ff4ae176-d2ca-4236-8169-c094df4fb95f).html",
        "abstract": "",
        "title": "INOR 121-C-H bond functionalization directed by asymmetric Pd NHC complexes",
        "keywords": "",
        "authors": [
            {
                "name": "Andrew Turner",
                "uuid": "7f157976-5a16-428d-a95e-42f5f7c33e17"
            }
        ]
    },
    "bdd40364-b6d9-422b-b3b3-f8246b497d28": {
        "id": "bdd40364-b6d9-422b-b3b3-f8246b497d28",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/molecular-orbital-calculations-of-inorganic-compounds(bdd40364-b6d9-422b-b3b3-f8246b497d28).html",
        "abstract": "",
        "title": "Molecular Orbital Calculations of Inorganic Compounds",
        "keywords": "",
        "authors": [
            {
                "name": "Andrew Turner",
                "uuid": "7f157976-5a16-428d-a95e-42f5f7c33e17"
            }
        ]
    },
    "d5ad2bb8-a405-43d3-baa3-2956bfb66500": {
        "id": "d5ad2bb8-a405-43d3-baa3-2956bfb66500",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/tripodlike-cationic-lipids-as-novel-gene-carriers(d5ad2bb8-a405-43d3-baa3-2956bfb66500).html",
        "abstract": "<p>An innovative family of tridentate-cationic \"single-chained lipids\" designed to enhance DNA compaction and to promote endosomal escape was synthesized by coupling various lipids to a multibranched scaffold. DNA retardation assays confirmed the ability of the most members of the library to complex DNA. Classical molecular dynamics simulations performed on the lauryl derivative, bound to a short strand of DNA in aqueous solution supported these observations. These showed that two \"arms\" of the tripodal molecule are ideally suited to forming strong Coulombic interactions with two contiguous phosphate groups from the DNA backbone while the lipophilic tail stays perpendicular to the DNA helix. Gene transfer abilities of the library were assessed in multiple cell lines (CHO, Cos7, and 16HBE14o-) with some library members giving excellent transfection abilities and low cytotoxicity, supporting the use of this tripodal approach for the development of efficient gene delivery agents.</p>",
        "title": "Tripod-like cationic lipids as novel gene carriers",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Andrew Turner",
                "uuid": "7f157976-5a16-428d-a95e-42f5f7c33e17"
            }
        ]
    },
    "f34a544b-d19e-4976-ac44-5c1d2123cc1d": {
        "id": "f34a544b-d19e-4976-ac44-5c1d2123cc1d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/spectroscopic-electrochemical-and-computational-study-of-ptdiiminedithiolene-complexes-rationalising-the-properties-of-solar-cell-dyes(f34a544b-d19e-4976-ac44-5c1d2123cc1d).html",
        "abstract": "<p>A series of [Pt(II)(diimine)(dithiolate)] complexes of general formula [Pt{X, X'-(CO<sub>2</sub>R)<sub>2</sub>-bpy}(mnt)] (where X = 3, 4 or 5; R = H or Et, bpy = 2,2'-bipyridyl and mnt = maleonitriledithiolate), have been spectroscopically, electrochemically and computationally characterised and compared with the precursors [Pt{X, X'-(CO<sub>2</sub>R)<sub>2</sub>-bpy}Cl<sub>2</sub>] and X, X'-(CO<sub>2</sub>R)<sub>2</sub>-bpy. The study includes cyclic voltammetry, <em>in situ</em> EPR spectroelectrochemical studies of fluid solution and frozen solution samples, UV/Vis/NIR spectroelectrochemistry, hyrid DFT and TD-DFT calculations. The effect of changing the position of the bpy substituents from 3,3' to 4,4' and 5,5' is discussed with reference to electronic changes seen within the different members of the family of molecules. The performance of the mnt complexes in dye-sensitised solar cells has been previously described and the superior performance of [Pt{3,3' -(CO<sub>2</sub>R)<sub>2</sub>-bpy}(mnt)] is now explained in terms of decreased electronic delocalisation through twisting of the bipyridyl ligand as supported by the EPR and computational results.</p>",
        "title": "Spectroscopic, electrochemical and computational study of Pt-diimine-dithiolene complexes: Rationalising the properties of solar cell dyes",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Andrew Turner",
                "uuid": "7f157976-5a16-428d-a95e-42f5f7c33e17"
            }
        ]
    },
    "0b257dc0-bef0-4cfd-881a-54303ce8419f": {
        "id": "0b257dc0-bef0-4cfd-881a-54303ce8419f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/inor-329dithiolenes-as-functional-ligands-in-solar-cell-dyes(0b257dc0-bef0-4cfd-881a-54303ce8419f).html",
        "abstract": "",
        "title": "INOR 329-Dithiolenes as functional ligands in solar cell dyes",
        "keywords": "",
        "authors": [
            {
                "name": "Andrew Turner",
                "uuid": "7f157976-5a16-428d-a95e-42f5f7c33e17"
            }
        ]
    },
    "062b6ff6-369a-4331-9e8f-f9130a756148": {
        "id": "062b6ff6-369a-4331-9e8f-f9130a756148",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/gasphase-structures-of-1adamantylphosphines-phn1ad3n-n-13(062b6ff6-369a-4331-9e8f-f9130a756148).html",
        "abstract": "<p>The gas-phase structure of 1-adamantylphosphine has been determined by electron diffraction, supplemented with data from <em>ab initio</em> and DFT calculations. The adamantyl fragment was modeled with local <em>C</em><sub>3v</sub> symmetry and the phosphino group was found to be in a position almost bisecting a mirror plane of the adamantyl group, giving the molecule overall approximate <em>C</em><sub>s</sub> symmetry. There is a small displacement of the C-P bond from the local threefold axis of the adamantyl group. Geometry optimizations were also performed for bis-(1-adamantyl)phosphine (<em>C</em><sub>1</sub> point-group symmetry) and tris-(1-adamantyl)phosphine (<em>C</em><sub>3</sub> symmetry), demonstrating extremely crowded environments around the phosphorus atoms leading to adamantyl groups that were much less symmetric. The adamantyl groups were also found to twist by a significant amount to minimize the strain.</p>",
        "title": "Gas-phase structures of 1-adamantylphosphines, PH<sub style=\"font-style: italic;\">n</sub>(1-Ad)<sub><em>3-n</em></sub> (<em>n</em> =1-3)",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Andrew Turner",
                "uuid": "7f157976-5a16-428d-a95e-42f5f7c33e17"
            }
        ]
    },
    "bedd0467-4ed9-4d1b-8d0a-058e444bd716": {
        "id": "bedd0467-4ed9-4d1b-8d0a-058e444bd716",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/synthesis-and-properties-of-pt4co2ch3py2mnt-comparison-of-pyridyl-and-bipyridylbased-dyes-for-solar-cells(bedd0467-4ed9-4d1b-8d0a-058e444bd716).html",
        "abstract": "<p>The dye complexes [Pt(4-CO<sub>2</sub>R-py)<sub>2</sub>(mnt)] (R = H (<strong>3a</strong>), CH<sub>3</sub> (<strong>3b</strong>)) and the precursor complexes [Pt(4-CO<sub>2</sub>R-py)<sub>2</sub>Cl<sub>2</sub>] (<strong>2a</strong>, <strong>2b</strong>) (py = pyridyl) were synthesised, characterised by electrochemical, spectroscopic, spectroelectrochemical (UV-vis-nIR and <em>in situ</em> EPR) and hybrid DFT computational methods and attached to a TiO<sub>2</sub> substrate to determine charge recombination kinetics. The results were compared to the bipyridyl analogues [Pt{<em>X, X'</em>-(CO<sub>2</sub>R)-2,2'-bipyridyl}(mnt)], (<em>X</em> = 3 or 4). The electronic characteristics of the bis-pyridyl complex were found to be different to the bipyridyl complexes making the former harder to reduce, shifting the lowest-energy absorption band to higher energy and showing separate degenerate LUMO orbitals on the two pyridine rings. The latter point determines that the di-reduced pyridyl complex remains EPR active, unlike the bipyridyl analogue. Complex <strong>3a</strong> attached to nanocrystalline TiO<sub>2</sub> shows a long charge recombination lifetime in comparison with the analogous complex with the ubiquitous 4,4'-(CO<sub>2</sub>H)<sub>2</sub>-bipyridyl ligand, suggesting that pyridyl complexes may possess some advantage over bipyridyl complexes in dye-sensitised solar cells.</p>",
        "title": "Synthesis and properties of [Pt(4-CO<sub>2</sub>CH<sub>3</sub>-py)<sub>2</sub>(mnt)]: Comparison of pyridyl and bipyridyl-based dyes for solar cells",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Andrew Turner",
                "uuid": "7f157976-5a16-428d-a95e-42f5f7c33e17"
            }
        ]
    },
    "69c0358a-90cd-495d-bf3d-a7c732bac5fd": {
        "id": "69c0358a-90cd-495d-bf3d-a7c732bac5fd",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/evaluation-of-variation-in-the-phosphoinositide3kinase-catalytic-subunit-alpha-oncogene-and-breast-cancer-risk(69c0358a-90cd-495d-bf3d-a7c732bac5fd).html",
        "abstract": "",
        "title": "Evaluation of variation in the phosphoinositide-3-kinase catalytic subunit alpha oncogene and breast cancer risk",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            }
        ]
    },
    "6db2277a-e830-4058-ab5d-f1158e5155db": {
        "id": "6db2277a-e830-4058-ab5d-f1158e5155db",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/rcslens-the-red-cluster-sequence-lensing-survey(6db2277a-e830-4058-ab5d-f1158e5155db).html",
        "abstract": "We present the Red Cluster Sequence Lensing Survey (RCSLenS), an\napplication of the methods developed for the Canada-France-Hawaii\nTelescope Lensing Survey (CFHTLenS) to the \u02dc785 deg2,\nmulti-band imaging data of the Red-sequence Cluster Survey 2. This\nproject represents the largest public, sub-arcsecond seeing, multi-band\nsurvey to date that is suited for weak gravitational lensing\nmeasurements. With a careful assessment of systematic errors in shape\nmeasurements and photometric redshifts, we extend the use of this data\nset to allow cross-correlation analyses between weak lensing observables\nand other data sets. We describe the imaging data, the data reduction,\nmasking, multi-colour photometry, photometric redshifts, shape\nmeasurements, tests for systematic errors, and a blinding scheme to\nallow for more objective measurements. In total, we analyse 761\npointings with r-band coverage, which constitutes our lensing sample.\nResidual large-scale B-mode systematics prevent the use of this shear\ncatalogue for cosmic shear science. The effective number density of\nlensing sources over an unmasked area of 571.7 deg2 and down\nto a magnitude limit of r \u02dc 24.5 is 8.1 galaxies per\narcmin2 (weighted: 5.5 arcmin-2) distributed over\n14 patches on the sky. Photometric redshifts based on four-band griz\ndata are available for 513 pointings covering an unmasked area of 383.5\ndeg2. We present weak lensing mass reconstructions of some\nexample clusters as well as the full survey representing the largest\nareas that have been mapped in this way. All our data products are\npublicly available through Canadian Astronomy Data Centre at\nhttp://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/en/community/rcslens/query.html\nin a format very similar to the CFHTLenS data release.",
        "title": "RCSLenS: The Red Cluster Sequence Lensing Survey",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            }
        ]
    },
    "2fd2ce3a-cec0-412b-aaea-370db29456dc": {
        "id": "2fd2ce3a-cec0-412b-aaea-370db29456dc",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/on-the-tradeoffs-between-energy-to-solution-and-runtime-for-realworld-cfd-testcases(2fd2ce3a-cec0-412b-aaea-370db29456dc).html",
        "abstract": "This paper provides an insight into the optimisation of runtime and energy performance for two widely-used CFD codes. Energy efficiency is a hot-topic in HPC and methods to reduce the energy consumption of large machines are an active area of research. In this paper, we examine the energy efficiency and runtime performance of the SBLI and Nektar++ codes, using small but real-world test cases. The codes are instrumented in sufficient detail to reveal significant variability in energy usage during the course of the simulations. In addition, the test cases are run at different CPU frequencies and the consequences of changing this parameter, for both runtime performance (time to solution) and power performance (energy to solution) are presented.",
        "title": "On the Trade-offs between Energy to Solution and Runtime for Real-World CFD Test-Cases",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "33370266-9419-4415-a699-25cc3edd9d96": {
        "id": "33370266-9419-4415-a699-25cc3edd9d96",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/inputaware-autotuning-for-directivebased-gpu-programming(33370266-9419-4415-a699-25cc3edd9d96).html",
        "abstract": "<p>The difficulties posed by GPGPU programming and the need to increase productivity have guided research towards directive-based high-level programs for accelerators. This effort has led to the definition of the OpenACC industry standard. It significantly simplifies writing code for graph- ics engines leaving the programmer the opportunity to tune the application for the target hardware and input. In this paper we address the problem of choosing the best mapping of sequential OpenACC loops to the parallel thread- space for a given program and input size. We show that auto-tuning on mapping parameters can improve performance by up to 4.8x over the default chosen by a state-of-the- art compiler. To reduce the overhead of auto-tuning we introduce a search technique that exploits similarities in be- haviour across inputs using a nearest neighbour approach. This dramatically reduces the search for a good mapping (by 97% compared to random search). Finally we propose a heuristic for stopping the focused search which, averaged across 12 benchmarks and 30 input sizes each, achieves a speedup over the default of 1.26x with only 8 sampling runs.</p>",
        "title": "Input-aware auto-tuning for directive-based GPU programming",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            }
        ]
    },
    "8ef7fe97-45c5-405e-bd82-bf9db7126b30": {
        "id": "8ef7fe97-45c5-405e-bd82-bf9db7126b30",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/benchmarking-for-power-consumption-monitoring(8ef7fe97-45c5-405e-bd82-bf9db7126b30).html",
        "abstract": "This paper presents a set of benchmarks that are designed to measure power consumption in parallel systems. The benchmarks range from low-level, single instructions or operations, to small kernels. In addition to describing the motivation behind developing the benchmarks and the de- sign principles that were followed, the paper also introduces a metric to quantify the power-performance of a parallel sys- tem. Initial results are presented and help to illustrate the contribution of the paper.",
        "title": "Benchmarking for power consumption monitoring",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "3b8d7fbf-398f-41af-aa1d-12d507c9ddc7": {
        "id": "3b8d7fbf-398f-41af-aa1d-12d507c9ddc7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/towards-control-algorithms-for-distributed-wireless-networks(3b8d7fbf-398f-41af-aa1d-12d507c9ddc7).html",
        "abstract": "",
        "title": "Towards control algorithms for distributed wireless networks",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            }
        ]
    },
    "a481a7be-c51f-4cd3-8119-6557875f2c8e": {
        "id": "a481a7be-c51f-4cd3-8119-6557875f2c8e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/delay-estimation-network-tomography-amp-bottlenecklink-detection(a481a7be-c51f-4cd3-8119-6557875f2c8e).html",
        "abstract": "",
        "title": "Delay Estimation, Network Tomography amp; Bottleneck-link Detection",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            }
        ]
    },
    "666c9374-97b6-4eee-a5e7-91ae09bb1b50": {
        "id": "666c9374-97b6-4eee-a5e7-91ae09bb1b50",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-comparison-of-some-bottlenecklink-detection-methods-for-network-tomography(666c9374-97b6-4eee-a5e7-91ae09bb1b50).html",
        "abstract": "",
        "title": "A Comparison of Some Bottleneck-link Detection Methods for Network Tomography",
        "keywords": "",
        "authors": [
            {
                "name": "Nicholas Johnson",
                "uuid": "49cba413-d418-406d-8d4f-14ca7bf5994a"
            }
        ]
    },
    "b4162d30-94d7-47b7-b42b-b985b245a606": {
        "id": "b4162d30-94d7-47b7-b42b-b985b245a606",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/student-use-of-peerwise-a-multiinstitutional-multidisciplinary-evaluation(b4162d30-94d7-47b7-b42b-b985b245a606).html",
        "abstract": "This study explores the relationship between engagement with an online, free to use question-generation application (PeerWise) and student achievement. Using PeerWise, students can create and answer multiplechoice questions and can provide feedback to the question authors on question quality. This provides further scope for students to engage in discussion about the question with their peers. Data on PeerWise use and examination performance was collected from over 3000 students across six large undergraduate courses (in physics, chemistry and biology) over three academic years in three research intensive UK universities. A reliable and valid measure of overall PeerWise activity was created and a multilevel model developed describing the relationship between PeerWise activity and student performance in end of course examinations. Using this<br/>approach, a significant positive association was found between students\u2019 engagement with PeerWise and their academic attainment in end of course exams, even controlling for prior ability. The implications of these findings for educators are discussed.",
        "title": "Student use of PeerWise: a multi-institutional, multi-disciplinary evaluation",
        "keywords": "",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "43ea1146-f266-47ba-8ade-7ffeff35dabb": {
        "id": "43ea1146-f266-47ba-8ade-7ffeff35dabb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/learning-from-peer-feedback-on-studentgenerated-multiple-choice-questions-views-of-introductory-physics-students(43ea1146-f266-47ba-8ade-7ffeff35dabb).html",
        "abstract": "",
        "title": "Learning from peer feedback on student-generated multiple choice questions: Views of introductory physics students",
        "keywords": "",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "7bc54282-fe00-49c7-9e00-0c6f96157a70": {
        "id": "7bc54282-fe00-49c7-9e00-0c6f96157a70",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/teacherstudent-discourse-in-active-learning-lectures(7bc54282-fe00-49c7-9e00-0c6f96157a70).html",
        "abstract": "In this paper we develop knowledge of the discourse that takes place between teacher and students in two large undergraduate classes which use a flipped, active learning approach. In flipped classes students encounter the content through pre-class resources, freeing up class time for more active engagement with the material. This results in increased opportunities for teacher-student interactions which may be beneficial for learning. Our aim here is to explore the nature and purposes of these dialogues. Two case studies from introductory physics classes at the University of Edinburgh are analysed through a sociocultural perspective. Three main purposes of dialogues are observed: (1) Involving students in sense-making, (2) Guided expert modelling and (3) Wonderment questions. We found that the dialogues predominantly use a triadic Initiation, Response, Feedback (IRF) format and are authoritative in nature, but work together to create an interactive learning environment that can be described as \u2018ideologically dialogic\u2019",
        "title": "Teacher-student discourse in active learning lectures",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "fffa5f9c-dca7-4c16-a15e-71474d0deec6": {
        "id": "fffa5f9c-dca7-4c16-a15e-71474d0deec6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/characterizing-interactive-engagement-activities-in-a-flipped-introductory-physics-class(fffa5f9c-dca7-4c16-a15e-71474d0deec6).html",
        "abstract": "<p>Interactive engagement activities are increasingly common in undergraduate physics teaching. As research efforts move beyond simply showing that interactive engagement pedagogies work towards developing an understanding of how they lead to improved learning outcomes, a detailed analysis of the way in which these activities are used in practice is needed. Our aim in this paper is to present a characterization of the type and duration of interactions, as experienced by students, that took place during two introductory physics courses (1A and 1B) at a university in the United Kingdom. Through this work, a simple framework for analyzing lectures-the framework for interactive learning in lectures (FILL), which focuses on student interactions (with the lecturer, with each other, and with the material) is proposed. The pedagogical approach is based on Peer Instruction (PI) and both courses are taught by the same lecturer. We find lecture activities can be categorized into three types: interactive (25%), vicarious interactive (20%) (involving questions to and from the lecturer), and noninteractive (55%). As expected, the majority of both interactive and vicarious interactive activities took place during PI. However, the way that interactive activities were used during non-PI sections of the lecture varied significantly between the two courses. Differences were also found in the average time spent on lecturer-student interactions (28% for 1A and 12% for 1B), although not on student-student interactions (12% and 12%) or on individual learning (10% and 7%). These results are explored in detail and the implications for future research are discussed.</p>",
        "title": "Characterizing interactive engagement activities in a flipped introductory physics class",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "fdf0c329-4037-4eef-a311-c7db4b2de600": {
        "id": "fdf0c329-4037-4eef-a311-c7db4b2de600",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/can-dual-processing-theory-explain-physics-students-performance-on-the-force-concept-inventory(fdf0c329-4037-4eef-a311-c7db4b2de600).html",
        "abstract": "<p>According to dual processing theory there are two types, or modes, of thinking: system 1, which involves intuitive and nonreflective thinking, and system 2, which is more deliberate and requires conscious effort and thought. The Cognitive Reflection Test (CRT) is a widely used and robust three item instrument that measures the tendency to override system 1 thinking and to engage in reflective, system 2 thinking. Each item on the CRT has an intuitive (but wrong) answer that must be rejected in order to answer the item correctly. We therefore hypothesized that performance on the CRT may give useful insights into the cognitive processes involved in learning physics, where success involves rejecting the common, intuitive ideas about the world (often called misconceptions) and instead carefully applying physical concepts. This paper presents initial results from an ongoing study examining the relationship between students' CRT scores and their performance on the Force Concept Inventory (FCI), which tests students' understanding of Newtonian mechanics. We find that a higher CRT score predicts a higher FCI score for both precourse and postcourse tests. However, we also find that the FCI normalized gain is independent of CRT score. The implications of these results are discussed.</p>",
        "title": "Can dual processing theory explain physics students' performance on the Force Concept Inventory?",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "b5064a2b-f070-488c-bfa6-43956e9dcf91": {
        "id": "b5064a2b-f070-488c-bfa6-43956e9dcf91",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/how-design-of-online-learning-materials-can-accommodate-the-heterogeneity-in-student-abilities-aptitudes-and-aspirations(b5064a2b-f070-488c-bfa6-43956e9dcf91).html",
        "abstract": "We describe the challenges facing higher education in terms of the heterogeneity of the cohort of students that arrive at university. The reasons why such diversity exists are many: students differ widely in terms of their preparedness for study at university, their degree choice aspirations and the issue of motivation for study of a particular subject. We illustrate how well-designed e-learning course materials can support many of the particular facets of heterogeneity by offering an inherently non-linear pathway through a collection of materials, so as to offer a degree of personalisation of the learning experience.<br/><br/>Drawing on our own experience of several years\u2019 development<br/>of extensive online materials to support the traditional teaching methods of a large first year physics course at the University of Edinburgh, we highlight three aspects of the design of e-learning materials that facilitate this personalisation. These are: a highly granular source of individual learning objects; online constructions (\u2018one-downs\u2019 and \u2018popups\u2019) that provide additional depth and breadth of material; and the ability to import external resources adapted to the local context.",
        "title": "How Design of Online Learning Materials Can Accommodate the Heterogeneity in Student Abilities, Aptitudes and Aspirations",
        "keywords": "",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "35754e83-f63e-4095-a57d-255520facb01": {
        "id": "35754e83-f63e-4095-a57d-255520facb01",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/analyzing-learning-during-peer-instruction-dialogues(35754e83-f63e-4095-a57d-255520facb01).html",
        "abstract": "<p>Peer Instruction (PI) is an evidence based pedagogy commonly used in undergraduate physics instruction. When asked questions designed to test conceptual understanding, it has been observed that the proportion of students choosing the correct answer increases following peer discussion; however, relatively little is known about what takes place during these discussions or how they are beneficial to the processes of learning physics [M. C. James and S. Willoughby, Am. J. Phys. 79, 123 (2011)]. In this paper a framework for analyzing PI discussions developed through the lens of the \"resources model\" [D. Hammer, Am. J. Phys. 64, 1316 (1996); D. Hammer et al., Information Age Publishing (2005)] is proposed. A central hypothesis for this framework is that the dialogue with peers plays a crucial role in activating appropriate cognitive resources, enabling the students to see the problem differently, and therefore to answer the questions correctly. This framework is used to gain greater insights into the PI discussions of first year undergraduate physics students at the University of Edinburgh, UK, which were recorded using Livescribe Smartpens. Analysis of the dialogues revealed three different types of resource activation corresponding to increasing cognitive grain size. These were activation of knowledge elements, activation of linkages between knowledge elements, and activation of control structures (epistemic games and epistemological frames). Three case studies are examined to illustrate the role that peer dialogue plays in the activation of these cognitive resources in a PI session. The implications for pedagogical practice are discussed.</p>",
        "title": "Analyzing learning during Peer Instruction dialogues",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "141826cd-ee03-49b9-9f9d-91c5d6a8533f": {
        "id": "141826cd-ee03-49b9-9f9d-91c5d6a8533f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/scaffolding-student-engagement-via-online-peer-learning(141826cd-ee03-49b9-9f9d-91c5d6a8533f).html",
        "abstract": "<p>We describe one aspect of a UK inter-institutional project wherein an online tool was used to support student generation of multiple choice questions. Across three universities and in five modules in physics, chemistry and biology, we introduced the PeerWise online system as a summative assessment tool in our classes, the desire being to increase student engagement, academic attainment and level of cognitive challenge. Engagement with the system was high with many students exceeding the minimum requirements set out in the assessment criteria. We explore the nature of student engagement and describe a working model to enable high-impact student-learning and academic gain with minimal instructor intervention.</p>",
        "title": "Scaffolding student engagement via online peer learning",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "2428b5b7-7b3a-4815-960d-5c66628cbe4d": {
        "id": "2428b5b7-7b3a-4815-960d-5c66628cbe4d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/studentgenerated-content(2428b5b7-7b3a-4815-960d-5c66628cbe4d).html",
        "abstract": "<p>The relationship between students' use of PeerWise, an online tool that facilitates peer learning through student-generated content in the form of multiple-choice questions (MCQs), and achievement, as measured by their performance in the end-of-module examinations, was investigated in 5 large early-years science modules (in physics, chemistry and biology) across 3 research-intensive UK universities. A complex pattern was observed in terms of which type of activity (writing, answering or commenting on questions) was most beneficial for students; however, there was some evidence that students of lower intermediate ability may have gained particular benefit. In all modules, a modest but statistically significant positive correlation was found between students' PeerWise activity and their examination performance, after taking prior ability into account. This suggests that engaging with the production and discussion of student-generated content in the form of MCQs can support student learning in a way that is not critically dependent on course, institution, instructor or student.</p>",
        "title": "Student-generated content",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "99b28173-1602-4a70-8449-215315e6bd91": {
        "id": "99b28173-1602-4a70-8449-215315e6bd91",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/elearner-tracking-tools-for-discovering-learner-behaviour(99b28173-1602-4a70-8449-215315e6bd91).html",
        "abstract": "<p>To be effective an e-Learning environment must be able to enrich and support student-centred teaming. In order to evaluate the effectiveness and hence refine the e-Learning approach, it is important to understand how learners make use of the e-Learning materials and interact with the associated delivery environment. This paper presents a set of tools to track, analyse and display learners' interactions within a virtual teaming environment (VLE). The information obtained is used to derive views of the data, including coverage of the course content, information about the users of the system and routes taken through the course. These can provide a valuable input when evaluating the effectiveness of the e-Learning materials and framework. The tooling is extensible and can provide additional views of data if required. The tools are not coupled to any VLE, so can be used to supplement existing tracking data.</p>",
        "title": "e-learner tracking: Tools for discovering learner behaviour",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "54b8c7d2-1142-4392-9478-25429c5603d9": {
        "id": "54b8c7d2-1142-4392-9478-25429c5603d9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/tracking-and-visualisation-of-student-use-of-online-learning-materials-in-a-large-undergraduate-course(54b8c7d2-1142-4392-9478-25429c5603d9).html",
        "abstract": "This paper presents a detailed study that tracks the use of online supplementary material used by 250 students enrolled on an introductory University course in Physics. We describe the software tools used for tracking, which provide a richer and far greater level of detail than tools included as standard within Virtual Learning Environments. We also describe how the recorded data can be visualised in order to illuminate spatial and temporal routes taken by students through the material. The recorded styles of use are analysed in terms of students' level of achievement, as measured by their performance in the end-of-course examination, and how this changes for students failing the course and resitting the exam six months later. \u00a9 2008 Springer-Verlag Berlin Heidelberg.",
        "title": "Tracking and visualisation of student use of online learning materials in a large undergraduate course",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "42285117-a1d9-426b-9610-2d1b32c96753": {
        "id": "42285117-a1d9-426b-9610-2d1b32c96753",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/protection-appts-for-multiconductor-connectoruses-layer-of-gel-having-holes-sealing-up-against-contact-pins-when-gel-is-compressed(42285117-a1d9-426b-9610-2d1b32c96753).html",
        "abstract": "",
        "title": "Protection appts. for multi-conductor connector|uses layer of gel having holes sealing up against contact pins when gel is compressed",
        "keywords": "",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "8e3f3756-8534-4ed7-a4d7-076255037172": {
        "id": "8e3f3756-8534-4ed7-a4d7-076255037172",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/microwavespectra-of-cf3br-and-cf3i--structures-and-dipolemoments(8e3f3756-8534-4ed7-a4d7-076255037172).html",
        "abstract": "",
        "title": "MICROWAVE-SPECTRA OF CF3BR AND CF3I - STRUCTURES AND DIPOLE-MOMENTS",
        "keywords": "",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "d30746db-8389-4924-80fb-16b45da4ad66": {
        "id": "d30746db-8389-4924-80fb-16b45da4ad66",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/determination-of-a-highpotential-barrier-hindering-internalrotation-from-the-groundstate-spectrum--the-methylbarrier-of-cispropanal(d30746db-8389-4924-80fb-16b45da4ad66).html",
        "abstract": "",
        "title": "DETERMINATION OF A HIGH-POTENTIAL BARRIER HINDERING INTERNAL-ROTATION FROM THE GROUND-STATE SPECTRUM - THE METHYLBARRIER OF CIS-PROPANAL",
        "keywords": "",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "5f424bab-1998-4682-88b8-e52b0c59d1c7": {
        "id": "5f424bab-1998-4682-88b8-e52b0c59d1c7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/microwavespectrum-of-acetaldehyde-with-asymmetric-ch2d-and-chd2-internal-rotors(5f424bab-1998-4682-88b8-e52b0c59d1c7).html",
        "abstract": "",
        "title": "MICROWAVE-SPECTRUM OF ACETALDEHYDE WITH ASYMMETRIC CH2D AND CHD2 INTERNAL ROTORS",
        "keywords": "",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "4d3b30a9-482f-41b4-a43f-94275828d66c": {
        "id": "4d3b30a9-482f-41b4-a43f-94275828d66c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/microwavespectrum-and-rotationalisomerism-of-gaseous-nitrosoethane-ch3ch2no(4d3b30a9-482f-41b4-a43f-94275828d66c).html",
        "abstract": "<p>The microwave spectrum of gaseous nitrosoethane has been measured in the 7-40 GHz region. The monomeric vapour is shown to exist as two rotational isomers, one the cis form with a planar heavy-atom structure, the other a staggered gauche conformer. The microwave spectrum of gauche-nitrosoethane shows large centrifugal distortion shifts and additional splitting arising from tunnelling through the trans barrier. Relative intensity measurements show the cis to be more stable than the gauche form by 2.1 +/- 0.4 kJ mol-1. The dipole moments were determined through the Stark effect: mu(a) = 2.316 (2), mu(b) = 0.623 (4) and mu(t) = 2.398 (2) D (1 D almost-equal-to 3.33564 x 10(-30) C m) for the N-15 cis, and mu(a) = 2.288 (4), mu(b) = 0.814 (5), mu(c) = 0.460 (9) and mu(t) = 2.471 (4) D for the N-15 gauche form. Nitrogen-14 quadrupole coupling constants have been determined to be chi(aa) = -2.525 (56) and (chi(bb) - chi(cc)) = -7.311 (97) MHz for the cis, and (chi(bb) - chi(cc)) = 3.518 (40) MHz for the gauche conformer.</p><p>Molecular structures have been calculated for both conformers on the basis of the oxygen-18, nitrogen-15 and main species data. The angle CCN angle opens up by 8-degrees on going from gauche- to cis-nitrosoethane. The barrier hindering internal rotation of the methyl group is the same for both conformers within experimental error, V3 = 10.9 +/- 0.3 kJ mol-1 for the cis form and 10.9 +/- 0.3 kJ mol-1 for the gauche conformer.</p>",
        "title": "MICROWAVE-SPECTRUM AND ROTATIONAL-ISOMERISM OF GASEOUS NITROSOETHANE, CH3CH2NO",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "935c369b-5672-490b-ab3c-1c9a1a7ff229": {
        "id": "935c369b-5672-490b-ab3c-1c9a1a7ff229",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-microwavespectrum-and-potential-function-of-propanal(935c369b-5672-490b-ab3c-1c9a1a7ff229).html",
        "abstract": "",
        "title": "THE MICROWAVE-SPECTRUM AND POTENTIAL FUNCTION OF PROPANAL",
        "keywords": "",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "ee5716b7-c7fe-40da-915f-79ebb7a9945b": {
        "id": "ee5716b7-c7fe-40da-915f-79ebb7a9945b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-microwavespectrum-and-potential-function-of-nitrosoethane-ch3ch2no(ee5716b7-c7fe-40da-915f-79ebb7a9945b).html",
        "abstract": "<p>The potential function for internal rotation of the nitroso group in nitrosoethane, CH3CH2NO, has been determined. All available microwave data are fitted to the potential,</p><p>[GRAPHICS]</p><p>where V-1 = (-15), V-2 = 63(2), V-3 = 389(1), V-4 = 135(1) and V-5 = 166(2) cm(-1). Torsional fundamentals for the nitroso group (C-N) have been measured by microwave relative intensity measurements for both rotamers: nu(t)(cis) = 182(17) cm(-1) and nu(t)(gauche) = 61(19) cm(-1). The energy difference between the two stable conformers has been determined to be Delta W(gauche - cis) = 2.1(4) kJ mol(-1). The ground state torsional splitting for gauche CH3CH2NO has been re-evaluated as Delta E(+/-) = 153.5(4) MHz corresponding to a calculated value of the coupling constant T-be = 34.7 MHz. Accurate structural data have been used in the potential function calculations. The resulting potential is compared with those of some isoelectronic molecules.</p>",
        "title": "THE MICROWAVE-SPECTRUM AND POTENTIAL FUNCTION OF NITROSOETHANE, CH3CH2NO",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "566199a0-435c-4f66-8da4-d9812faa9d76": {
        "id": "566199a0-435c-4f66-8da4-d9812faa9d76",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/preliminary-investigation-into-the-prediction-of-stonefree-rates-after-shock-wave-lithotripsy-using-neural-networks(566199a0-435c-4f66-8da4-d9812faa9d76).html",
        "abstract": "",
        "title": "Preliminary investigation into the prediction of stone-free rates after shock wave lithotripsy using neural networks",
        "keywords": "",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "2cd89e7f-dafc-4c0d-9fdd-8f1d9f70c7ec": {
        "id": "2cd89e7f-dafc-4c0d-9fdd-8f1d9f70c7ec",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-evaluation-of-an-elearning-strategy-watching-the-elearners-learn(2cd89e7f-dafc-4c0d-9fdd-8f1d9f70c7ec).html",
        "abstract": "",
        "title": "An Evaluation of an e-Learning Strategy: Watching the e-Learners Learn",
        "keywords": "",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "1b7b0a70-53a1-492f-9ce1-dc17ef9e703b": {
        "id": "1b7b0a70-53a1-492f-9ce1-dc17ef9e703b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/how-learners-change-critical-moments-changing-minds(1b7b0a70-53a1-492f-9ce1-dc17ef9e703b).html",
        "abstract": "",
        "title": "How Learners Change: Critical Moments, Changing Minds",
        "keywords": "",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            }
        ]
    },
    "91734a8e-e903-44c5-9709-975e25c50113": {
        "id": "91734a8e-e903-44c5-9709-975e25c50113",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ligand-discovery-on-massively-parallel-systems(91734a8e-e903-44c5-9709-975e25c50113).html",
        "abstract": "",
        "title": "Ligand Discovery on Massively Parallel Systems",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Judy Hardy",
                "uuid": "5a78137c-d187-4661-b76a-42df9084cd16"
            },
            {
                "name": "Lorna Smith",
                "uuid": "5c748338-46b1-485e-95af-511b43c62836"
            }
        ]
    },
    "4c444833-43ac-4f94-8cd6-ed476058dd06": {
        "id": "4c444833-43ac-4f94-8cd6-ed476058dd06",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/extending-the-message-passing-interface-mpi-with-userlevel-schedules(4c444833-43ac-4f94-8cd6-ed476058dd06).html",
        "abstract": "Composability is one of seven reasons for the long-standing and continuing success of MPI. Extending MPI by composing its operations with user-level operations provides useful integration with the progress engine and completion notification methods of MPI. However, the existing extensibility mechanism in MPI (generalized requests) is not widely utilized and has significant drawbacks.<br/><br/>MPI can be generalized via scheduled communication primitives, for example, by utilizing implementation techniques from existing MPI-3 nonblocking collectives and from forthcoming MPI-4 persistent and partitioned APIs. Non-trivial schedules are used internally in some MPI libraries; but, they are not accessible to end-users.<br/>Message-based communication patterns can be built as libraries on top of MPI. Such libraries can have comparable implementation maturity and potentially higher performance than MPI library code, but do not require intimate knowledge of the MPI implementation. Libraries can provide performance-portable interfaces that cross MPI implementation boundaries. The ability to compose additional user-defined operations using the same progress engine benefits all kinds of general purpose HPC libraries.<br/><br/>We propose a definition for MPI schedules: a user-level programming model suitable for creating persistent collective communication composed with new application-specific sequences of user-defined operations managed by MPI and fully integrated with MPI progress and completion notification. The API proposed offers a path to standardization for extensible communication schedules involving user-defined operations. Our approach has the potential to introduce event-driven programming into MPI (beyond the tools interface), although connecting schedules with events comprises future work.<br/><br/>Early performance results described here are promising and indicate strong overlap potential.",
        "title": "Extending the Message Passing Interface (MPI) with User-Level Schedules",
        "keywords": "",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            }
        ]
    },
    "15d32eca-9d28-46f6-bf21-aaa8a71a7f0d": {
        "id": "15d32eca-9d28-46f6-bf21-aaa8a71a7f0d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mpi-sessions-evaluation-of-an-implementation-in-open-mpi(15d32eca-9d28-46f6-bf21-aaa8a71a7f0d).html",
        "abstract": "The recently proposed MPI Sessions extensions to the MPI standard present a new paradigm for applications to use with MPI. MPI Sessions has the potential to address several limitations of MPI\u2019s current specification: MPI cannot be initialized within an MPI process from different application components without a priori knowledge or coordination; MPI cannot be initialized more than once; and, MPI cannot be reinitialized after MPI finalization. MPI Sessions also offers the possibility for more flexible ways for individual components of an application to express the capabilities they require from MPI at a finer granularity than is presently possible.<br/><br/>At this time, MPI Sessions has reached sufficient maturity for implementation and evaluation, which are the focuses of this paper. This paper presents a prototype implementation of MPI Sessions, discusses certain of its performance characteristics, and describes its successful use in a large-scale production MPI application. Overall, MPI Sessions is shown to be implementable, integrable with key infrastructure, and effective, but with certain overheads involving the initialization of MPI as well as communicator construction. Small impacts on message-passing latency and throughput are noted. Open MPI was used as the implementation vehicle, but results here are also relevant to other middleware stacks.",
        "title": "MPI Sessions: Evaluation of an Implementation in Open MPI",
        "keywords": "",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            }
        ]
    },
    "40721949-f868-4437-b5dd-68f64a99efe4": {
        "id": "40721949-f868-4437-b5dd-68f64a99efe4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mpi-semantic-terms-and-conventions-explained(40721949-f868-4437-b5dd-68f64a99efe4).html",
        "abstract": "",
        "title": "MPI Semantic Terms and Conventions Explained",
        "keywords": "",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            }
        ]
    },
    "e5cefdb1-0d25-42d8-83e8-33e41bafe9ca": {
        "id": "e5cefdb1-0d25-42d8-83e8-33e41bafe9ca",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/userlevel-schedules(e5cefdb1-0d25-42d8-83e8-33e41bafe9ca).html",
        "abstract": "",
        "title": "User-level schedules",
        "keywords": "",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            }
        ]
    },
    "6cf3b8ea-2939-4712-895e-f75a8aa32541": {
        "id": "6cf3b8ea-2939-4712-895e-f75a8aa32541",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/exposition-clarification-and-expansion-of-mpi-semantic-terms-and-conventions-is-a-nonblocking-mpi-function-permitted-to-block(6cf3b8ea-2939-4712-895e-f75a8aa32541).html",
        "abstract": "",
        "title": "Exposition, clarification, and expansion of MPI semantic terms and conventions: is a nonblocking MPI function permitted to block?",
        "keywords": "",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            }
        ]
    },
    "7ba0389a-6d97-4f02-9ac0-6d806a223ce1": {
        "id": "7ba0389a-6d97-4f02-9ac0-6d806a223ce1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/improving-the-interoperability-between-mpi-and-taskbased-programming-models(7ba0389a-6d97-4f02-9ac0-6d806a223ce1).html",
        "abstract": "In this paper we propose an API to pause and resume task execution depending on external events. We leverage this generic API to improve the interoperability between MPI synchronous communication primitives and tasks. When an MPI operation blocks, the task running is paused so that the runtime system can schedule a new task on the core that became idle. Once the MPI operation is completed, the paused task is put again on the runtime system's ready queue. We expose our proposal through a new MPI threading level which we implement through two approaches.<br/><br/>The first approach is an MPI wrapper library that works with any MPI implementation by intercepting MPI synchronous calls, implementing them on top of their asynchronous counterparts. In this case, the task-based runtime system is also extended to periodically check for pending MPI operations and resume the corresponding tasks once MPI operations complete. The second approach consists in directly modifying the MPICH runtime system, a well-known implementation of MPI, to directly call the pause/resume API when a synchronous MPI operation blocks and completes, respectively.<br/><br/>Our experiments reveal that this proposal not only simplifies the development of hybrid MPI+OpenMP applications that naturally overlap computation and communication phases; it also improves application performance and scalability by removing artificial dependencies across communication tasks.",
        "title": "Improving the Interoperability between MPI and Task-Based Programming Models",
        "keywords": "",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            }
        ]
    },
    "8f417fc0-7a91-4cba-b7f3-0ad29a05788d": {
        "id": "8f417fc0-7a91-4cba-b7f3-0ad29a05788d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/planning-for-performance-enhancing-achievable-performance-for-mpi-through-persistent-collective-operations(8f417fc0-7a91-4cba-b7f3-0ad29a05788d).html",
        "abstract": "Advantages of nonblocking collective communication in MPI have been established over the past quarter century, even predating MPI-1. For regular computations with fixed communication patterns, significant additional optimizations can be revealed through the use of persistence (planned transfers) not currently available in the MPI-3 API except for a limited form of point-to-point persistence (aka half-channels) standardized since MPI-1. This paper covers the design, prototype implementation of LibPNBC (based on LibNBC), and MPI-4 standardization status of persistent nonblocking collective operations. We provide early performance results, using a modified version of NBCBench and an example application (based on 3D conjugate gradient) illustrating the potential performance enhancements for such operations. Persistent operations enable MPI implementations to make intelligent choices about algorithm and resource utilization once and amortize this decision cost across many uses in a long-running program. Evidence that this approach is of value is provided. As with non-persistent, nonblocking collective operations, the requirement for strong progress and blocking completion notification are jointly needed to maximize the benefit of such operations (e.g., to support overlap of communication with computation and/or other communication). Further enhancement of the current reference implementation, as well as additional opportunities to enhance performance through the application of these new APIs, comprise future work.",
        "title": "Planning for Performance: Enhancing Achievable Performance for MPI through Persistent Collective Operations",
        "keywords": "",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            }
        ]
    },
    "f483bbc3-fe1a-4676-8839-cf80c38542f6": {
        "id": "f483bbc3-fe1a-4676-8839-cf80c38542f6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-data-streaming-model-in-mpi(f483bbc3-fe1a-4676-8839-cf80c38542f6).html",
        "abstract": "Data streaming model is an effective way to tackle the challenge of data-intensive applications. As traditional HPC applications generate large volume of data and more data-intensive applications move to HPC infrastructures, it is necessary to investigate the feasibility of combining message-passing and streaming programming models. MPI, the de facto standard for programming on HPC, cannot intuitively express the communication pattern and the functional operations required in streaming models. In this work, we designed and implemented a data streaming library MPIStream atop MPI to allocate data producers and consumers, to stream data continuously or irregularly and to process data at run-time. In the same spirit as the STREAM benchmark, we developed a parallel stream benchmark to measure data processing rate. The performance of the library largely depends on the size of the stream element, the number of data producers and consumers and the computational intensity of processing one stream element. With 2,048 data producers and 2,048 data consumers in the parallel benchmark, MPIStream achieved 200 GB/s processing rate on a Blue Gene/Q supercomputer. We illustrate that a streaming library for HPC applications can effectively enable irregular parallel I/O, application monitoring and threshold collective operations.<br/><br/>",
        "title": "A data streaming model in MPI",
        "keywords": "",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "6ab9b878-9db3-4af0-a170-a06f68e2ea6b": {
        "id": "6ab9b878-9db3-4af0-a170-a06f68e2ea6b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/planning-for-performance-persistent-collective-operations-for-mpi(6ab9b878-9db3-4af0-a170-a06f68e2ea6b).html",
        "abstract": "Advantages of nonblocking collective communication in MPI have been established over the past quarter century, even predating MPI-1. For regular computations with fixed communication patterns, more optimizations can be revealed through the use of persistence (planned transfers) not currently available in the MPI-3 API except for a limited form of point-to-point persistence (aka half-channels) standardized since MPI-1. This paper covers the design, prototype implementation of LibPNBC (based on LibNBC), and MPI-4 standardization status of persistent nonblocking collective operations. We provide early performance results, using a modified version of NBCBench and an example illustrating the potential performance enhancements for such operations. Persistent operations allow MPI implementations to make intelligent choices about algorithm and resource utilization once and amortize this decision cost across many uses in a long-running program. Evidence that this approach is of value is provided. As with non-persistent, nonblocking collective operations, the requirement for strong progress and blocking completion notification are jointly needed to maximize the benefit of such operations (e.g., overlap of communication with computation or other communication). Further enhancement of the current implementation prototype as well as additional opportunities to enhance performance through the application of these new APIs comprise future work.",
        "title": "Planning for Performance: Persistent Collective Operations for MPI",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            }
        ]
    },
    "c5d3303d-3cf7-4ecd-bfe0-f65d8ace595f": {
        "id": "c5d3303d-3cf7-4ecd-bfe0-f65d8ace595f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/streams-as-an-alternative-to-halo-exchange(c5d3303d-3cf7-4ecd-bfe0-f65d8ace595f).html",
        "abstract": "",
        "title": "Streams as an alternative to halo exchange",
        "keywords": "",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            }
        ]
    },
    "88e93af7-89ee-4184-b95e-cda4ccb6f544": {
        "id": "88e93af7-89ee-4184-b95e-cda4ccb6f544",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-epigram-project-preparing-parallel-programming-models-for-exascale(88e93af7-89ee-4184-b95e-cda4ccb6f544).html",
        "abstract": "EPiGRAM is a European Commission funded project to improve existing parallel programming models to run efficiently large scale applications on exascale supercomputers. The EPiGRAM project focuses on the two current dominant petascale programming models, message-passing and PGAS, and on the improvement of two of their associated programming systems, MPI and GASPI. In EPiGRAM, we work on two major aspects of programming systems. First, we improve the performance of communication operations by decreasing the memory consumption, improving collective operations and introducing emerging computing models. Second, we enhance the interoperability of message-passing and PGAS by integrating them in one PGAS-based MPI implementation, called <i>EMPI4Re</i>, implementing MPI endpoints and improving GASPI interoperability with MPI. The new EPiGRAM concepts are tested in two large-scale applications, iPIC3D, a Particle-in-Cell code for space physics simulations, and Nek5000, a Computational Fluid Dynamics code.",
        "title": "The EPiGRAM Project: Preparing Parallel Programming Models for Exascale",
        "keywords": "",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "d26fe05b-347d-41eb-ac78-b8e9e9a21079": {
        "id": "d26fe05b-347d-41eb-ac78-b8e9e9a21079",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mpi-sessions-leveraging-runtime-infrastructure-to-increase-scalability-of-applications-at-exascale(d26fe05b-347d-41eb-ac78-b8e9e9a21079).html",
        "abstract": "",
        "title": "MPI Sessions: Leveraging Runtime Infrastructure to Increase Scalability of Applications at Exascale",
        "keywords": "",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            }
        ]
    },
    "93696fd4-d783-4dba-a11b-fce137e4537c": {
        "id": "93696fd4-d783-4dba-a11b-fce137e4537c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mcmpi(93696fd4-d783-4dba-a11b-fce137e4537c).html",
        "abstract": "<p>This paper presents McMPI, an entirely new MPI library written in C# using only safe managed-code, and performance results from low-level benchmarks demonstrating ping-pong latency and bandwidth comparable with MS-MPI and MPICH2. McMPI enables all .Net languages to use MPI messaging without introducing a dependency on unsafe non-managed code, e.g. an existing MPI library. It also takes advantage of .Net thread support to improve intra-node latency. This paper also discusses support for multiple threads in McMPI and proposes an extension to the MPI Standard that resolves current ambiguities relating to hosting multiple MPI processes in a single operating system process.</p>",
        "title": "McMPI",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Daniel Holmes",
                "uuid": "453e012c-8207-4cab-b753-aab42b071182"
            },
            {
                "name": "Stephen Booth",
                "uuid": "b1fdf0bf-ae1e-4b47-94f6-a488f8d2f14c"
            }
        ]
    },
    "4f359076-9be1-4331-bc8c-8df98df52216": {
        "id": "4f359076-9be1-4331-bc8c-8df98df52216",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/case-studies-in-automatic-gpgpu-code-generation-with-llc(4f359076-9be1-4331-bc8c-8df98df52216).html",
        "abstract": "The evolution of high performance computers is progressing toward increasingly heterogeneous systems. These new architectures pose new challenges, particularly in the field of programming languages. New tools and languages are needed if we want to make a full use of the advantages offered by these new architectures. llc is a language with a C-like syntax where parallelism is expressed using compiler directives. In this work we focus our attention on the new backend of our prototype compiler for llc which generates CUDA code. We evaluate the performance of the target code using three different applications. The preliminary results that we present make us believe that our approach is worth to be explored more deeply.",
        "title": "Case studies in automatic gPGPU code generation with llc",
        "keywords": "",
        "authors": [
            {
                "name": "Ruyman Reyes Castro",
                "uuid": "eaf9f1b5-3190-49ef-a8d0-663996c70871"
            }
        ]
    },
    "99d6b393-1066-47c7-9b6d-9433a714c3f2": {
        "id": "99d6b393-1066-47c7-9b6d-9433a714c3f2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/directivebased-programming-for-gpus(99d6b393-1066-47c7-9b6d-9433a714c3f2).html",
        "abstract": "GPUs and other accelerators are available on many different devices, while GPGPU has been massively adopted by the HPC research community. Although a plethora of libraries and applications providing GPU support are available, the need of implementing new algorithms from scratch, or adapting sequential programs to accelerators, will always exist. Writing CUDA or OpenCL codes, although an easier task than using their predecessors, is not trivial. Obtaining performance is even harder, as it requires deep understanding of the underlying architecture. Some efforts have been directed toward the automatic code generation for GPU devices, with different results. In particular, several directive-oriented programming models, taking advantage of the OpenMP success, have been created. Although future OpenMP releases will integrate accelerators into the standard, tools are needed in the meantime. In this work, we present a comparison between three directive-based programming models: hiCUDA, PGI Accelerator and OpenACC, using for the last our novel accULL implementation. With this comparison, we aim to showcase the evolution of the directive-based programming models and how users can guide tools toward better performance results.",
        "title": "Directive-based programming for GPUs",
        "keywords": "",
        "authors": [
            {
                "name": "Ruyman Reyes Castro",
                "uuid": "eaf9f1b5-3190-49ef-a8d0-663996c70871"
            }
        ]
    },
    "02199177-e5b6-432d-9d34-23e3b7c3e5bb": {
        "id": "02199177-e5b6-432d-9d34-23e3b7c3e5bb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/accull(02199177-e5b6-432d-9d34-23e3b7c3e5bb).html",
        "abstract": "The world of HPC is undergoing rapid changes and computer architectures capable to achieve high performance have broadened. The irruption in the scene of computational accelerators, like GPUs, is increasing performance while maintaining low cost per GFLOP, thus expanding the popularity of HPC. However, it is still difficult to exploit the new complex processor hierarchies. To adapt the message passing model to program heterogeneous CPU+GPUs environments is not an easy task. Furthermore, message passing does not seem to be the best choice from the programmer point of view. Traditional shared memory approaches like OpenMP are interesting to ease the popularization of these platforms, but the fact is that GPU devices are connected to the CPU through a bus and have a separate memory space. We need to find a way to deal with this issue at programming language level, otherwise, developers will spend most of their time focusing on low-level code details instead of algorithmic enhancements. The recent advent of the OpenACC standard for heterogeneous computing represents an effort in the direction of leveraging the development effort. This initiative, combined with future releases of the OpenMP standard, will converge into a fully heterogeneous framework that will cope the programming requirements of future computer architectures. In this work we present preliminary results of accULL, a novel implementation of the OpenACC standard, based on a source-to-source compiler and a runtime library. To our knowledge, our approach is the first providing support for both OpenCL and CUDA platforms under this new standard.",
        "title": "accULL",
        "keywords": "",
        "authors": [
            {
                "name": "Ruyman Reyes Castro",
                "uuid": "eaf9f1b5-3190-49ef-a8d0-663996c70871"
            }
        ]
    },
    "ac7d1963-156b-4c7b-95ec-ca3cd03bd991": {
        "id": "ac7d1963-156b-4c7b-95ec-ca3cd03bd991",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/energy-efficient-and-co2-aware-cloud-computing(ac7d1963-156b-4c7b-95ec-ca3cd03bd991).html",
        "abstract": "<p>Energy efficiency and CO<sub>2</sub> awareness are globallyimportant issues in cloud computing. With increasing attention being paid to the environmental impact of cloud computing there are concerns about the sustainability of cloud computing model as its uptake increases. In this respect, we consider it useful to provide a snapshot of the requirements for energy efficient and CO <sub>2</sub> aware cloud computing to allow the conception and development of new techniques and approaches in this area. Further, we present a case study approach for energy efficient cloud sourcing that aims to build on these requirements.</p>",
        "title": "Energy efficient and CO2 aware cloud computing",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Gareth Francis",
                "uuid": "d93f1c2f-7c33-4cfe-bc7c-12d5bab05e67"
            }
        ]
    },
    "0b2301bd-2b8a-4513-9018-62cfade530ad": {
        "id": "0b2301bd-2b8a-4513-9018-62cfade530ad",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/federation-of-the-bonfire-multicloud-infrastructure-with-networking-facilities(0b2301bd-2b8a-4513-9018-62cfade530ad).html",
        "abstract": "<p>Network performance in terms of throughput, latency, packet loss or jitter significantly influences user's quality of experience of cloud applications. Network services impact on cloud applications performance and this impact is even more significant when the cloud infrastructure spreads over different administrative domains, such as in a federated cloud or hybrid-cloud scenarios. Given this strong coupling between cloud application performance and network performance there is great value to be gained by supporting advanced controlled networking functionalities between distributed cloud infrastructures. These functionalities would be useful to the Future Internet (FI) experimentation community as well as future production clouds. This paper describes an architecture and a set of procedures to interconnect a multi-cloud environment with advanced facilities for controlled networking. This integration allows the provisioning of customized network functions and services in support of experiments running in a multi-cloud test-bed. The possibility to control the network connectivity is a key feature to provide better performance for the experimenters' cloud applications. We focus on the details of federating three advanced networking facilities with the BonFIRE multi-cloud environment. These three networking facilities are: FEDERICA, which supports controlled routing; G\u00c9ANT's Bandwidth-on-Demand service and OFELIA that uses OpenFlow to provide Software Defined Network functionalities. The interconnections with FEDERICA and G\u00c9ANT are already active, while OFELIA is envisaged as future work for a third facility to interconnect.</p>",
        "title": "Federation of the BonFIRE multi-cloud infrastructure with networking facilities",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Gareth Francis",
                "uuid": "d93f1c2f-7c33-4cfe-bc7c-12d5bab05e67"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            }
        ]
    },
    "8c17df26-fb9e-48a4-be91-7675f7c7da74": {
        "id": "8c17df26-fb9e-48a4-be91-7675f7c7da74",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/autotuning-an-openacc-accelerated-version-of-nek5000(8c17df26-fb9e-48a4-be91-7675f7c7da74).html",
        "abstract": "",
        "title": "Auto-tuning an OpenACC Accelerated Version of Nek5000",
        "keywords": "",
        "authors": [
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            }
        ]
    },
    "6121d3db-623b-4678-916c-526e94839255": {
        "id": "6121d3db-623b-4678-916c-526e94839255",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/nekbone-with-optimized-openacc-directives(6121d3db-623b-4678-916c-526e94839255).html",
        "abstract": "",
        "title": "NekBone with Optimized OpenACC directives",
        "keywords": "",
        "authors": [
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            }
        ]
    },
    "60300300-c27c-4406-a280-cc4196d620d3": {
        "id": "60300300-c27c-4406-a280-cc4196d620d3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-stochastic-finite-element-method-for-nuclear-applications(60300300-c27c-4406-a280-cc4196d620d3).html",
        "abstract": "",
        "title": "The stochastic finite element method for nuclear applications",
        "keywords": "",
        "authors": [
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            }
        ]
    },
    "bf387f6c-59ec-4d01-bb34-fe7a9dc1f806": {
        "id": "bf387f6c-59ec-4d01-bb34-fe7a9dc1f806",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/scaling-hybrid-coarraympi-miniapps-on-archer(bf387f6c-59ec-4d01-bb34-fe7a9dc1f806).html",
        "abstract": "",
        "title": "Scaling hybrid coarray/MPI miniapps on Archer",
        "keywords": "",
        "authors": [
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            }
        ]
    },
    "993984c9-3253-4c20-919a-d01c398da6d7": {
        "id": "993984c9-3253-4c20-919a-d01c398da6d7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/fortran-coarraympimultiscale-cafe-for-fracture-in-heterogeneous-materials(993984c9-3253-4c20-919a-d01c398da6d7).html",
        "abstract": "",
        "title": "Fortran coarray/MPIMulti-scale CAFE for fracture in heterogeneous materials",
        "keywords": "",
        "authors": [
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            }
        ]
    },
    "aba9615e-fdf2-44ac-8336-d5e49f0ad08e": {
        "id": "aba9615e-fdf2-44ac-8336-d5e49f0ad08e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/multiscale-cafe-framework-for-simulating-fracture-in-heterogeneous-materials-implemented-in-fortran-coarrays-and-mpi(aba9615e-fdf2-44ac-8336-d5e49f0ad08e).html",
        "abstract": "Fortran coarrays have been used as an extension to the standard for over 20 years, mostly on Cray systems. Their appeal to users increased substantially when they were standardised in 2010. In this work we show that coarrays offer simple and intuitive data structures for 3D cellular automata (CA) modelling of material microstructures. We show how coarrays can be used together with an MPI finite element (FE) library to create a two-way concurrent hierarchical and scalable multi-scale CAFE deformation and fracture framework. Design of a coarray cellular automata microstructure evolution library CGPACK is described. A highly portable MPI FE library ParaFEM was used in this work. We show that independently CGPACK and ParaFEM programs can scale up well into tens of thousands of cores. Strong scaling of a hybrid ParaFEM/CGPACK MPI/coarray multi-scale framework was measured on an important solid mechanics practical example of a fracture of a steel round bar under tension. That program did not scale beyond 7 thousand cores. Excessive synchronisation might be one contributing factor to relatively poor scaling. Therefore we conclude with a comparative analysis of synchronisation requirements in MPI and coarray programs. Specific challenges of synchronising a coarray library are discussed.",
        "title": "Multi-scale CAFE framework for simulating fracture in heterogeneous materials implemented in Fortran co-arrays and MPI",
        "keywords": "",
        "authors": [
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            }
        ]
    },
    "320bdf4c-cf29-4a02-80ff-c8ec128c137a": {
        "id": "320bdf4c-cf29-4a02-80ff-c8ec128c137a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/interoperability-strategies-for-gaspi-and-mpi-in-large-scale-scientific-applications(320bdf4c-cf29-4a02-80ff-c8ec128c137a).html",
        "abstract": "One of the main hurdles of partitioned global address space (PGAS) approaches is the dominance of message passing interface (MPI), which as a de facto standard appears in the code basis of many applications. To take advantage of the PGAS APIs like global address space programming interface (GASPI) without a major change in the code basis, interoperability between MPI and PGAS approaches needs to be ensured. In this article, we consider an interoperable GASPI/MPI implementation for the communication/performance crucial parts of the Ludwig and iPIC3D applications. To address the discovered performance limitations, we develop a novel strategy for significantly improved performance and interoperability between both APIs by leveraging GASPI shared windows and shared notifications. First results with a corresponding implementation in the MiniGhost proxy application and the Allreduce collective operation demonstrate the viability of this approach.",
        "title": "Interoperability Strategies for GASPI and MPI in Large Scale Scientific Applications",
        "keywords": "",
        "authors": [
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            }
        ]
    },
    "2745c998-0294-406a-87bb-e33d6577297e": {
        "id": "2745c998-0294-406a-87bb-e33d6577297e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/modelling-fracture-in-heterogeneous-materials-on-hpc-systems-using-a-hybrid-mpifortran-coarray-multiscale-cafe-framework(2745c998-0294-406a-87bb-e33d6577297e).html",
        "abstract": "A 3D multi-scale cellular automata finite element (CAFE) framework for modelling fracture in heterogeneous materials is described. The framework is implemented in a hybrid MPI/Fortran coarray code for efficient parallel execution on HPC platforms. Two open source BSD licensed libraries developed by the authors in modern Fortran were used: CGPACK, implementing cellular automata (CA) using Fortran coarrays, and ParaFEM, implementing finite elements (FE) using MPI. The framework implements a two-way concurrent hierarchical information exchange between the structural level (FE) and the microstructure (CA). MPI to coarrays interface and data structures are described. The CAFE framework is used to predict transgranular cleavage propagation in a polycrystalline iron round bar under tension. Novel results enabled by this CAFE framework include simulation of progressive cleavage propagation through individual grains and across grain boundaries, and emergence of a macro-crack from merging of cracks on preferentially oriented cleavage planes in individual crystals. Nearly ideal strong scaling up to at least tens of thousands of cores was demonstrated by CGPACK and by ParaFEM in isolation in prior work on Cray XE6. Cray XC30 and XC40 platforms and CrayPAT profiling were used in this work. Initially the strong scaling limit of hybrid CGPACK/ParaFEM CAFE model was 2000 cores. After replacing all-to-all communication patterns with the nearest neighbour algorithms the strong scaling limit on Cray XC30 was increased to 7000 cores. TAU profiling on non-Cray systems identified deficiencies in Intel Fortran 16 optimisation of remote coarray operations. Finally, coarray synchronisation challenges and opportunities for thread parallelisation in CA are discussed.",
        "title": "Modelling fracture in heterogeneous materials on HPC systems using a hybrid MPI/Fortran coarray multi-scale CAFE framework",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            }
        ]
    },
    "c42f570b-9d2d-4d69-802e-0a803d884257": {
        "id": "c42f570b-9d2d-4d69-802e-0a803d884257",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mpi-vs-fortran-coarrays-beyond-100k-cores-3d-cellular-automata(c42f570b-9d2d-4d69-802e-0a803d884257).html",
        "abstract": "Fortran coarrays are an attractive alternative to MPI due to a familiar Fortran syntax, single sided communications and implementation in the compiler. Scaling of coarrays is compared in this work to MPI, using cellular automata (CA) 3D Ising magnetisation miniapps, built with the CASUP CA library, https://cgpack.sourceforge.io, developed by the authors. Ising energy and magnetisation were calculated with MPI_ALLREDUCE and Fortran 2018 co_sum collectives. The work was done on ARCHER (Cray XC30) up to the full machine capacity: 109,056 cores. Ping-pong latency and bandwidth results are very similar with MPI and with coarrays for message sizes from 1B to several MB. MPI halo exchange (HX) scaled better than coarray HX, which is surprising because both algorithms use pair-wise communications: MPI IRECV/ISEND/WAITALL vs Fortran sync images. Adding OpenMP to MPI or to coarrays resulted in worse L2 cache hit ratio, and lower performance in all cases, even though the NUMA effects were ruled out. This is likely because the CA algorithm is network bound at scale. This is further evidenced by the fact that very aggressive cache and inter-procedural optimisations lead to no performance gain. The sampling and tracing analysis shows good load balancing in compute in all miniapps, but imbalance in communication, indicating that the difference in performance between MPI and coarrays is likely due to parallel libraries (MPICH2 vs libpgas) and the Cray hardware specific libraries (uGNI vs DMAPP). Overall, the results look promising for coarray use beyond 100k cores. However, further coarray optimisation is needed to narrow the performance gap between coarrays and MPI.",
        "title": "MPI vs Fortran coarrays beyond 100k cores: 3D cellular automata",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            }
        ]
    },
    "f8b57836-15e4-492c-b9f0-dfab3987522c": {
        "id": "f8b57836-15e4-492c-b9f0-dfab3987522c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/autotuning-an-openacc-accelerated-version-of-nek5000(f8b57836-15e4-492c-b9f0-dfab3987522c).html",
        "abstract": "<p>Accelerators and, in particular, Graphics Processing Units (GPUs) have emerged as promising computing technologies which may be suitable for the future Exascale systems. However, the complexity of their architectures and the impenetrable structure of some large applications makes the hand-tuning algorithms process more challenging and unproductive. On the contrary, auto-tuning technology has appeared as a solution to this problems since it can address the inherent complexity of the latest and future computer architectures. By auto-tuning, an application may be optimised for a target platform by making automated optimal choices. To exploit this technology on modern GPUs, we have created an auto-tuned version of Nek5000 based on OpenACC directives which has demonstrated to obtained improved results over a hand-tune optimised version of the same computation kernels. This paper focuses on a particular role for auto-tuning Nek5000 to utilise a massively parallel GPU accelerated system based on OpenACC directive to adapt the Nek5000 code for the Exascale computation.</p>",
        "title": "Auto-tuning an OpenACC Accelerated Version of Nek5000",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            },
            {
                "name": "David Henty",
                "uuid": "9b898231-a59e-46f9-ad57-50520c64714c"
            }
        ]
    },
    "c89af082-6003-4b70-b707-5ccb3ed76805": {
        "id": "c89af082-6003-4b70-b707-5ccb3ed76805",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/regional-heritability-advanced-complex-trait-analysis-for-gpu-and-traditional-parallel-architectures(c89af082-6003-4b70-b707-5ccb3ed76805).html",
        "abstract": "Quantification of the contribution of genetic variation to phenotypic variation for complex traits becomes increasingly computationally demanding with increasing numbers of SNPs and individuals. To meet the challenges in making feasible large scale studies, we present the REACTA software. Adapted from ACTA (and, in turn, GCTA), it is tailored to exploit the parallelism present in modern traditional and GPU-accelerated machines, from workstations to supercomputers.",
        "title": "Regional Heritability Advanced Complex Trait Analysis for GPU and Traditional Parallel Architectures",
        "keywords": "",
        "authors": [
            {
                "name": "Luis Cebamanos",
                "uuid": "17de2d57-7fe8-420a-927b-1ab15928882c"
            },
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "f16240c4-9b39-4235-b13f-eee495758c60": {
        "id": "f16240c4-9b39-4235-b13f-eee495758c60",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/tempss-a-service-providing-software-parameter-templates-and-profiles-for-scientific-hpc(f16240c4-9b39-4235-b13f-eee495758c60).html",
        "abstract": "",
        "title": "TemPSS: A Service Providing Software Parameter Templates and Profiles for Scientific HPC",
        "keywords": "",
        "authors": [
            {
                "name": "Xu Guo",
                "uuid": "0150939e-12bd-44ca-881b-36e8463aee37"
            },
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            }
        ]
    },
    "30b36322-52df-44ce-af43-386a43faee09": {
        "id": "30b36322-52df-44ce-af43-386a43faee09",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/filmgrid-revolutionising-asset-management-in-a-filmoriented-postproduction-environment(30b36322-52df-44ce-af43-386a43faee09).html",
        "abstract": "",
        "title": "FilmGrid: Revolutionising Asset Management in a Film-Oriented Post-Production Environment",
        "keywords": "",
        "authors": [
            {
                "name": "Xu Guo",
                "uuid": "0150939e-12bd-44ca-881b-36e8463aee37"
            },
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Charaka Palansuriya",
                "uuid": "fa7ecedb-db73-44ce-9703-b55c93331e57"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "14cf9a9c-6bac-4173-a77c-9c628e3dce8b": {
        "id": "14cf9a9c-6bac-4173-a77c-9c628e3dce8b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/nek5000-with-openacc(14cf9a9c-6bac-4173-a77c-9c628e3dce8b).html",
        "abstract": "<p>Nek5000 is a computational fluid dynamics code based on the spectral element method used for the simulation of incompressible flows. We follow up on an earlier study which ported the simplified version of Nek5000 to a GPU-accelerated system by presenting the hybrid CPU/GPU implementation of the full Nek5000 code using OpenACC. The matrix-matrix multiplication, the Nek5000 gather-scatter operator and a preconditioned Conjugate Gradient solver have implemented using OpenACC for multi-GPU systems.We report an speed-up of 1.3 on single node of a Cray XK6 when using OpenACC directives in Nek5000. On 512 nodes of the Titan supercomputer, the speed-up can be approached to 1.4. A performance analysis of the Nek5000 code using Score-P and Vampir performance monitoring tools shows that overlapping of GPU kernels with host-accelerator memory transfers would considerably increase the performance of the OpenACC version of Nek5000 code.</p>",
        "title": "Nek5000 with OpenACC",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Henty",
                "uuid": "9b898231-a59e-46f9-ad57-50520c64714c"
            }
        ]
    },
    "a36396d3-5240-443d-afe3-7f8912b895fa": {
        "id": "a36396d3-5240-443d-afe3-7f8912b895fa",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/openacc-acceleration-of-the-nek5000-spectral-element-code(a36396d3-5240-443d-afe3-7f8912b895fa).html",
        "abstract": "<p>We present a case study of porting NekBone, a skeleton version of the Nek5000 code, to a parallel GPU-accelerated system. Nek5000 is a computational fluid dynamics code based on the spectral element method used for the simulation of incompressible flow. The original NekBone Fortran source code has been used as the base and enhanced by OpenACC directives. The profiling of NekBone provided an assessment of the suitability of the code for GPU systems, and indicated possible kernel optimizations. To port NekBone to GPU systems required little effort and a small number of additional lines of code (approximately one OpenACC directive per 1000 lines of code). The na\u00efve implementation using OpenACC leads to little performance improvement: on a single node, from 16 Gflops obtained with the version without OpenACC, we reached 20 Gflops with the na\u00efve OpenACC implementation. An optimized NekBone version leads to a 43 Gflop performance on a single node. In addition, we ported and optimized NekBone to parallel GPU systems, reaching a parallel efficiency of 79.9% on 1024 GPUs of the Titan XK7 supercomputer at the Oak Ridge National Laboratory.</p>",
        "title": "OpenACC acceleration of the Nek5000 spectral element code",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Henty",
                "uuid": "9b898231-a59e-46f9-ad57-50520c64714c"
            }
        ]
    },
    "51bd693c-8782-4fc5-a23d-3527f539e0ac": {
        "id": "51bd693c-8782-4fc5-a23d-3527f539e0ac",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/correction-to-(51bd693c-8782-4fc5-a23d-3527f539e0ac).html",
        "abstract": "<p>The authors regret that the original version of the above article contained errors in the Figs. 3, 4 and Tables 3 legends. The errors has been corrected.</p>",
        "title": "Correction to :",
        "keywords": "",
        "authors": [
            {
                "name": "Christopher Johnson",
                "uuid": "a8de15a3-eda9-4534-8b2d-a922f57bd7f9"
            }
        ]
    },
    "975b065b-1252-4492-9884-7385fdc30d32": {
        "id": "975b065b-1252-4492-9884-7385fdc30d32",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/differences-in-the-rotational-properties-of-multiple-stellar-populations-in-m13-a-faster-rotation-for-the-extreme-chemical-subpopulation(975b065b-1252-4492-9884-7385fdc30d32).html",
        "abstract": "We use radial velocities from spectra of giants obtained with the WIYN\ntelescope, coupled with existing chemical abundance measurements of Na\nand O for the same stars, to probe the presence of kinematic differences\namong the multiple populations of the globular cluster (GC) M13. To\ncharacterize the kinematics of various chemical subsamples, we introduce\na method using Bayesian inference along with a Markov chain Monte Carlo\nalgorithm to fit a six-parameter kinematic model (including rotation) to\nthese subsamples. We find that the so-called extreme population\n(Na-enhanced and extremely O-depleted) exhibits faster rotation around\nthe centre of the cluster than the other cluster stars, in particular,\nwhen compared with the dominant 'intermediate' population (moderately\nNa-enhanced and O-depleted). The most likely difference between the\nrotational amplitude of this extreme population and that of the\nintermediate population is found to be \u223c4 km s-1 , with a\n98.4 per cent probability that the rotational amplitude of the extreme\npopulation is larger than that of the intermediate population. We argue\nthat the observed difference in rotational amplitudes, obtained when\nsplitting subsamples according to their chemistry, is not a product of\nthe long-term dynamical evolution of the cluster, but more likely a\nsurviving feature imprinted early in the formation history of this GC\nand its multiple populations. We also find an agreement (within\nuncertainties) in the inferred position angle of the rotation axis of\nthe different subpopulations considered. We discuss the constraints that\nthese results may place on various formation scenarios.",
        "title": "Differences in the rotational properties of multiple stellar populations in M13: a faster rotation for the `extreme' chemical subpopulation",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Christopher Johnson",
                "uuid": "a8de15a3-eda9-4534-8b2d-a922f57bd7f9"
            }
        ]
    },
    "b46d9bec-b499-4075-86f6-d1caed85aefb": {
        "id": "b46d9bec-b499-4075-86f6-d1caed85aefb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cytokine-stimulation-for-in-vitro-models-of-early-oa(b46d9bec-b499-4075-86f6-d1caed85aefb).html",
        "abstract": "",
        "title": "Cytokine stimulation for in vitro models of early OA",
        "keywords": "",
        "authors": [
            {
                "name": "Christopher Johnson",
                "uuid": "a8de15a3-eda9-4534-8b2d-a922f57bd7f9"
            }
        ]
    },
    "7c0ddfad-b930-4c44-82d3-eae993027a08": {
        "id": "7c0ddfad-b930-4c44-82d3-eae993027a08",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/directed-differentiation-of-embryonic-stem-cells-using-a-beadbased-combinatorial-screening-method(7c0ddfad-b930-4c44-82d3-eae993027a08).html",
        "abstract": "<p>We have developed a rapid, bead-based combinatorial screening method to determine optimal combinations of variables that direct stem cell differentiation to produce known or novel cell types having pre-determined characteristics. Here we describe three experiments comprising stepwise exposure of mouse or human embryonic cells to 10,000 combinations of serum-free differentiation media, through which we discovered multiple novel, efficient and robust protocols to generate a number of specific hematopoietic and neural lineages. We further demonstrate that the technology can be used to optimize existing protocols in order to substitute costly growth factors with bioactive small molecules and/or increase cell yield, and to identify in vitro conditions for the production of rare developmental intermediates such as an embryonic lymphoid progenitor cell that has not previously been reported.</p>",
        "title": "Directed differentiation of embryonic stem cells using a bead-based combinatorial screening method",
        "keywords": "",
        "authors": [
            {
                "name": "Christopher Johnson",
                "uuid": "a8de15a3-eda9-4534-8b2d-a922f57bd7f9"
            }
        ]
    },
    "6bde7dc7-141d-4ee8-913d-73c8daba9bb6": {
        "id": "6bde7dc7-141d-4ee8-913d-73c8daba9bb6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/bounds-on-the-convergence-of-ritz-values-from-krylov-subspaces-to-interior-eigenvalues-of-hermitean-matrices(6bde7dc7-141d-4ee8-913d-73c8daba9bb6).html",
        "abstract": "We consider bounds on the convergence of Ritz values from a sequence of Krylov subspaces to interior eigenvalues of Hermitean matrices. These bounds are useful in regions of low spectral density, for example near voids in the spectrum, as is required in many applications. Our bounds are obtained by considering the usual Kaniel-Paige-Saad formalism applied to the shifted and squared matrix.",
        "title": "Bounds on the convergence of Ritz values from Krylov subspaces to interior eigenvalues of Hermitean matrices",
        "keywords": "",
        "authors": [
            {
                "name": "Christopher Johnson",
                "uuid": "a8de15a3-eda9-4534-8b2d-a922f57bd7f9"
            }
        ]
    },
    "e0754dd2-c9ed-4a9b-bcb6-bf6e6ad91903": {
        "id": "e0754dd2-c9ed-4a9b-bcb6-bf6e6ad91903",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dynamical-transition-in-the-openboundary-totally-asymmetric-exclusion-process(e0754dd2-c9ed-4a9b-bcb6-bf6e6ad91903).html",
        "abstract": "<p>We revisit the totally asymmetric simple exclusion process (TASEP) with open boundaries, focussing on the recent discovery by de Gier and Essler that the model has a dynamical transition along a nontrivial line in the phase diagram. This line coincides neither with any change in the steady-state properties of the TASEP nor with the corresponding line predicted by the domain wall theory. We provide numerical evidence that the TASEP indeed has a dynamical transition along the de Gier-Essler line, finding that the most convincing evidence was obtained from the density matrix renormalization group calculations. By contrast, we find that the dynamical transition is rather difficult to see in direct Monte Carlo simulations of the TASEP. We furthermore discuss in general terms scenarios that admit a distinction between the static and dynamic phase behaviour.</p>",
        "title": "Dynamical transition in the open-boundary totally asymmetric exclusion process",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Arno Proeme",
                "uuid": "1c3c288f-8a74-4f3a-90e8-ee7742784b58"
            }
        ]
    },
    "a862b1f9-0178-408c-b96c-9cc34ac0d748": {
        "id": "a862b1f9-0178-408c-b96c-9cc34ac0d748",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/duloxetine-a-serotonin-and-noradrenaline-reuptake-inhibitor-snri-for-the-treatment-of-stress-urinary-incontinence(a862b1f9-0178-408c-b96c-9cc34ac0d748).html",
        "abstract": "<p>Objective: Surgery and pelvic floor muscle training are established methods for treating stress urinary incontinence (SUI). A new serotonin and noradrenaline reuptake inhibitor, duloxetine, has been studied in multiple phase 3 trials as a form of medical management of this condition. This systematic review determined the effectiveness and acceptability of duloxetine in managing SUI. Methods: We reviewed all randomised controlled trials comparing duloxetine with placebo or no treatment. The search included the Cochrane Incontinence Group specialised register, CENTRAL, MEDLINE, PREMEDLINE, dissertation abstracts, and the reference lists of relevant articles. The primary outcome was the number of participants whose symptoms were \"cured\" while on treatment. Secondary outcomes included subjective improvement, incontinent episodes, quality of life, adverse events, and discontinuation rates. Results: Nine trials were included, totalling 3063 women with predominantly SUI, all randomised to receive duloxetine or placebo. Treatment duration was 3-36 wk. Subjective cure favoured duloxetine (from three trials, 10.8% vs. 7.7%; RR = 1.42; 95%CI, 1.02-1.98, p = 0.04). The limited data available to assess objective cure rates were consistent with this. Individual studies showed a significant reduction in the Incontinence Episode Frequency (IEF) by approximately 50% during treatment. Duloxetine groups had significantly better quality-of-life scores (weighted mean difference for Incontinence Quality of Life Index for participants on 80 mg daily: 4.5; 95%CI, 2.83-6.18; p &lt; 0.00001) and rates of symptom improvement. Adverse effects were common (71% vs. 59%) but are reported as not serious and were equivalent to about one in eight participants reporting adverse effects (most commonly nausea) directly related to duloxetine treatment. About one in eight stopped treatment as a consequence of taking duloxetine (17% vs. 4%). Conclusions: Duloxetine can significantly improve the quality of life of patients with SUI, but it is unclear whether or not benefits are sustainable. Side-effects such as nausea are common.</p>",
        "title": "Duloxetine, a Serotonin and Noradrenaline Reuptake Inhibitor (SNRI) for the Treatment of Stress Urinary Incontinence",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Alistair Grant",
                "uuid": "2a4c1816-597b-4031-b6e9-a0a7cb1854e6"
            }
        ]
    },
    "563466b8-dd95-441f-991a-57f2dda0430b": {
        "id": "563466b8-dd95-441f-991a-57f2dda0430b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/multimessenger-observations-of-a-binary-neutron-star-merger(563466b8-dd95-441f-991a-57f2dda0430b).html",
        "abstract": "On 2017 August 17 a binary neutron star coalescence candidate (later designated GW170817) with merger time 12:41:04 UTC was observed through gravitational waves by the Advanced LIGO and Advanced Virgo detectors. The\u00a0<i style=\"margin: 0px; padding: 0px; border: 0px; font-style: italic; font-variant-ligatures: normal; font-variant-caps: normal; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-weight: 400; font-stretch: inherit; font-size: 18px; line-height: inherit; font-family: minion-pro, Georgia, &quot;Times New Roman&quot;, STIXGeneral, serif; vertical-align: baseline; color: rgb(51, 51, 51); letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-style: initial; text-decoration-color: initial;\">Fermi</i>\u00a0Gamma-ray Burst Monitor independently detected a gamma-ray burst (GRB 170817A) with a time delay of\u00a0\u00a0with respect to the merger time. From the gravitational-wave signal, the source was initially localized to a sky region of 31 deg<sup style=\"margin: 0px; padding: 0px; border: 0px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-weight: 400; font-stretch: inherit; font-size: 13.5px; line-height: 1; font-family: minion-pro, Georgia, &quot;Times New Roman&quot;, STIXGeneral, serif; vertical-align: baseline; position: relative; height: 0px; bottom: 1ex; color: rgb(51, 51, 51); letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-style: initial; text-decoration-color: initial;\">2</sup>\u00a0at a luminosity distance of\u00a0\u00a0Mpc and with component masses consistent with neutron stars. The component masses were later measured to be in the range 0.86 to 2.26\u00a0. An extensive observing campaign was launched across the electromagnetic spectrum leading to the discovery of a bright optical transient (SSS17a, now with the IAU identification of AT 2017gfo) in NGC 4993 (at\u00a0) less than 11 hours after the merger by the One-Meter, Two Hemisphere (1M2H) team using the 1 m Swope Telescope. The optical transient was independently detected by multiple teams within an hour. Subsequent observations targeted the object and its environment. Early ultraviolet observations revealed a blue transient that faded within 48 hours. Optical and infrared observations showed a redward evolution over ~10 days. Following early non-detections, X-ray and radio emission were discovered at the transient's position\u00a0\u00a0and\u00a0\u00a0days, respectively, after the merger. Both the X-ray and radio emission likely arise from a physical process that is distinct from the one that generates the UV/optical/near-infrared emission. No ultra-high-energy gamma-rays and no neutrino candidates consistent with the source were found in follow-up searches. These observations support the hypothesis that GW170817 was produced by the merger of two neutron stars in NGC 4993 followed by a short gamma-ray burst (GRB 170817A) and a kilonova/macronova powered by the radioactive decay of\u00a0<i style=\"margin: 0px; padding: 0px; border: 0px; font-style: italic; font-variant-ligatures: normal; font-variant-caps: normal; font-variant-numeric: inherit; font-variant-east-asian: inherit; font-weight: 400; font-stretch: inherit; font-size: 18px; line-height: inherit; font-family: minion-pro, Georgia, &quot;Times New Roman&quot;, STIXGeneral, serif; vertical-align: baseline; color: rgb(51, 51, 51); letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-style: initial; text-decoration-color: initial;\">r</i>-process nuclei synthesized in the ejecta.",
        "title": "Multi-messenger Observations of a Binary Neutron Star Merger",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alistair Grant",
                "uuid": "2a4c1816-597b-4031-b6e9-a0a7cb1854e6"
            }
        ]
    },
    "a54c847c-26ba-46dc-bbd0-20a1c71d2efe": {
        "id": "a54c847c-26ba-46dc-bbd0-20a1c71d2efe",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/pelvic-floor-muscle-training-after-prostate-surgery-reply(a54c847c-26ba-46dc-bbd0-20a1c71d2efe).html",
        "abstract": "",
        "title": "Pelvic floor muscle training after prostate surgery Reply",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alistair Grant",
                "uuid": "2a4c1816-597b-4031-b6e9-a0a7cb1854e6"
            }
        ]
    },
    "1f4c83e0-78b2-43eb-8715-b5b39321daac": {
        "id": "1f4c83e0-78b2-43eb-8715-b5b39321daac",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/conservative-treatment-for-urinary-incontinence-in-men-after-prostate-surgery-maps(1f4c83e0-78b2-43eb-8715-b5b39321daac).html",
        "abstract": "<p>Objective: To determine the clinical effectiveness and cost-effectiveness of active conservative treatment, compared with standard management, in regaining urinary continence at 12 months in men with urinary incontinence at 6 weeks after a radical prostatectomy or a transurethral resection of the prostate (TURP). Background: Urinary incontinence after radical prostate surgery is common immediately after surgery, although the chance of incontinence is less after TURP than following radical prostatectomy. Design: Two multicentre, UK, parallel randomised controlled trials (RCTs) comparing active conservative treatment [pelvic floor muscle training (PFMT) delivered by a specialist continence physiotherapist or a specialist continence nurse] with standard management in men after radial prostatectomy and TURP. Setting: Men having prostate surgery were identified in 34 centres across the UK. If they had urinary incontinence, they were invited to enrol in the RCT. Participants: Men with urinary incontinence at 6 weeks after prostate surgery were eligible to be randomised if they consented and were able to comply with the intervention. Interventions: Eligible men were randomised to attend four sessions with a therapist over a 3-month period. The therapists provided standardised PFMT and bladder training for male urinary incontinence and erectile dysfunction. The control group continued with standard management. Main outcome measures: The primary outcome of clinical effectiveness was urinary incontinence at 12 months after randomisation, and the primary measure of costeffectiveness was incremental cost per quality-adjusted life-year (QALY). Outcome data were collected by postal questionnaires at 3, 6, 9 and 12 months. Results: Within the radical group (n = 411), 92% of the men in the intervention group attended at least one therapy visit and were more likely than those in the control group to be carrying out any PFMT at 12 months {adjusted risk ratio (RR) 1.30 [95% confidence interval (CI) 1.09 to 1.53]}. The absolute risk difference in urinary incontinence rates at 12 months between the intervention (75.5%) and control (77.4%) groups was -1.9% (95% CI -10% to 6%). NHS costs were higher in the intervention group [\u00a3181.02 (95% CI \u00a3107 to \u00a3255)] but there was no evidence of a difference in societal costs, and QALYs were virtually identical for both groups. Within the TURP group (n = 442), over 85% of men in the intervention group attended at least one therapy visit and were more likely to be carrying out any PFMT at 12 months after randomisation [adjusted RR 3.20 (95% CI 2.37 to 4.32)]. The absolute risk difference in urinary incontinence rates at 12 months between the intervention (64.9%) and control (61.5%) groups for the unadjusted intention-to-treat analysis was 3.4% (95% CI -6% to 13%). NHS costs [\u00a3209 (95% CI \u00a3147 to \u00a3271)] and societal costs [\u00a3420 (95% CI \u00a354 to \u00a3785)] were statistically significantly higher in the intervention group but QALYs were virtually identical. Conclusions: The provision of one-to-one conservative physical therapy for men with urinary incontinence after prostate surgery is unlikely to be effective or cost-effective compared with standard care that includes the provision of information about conducting PFMT. Future work should include research into the value of different surgical options in controlling urinary incontinence. Trial registration: Current Controlled Trials ISRCTN87696430. Funding: This project was funded by the NIHR Health Technology Assessment programme and will be published in full in Health Technology Assessment; Vol. 15, No. 24. See the HTA programme website for further project information.</p>",
        "title": "Conservative treatment for urinary incontinence in Men After Prostate Surgery (MAPS)",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Alistair Grant",
                "uuid": "2a4c1816-597b-4031-b6e9-a0a7cb1854e6"
            }
        ]
    },
    "c6033ffa-cefb-4a7e-b166-d4c2fada8290": {
        "id": "c6033ffa-cefb-4a7e-b166-d4c2fada8290",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/pelvic-floor-muscle-training-after-prostate-surgery--authors-reply(c6033ffa-cefb-4a7e-b166-d4c2fada8290).html",
        "abstract": "",
        "title": "Pelvic floor muscle training after prostate surgery - Authors' reply",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Alistair Grant",
                "uuid": "2a4c1816-597b-4031-b6e9-a0a7cb1854e6"
            }
        ]
    },
    "a7963d61-6ea2-41df-a3f7-415be02c2d49": {
        "id": "a7963d61-6ea2-41df-a3f7-415be02c2d49",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ogsadai-middleware-for-data-integration-selected-applications(a7963d61-6ea2-41df-a3f7-415be02c2d49).html",
        "abstract": "",
        "title": "OGSA-DAI: Middleware for Data Integration: Selected Applications",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alistair Grant",
                "uuid": "2a4c1816-597b-4031-b6e9-a0a7cb1854e6"
            },
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "1d6041d9-44a6-4365-a8b6-cbd4e22ba647": {
        "id": "1d6041d9-44a6-4365-a8b6-cbd4e22ba647",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/integrating-distributed-data-sources-with-ogsadai-dqp-and-views(1d6041d9-44a6-4365-a8b6-cbd4e22ba647).html",
        "abstract": "OGSA-DAI (Open Grid Services Architecture Data Access and Integration) \tis a framework for building distributed data access and integration \tsystems. Until recently, it lacked the built-in functionality that \twould allow easy creation of federations of distributed data sources. \tThe latest release of the OGSA-DAI framework introduced the OGSA-DAI \tDQP (Distributed Query Processing) resource. The new resource encapsulates \ta distributed query processor, that is able to orchestrate distributed \tdata sources when answering declarative user queries. The query processor \thas many extensibility points, making it easy to customize. We have \talso introduced a new OGSA-DAI Views resource that provides a flexible \tmethod for defining views over relational data. The interoperability \tof the two new resources, together with the flexibility of the OGSA-DAI \tframework, allows the building of highly customized data integration \tsolutions.",
        "title": "Integrating distributed data sources with OGSA-DAI DQP and Views",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Alistair Grant",
                "uuid": "2a4c1816-597b-4031-b6e9-a0a7cb1854e6"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "6fd1db81-60bf-493b-a11e-6e91be08f7a3": {
        "id": "6fd1db81-60bf-493b-a11e-6e91be08f7a3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/variation-of-molecular-mean-free-path-in-confined-geometries(6fd1db81-60bf-493b-a11e-6e91be08f7a3).html",
        "abstract": "<p>This paper aims to settle disputes in the literature about the spatial variation of the molecular mean free path (MFP) in confined geometries. The MFP of a gas is determined by using both molecular dynamics (MD) and the direct simulation Monte Carlo (DSMC) technique. In spatially-homogeneous cases, the numerical results exactly recover the kinetic theory predictions of a constant MFP. However, in microchannels, the MFP is found to vary near to the bounding walls and reduce at the surfaces to half of its bulk value as long as collisions between gas molecules and wall atoms are taken into account in the calculation of the MFP.</p>",
        "title": "Variation of molecular mean free path in confined geometries",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "67e44f31-367b-4481-8ded-53255f7558be": {
        "id": "67e44f31-367b-4481-8ded-53255f7558be",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/effective-mean-free-path-and-viscosity-of-confined-gases(67e44f31-367b-4481-8ded-53255f7558be).html",
        "abstract": "The molecular mean free path (MFP) of gases in confined geometries is numerically evaluated by means of the direct simulation Monte Carlo method and molecular dynamics simulations. Our results show that if calculations take into account not only intermolecular interactions between gas molecules but also collisions between gas molecules and wall atoms, then a space-dependent MFP is obtained. The latter, in turn, permits one to define an effective viscosity of confined gases that also varies spatially. Both the gas MFP and viscosity variation in surface-confined systems have been questioned in the past. In this work, we demonstrate that this effective viscosity derived from our MFP calculations is consistent with those deduced from the linear-response relationship between the shear stress and strain rate using independent nonequilibrium Couette-style simulations as well as the equilibrium Green-Kubo predictions.<br/>",
        "title": "Effective mean free path and viscosity of confined gases",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "9292d944-8d4a-4c9d-9477-a42632e2e24e": {
        "id": "9292d944-8d4a-4c9d-9477-a42632e2e24e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/flow-of-deformable-droplets(9292d944-8d4a-4c9d-9477-a42632e2e24e).html",
        "abstract": "<p>We study the rheology of a suspension of soft deformable droplets subjected to a pressure-driven flow. Through computer simulations, we measure the apparent viscosity as a function of droplet concentration and pressure gradient, and provide evidence of a discontinuous shear thinning behavior, which occurs at a concentration-dependent value of the forcing. We further show that this response is associated with a nonequilibrium transition between a \"hard\" (or less deformable) phase, which is nearly jammed and flows very slowly, and a \"soft\" (or more deformable) phase, which flows much more easily. The soft phase is characterized by flow-induced time dependent shape deformations and internal currents, which are virtually absent in the hard phase. Close to the transition, we find sustained oscillations in both the droplet and fluid velocities. Polydisperse systems show similar phenomenology but with a smoother transition, and less regular oscillations.</p>",
        "title": "Flow of Deformable Droplets",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "8ac6f344-39db-428a-a7fa-27ba731dc5f3": {
        "id": "8ac6f344-39db-428a-a7fa-27ba731dc5f3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mesoscopic-modelling-and-simulation-of-soft-matter(8ac6f344-39db-428a-a7fa-27ba731dc5f3).html",
        "abstract": "The deformability of soft condensed matter often requires modelling of hydrodynamical aspects to gain quantitative understanding. This, however, requires specialised methods that can resolve the multiscale nature of soft matter systems. We review a number of the most popular simulation methods that have emerged, such as Langevin dynamics, dissipative particle dynamics, multi-particle collision dynamics, sometimes also referred to as stochastic rotation dynamics, and the lattice-Boltzmann method. We conclude this review with a short glance at current compute architectures for high-performance computing and community codes for soft matter simulation.",
        "title": "Mesoscopic Modelling and Simulation of Soft Matter",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "0d595aa9-5ca3-4d60-844d-650d824310b5": {
        "id": "0d595aa9-5ca3-4d60-844d-650d824310b5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-single-nucleotide-resolution-model-for-largescale-simulations-of-double-stranded-dna(0d595aa9-5ca3-4d60-844d-650d824310b5).html",
        "abstract": "The computational modelling of DNA is becoming crucial in light of new advances in DNA nanotechnology, single-molecule experiments and in vivo DNA tampering. Here we present a mesoscopic model for double stranded DNA (dsDNA) at the single nucleotide level which retains the characteristic helical structure, while being able to simulate large molecules -- up to a million base pairs -- for time-scales which are relevant to physiological processes. This is made possible by an efficient and highly-parallelised implementation of the model which we discuss here. We compare the behaviour of our model with single molecule experiments where dsDNA is manipulated by external forces or torques. We also present some results on the kinetics of denaturation of linear DNA.",
        "title": "A Single Nucleotide Resolution Model for Large-Scale Simulations of Double Stranded DNA",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "b767ffb2-fac3-429c-875c-df0b902c72d8": {
        "id": "b767ffb2-fac3-429c-875c-df0b902c72d8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/scaling-soft-matter-physics-to-thousands-of-graphics-processing-units-in-parallel(b767ffb2-fac3-429c-875c-df0b902c72d8).html",
        "abstract": "We describe a multi-graphics processing unit (GPU) implementation of the Ludwig application, which specialises in simulating a variety of complex fluids via lattice Boltzmann fluid dynamics coupled to additional physics describing complex fluid constituents. We describe our methodology in augmenting the original central processing unit (CPU) version with GPU functionality in a maintainable fashion. We present several optimisations that maximise performance on the GPU architecture through tuning for the GPU memory hierarchy. We describe how we implement particles within the fluid in such a way to avoid a major diversion of the CPU and GPU codebases, whilst minimising data transfer at each time step. We detail our halo-exchange communication phase for the code, which exploits overlapping to allow efficient parallel scaling to many GPUs. We present results showing that the application demonstrates excellent scaling to at least 8192 GPUs in parallel, the largest system tested at the time of writing. The GPU version (on NVIDIA K20X GPUs) is around 3.5\u20135 times faster that the CPU version (on fully utilised AMD Opteron 6274 16-core CPUs), comparing equal numbers of CPUs and GPUs.",
        "title": "Scaling soft matter physics to thousands of graphics processing units in parallel",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            },
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "62056567-b342-4590-aa92-7f85f18b4ebb": {
        "id": "62056567-b342-4590-aa92-7f85f18b4ebb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/selfassembly-of-colloidcholesteric-composites-provides-a-possible-route-to-switchable-optical-materials(62056567-b342-4590-aa92-7f85f18b4ebb).html",
        "abstract": "Colloidal particles dispersed in liquid crystals can form new materials with tunable elastic and electro-optic properties. In a periodic 'blue phase' host, particles should template into colloidal crystals with potential uses in photonics, metamaterials and transformational optics. Here we show by computer simulation that colloid/cholesteric mixtures can give rise to regular crystals, glasses, percolating gels, isolated clusters, twisted rings and undulating colloidal ropes. This structure can be tuned via particle concentration, and by varying the surface interactions of the cholesteric host with both the particles and confining walls. Many of these new materials are metastable: two or more structures can arise under identical thermodynamic conditions. The observed structure depends not only on the formulation protocol but also on the history of an applied electric field. This new class of soft materials should thus be relevant to design of switchable, multistable devices for optical technologies such as smart glass and e-paper.",
        "title": "Self-assembly of colloid-cholesteric composites provides a possible route to switchable optical materials",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "1219ea2a-e59b-4eef-ba38-6826156f84a4": {
        "id": "1219ea2a-e59b-4eef-ba38-6826156f84a4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/switching-hydrodynamics-in-liquid-crystal-devices-a-simulation-perspective(1219ea2a-e59b-4eef-ba38-6826156f84a4).html",
        "abstract": "In liquid crystal devices it is important to understand the physics underlying their switching between different states, which is usually achieved by applying or removing an electric field. Flow is known to be a key determinant of the timescales and pathways of the switching kinetics. Incorporating hydrodynamic effects into theories for liquid crystal devices is therefore important; however this is also highly non-trivial, and typically requires the use of accurate numerical methods. Here, we review some recent advances in our theoretical understanding of the dynamics of switching in liquid crystal devices, mainly gained through computer simulations. These results, as we shall show, uncover interesting new physics, and may be important for future applications.",
        "title": "Switching hydrodynamics in liquid crystal devices: a simulation perspective",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "2ae1eb1d-d2b0-4fab-a68f-42f3ea06c6d9": {
        "id": "2ae1eb1d-d2b0-4fab-a68f-42f3ea06c6d9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/rheology-of-cubic-blue-phases(2ae1eb1d-d2b0-4fab-a68f-42f3ea06c6d9).html",
        "abstract": "",
        "title": "Rheology of cubic blue phases",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "a60f5350-6e69-4f89-8948-244a20dc7b7e": {
        "id": "a60f5350-6e69-4f89-8948-244a20dc7b7e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/yield-stress-discontinuity-in-a-simple-glass(a60f5350-6e69-4f89-8948-244a20dc7b7e).html",
        "abstract": "<p>Large-scale molecular-dynamics simulations are performed to study the steady-state yielding dynamics of a well-established simple glass. In contrast to the supercooled state, where the shear stress, sigma, tends to zero at vanishing shear rate, gamma, a stress plateau forms in the glass which extends over about two decades in shear rate. This strongly suggests the existence of a finite dynamic yield stress in the glass, sigma(+)(T)equivalent to sigma(T;gamma -&gt; 0)&gt; 0. Furthermore, the temperature dependence of sigma(+) suggests a yield stress discontinuity at a critical temperature of T-c=0.4 in agreement with recent mode coupling theory predictions. The corresponding qualitative change of the flow curves enables us to bracket the critical temperature T-c of the theory from above and from below. We scrutinize and support this observation by testing explicitly for the assumptions (affine flow, absence of flow-induced ordering) inherent in the theory. Furthermore, while qualitative similarity is found between the viscosity and the final relaxation time of stress fluctuations, significant quantitative differences are observed in the nonlinear regime.</p>",
        "title": "Yield stress discontinuity in a simple glass",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "1bed2908-7ba5-497d-81c1-0fa0c7ca21a8": {
        "id": "1bed2908-7ba5-497d-81c1-0fa0c7ca21a8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/thermosensitive-coreshell-particles-as-model-systems-for-studying-the-flow-behavior-of-concentrated-colloidal-dispersions(1bed2908-7ba5-497d-81c1-0fa0c7ca21a8).html",
        "abstract": "<p>We report on a comprehensive investigation of the flow behavior of colloidal thermosensitive core-shell particles at high densities. The particles consist of a solid core of poly(styrene) onto which a network of cross-linked poly(N-isopropylacrylamide) is affixed. Immersed in water the shell of these particles will swell if the temperature is low. Raising the temperature above 32 degrees C leads to a volume transition within this shell which leads to a marked shrinking of the shell. The particles have well-defined core-shell structure and a narrow size distribution. The remaining electrostatic interactions due to a small number of charges affixed to the core particles can be screened by adding 0.05M KCl to the suspensions. Below the lower critical solution temperature at 32 degrees C the particles are purely repulsive. Above this transition, a thermoreversible coagulation takes place. Lowering the temperature again leads to full dissociation of the aggregates formed by this process. The particles crystallize for effective volume fractions between 0.48 and 0.55. The crystallites can be molten by shear in order to reach a fluid sample again. The reduced shear stress measured in this metastable disordered state was found to be a unique function of the shear rate and the effective volume fraction. These reduced flow curves thus obtained can be described quantitatively by the theory of Fuchs and Cates [Phys. Rev. Lett. 89, 248304 (2002)] which is based on the mode-coupling theory of the glass transition.</p>",
        "title": "Thermosensitive core-shell particles as model systems for studying the flow behavior of concentrated colloidal dispersions",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "c70c7bfb-69e1-44f3-b02a-a4afe8f1c381": {
        "id": "c70c7bfb-69e1-44f3-b02a-a4afe8f1c381",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/nonequilibrium-structure-of-concentrated-colloidal-fluids-under-steady-shear-leadingorder-response(c70c7bfb-69e1-44f3-b02a-a4afe8f1c381).html",
        "abstract": "<p>The flow-induced microstructural distortions of dense colloidal dispersions under steady shearing are derived within a recent first-principles approach to the nonlinear rheology of colloidal fluids and glasses. The stationary structure factor is discussed to leading orders in shear rate gamma. We find that shear affects the stationary structure whenever the dressed Peclet/Weissenberg number Pe = gamma tau becomes appreciable; here tau is the structural or alpha-relaxation time. Close to vitrification, this predicts significantly larger shear distortions than expected from considering the bare Peclet number Pe(0); it compares gamma with the diffusion time of a colloid at infinite dilution.</p>",
        "title": "Nonequilibrium structure of concentrated colloidal fluids under steady shear: leading-order response",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "c0c5548e-f05b-4dd4-b076-f51e7ca63004": {
        "id": "c0c5548e-f05b-4dd4-b076-f51e7ca63004",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/bond-formation-and-slow-heterogeneous-dynamics-in-adhesive-spheres-with-longranged-repulsion-quantitative-test-of-mode-coupling-theory(c0c5548e-f05b-4dd4-b076-f51e7ca63004).html",
        "abstract": "<p>A colloidal system of spheres interacting with both a deep and narrow attractive potential and a shallow long-ranged barrier exhibits a prepeak in the static structure factor. This peak can be related to an additional mesoscopic length scale of clusters and/or voids in the system. Simulation studies of this system have revealed that it vitrifies upon increasing the attraction into a gel-like solid at intermediate densities. The dynamics at the mesoscopic length scale corresponding to the prepeak represents the slowest mode in the system. Using mode coupling theory with all input directly taken from simulations, we reveal the mechanism for glassy arrest in the system at 40% packing fraction. The effects of the low-q peak and of polydispersity are considered in detail. We demonstrate that the local formation of physical bonds is the process whose slowing down causes arrest. It remains largely unaffected by the large-scale heterogeneities, and sets the clock for the slow cluster mode. Results from mode-coupling theory without adjustable parameters agree semiquantitatively with the local density correlators but overestimate the lifetime of the mesoscopic structure (voids).</p>",
        "title": "Bond formation and slow heterogeneous dynamics in adhesive spheres with long-ranged repulsion: Quantitative test of mode coupling theory",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "33e53e21-7926-4493-91db-cb8d950818fe": {
        "id": "33e53e21-7926-4493-91db-cb8d950818fe",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/shear-stresses-of-colloidal-dispersions-at-the-glass-transition-in-equilibrium-and-in-flow(33e53e21-7926-4493-91db-cb8d950818fe).html",
        "abstract": "<p>We consider a model dense colloidal dispersion at the glass transition, and investigate the connection between equilibrium stress fluctuations, seen in linear shear moduli, and the shear stresses under strong flow conditions far from equilibrium, viz., flow curves for finite shear rates. To this purpose, thermosensitive core-shell particles consisting of a polystyrene core and a cross-linked poly(N-isopropylacrylamide) shell were synthesized. Data over an extended range in shear rates and frequencies are compared to theoretical results from integrations through transients and mode coupling approaches. The connection between nonlinear rheology and glass transition is clarified. While the theoretical models semiquantitatively fit the data taken in fluid states and the predominant elastic response of glass, a yet unaccounted dissipative mechanism is identified in glassy states. (C) 2008 American Institute of Physics.</p>",
        "title": "Shear stresses of colloidal dispersions at the glass transition in equilibrium and in flow",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "e50d6808-4625-4121-a35a-a3eb94f9ab62": {
        "id": "e50d6808-4625-4121-a35a-a3eb94f9ab62",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/theory-of-thermodynamic-stresses-in-colloidal-dispersions-at-the-glass-transition(e50d6808-4625-4121-a35a-a3eb94f9ab62).html",
        "abstract": "<p>We discuss the nonlinear rheology of dense colloidal dispersions at the glass transition. A first principles approach starting with interacting Brownian particles in given arbitrary homogeneous (incompressible) flow neglecting hydrodynamic interactions is sketched. It e.g. explains steady state flow curves for finite shear rates measured in dense suspensions of thermosensitive core-shell particles consisting of a polystyrene core and a crosslinked poly(N-isopropylacrylamide)(PNIPAM) shell. The exponents of simple and generalized Herschel Bulkley laws are computed for hard spheres.</p>",
        "title": "Theory of thermodynamic stresses in colloidal dispersions at the glass transition",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "a7a79e23-88cf-449d-9a21-3eb4ce90ff38": {
        "id": "a7a79e23-88cf-449d-9a21-3eb4ce90ff38",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-empirical-constitutive-law-for-concentrated-colloidal-suspensions-in-the-approach-of-the-glass-transition(a7a79e23-88cf-449d-9a21-3eb4ce90ff38).html",
        "abstract": "<p>Concentrated, non-crystallizing colloidal suspensions in their approach of the glass state exhibit distinct dynamics patterns. These patterns suggest a powerlaw rheological constitutive model for near-glass viscoelasticity, as presented here. The rheological parameters used for this model originate in the mode-coupling theory. The proposed constitutive model provides explicit expressions for the steady shear viscosity, the steady normal stress coefficient, the modulus-compliance relation, and the alpha peak of GaEuro(3). The relaxation pattern distinctly differs from gelation.</p>",
        "title": "An empirical constitutive law for concentrated colloidal suspensions in the approach of the glass transition",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "039704a3-4bed-4171-9d29-58d31c1cdf24": {
        "id": "039704a3-4bed-4171-9d29-58d31c1cdf24",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dynamic-yield-stresses-of-glasses-asymptotic-formulae(039704a3-4bed-4171-9d29-58d31c1cdf24).html",
        "abstract": "<p>The stationary, shear rate dependent flow curves of yielding glasses are discussed within a mode coupling theory approach. Asymptotic formulae for the shear stress at the transition point are obtained that take the form of generalized Hershel-Bulkeley constitutive equations, and enable one to find dynamical yield stresses by extrapolation.</p>",
        "title": "Dynamic yield stresses of glasses: asymptotic formulae",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "2c3e3216-11d9-4d0a-a39e-9e1e4fbeb8e4": {
        "id": "2c3e3216-11d9-4d0a-a39e-9e1e4fbeb8e4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/confined-cubic-blue-phases-under-shear(2c3e3216-11d9-4d0a-a39e-9e1e4fbeb8e4).html",
        "abstract": "<p>We study the behaviour of confined cubic blue phases under shear flow via lattice Boltzmann simulations. We focus on the two experimentally observed phases, blue phase I and blue phase II. The disclination network of blue phase II continuously breaks and reforms under shear, leading to an oscillatory stress response in time. The oscillations are only regular for very thin samples. For thicker samples, the shear leads to a 'stick-slip' motion of part of the network along the vorticity direction. Blue phase I responds very differently: its defect network undergoes seemingly chaotic rearrangements under shear, irrespective of system size.</p>",
        "title": "Confined cubic blue phases under shear",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "2297be4d-dd2e-41c1-85ec-e3c0df41e2e8": {
        "id": "2297be4d-dd2e-41c1-85ec-e3c0df41e2e8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hard-discs-under-steady-shear-comparison-of-brownian-dynamics-simulations-and-mode-coupling-theory(2297be4d-dd2e-41c1-85ec-e3c0df41e2e8).html",
        "abstract": "<p>Brownian dynamics simulations of bidisperse hard discs moving in two dimensions in a given steady and homogeneous shear flow are presented close to and above the glass transition density. The stationary structure functions and stresses of shear-melted glass are compared quantitatively to parameter-free numerical calculations of monodisperse hard discs using mode coupling theory within the integration through transients framework. Theory qualitatively explains the properties of the yielding glass but quantitatively overestimates the shear-driven stresses and structural anisotropies.</p>",
        "title": "Hard discs under steady shear: comparison of Brownian dynamics simulations and mode coupling theory",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            }
        ]
    },
    "1bcd8c05-69e2-42ab-9a09-bc270b639302": {
        "id": "1bcd8c05-69e2-42ab-9a09-bc270b639302",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/rheology-of-lamellar-liquid-crystals-in-two-and-three-dimensions-a-simulation-study(1bcd8c05-69e2-42ab-9a09-bc270b639302).html",
        "abstract": "<p>We present large scale computer simulations of the nonlinear bulk rheology of lamellar phases (smectic liquid crystals) at moderate to large values of the shear rate (Peclet numbers 10-100), in both two and three dimensions. In two dimensions we find that modest shear rates align the system and stabilise an almost regular lamellar phase, but high shear rates induce the nucleation and proliferation of defects, which in steady state is balanced by the annihilation of defects of opposite sign. The shear rate gamma at onset of this second regime is controlled by thermodynamic and kinetic parameters; we offer a scaling analysis that relates gamma to a critical \"capillary number\" involving those variables. Within the defect proliferation regime, the defects may be partially annealed by slowly decreasing the applied shear rate; this causes marked memory effects, and history-dependent rheology. Simulations in three dimensions show instead shear-induced ordering even at the highest shear rates studied here. This suggests that g_ c shifts markedly upward on increasing dimensionality. This may in part reflect the reduced constraints on defect motion, allowing them to find and annihilate each other more easily. Residual edge defects in the 3D aligned state mostly point along the flow velocity, an orientation impossible in two dimensions.</p>",
        "title": "Rheology of lamellar liquid crystals in two and three dimensions: a simulation study",
        "keywords": "",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "c4ded019-1bd2-49d6-bb4e-bcbad27d2b53": {
        "id": "c4ded019-1bd2-49d6-bb4e-bcbad27d2b53",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/lattice-boltzmann-simulations-of-liquid-crystalline-fluids-active-gels-and-blue-phases(c4ded019-1bd2-49d6-bb4e-bcbad27d2b53).html",
        "abstract": "<p>Lattice Boltzmann simulations have become the method of choice to solve the hydrodynamic equations of motion of a number of complex fluids. Here we review some recent applications of lattice Boltzmann to study the hydrodynamics of liquid crystalline materials. In particular, we focus on the study of (a) the exotic blue phases of cholesteric liquid crystals, and (b) active gels-a model system for actin plus myosin solutions or bacterial suspensions. In both cases lattice Boltzmann studies have proved useful to provide new insights into these complex materials.</p>",
        "title": "Lattice Boltzmann simulations of liquid crystalline fluids: active gels and blue phases",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "ac8eb38f-24af-4e86-a32f-05a3b0c75fa1": {
        "id": "ac8eb38f-24af-4e86-a32f-05a3b0c75fa1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/thermodynamics-of-blue-phases-in-electric-fields(ac8eb38f-24af-4e86-a32f-05a3b0c75fa1).html",
        "abstract": "<p>We present extensive numerical studies to determine the phase diagrams of cubic and hexagonal blue phases in an electric field. We confirm the earlier prediction that hexagonal phases, both two and three dimensional, are stabilized by a field, but we significantly refine the phase boundaries, which were previously estimated by means of a semianalytical approximation. In particular, our simulations show that the blue phase I-blue phase II transition at fixed chirality is largely unaffected by electric field, as observed experimentally.</p>",
        "title": "Thermodynamics of blue phases in electric fields",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "4c5cc681-2822-4c7f-af20-16c73ca41e74": {
        "id": "4c5cc681-2822-4c7f-af20-16c73ca41e74",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/domain-growth-in-cholesteric-blue-phases-hybrid-lattice-boltzmann-simulations(4c5cc681-2822-4c7f-af20-16c73ca41e74).html",
        "abstract": "<p>Here we review a hybrid lattice Boltzmann algorithm to solve the equations of motion of cholesteric liquid crystals. The method consists in coupling a lattice Boltzmann solver for the Navier-Stokes equation to a finite difference method to solve the dynamical equations governing the evolution of the liquid crystalline order parameter. We apply this method to study the growth of cholesteric blue phase domains, within a cholesteric phase. We focus on the growth of blue phase II and on a thin slab geometry in which the domain wall is flat. Our results show that, depending on the chirality, the growing blue phase is either BPII with no or few defects, or another structure with hexagonal ordering. We hope that our simulations will spur further experimental investigations on quenches in micron-size blue phase samples. The computational size that our hybrid lattice Boltzmann scheme can handle suggests that large scale simulations of new generation of blue phase liquid crystal devices are within reach. (C) 2009 Elsevier Ltd. All rights reserved.</p>",
        "title": "Domain growth in cholesteric blue phases: Hybrid lattice Boltzmann simulations",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "52a4da44-5130-4ee5-88f9-edb7bfb0cbcf": {
        "id": "52a4da44-5130-4ee5-88f9-edb7bfb0cbcf",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ordering-dynamics-of-blue-phases-entails-kinetic-stabilization-of-amorphous-networks(52a4da44-5130-4ee5-88f9-edb7bfb0cbcf).html",
        "abstract": "<p>The cubic blue phases of liquid crystals are fascinating and technologically promising examples of hierarchically structured soft materials, comprising ordered networks of defect lines (disclinations) within a liquid crystalline matrix. We present large-scale simulations of their domain growth, starting from a blue phase nucleus within a supercooled isotropic or cholesteric background. The nucleated phase is thermodynamically stable; one expects its slow orderly growth, creating a bulk cubic phase. Instead, we find that the strong propensity to form disclinations drives the rapid disorderly growth of a metastable amorphous defect network. During this process, the original nucleus is destroyed; reemergence of the stable phase may therefore require a second nucleation step. Our findings suggest that blue phases exhibit hierarchical behavior in their ordering dynamics, to match the hierarchy in their structure.</p>",
        "title": "Ordering dynamics of blue phases entails kinetic stabilization of amorphous networks",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "24e8fb22-7704-4623-b0a6-defc18131ca2": {
        "id": "24e8fb22-7704-4623-b0a6-defc18131ca2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/structure-of-blue-phase-iii-of-cholesteric-liquid-crystals(24e8fb22-7704-4623-b0a6-defc18131ca2).html",
        "abstract": "<p>We report large scale simulations of the blue phases of cholesteric liquid crystals. Our results suggest a structure for blue phase III, the blue fog, which has been the subject of a long debate in liquid crystal physics. We propose that blue phase III is an amorphous network of disclination lines, which is thermodynamically and kinetically stabilized over crystalline blue phases at intermediate chiralities. This amorphous network becomes ordered under an applied electric field, as seen in experiments.</p>",
        "title": "Structure of Blue Phase III of Cholesteric Liquid Crystals",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Oliver Henrich",
                "uuid": "bf5afdda-4487-4f05-bf19-c2fbbfe820e4"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "4a8471bb-94b7-41dc-aff9-4d9a30f5c201": {
        "id": "4a8471bb-94b7-41dc-aff9-4d9a30f5c201",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/developing-the-multilevel-parallelisms-for-fluidityicom--paving-the-way-to-exascale-for-the-next-generation-geophysical-fluid-modelling-technology(4a8471bb-94b7-41dc-aff9-4d9a30f5c201).html",
        "abstract": "The major challenges caused by the increasing scale and complexity of the<br/> current petascale and the future exascale systems are cross-cutting concerns of<br/> the whole software ecosystem. The trend for compute nodes is towards greater<br/> numbers of lower power cores, with a decreasing memory to core ratio. This is<br/> imposing a strong evolutionary pressure on numerical algorithms and software to<br/> efficiently utilise the available memory and network bandwidth.<br/><br/> Unstructured finite elements codes have been effectively parallelised using<br/> domain decomposition methods, implemented using libraries such as the Message<br/> Passing Interface (MPI) for a long time. However, there are many algorithmic and<br/> implementation optimisation opportunities when threading is used for intra-node<br/> parallelisation for the latest multi-core/many-core platforms. The benefits include<br/> reduced memory requirements, cache sharing, reduced number of partitions and<br/> less MPI communication. While OpenMP is promoted as being easy to use and<br/> allows incremental parallelisation of codes, naive implementations frequently<br/> yield poor performance. In practice, as with MPI, the same care and attention<br/> should be exercised over algorithm and hardware details when programming with<br/> OpenMP.<br/><br/> In this paper, we report progress in implementing a hybrid OpenMP-MPI version of the<br/> unstructured finite element application Fluidity. In the matrix<br/> assembly kernels, the OpenMP parallel algorithm uses graph colouring to identify<br/> independent sets of elements that can be assembled simultaneously with no race<br/> conditions. The sparse linear systems defined by various equations are solved using<br/> threaded PETSc and HYPRE which is utilised as a threaded preconditioner through<br/> the PETSc interface. Since unstructured finite element codes are well known to be memory bound,<br/> particular attention is paid to ccNUMA architectures where data locality is<br/> particularly important to achieve good intra-node scaling characteristics. We also<br/> demonstrate that utilising non-blocking algorithm and libraries are critical to<br/> mixed-mode application so that it can achieve better parallel performance than<br/> the pure MPI version.",
        "title": "Developing the multi-level parallelisms for Fluidity-ICOM -- Paving the way to exascale for the next generation geophysical fluid modelling technology",
        "keywords": "",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "385755f6-271a-4aa9-be40-4e404790dfc3": {
        "id": "385755f6-271a-4aa9-be40-4e404790dfc3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/achieving-efficient-strong-scaling-with-petsc-using-hybrid-mpiopenmp-optimisation(385755f6-271a-4aa9-be40-4e404790dfc3).html",
        "abstract": "The increasing number of processing elements and decreasing memory to core ratio in modern high-performance platforms makes efficient strong scaling a key requirement for numerical algorithms. In order to achieve efficient scalability on massively parallel systems scientific software must evolve across the entire stack to exploit the multiple levels of parallelism exposed in modern architectures. In this paper we demonstrate the use of hybrid MPI/OpenMP parallelisation to optimise parallel sparse matrix-vector multiplication in PETSc, a widely used scientific library for the scalable solution of partial differential equations. Using large matrices generated by Fluidity, an open source CFD application code which uses PETSc as its linear solver engine, we evaluate the effect of explicit communication overlap using task-based parallelism and show how to further improve performance by explicitly load balancing threads within MPI processes. We demonstrate a significant speedup over the pure-MPI mode and efficient strong scaling of sparse matrix-vector multiplication on Fujitsu PRIMEHPC FX10 and Cray XE6 systems.",
        "title": "Achieving Efficient Strong Scaling with PETSc Using Hybrid MPI/OpenMP Optimisation",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "1edf5d86-9dc9-4fbb-8add-f208f4c07ca3": {
        "id": "1edf5d86-9dc9-4fbb-8add-f208f4c07ca3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/exploring-the-threadlevel-parallelism-for-the-next-generation-geophysical-fluid-modelling-framework-fluidityicom(1edf5d86-9dc9-4fbb-8add-f208f4c07ca3).html",
        "abstract": "In this paper, we highlight our progress in implementing a hybrid OpenMP-MPI version of the unstructured finite element appli- cation Fluidity-ICOM. We demonstrate that utilising non-blocking algorithms and libraries are critical to mixed-mode application so that it can achieve better parallel performance than the pure MPI version. In the matrix assembly kernels, the OpenMP parallel algorithm utilises graph colouring to identify independent sets of elements that can be assembled simultaneously with no race con- ditions. The TCMalloc are used here to tackle performance issues arising from automatic arrays memory allocations. The sparse linear systems defined by various equations are solved by using threaded PETSc and HYPRE is utilised as a threaded preconditioner through the PETSc interface. Since unstructured finite element codes are well known to be memory bound, particular attention has to be paid to ccNUMA architectures where data locality is particularly important to achieve good intra-node scaling characteristics. With mixed mode MPI/OpenMP, Fluidity-ICOM can now run well above 32K cores job, which offers Fluidity-ICOM capability to solve the \u201dgrand-challenge\u201d problems.",
        "title": "Exploring the thread-level parallelism for the next generation geophysical fluid modelling framework Fluidity-ICOM",
        "keywords": "",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "ffa70ad1-22d4-4e7a-b2a0-b88109f0a31b": {
        "id": "ffa70ad1-22d4-4e7a-b2a0-b88109f0a31b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sprint-parallel-computing-with-r-on-hector(ffa70ad1-22d4-4e7a-b2a0-b88109f0a31b).html",
        "abstract": "Description: The course aims to give a general overview of the hardware, software and configuration of the HECToR systems in the context of using SPRINT. SPRINT provides an easy access to high performance computing for the analysis of high throughput post genomic data using the statistical programming language R.<br/><br/>SPRINT is available on HECToR and contains optimised versions of the following R functionality: pair-wise Pearson's correlation, permutation testing, random forest, rank product, partitioning around medoids and apply.<br/><br/>The course will also cover the key features of the Cray XE6, including the various compilers, tools and libraries that comprise the programming environment, as well as the specific configuration of the queues and file systems for HECToR users. We also give details of how users can obtain help when working on the systems, including documentation, the helpdesk and training.",
        "title": "SPRINT: Parallel computing with R on HECToR",
        "keywords": "",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "a473b061-7196-4273-a9d0-7f195075f917": {
        "id": "a473b061-7196-4273-a9d0-7f195075f917",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/benchmarking-mixedmode-petsc-performance-on-highperformance-architectures(a473b061-7196-4273-a9d0-7f195075f917).html",
        "abstract": "",
        "title": "Benchmarking mixed-mode PETSc performance on high-performance architectures",
        "keywords": "",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "dd256343-e559-4c4f-b4e2-57bf6e520631": {
        "id": "dd256343-e559-4c4f-b4e2-57bf6e520631",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/developing-hybrid-mpiopenmp-for-petsc(dd256343-e559-4c4f-b4e2-57bf6e520631).html",
        "abstract": "",
        "title": "Developing hybrid MPI/OpenMP for PETSc",
        "keywords": "",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "cc6bdb70-deba-4a9a-9024-67b225f9028e": {
        "id": "cc6bdb70-deba-4a9a-9024-67b225f9028e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/parallel-classification-and-feature-selection-in-microarray-data-using-sprint(cc6bdb70-deba-4a9a-9024-67b225f9028e).html",
        "abstract": "The statistical language R is favoured by many biostatisticians for processing microarray data. In recent times, the quantity of data that can be obtained in experiments has risen significantly, making previously fast analyses time consuming or even not possible at all with the existing software infrastructure. High performance computing (HPC) systems offer a solution to these problems but at the expense of increased complexity for the end user. The Simple Parallel R Interface is a library for R that aims to reduce the complexity of using HPC systems by providing biostatisticians with drop-in parallelised replacements of existing R functions. In this paper we describe parallel implementations of two popular techniques: exploratory clustering analyses using the random forest classifier and feature selection through identification of differentially expressed genes using the rank product method.",
        "title": "Parallel classification and feature selection in microarray data using SPRINT",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "7ff524fe-041d-47db-9c3c-1a458b72d274": {
        "id": "7ff524fe-041d-47db-9c3c-1a458b72d274",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/accelerating-cardiac-bidomain-simulations-using-graphics-processing-units(7ff524fe-041d-47db-9c3c-1a458b72d274).html",
        "abstract": "",
        "title": "Accelerating cardiac bidomain simulations using Graphics Processing Units",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            }
        ]
    },
    "590b984d-0c0f-4c1c-8bc8-593a3749683c": {
        "id": "590b984d-0c0f-4c1c-8bc8-593a3749683c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/exploiting-parallel-r-in-the-cloud-with-sprint(590b984d-0c0f-4c1c-8bc8-593a3749683c).html",
        "abstract": "Advances in DNA Microarray devices and next-generation massively parallel DNA sequencing platforms have led to an exponential growth in data availability but the arising opportunities require adequate computing resources. High Performance Computing (HPC) in the Cloud offers an affordable way of meeting this need.",
        "title": "Exploiting Parallel R in the Cloud with SPRINT",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "e041f0b1-3d9f-4828-a393-2a8cf04e190c": {
        "id": "e041f0b1-3d9f-4828-a393-2a8cf04e190c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hawkes-process-as-a-model-of-social-interactions-a-view-on-video-dynamics(e041f0b1-3d9f-4828-a393-2a8cf04e190c).html",
        "abstract": "<p>We study by computer simulation the 'Hawkes process' that was proposed in a recent paper by Crane and Sornette (2008 Proc. Natl Acad. Sci. USA 105 15649) as a plausible model for the dynamics of YouTube video viewing numbers. We test the claims made there that robust identification is possible for classes of dynamic response following activity bursts. Our simulated time series for the Hawkes process indeed fall into the different categories predicted by Crane and Sornette. However, the Hawkes process gives a much narrower spread of decay exponents than the YouTube data, suggesting limits to the universality of the Hawkes-based analysis.</p>",
        "title": "Hawkes process as a model of social interactions: a view on video dynamics",
        "keywords": "",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            }
        ]
    },
    "69aea367-cad5-49f2-b2da-3445b9d0b1d2": {
        "id": "69aea367-cad5-49f2-b2da-3445b9d0b1d2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/simulating-human-cardiac-electrophysiology-on-clinical-timescales(69aea367-cad5-49f2-b2da-3445b9d0b1d2).html",
        "abstract": "In this study, the feasibility of conducting in silico experiments in near-realtime with anatomically realistic, biophysically detailed models of human cardiac electrophysiology is demonstrated using a current national high-performance computing facility. The required performance is achieved by integrating and optimizing load balancing and parallel I/O, which lead to strongly scalable simulations up to 16,384 compute cores. This degree of parallelization enables computer simulations of human cardiac electrophysiology at 240 times slower than real time and activation times can be simulated in approximately 1\u2009min. This unprecedented speed suffices requirements for introducing in silico experimentation into a clinical workflow.",
        "title": "Simulating human cardiac electrophysiology on clinical time-scales",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            }
        ]
    },
    "d03d5d3d-225a-447e-b3cb-a6acee7454f0": {
        "id": "d03d5d3d-225a-447e-b3cb-a6acee7454f0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/modeling-cardiac-electrophysiology-at-the-organ-level-in-the-peta-flops-computing-age(d03d5d3d-225a-447e-b3cb-a6acee7454f0).html",
        "abstract": "<p>Despite a steep increase in available compute power, in-silico experimentation with highly detailed models of the heart remains to be challenging due to the high computational cost involved. It is hoped that next generation high performance computing (HPC) resources lead to significant reductions in execution times to leverage a new class of in-silico applications. However, peformance gains with these new platforms can only be achieved by engaging a much larger number of compute cores, necessitating strongly scalable numerical techniques. So far strong scalability has been demonstrated only for a moderate number of cores, orders of magnitude below the range required to achieve the desired performance boost.</p><p>In this study, strong scalability of currently used techniques to solve the bidomain equations is investigated. Benchmark results suggest that scalability is limited to 512-4096 cores within the range of :relevant problem sizes even when systems are carefully load-balanced and advanced 10 strategies are employed.</p>",
        "title": "Modeling Cardiac Electrophysiology at the Organ Level in the Peta FLOPS Computing Age",
        "keywords": "",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            }
        ]
    },
    "e8321580-8fb1-4e29-ad79-a76eb37ab611": {
        "id": "e8321580-8fb1-4e29-ad79-a76eb37ab611",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-parallel-random-forest-classifier-for-r(e8321580-8fb1-4e29-ad79-a76eb37ab611).html",
        "abstract": "The statistical language R is favoured by many biostaticians for processing microarray data. In recent times, the quantity of data that can be obtained in experiments has risen significantly, making previously fast analyses time consuming, or even not possible at all with the existing software infrastructure. High Performance Computing (HPC) systems offer a solution to these problems, but at the expense of increased complexity for the end user. The Simple Parallel R Interface (SPRINT) is a library for R that aims to reduce the complexity of using HPC systems by providing biostatisticians with drop-in parallelized replacements of existing R functions. In this paper we describe the implementation of a parallel version of the Random Forest classifier in the SPRINT library.",
        "title": "A parallel random forest classifier for R",
        "keywords": "",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "7643e20a-7114-4630-8df2-aaeaf8877ea9": {
        "id": "7643e20a-7114-4630-8df2-aaeaf8877ea9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/optimisation-and-parallelisation-of-the-partitioning-around-medoids-function-in-r(7643e20a-7114-4630-8df2-aaeaf8877ea9).html",
        "abstract": "",
        "title": "Optimisation and parallelisation of the partitioning around medoids function in R",
        "keywords": "",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            },
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "a6d111e4-e280-41e7-874c-d0419478770d": {
        "id": "a6d111e4-e280-41e7-874c-d0419478770d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/strategy-bifurcation-and-spatial-inhomogeneity-in-a-simple-model-of-competing-sellers(a6d111e4-e280-41e7-874c-d0419478770d).html",
        "abstract": "<p>We present a simple one-parameter model for spatially localised evolving agents competing for spatially localised resources. The model considers selling agents able to evolve their pricing strategy in competition for a fixed market. Despite its simplicity, the model displays extraordinarily rich behaviour. In addition to \"cheap\" sellers pricing to cover their costs, \"expensive\" sellers spontaneously appear to exploit short-term favourable situations. These expensive sellers \"speciate\" into discrete price bands. As well as variety in pricing strategy, the \"cheap\" sellers evolve a strongly correlated spatial structure, which in turn creates niches for their expensive competitors. Thus an entire ecosystem of coexisting, discrete, symmetry-breaking strategies arises. Copyright (C) EPLA, 2007.</p>",
        "title": "Strategy bifurcation and spatial inhomogeneity in a simple model of competing sellers",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            }
        ]
    },
    "80f4f72a-6728-4ea0-8180-597038866c62": {
        "id": "80f4f72a-6728-4ea0-8180-597038866c62",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/boom-and-bust-in-continuous-time-evolving-economic-model(80f4f72a-6728-4ea0-8180-597038866c62).html",
        "abstract": "<p>We show that a simple model of a spatially resolved evolving economic system, which has a steady state under simultaneous updating, shows stable oscillations in price when updated asynchronously. The oscillations arise from a gradual decline of the mean price due to competition among sellers competing for the same resource. This lowers profitability and hence population but is followed by a sharp rise as speculative sellers invade the large un-inhabited areas. This cycle then begins again.</p>",
        "title": "Boom and bust in continuous time evolving economic model",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Lawrence Mitchell",
                "uuid": "0b33a594-ffb5-4a6d-95d2-05b84ee24fa8"
            }
        ]
    },
    "f6cfede0-5ec5-4d45-9ef2-e317c0313893": {
        "id": "f6cfede0-5ec5-4d45-9ef2-e317c0313893",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/experimentation-and-the-diffusion-of-technology-in-china(f6cfede0-5ec5-4d45-9ef2-e317c0313893).html",
        "abstract": "A key challenge for academic research on behavior in society is access to data of the required volume, variety and veracity. Such data is of quantifiable operational value to corporate data owners, however, unlocking its strategic value through inductive \u2018Big Data\u2019 analysis invites a company to give access to that data before the bounds on data value can be fully assessed. This requires high degrees of trust. In this paper we report results from a decade of infrastructure and trust building that has allowed exploration of technology diffusion in China, the world\u2019s largest market for digital technologies. We innovate by including in our sample both early adoption and early rejection of a new technology to enable characterization of the first stage of the diffusion process: \u2018Experiri\u2019 \u2013 to try out. We explore this by examining consumer channel choice over a period of two years for over 1 million individual consumers and over 1000 products. Using a highly scalable data-mining tool we demonstrate that propensity to experiment with new channels is predictable and has a dependency on the demographics of the consumer. This offers the possibility of better management of new technology introduction and market development.",
        "title": "Experimentation and the diffusion of technology in China",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "efd61e36-a98a-4a23-91b6-3b894689339b": {
        "id": "efd61e36-a98a-4a23-91b6-3b894689339b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/able-but-not-willing(efd61e36-a98a-4a23-91b6-3b894689339b).html",
        "abstract": "Purpose<br/>\u2013 China is the world\u2019s largest user market for digital technologies and experiencing unprecedented rates of rural-urban migration set to create the world\u2019s first \u201curban billion\u201d. This is an important context for studying nuanced adoption behaviours that define a digital divide. Large-scale studies are required to determine what behaviours exist in such populations, but can offer limited ability to draw inferences about why. The purpose of this paper is to report a large-scale study inside China that probes a nuanced \u201cdigital divide\u201d behaviour: consumer demographics indicating ability to pay by electronic means but behaviour suggesting lack of willingness to do so, and extends current demographics to help explain this.<br/><br/>Design/methodology/approach<br/>\u2013 The authors report trans-national access to commercial \u201cBig Data\u201d inside China capturing the demographics and consumption of millions of consumers across a wide range of physical and digital market channels. Focusing on one urban location we combine traditional demographics with a new measure that reflecting migration: \u201cDistance from Home\u201d, and use data-mining techniques to develop a model that predicts use behaviour.<br/><br/>Findings<br/>\u2013 Use behaviour is predictable. Most use is explained by value of the transaction. \u201cDistance from Home\u201d is more predictive of technology use than traditional demographics.<br/><br/>Research limitations/implications<br/>\u2013 Results suggest traditional demographics are insufficient to explain \u201cwhy\u201d use/non-use occurs and hence an insufficient basis to formulate and target government policy.<br/><br/>Originality/value<br/>\u2013 The authors understand this to be the first large-scale trans-national study of use/non-use of digital channels within China, and the first study of the impact of distance on ICT adoption.",
        "title": "Able but not willing?",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "29660194-773c-4eca-9a80-50399d04078e": {
        "id": "29660194-773c-4eca-9a80-50399d04078e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/using-global-research-infrastructure-with-big-commercial-data(29660194-773c-4eca-9a80-50399d04078e).html",
        "abstract": "<p>The advent of globally distributed computing services and network access allows 'big data' on consumption to be used to model, explain and predict consumer behavior at resolutions that range from individual cities to whole countries. Given access to suitable infrastructure, the most significant challenge is to create conditions under which 'Data Scientists' may access and manipulate the required data whilst observing individual, national, and commercial constraints set by the type and location of the data. This paper draws on the experience of building the first Global Computing Grid to connect collaborating sites in three continents and describes the architecture of an embedded analytical facility installed within a Chinese commercial organisation that has enabled collaborative analysis of millions of consumer records. We report how this access has provided new insights into consumer behaviour within China ranging from testing strategic models of economic development to exploring 'digital exclusion' and the impact of migration on technology adoption.</p>",
        "title": "Using global research infrastructure with big (commercial) data",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "cecb0a5e-bd57-446e-9d9f-df1bba5f6525": {
        "id": "cecb0a5e-bd57-446e-9d9f-df1bba5f6525",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/exploring-invisibility-in-chinas-digital-economy(cecb0a5e-bd57-446e-9d9f-df1bba5f6525).html",
        "abstract": "Access to products and services is increasingly 'digital by default'. <br/>Non-users of digital channels have no direct means of signalling <br/>preferences through consumption, rendering them effectively <br/>invisible to designers of future products and at risk of permanent <br/>exclusion. We explore this in China by sampling millions of <br/>consumer\u2019s records across digital and non-digital channels. <br/>Separating consumers into digital/non-digital user groups allows <br/>the characteristics of those at risk of \u2018digital exclusion\u2019 to be <br/>predicted. From a corporate perspective, this scale of analysis <br/>allows strategic models of economic development in China based <br/>on both City Tier and McKinsey\u2019s City Cluster to be tested, and <br/>delivers \u2018at risk\u2019 groups that are large enough to provide economic <br/>incentives for inclusion. Non-use may, however, be elective, with <br/>consequences for the effectiveness with which governments <br/>formulate and target \u2018digital inclusion\u2019 policies. Hence we also <br/>explore how elective non-users might be distinguished from the <br/>potentially excluded.",
        "title": "Exploring \u02bbinvisibility\u02bc in China\u02bcs Digital Economy",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "e2f3a273-040c-4a1a-9d28-c97c58ac53fb": {
        "id": "e2f3a273-040c-4a1a-9d28-c97c58ac53fb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/parallel-optimisation-of-bootstrapping-in-r(e2f3a273-040c-4a1a-9d28-c97c58ac53fb).html",
        "abstract": "Bootstrapping is a popular and computationally demanding resampling method used for measuring the accuracy of sample estimates and assisting with statistical inference. R is a freely available language and environment for statistical computing popular with biostatisticians for genomic data analyses. A survey of such R users highlighted its implementation of bootstrapping as a prime candidate for parallelization to overcome computational bottlenecks. The Simple Parallel R Interface (SPRINT) is a package that allows R users to exploit high performance computing in multi-core desktops and supercomputers without expert knowledge of such systems. This paper describes the parallelization of bootstrapping for inclusion in the SPRINT R package. Depending on the complexity of the bootstrap statistic and the number of resamples, this implementation has close to optimal speed up on up to 16 nodes of a supercomputer and close to 100 on 512 nodes. This performance in a multi-node setting compares favourably with an existing parallelization option in the native R implementation of bootstrapping.",
        "title": "Parallel Optimisation of Bootstrapping in R",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "eccda08e-1b4b-4edb-972c-e83b76103a82": {
        "id": "eccda08e-1b4b-4edb-972c-e83b76103a82",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sprint-taking-biomedical-analysis-from-the-desktop-to-supercomputers-and-the-cloud(eccda08e-1b4b-4edb-972c-e83b76103a82).html",
        "abstract": "The statistical environment, R, is key to many of the workloads in biomedical sequence analysis and systems biology.",
        "title": "SPRINT: taking biomedical analysis from the desktop to supercomputers and the cloud",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "a2661d9d-1467-4447-b5b8-c2954266ef53": {
        "id": "a2661d9d-1467-4447-b5b8-c2954266ef53",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sprint-data-analysis-in-minutes-not-days(a2661d9d-1467-4447-b5b8-c2954266ef53).html",
        "abstract": "SPRINT is an easy to use, parallel version of the statistical <br/>language R. It is now available from the Comprehensive R <br/>Archive Network (CRAN), a network of ftp and web servers <br/>around the world that store identical, up-to-date, versions of <br/>code and documentation for R.",
        "title": "SPRINT: data analysis in minutes, not days",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "363abecc-8c37-4b26-ae0e-b7e73c64b4d5": {
        "id": "363abecc-8c37-4b26-ae0e-b7e73c64b4d5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/enabling-access-to-federated-grid-databases-an-ogsadai-odbc-driver(363abecc-8c37-4b26-ae0e-b7e73c64b4d5).html",
        "abstract": "Access to distributed heterogeneous data resources is possible through Grid middleware such as OGSA-DAI (Open Grid Services Architecture \u2013 Data Access and Integration) which is designed to assist with the integration of data from separate resources via Web services. This paper reports on the INWA project\u2019s investigations into whether OGSA-DAI can be exposed as an ODBC data source and used as a back-end to existing, popular data extraction and processing programs that are ODBC-compliant. This capability would provide additional location and product transparency for the data resources used by these programs. It also opens up the possibility of allowing these programs to extract data from federated data resources or \u201cvirtual databases\u201d.",
        "title": "Enabling Access to Federated Grid Databases: An OGSA-DAI ODBC Driver",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "5ad5ec83-9079-4d08-8423-a8f8740ab4a6": {
        "id": "5ad5ec83-9079-4d08-8423-a8f8740ab4a6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/embedded-systems-for-global-esocial-science(5ad5ec83-9079-4d08-8423-a8f8740ab4a6).html",
        "abstract": "There is a wealth of digital data currently being gathered by commercial and private concerns that could supplement academic research. To unlock this data it is important to gain the trust of the companies that hold the data as well as showing them how they may benefit from this research. Part of this trust is gained through established reputation and the other through the technology used to safeguard the data. This paper discusses how different technology frameworks have been applied to safeguard the data and facilitate collaborative work between commercial concerns and academic institutions. The paper focuses on the distinctive requirements of e-Social Science: access to large-scale data on behaviour in society in environments that impose confidentiality constraints on access. These constraints arise from both privacy concerns and the commercial sensitivities of that data. In particular, the paper draws on the experiences of building an intercontinental Grid\u2013INWA\u2013from its first operation connecting Australia and Scotland to its subsequent extension to China across the Trans-Eurasia Information Network\u2013the first large-scale research and education network for the Asia-Pacific region. This allowed commercial data to be analysed by experts that were geographically distributed across the globe. It also provided an entry point for a major Chinese commercial organization to approve use of a Grid solution in a new collaboration provided the centre of gravity of the data is retained within the jurisdiction of the data owner. We describe why, despite this approval, an embedded solution was eventually adopted. We find that \u2018data sovereignty\u2019 dominates any decision on whether and how to participate in e-Social Science collaborations and how this might impact on a Cloud based solution to this type of collaboration.",
        "title": "Embedded systems for global e-Social Science",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "d1db4d59-392b-4d97-b9c1-2be33057b809": {
        "id": "d1db4d59-392b-4d97-b9c1-2be33057b809",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/optimization-of-a-parallel-permutation-testing-function-for-the-sprint-r-package(d1db4d59-392b-4d97-b9c1-2be33057b809).html",
        "abstract": "The statistical language R and its Bioconductor package are favoured by many biostatisticians for processing microarray data. The amount of data produced by some analyses has reached the limits of many common bioinformatics computing infrastructures. High Performance Computing systems offer a solution to this issue. The Simple Parallel R Interface (SPRINT) is a package that provides biostatisticians with easy access to High Performance Computing systems and allows the addition of parallelized functions to R. Previous work has established that the SPRINT implementation of an R permutation testing function has close to optimal scaling on up to 512 processors on a supercomputer. Access to supercomputers, however, is not always possible, and so the work presented here compares the performance of the SPRINT implementation on a supercomputer with benchmarks on a range of platforms including cloud resources and a common desktop machine with multiprocessing capabilities. Copyright \u00a9 2011 John Wiley &amp; Sons, Ltd.",
        "title": "Optimization of a parallel permutation testing function for the SPRINT R package",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "ee9605f5-4371-435d-b4c8-1f85aa003857": {
        "id": "ee9605f5-4371-435d-b4c8-1f85aa003857",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/evaluating-gis-performance-in-a-multiprocessor-environment(ee9605f5-4371-435d-b4c8-1f85aa003857).html",
        "abstract": "",
        "title": "Evaluating GIS performance in a multiprocessor environment",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "c7411f26-0584-44ec-8f42-db54f410891a": {
        "id": "c7411f26-0584-44ec-8f42-db54f410891a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/data-mining(c7411f26-0584-44ec-8f42-db54f410891a).html",
        "abstract": "",
        "title": "Data Mining",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "90fd6b2a-3fc8-451e-b905-e965797d856a": {
        "id": "90fd6b2a-3fc8-451e-b905-e965797d856a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ukhec-report-on-software-estimation(90fd6b2a-3fc8-451e-b905-e965797d856a).html",
        "abstract": "",
        "title": "UKHEC Report on Software Estimation",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Alan Simpson",
                "uuid": "edbe5450-e7d0-43d8-8700-4982f415b3e7"
            }
        ]
    },
    "a20a1f30-32a9-46e1-8c97-b3b9b0c9765e": {
        "id": "a20a1f30-32a9-46e1-8c97-b3b9b0c9765e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sprint-a-simple-parallel-interface-to-high-performance-computing-and-a-parallel-r-function-library(a20a1f30-32a9-46e1-8c97-b3b9b0c9765e).html",
        "abstract": "The analysis of post genomic data is increasingly becoming harder to perform on standard computing infrastructures due to the sheer amount of data involved requiring more disk space and longer processing times. High Performance Computing (HPC) is an obvious answer to the need for more computing power. Access to computer clusters is common now with HPC resources becoming available to all through local or national initiatives such as the UK supercomputing service HECToR. However, the transition from general computing, such as R Language and Environment for Statistical Computing, to parallel computing is not straight forward. Software application and tools have to be adapted to take advantage of the extra computing power. SPRINT aims<br/>to provide bioinformaticians using R/Bioconductor to analyse microarray data with easy access to HPC providing maximum performance but requiring minimal expert knowledge and minimal changes to existing R scripts. <br/><br/>The SPRINT framework consists of an HPC harness and a library of parallelized R functions. SPRINT is very flexible; it runs on a range of HPC systems and allows the addition of user contributed functions. It handles functions that<br/>are trivial to parallelize, functions that are non trivial to parallelize and functions generating very large output.<br/><br/>The SPRINT parallel harness is written in C and uses the Message Passing Interface (MPI) library. It takes as input the R script and data to be analyzed. The use of the parallel IO support of the MPI library helps ensure that the results can be output in parallel providing great scalability. The use of ff objects from the ff package which allows the manipulation of large objects on file almost as if they were in memory, also removes the limitation on the size of the data that can be successfully analyzed. SPRINT can therefore handle very large amount of data increasing further its scalability.<br/><br/>The SPRINT library currently includes a parallel implementation of functions that have been highlighted as bottlenecks in the analysis of post genomic data by a user requirement survey. These include a Person pair-wise correlation (cor from stats) and a permutation test function (mt.maxT from multtest). Benchmarking runs on the HECToR Cray XT system have shown an almost perfect scaling to 512 processors.",
        "title": "SPRINT: a Simple Parallel INTerface to High Performance Computing and a Parallel R Function Library.",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "cb7f9468-b652-47c7-8805-5fba5871198f": {
        "id": "cb7f9468-b652-47c7-8805-5fba5871198f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-development-of-a-sociotechnical-infrastructure-to-support-open-access-publishing-though-institutional-repositories(cb7f9468-b652-47c7-8805-5fba5871198f).html",
        "abstract": "The UK RepositoryNet+ project (RepNet) has been funded by JISC (UK Joint information Systems Committee) to establish an infrastructure based around Institutional Repositories (IRs)to support Open Access publishing models for research papers. With the scoping phase of the project now complete, and the build phase slated to commence in March, it is planned to launch the service during OR12 in July. This paper will discuss the background to the funding of the project, the methodology followed to map the academic publishing landscape and establish user requirements, the process followed to develop and refine the components catalogue, and the bringing into service of the main functional services and components for Waves 1 and 2 of the project through to March 2013",
        "title": "The Development of a Socio-technical infrastructure to support Open Access Publishing though Institutional Repositories",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "2309561e-2d30-4c9e-b72c-62dc8fc6ebb3": {
        "id": "2309561e-2d30-4c9e-b72c-62dc8fc6ebb3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-pedestrian-view-of-the-roads-to-open-access-understanding-workflows-to-enrich-infrastructure(2309561e-2d30-4c9e-b72c-62dc8fc6ebb3).html",
        "abstract": "Things are moving quickly on the policy front with respect to the roads to Open Access with renewed focus on Gold Open Access. Gold OA is essentially the purchase of a service from a publisher: that the Publisher\u2019s (or Published) Final Copy is made available under specified terms of Open Access. This is in contrast to the Green Road to Open Access, which typically involves the deposit and availability of the Authors\u2019 Final Copy, by an author or an authorised agent. UK RepositoryNet+ (UKRepNet) is a JISC initiative being developed by EDINA. This is infrastructure to enable the delivery of services to universities and colleges in the UK in their work with Institutional Repositories (IRs) and the like to support Open Access (OA) and reporting arrangements for research outputs and outcomes. The focus is upon research literature as part of research output, noting the growth of the enhanced publication (i.e. the data behind the graph) and the importance of citation of data sources and instrumentation. Though Green OA is still important, the move to Gold OA is being accelerated faster than originally anticipated at the project kick-off in October 2011. Accordingly UKRepNet was given a \u2018watching brief\u2019 to monitor the significance of Gold OA in order that infrastructure being created remained relevant. What follows is report from that Watch activity, setting out the envisaged workflows, both financial and informational. The RepNet focus is on delivering a sustainable and fit for purpose repository service infrastructure. This has an emphasis on institutional repository infrastructure and therefore a focus on Green but naturally there are links to Gold, and as other service requirements emerge the service environment would need to be extensible to encompass those or to at least interoperate with them. Related to this JISC initiative &amp; the wider OA environment ( both Gold &amp; Green) is the work on metadata to research outputs that JISC is taking forward with publishers &amp; RCUK: this includes RIOX, Vocabulary for OA (V4OA) &amp; also the activity via the Open Access Implementation Group (OAIG) on APCs ( which this short report is feeding into). RIOX &amp; V4OA constitute action with regards to the agreement on UK Repository Application Profile to include OA and Funder Metadata. The semantics of OA are being dealt with in V4OA which is a JISC action as a result resulting from the agreement to address this issue between OAIG &amp; Publishers. This work will feed into the National Information Standards Organisation (NISO).",
        "title": "A Pedestrian View of the Roads to Open Access: Understanding Workflows to Enrich Infrastructure",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "5154999b-f584-40a2-aee4-d9aa5fa3daf7": {
        "id": "5154999b-f584-40a2-aee4-d9aa5fa3daf7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sharing-high-performance-computing-data-intensive-computing-and-novel-computing-resources-across-scottish-heis(5154999b-f584-40a2-aee4-d9aa5fa3daf7).html",
        "abstract": "This document is the D-2 Report deliverable from the ERCPool project. The full title of the ERCPool project is \u201cPilot Project in Sharing High Performance Computing, Data Intensive Computing and Novel Computing Resources across Scottish HEIs\u201d.  For the remainder of this document the project will be referred to as ERCPool.<br/>The two major objectives of the ERCPool project are: <br/>1.\tTo promote and investigate potential opportunities, through equipment pooling initiatives, for the sharing of Edinburgh\u2019s leading-edge high performance and novel computing systems at EPCC with other universities.<br/>2.\tTo deliver a report documenting the strengths, weaknesses, opportunities and threats of a move to a system of resource sharing, as well as looking at the potential benefits to researchers. This report will also look at the practical barriers to resource sharing and undertake a cost/benefit analysis.<br/><br/>This document fulfils this project\u2019s second objective. The content for this document has been derived from the two major activities undertaken in ERCPool.<br/>1.\tA regional study, based on a pilot programme for resource sharing in novel computing.  This has involved opening up two state-of-the-art novel computing resources to researchers from outside Edinburgh. These are the Data Intensive Research (EDIM1) computer and EPCC\u2019s parallel GPGPU resource testbed. This has enabled the identification of some of the operational barriers to the sharing of these novel computing resources with researchers from outside the University of Edinburgh. <br/>2.\tAn investigation into the potential for operating regional or topical HPC resources instead of each University procuring and operating its own machine. Using the researchers from SUPA (which covers all of the Physics departments in Scotland) and other disciplines, ERCPool has investigated and documented the future computing needs of researchers to determine to what extent these could be met by shared resources. It has also looked at the potential tangible benefits for research of sharing research computing resources, such as increased collaboration between institutions, better access to training and consultancy, equality of access to state of the art facilities to researchers from a wide geographical area, integration of university, topical and regional facilities into the UK HPC ecosystem. This has involved contacts with more than 40 staff from HEIs from across Scotland and resulted in three projects running on the state-of-the-art  novel computing resources opened up as part of ERCPool\u2019s pilot programme described above.<br/><br/>Section 2 of this document therefore discusses if future computing needs as expressed by contacted IS providers and research groups can be met by resource pooling. Section 3 provides a SWOT analysis, whilst Section 4 discusses the possible cost benefits of resource sharing. Finally, Section 5 discusses the practical barriers to resource sharing and how these could be overcome.<br/>In summary, ERCPool has found that the barriers to sharing of novel and high performance computing resources can be broadly classified into four areas \u2013 access, resource management, application-related and costs. Overcoming the access related barriers is primarily about making the resource application process lightweight and timely. Regarding resource management, it must be recognised that traditional techniques such as batch systems and virtualisation are not appropriate for every circumstance. A range of possibilities needs to be provided that includes simple and flexible mechanisms that recognise, for example, that not all applications scale to hundreds or thousands of cores and so may require execution times of longer than 12 hours. Application based  training and not just software development training is required since many users do not program but instead run third-party applications, Such users need to know how to use these efficiently and to best effect. Probably the greatest barrier, however, to resource pooling is the lack of clarity around funding models and costs. Once these are better understood and clear, easy to understand, implement and monitor processes are in place then resource pooling will be far more appealing to researchers.  This, however, requires RCUK and HEIs to engage together to resolve this.<br/>",
        "title": "Sharing High Performance Computing, Data Intensive Computing and Novel Computing Resources across Scottish HEIs",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            }
        ]
    },
    "5e318544-cbde-4d2c-98d0-753a29418c91": {
        "id": "5e318544-cbde-4d2c-98d0-753a29418c91",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/global-competitiveness-and-regional-innovation--using-the-grid-to-close-the-gap-between-business-research-and-resources(5e318544-cbde-4d2c-98d0-753a29418c91).html",
        "abstract": "",
        "title": "Global Competitiveness and Regional Innovation - using the Grid to \"close the gap between Business, Research and Resources\"?",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "18be22c3-8717-4677-838a-c9bb0492532c": {
        "id": "18be22c3-8717-4677-838a-c9bb0492532c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/intercontinental-grids-an-infrastructure-for-demanddriven-innovation(18be22c3-8717-4677-838a-c9bb0492532c).html",
        "abstract": "",
        "title": "Intercontinental Grids: an infrastructure for demand-driven innovation",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "4e9f328d-feb0-4d50-b7f1-61ffa046948b": {
        "id": "4e9f328d-feb0-4d50-b7f1-61ffa046948b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/access-to-resources-in-heterogeneous-environments(4e9f328d-feb0-4d50-b7f1-61ffa046948b).html",
        "abstract": "A JOINT RESEARCH ACTIVITY (JRA7) WITHIN DEISA HAS USED EMERGING MODERN GRID STANDARDS TO DEVELOP A UNIFORM MEANS FOR ACCESSING AND EXPLOITING A HETEROGENEOUS SUPERCOMPUTING GRID ENVIRONMENT. THE DEISA SERVICES FOR THE HETEROGENEOUS MANAGEMENT LAYER (DESHL)<br/>HAS PROVEN POPULAR WITH RESEARCHERS. SCIENTIFIC USERS ARE NOW ABLE TO BUILD MIDDLEWARE AND HARDWARE INDEPENDENT TASK FARMS, WORKFLOWS AND CODE MIGRATION/RESUBMISSION SUITES.",
        "title": "Access to resources in heterogeneous environments",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "370c44d0-4c4a-404f-ae54-e4238a30b072": {
        "id": "370c44d0-4c4a-404f-ae54-e4238a30b072",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/first-data-investigation-on-the-grid-firstdig(370c44d0-4c4a-404f-ae54-e4238a30b072).html",
        "abstract": "The FirstDIG [1] project is a collaboration between First plc [2] and the National e-Science Centre (NeSC) [3] as represented by EPCC [4]. The project aims to deploy an early implementation of the OGSA Data Access and Integration services (OGSA-DAI) [5] within the First South Yorkshire bus operational environment. The project has two central goals. The first is to demonstrate the deployment of OGSA-DAI services in a commercial environment, and learn from this process. The second goal is to answer specific business questions posed by First through a short data mining analysis using the OGSA-DAI service enabled data sources. The project started in May 2003 and will run through to January 2004. This paper describes the project and its current status as of August 2003.",
        "title": "First Data Investigation on the Grid: FirstDIG",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            }
        ]
    },
    "44f6f66a-b094-46d6-947b-50767cbae97f": {
        "id": "44f6f66a-b094-46d6-947b-50767cbae97f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/linking-escience-capabilities-for-esocial-science-communities-extending-the-ukaustralia-inwa-project-to-the-chinese-academy-of-sciences(44f6f66a-b094-46d6-947b-50767cbae97f).html",
        "abstract": "The INWA Grid project connects grid resources in EPCC (Edinburgh, Scotland), Curtin Business School (Perth, Western Australia) and the Chinese Academy of Sciences (Beijing, China). The project has demonstrated the application of grid computing power to the analysis of distributed data drawn from collaborating companies in each time zone. This data describes regional behaviour within the \u201ce\u201d economy and provides a focus for global eSocial Science collaborations. The infrastructure supporting these interactions however is designed for eScience collaborations and hence differences with the models for global collaborative research within the social sciences, as well as regional differences in access to this infrastructure by the social science community, determine the immediate extent to which global grid technologies can support global eSocial Science. We explore this issue in an examination of the recent evolution of eScience/Grid infrastructure in China as well as broader measures relating to Internet access within China. We observe that some divergence in the uptake of access technologies is already evident within China with potential consequences for future modalities of collaborative social science research in this region.",
        "title": "Linking e-Science capabilities for e-Social Science communities: extending the UK-Australia INWA project to the Chinese Academy of Sciences",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "b10a1e04-8797-4c50-bc81-82d57bb70e7e": {
        "id": "b10a1e04-8797-4c50-bc81-82d57bb70e7e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/exploiting-soft-computation-in-smes(b10a1e04-8797-4c50-bc81-82d57bb70e7e).html",
        "abstract": "",
        "title": "Exploiting Soft Computation in SMEs",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "dd5f88b4-3e1b-46e9-b471-f95b3da111c1": {
        "id": "dd5f88b4-3e1b-46e9-b471-f95b3da111c1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/partitioning-of-vectortopological-data-for-parallel-gis-operations-assessment-and-performance-analysis(dd5f88b4-3e1b-46e9-b471-f95b3da111c1).html",
        "abstract": "<p>Geographical Information Systems (GIS) are able to manipulate spatial data. Such spatial data can be available in a variety of formats, one of the most important of which is the vector-topological, This format retains the topological relationships between geographical features and is commonly used in a range of geographical data analyses. This paper describes the implementation and performance of a parallel data partitioning algorithm for the input of vector-topological data to parallel processes.</p>",
        "title": "Partitioning of vector-topological data for parallel GIS operations: Assessment and performance analysis",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "1299d032-1799-42a1-b7dc-5f092f4512b9": {
        "id": "1299d032-1799-42a1-b7dc-5f092f4512b9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/parallilising-fuzzy-queries-for-spatial-data-modelling-on-a-cray-t3d(1299d032-1799-42a1-b7dc-5f092f4512b9).html",
        "abstract": "<p>In this paper we present some results about the use of parallel computing for fuzzy modelling in Geographic Information Systems (GIS) applications. Fuzzy modelling is going to gain an increasing popularity in the GIS community, but its application find an obstacle in the high computational cost. It is possible to design efficient parallel algorithms for fuzzy modelling: here we present an approach to parallelisation of fuzzy queries for digital terrain models. Load balancing is shown to be the key point to obtain good performances, and suitable load distribution strategy is discussed. Experimental results obtained on a Cray-T3D using MPI are presented as well.</p>",
        "title": "Parallilising fuzzy queries for spatial data modelling on a Cray T3D",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "b645d095-d0bc-49ba-9e5b-288790fa4f56": {
        "id": "b645d095-d0bc-49ba-9e5b-288790fa4f56",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/from-inwa-to-inca-an-international-collaboration-in-esocial-science(b645d095-d0bc-49ba-9e5b-288790fa4f56).html",
        "abstract": "The INWA Grid went \u2018live\u2019 in December 2003, connecting Curtin Business School in Western Australia through the US to EPCC in Edinburgh, making it one of the longest distance and longest running Grid-based \u2018collaboratories\u2019 in the Social Sciences. Stable network connections between Australia and China were established in January 2005, allowing the extension of INWA to the network centre of the Chinese Internet at the Computer Network and Information Center of the Chinese Academy of Sciences (CNIC, CAS). The present collaboration with CNIC - Project INCA - focusses on innovation processes that can be supported by Grid technologies across a \u2018virtual cluster\u2019. This paper describes the current INWA infrastructure, which is migrating from 2nd to 3rd generation Grid technologies, and provides an increasingly homogeneous platform for collaboration across distinctively different socio-economic contexts. Here the focus of \u2018innovation\u2019 moves from enhancements in technical capability associated with enhanced computing and telecommunications, to their relationship with \u2018innovation capacity\u2019 \u2013 i.e. the ability to expand potential for innovation and extend an innovator\u2019s reach. To explore this relationship, we outline a framework that is being used to track the capacity of this \u2018virtual organisation\u2019 as each advance in 2nd to 3rd generation technology is implemented.",
        "title": "From INWA to INCA: an international collaboration in eSocial Science",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "2071db68-4ce8-4e68-9291-f72158fc3a59": {
        "id": "2071db68-4ce8-4e68-9291-f72158fc3a59",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/submission-scripts-for-scientific-simulations-on-deisa(2071db68-4ce8-4e68-9291-f72158fc3a59).html",
        "abstract": "<p>The DEISA Services for the Heterogeneous management Layer, better known as the DESHL, allows users and their applications to manage batch jobs and data across a computing Grid ill a uniform manner regardless of the underlying hardware and software on the various nodes. The DESHL provides a means for coordinating and integrating services for distributed resource management in a heterogeneous supercomputing environment. It provides users and their applications with a command line tool and application programming interfaces for job and data management in DEISA's UNICORE-based grid.</p><p>The DESHL employs the SAGA (Simple API for Grid Applications) and JSDL (Job Submission Description Language) emerging grid standards, as well as the Open Group Batch Environment Services specification. Reliance on Grid standards will allow interoperability with other Grid environments.</p><p>Three DESHL-based bash script,, have been created which demonstrate how DEISA can be exploited directly from the user's workstation. These scripts are for Task Farms, Workflows, and for Code Migration/Resubmission.</p>",
        "title": "Submission Scripts for Scientific Simulations on DEISA",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Elena Breitmoser",
                "uuid": "1a2c3c66-ade8-42d7-ae85-85b3e4a84425"
            },
            {
                "name": "Gavin Pringle",
                "uuid": "66f4ae16-ad0a-4ab4-ae37-5f844ed07fae"
            }
        ]
    },
    "b68800e9-0887-44d6-91cb-2430fe8b3a31": {
        "id": "b68800e9-0887-44d6-91cb-2430fe8b3a31",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/deshlstandards-based-access-to-a-heterogeneous-european-supercomputing-infrastructure(b68800e9-0887-44d6-91cb-2430fe8b3a31).html",
        "abstract": "This paper describes the DESHL -- an open standards-based means for accessing the DEISA consortium\u00c2\u00bfs heterogeneous supercomputing Grid. The paper provides some background on DEISA before giving an overview of the functionality and architecture of the DESHL.",
        "title": "DESHL--Standards Based Access to a Heterogeneous European Supercomputing Infrastructure",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "31d1978d-cb50-4ac4-afdd-83855480ab54": {
        "id": "31d1978d-cb50-4ac4-afdd-83855480ab54",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/global-competitiveness-and-regional-innovation-using-the-grid-to-close-the-gap-between-business-research-and-resources(31d1978d-cb50-4ac4-afdd-83855480ab54).html",
        "abstract": "...Europe cannot compete unless it becomes more inventive, reacts better to consumer needs and preferences and innovates more. Our future depends on innovation<br/>European Union Regional Policy<br/>September 2006.<br/><br/>Growth in the competitiveness of economically associated but geographically distributed States such as those found within the EU, the US and across Asia, requires a balance between the natural desire to build local R&amp;D intensity and the increasing need for infrastructure that connects with global markets - i.e. to close the gap between Business, Research and Resources (EU Regional Policy, 2006).<br/><br/>This notion of clustering is essentially no different to Adam Smiths observations of the inter-relatedness of trades in The Wealth of Nations (1776), brought to a wider audience by Michael Porter in The Competitive Advantage of Nations (1990). Today the encouragement of cluster formation is common feature of regional policies across the globe; however, the resulting clusters often lack visibility or the critical mass required to advertise their existence and communicate their ideas to other States, let alone participate in global markets (EU, 2007).<br/><br/>Investment in cooperative global ICT infrastructure such as the Grid offers the promise of virtualisation of processes within and between organisations that would allow local clusters to compete globally without requiring the scale or intensity implied by traditional industry development patterns.<br/><br/>Unfortunately, the relationship between investment in ICT and the competitiveness of specific organisational processes is vexed, with Robert Solow, the Nobel Laureate in Economics, commenting in 1987 on a productivity paradox that: we see the computer age everywhere except in the productivity statistics.<br/><br/>The paradox was apparently resolved by Brynjolfsson and Hitt (1996), with ICT investments correlating strongly with productivity, especially where organisations were decentralised. However recent data allowing analysis of productivity before and after the investment cycles driven by Y2K and the dotcom boom and bust, have lead the respected economist Robert Gordon to defend his earlier argument that computers and the Internet have had a low impact on overall productivity (Gordon, 2000; McAfee, 2006).<br/><br/>In such an environment, justifying investments in a global hardware and software infrastructure that provides dependable, consistent, pervasive, and inexpensive access to high-end computational capabilities (Foster and Kesselman, 1999) requires a much clearer understanding of the relationship between performance at all levels of the stack from network capability to an organisational capacity for innovation.<br/><br/>The required technical capability is being demonstrated in multiple Grid and eScience programmes across the globe that have supported large-scale highly decentralised collaborations. These include the eVLBI collaborations in Radio- Astronomy, however as Szalay (2006) notes, such data carries little of the sensitivities associated with sharing socio-economic data, which is core to any interaction with global markets.<br/><br/>This raises questions as to the manner in which Grid and eScience technologies may be transferred to businesses that seek to become more innovative, more competitive and hence more productive by closing the gap between Business, Research and Resources.<br/><br/>The presentation explores this question by drawing on the experiences of having established a grid collaboratory to combine and analyse socio-economic data drawn from global markets in order to feed organisational innovation processes managed within a single secure Grid environment.<br/><br/>This Grid first connected Curtin Business School (Western Australia) and Edinburgh Parallel Computing Centre (Scotland) in 2003, was extended to include the Computer Network and Information Center of the Chinese Academy of Sciences in 2005, and continues to develop in the light of opportunities offered by infrastructures such as TEIN2.",
        "title": "Global Competitiveness and Regional Innovation: using the Grid to close the gap between Business, Research and Resources",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "b6f9c322-ceeb-4bf7-8d1f-11c2e6d323fa": {
        "id": "b6f9c322-ceeb-4bf7-8d1f-11c2e6d323fa",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-input-preparation-and-distribution-of-data-for-parallel-gis-operations(b6f9c322-ceeb-4bf7-8d1f-11c2e6d323fa).html",
        "abstract": "<p>Geographical Information Systems (GIS) manipulate spatial data from a variety of data formats. The widely adopted vector-topological format retains the topological relationships between geographical features and is typically used in a range of geographical data analyses. There are a number of characteristics of the format, however, that cause difficulties in the input, manipulation and processing of the data. This paper reports on the performance of a prototype parallel data partitioning algorithm for the input of vector-topological data to parallel processes.</p>",
        "title": "The input, preparation, and distribution of data for parallel GIS operations",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "cc8cf52a-5f0f-469a-adf3-2604e451acd0": {
        "id": "cc8cf52a-5f0f-469a-adf3-2604e451acd0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/extracting-business-benefit-from-operational-data(cc8cf52a-5f0f-469a-adf3-2604e451acd0).html",
        "abstract": "<p>EPCC is a technology transfer centre within the University of Edinburgh in the United Kingdom. It has assisted a number of organisations to extract extra business benefit from operational data. This paper outlines some of these data intensive, knowledge discovery projects undertaken by EPCC. It highlights issues common to these projects despite their diversity in solution methods, computational requirements and application area.</p>",
        "title": "Extracting business benefit from operational data",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            }
        ]
    },
    "13000665-6c10-4495-9aaf-b904c8fd074f": {
        "id": "13000665-6c10-4495-9aaf-b904c8fd074f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/developing-nonlocal-iterative-parallel-algorithms-for-gis-on-cray-t3d-using-mpi(13000665-6c10-4495-9aaf-b904c8fd074f).html",
        "abstract": "In the application context of spatial data analysis, several parallelisation strategies are proposed for algorithms which are characterized by the non-locality of computation and by the iterative nature of the data processing. Different parallelisation approaches are presented and the methods developed for Cray T3D using the MPI message passing library are briefly compared to a workstation-network solution. The better results in the two environments are obtained following different strategies. The lesson learned is that MPI and other message passing libraries provide valuable help for portability, but the development of efficient and portable parallel software needs the availability of higher level approaches supporting different parallelisation strategies in a simple and effective way.",
        "title": "Developing non-local iterative parallel algorithms for GIS on Cray T3D using MPI",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "feea8553-7388-4390-82c0-83c53aff052d": {
        "id": "feea8553-7388-4390-82c0-83c53aff052d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/applying-grid-technologies-to-distributed-data-mining(feea8553-7388-4390-82c0-83c53aff052d).html",
        "abstract": "<p>The Grid promises improvements in the effectiveness with which global businesses are managed if it enables distributed expertise to be efficiently applied to the analysis of distributed data. We report an ESRC-funded collaboration between EPCC in Edinburgh and Curtin University of Technology in Perth, Australia, that is applying public-domain Grid technologies to secure data mining within a commercial environment. We describe this Grid infrastructure and discuss its strengths and weaknesses.</p>",
        "title": "Applying grid technologies to distributed data mining",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            }
        ]
    },
    "025a2405-5947-4971-ab09-2f99c85867d2": {
        "id": "025a2405-5947-4971-ab09-2f99c85867d2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hpceuropa-towards-uniform-access-to-european-hpc-infrastructures(025a2405-5947-4971-ab09-2f99c85867d2).html",
        "abstract": "<p>One of the goals of the HPC-Europa project [1] is to provide users with a. Single Point of Access (SPA) to the resources of HPC centers in Europe. To this end, the HPC-Europa Portal is being built to provide transparent, uniform, flexible and intuitive user access to HPC-Europa resources.</p><p>In this paper, we present a mechanism that enables end-users to transparently access the diverse services available in the HPC-Europa environment. The uniform job submission interface that uses this mechanism, utilizing the Job Specification Description Language (JSDL) [3], is described. We also present the architecture of the SPA, based on the GridSphere portal framework [2]. Finally, we discuss the various interoperability problems encountered, in particular those concerning job submission, security and accounting.</p>",
        "title": "HPC-Europa: Towards uniform access to European HPC infrastructures",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            }
        ]
    },
    "6a1ef448-7fe0-4e2b-8326-6c0cdb7debd4": {
        "id": "6a1ef448-7fe0-4e2b-8326-6c0cdb7debd4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/vector-to-raster-conversion(6a1ef448-7fe0-4e2b-8326-6c0cdb7debd4).html",
        "abstract": "",
        "title": "Vector to Raster Conversion",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "353accb4-098b-4a87-ab08-1fa50443310d": {
        "id": "353accb4-098b-4a87-ab08-1fa50443310d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/parallel-vector-data-input(353accb4-098b-4a87-ab08-1fa50443310d).html",
        "abstract": "",
        "title": "Parallel Vector Data Input",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "5d99bc73-a0ed-4d9a-8448-a86c601f5d27": {
        "id": "5d99bc73-a0ed-4d9a-8448-a86c601f5d27",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hpceuropa-single-point-of-access-as-a-framework-for-building-science-gateways(5d99bc73-a0ed-4d9a-8448-a86c601f5d27).html",
        "abstract": "<p>One of the goals of the HPC-Europa project is to provide users with a single point of access (SPA) to the resources of HPC centers in Europe. To this end, the HPC-Europa portal is being built to provide transparent, uniform, flexible and intuitive user access to HPC-Europa resources. This portal will hide the underlying complexity and heterogeneity of these resources and the services that provide access to them. Since the computational environment of HPC-Europa is strongly heterogeneous, even in terms of the deployed Grid middleware, we need a mechanism that maps a uniform graphical user interface to the functionality provided by services available in the institutions belonging to the HPC-Europa consortium. In addition, accounting information has to be stored and provided on demand for both limiting resource usage and charging purposes in the HPC-Europa infrastructure. The important goal of the SPA is also to provide the means to support user access to specific applications. This should make access to Grid infrastructures easier for end-users. Both mechanisms (generic and application-specific interfaces), along with additional tools, will combine to provide flexible and efficient software for building science gateways for researchers in various domains. In this paper, we describe the architecture of the SPA, which is based on the GridSphere portal framework. We present a mechanism for enabling end-users to transparently access services available in the HPC-Europa environment. The uniform job submission interface that uses this mechanism and is based on the Job Specification Description Language (JSDL) is presented. The mechanism supporting development of application-specific user interfaces is also described. Finally, we discuss relevant issues and interoperability problems connected with the development of the SPA, in particular those concerning job submission, security and accounting. Copyright (c) 2006 John Wiley &amp; Sons, Ltd.</p>",
        "title": "HPC-Europa single point of access as a framework for building science gateways",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            },
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            }
        ]
    },
    "0cd26306-fd50-4c10-b089-0ef1bcdc7957": {
        "id": "0cd26306-fd50-4c10-b089-0ef1bcdc7957",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/optimization-of-a-parallel-permutation-testing-function-for-the-sprint-r-package(0cd26306-fd50-4c10-b089-0ef1bcdc7957).html",
        "abstract": "The statistical language R and Bioconductor package are<br/>favoured by many biostatisticians for processing microarray<br/>data. The amount of data produced by these analyses has<br/>reached the limits of many common bioinformatics computing<br/>infrastructures. High Performance Computing (HPC)<br/>systems offer a solution to this issue. The Simple Parallel R<br/>INTerface (SPRINT) is a package that provides biostatisticians<br/>with easy access to HPC systems and allows the addition<br/>of parallelized functions to R. This paper will present<br/>how we added a parallelized permutation testing function<br/>in R using SPRINT and how this function performs on a<br/>supercomputer for executions of up to 512 processes.",
        "title": "Optimization of a parallel permutation testing function for the SPRINT R package",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "49d8cf91-a221-44e1-889b-d250a3bda497": {
        "id": "49d8cf91-a221-44e1-889b-d250a3bda497",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/optimization-of-a-parallel-permutation-testing-function-for-the-sprint-r-package(49d8cf91-a221-44e1-889b-d250a3bda497).html",
        "abstract": "<p>The statistical language R and its Bioconductor package are favoured by many biostatisticians for processing microarray data. The amount of data produced by some analyses has reached the limits of many common bioinformatics computing infrastructures. High Performance Computing systems offer a solution to this issue. The Simple Parallel R Interface (SPRINT) is a package that provides biostatisticians with easy access to High Performance Computing systems and allows the addition of parallelized functions to R. Previous work has established that the SPRINT implementation of an R permutation testing function has close to optimal scaling on up to 512 processors on a supercomputer. Access to supercomputers, however, is not always possible, and so the work presented here compares the performance of the SPRINT implementation on a supercomputer with benchmarks on a range of platforms including cloud resources and a common desktop machine with multiprocessing capabilities. Copyright (C) 2011 John Wiley &amp; Sons, Ltd.</p>",
        "title": "Optimization of a parallel permutation testing function for the SPRINT R package",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "62759c81-11b3-443f-b555-3db39c856099": {
        "id": "62759c81-11b3-443f-b555-3db39c856099",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sprint-a-new-parallel-framework-for-r(62759c81-11b3-443f-b555-3db39c856099).html",
        "abstract": "Microarray analysis allows the simultaneous measurement of thousands to millions of genes or sequences across tens to thousands of different samples. The analysis of the resulting data tests the limits of existing bioinformatics computing infrastructure. A solution to this issue is to use High Performance Computing (HPC) systems, which contain many processors and more memory than desktop computer systems. Many biostatisticians use R to process the data gleaned from microarray analysis and there is even a dedicated group of packages, Bioconductor, for this purpose. However, to exploit HPC systems, R must be able to utilise the multiple processors available on these systems. There are existing modules that enable R to use multiple processors, but these are either difficult to use for the HPC novice or cannot be used to solve certain classes of problems. A method of exploiting HPC systems, using R, but without recourse to mastering parallel programming paradigms is therefore necessary to analyse genomic data to its fullest.",
        "title": "SPRINT: a new parallel framework for R",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "2badef82-a63b-4cb7-9367-0811a77d9ecb": {
        "id": "2badef82-a63b-4cb7-9367-0811a77d9ecb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/analysis-of-gis-performance-on-parallel-architectures-and-workstationserver-systems(2badef82-a63b-4cb7-9367-0811a77d9ecb).html",
        "abstract": "",
        "title": "Analysis of GIS Performance on Parallel Architectures and Workstation-Server Systems",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "cf66a0d3-1cd5-4322-936e-9cf5e9594019": {
        "id": "cf66a0d3-1cd5-4322-936e-9cf5e9594019",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/gis-performance-study(cf66a0d3-1cd5-4322-936e-9cf5e9594019).html",
        "abstract": "",
        "title": "GIS Performance Study",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "3b9f2d97-a986-430c-a565-b4d0275f263d": {
        "id": "3b9f2d97-a986-430c-a565-b4d0275f263d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/determination-of-computing-resource-requirements-for-gis-processing-in-a-workstationserver-environment(3b9f2d97-a986-430c-a565-b4d0275f263d).html",
        "abstract": "",
        "title": "Determination of computing resource requirements for GIS processing in a workstation-server environment",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "752900c1-138d-4631-a3c1-dfefba3db34e": {
        "id": "752900c1-138d-4631-a3c1-dfefba3db34e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/smp-benefits-for-gis(752900c1-138d-4631-a3c1-dfefba3db34e).html",
        "abstract": "",
        "title": "SMP:- Benefits for GIS?",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "82994213-a8cc-4e72-b41e-9e763c4940c5": {
        "id": "82994213-a8cc-4e72-b41e-9e763c4940c5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/managing-the-corporate-gis-the-role-of-massively-parallel-processing(82994213-a8cc-4e72-b41e-9e763c4940c5).html",
        "abstract": "",
        "title": "Managing The Corporate GIS: The Role of Massively Parallel Processing",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "75d8aeef-109c-4b48-a2bd-7e341c73427b": {
        "id": "75d8aeef-109c-4b48-a2bd-7e341c73427b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/exploring-gis-performance-issues(75d8aeef-109c-4b48-a2bd-7e341c73427b).html",
        "abstract": "",
        "title": "Exploring GIS Performance Issues.",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "d40cc9cc-ab7f-4bf5-860a-401b9c880b14": {
        "id": "d40cc9cc-ab7f-4bf5-860a-401b9c880b14",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/turbocharging-your-gis-dealing-with-performance-issues(d40cc9cc-ab7f-4bf5-860a-401b9c880b14).html",
        "abstract": "",
        "title": "Turbo-charging your GIS: Dealing with performance issues.",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "8abaf66a-505f-4eeb-acb2-bf6b4190bae1": {
        "id": "8abaf66a-505f-4eeb-acb2-bf6b4190bae1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/towards-portable-parallel-algorithms-for-gis-software(8abaf66a-505f-4eeb-acb2-bf6b4190bae1).html",
        "abstract": "",
        "title": "Towards Portable Parallel Algorithms for GIS Software",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "216b8314-39e3-444a-8423-d6e97a94b5b9": {
        "id": "216b8314-39e3-444a-8423-d6e97a94b5b9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/using-performance-analysis-to-identify-candidate-operations-for-gis-software-parallelization(216b8314-39e3-444a-8423-d6e97a94b5b9).html",
        "abstract": "This paper examines the potential impact of parallel computing on the computational performance of GIS. Performance analyses on existing GIS operations, vector topology creation and interpolation, in commercial GIS products in a serial environment are used to work out the critical computational factors that determine elapsed time performance. Analyses reveal that the extraction of all data necessary to perform a GIS operation at a particular geographical locality dominates the I/O and CPU resource usage. For GIS to benefit from parallel computing, the performance of this task must be addressed.",
        "title": "Using performance analysis to identify candidate operations for GIS software parallelization",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "0e11a02e-d7ad-46d7-a885-72ae3e6e2d41": {
        "id": "0e11a02e-d7ad-46d7-a885-72ae3e6e2d41",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/meeting-expectations-a-view-of-gis-performance-issues(0e11a02e-d7ad-46d7-a885-72ae3e6e2d41).html",
        "abstract": "",
        "title": "Meeting expectations: A View of GIS Performance Issues",
        "keywords": "",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "b136050c-cdbe-41b7-baf1-d8133a278f35": {
        "id": "b136050c-cdbe-41b7-baf1-d8133a278f35",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/intercontinental-grids-an-infrastructure-for-demanddriven-innovation(b136050c-cdbe-41b7-baf1-d8133a278f35).html",
        "abstract": "This paper charts the evolution of an<br/>intercontinental Grid\u2014INWA\u2014from its first operation<br/>connectingAustralia and Scotland; its subsequent<br/>extension to China; and its use to demonstrate<br/>the first large-scale research and education<br/>network for the Asia-Pacific region. The paper<br/>focuses on the gap between e-Science and e-Social<br/>Science arguing that the Grid topology is more<br/>compatible with the socio-legal demands of largescale<br/>study of society than more dynamically distributed<br/>approaches, such as Cloud Computing.<br/>Foundational texts on Grid Computing and its<br/>appropriation by research programmes in the UK,<br/>USA and China have helped create a positive,<br/>symbolic value for Grid Computing. For INWA,<br/>this value helped when communicating the aims<br/>of the project to potential collaborators and so<br/>created the conditions for high-quality, socioeconomic<br/>data to be placed in a collaborative,<br/>analytical environment. There is no equivalent<br/>symbolic value for Cloud Computing with potential<br/>consequences for its usefulness in establishing<br/>such collaborations in future.",
        "title": "Intercontinental Grids: an infrastructure for demand-driven innovation",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Terence Sloan",
                "uuid": "cb3314e0-f1db-4221-a19b-abf14001edd1"
            }
        ]
    },
    "f4789f54-9b96-4fef-bd06-8715573d138b": {
        "id": "f4789f54-9b96-4fef-bd06-8715573d138b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/deisa-escience-in-a-collaborative-secure-interoperable-and-userfriendly-environment(f4789f54-9b96-4fef-bd06-8715573d138b).html",
        "abstract": "",
        "title": "DEISA: eScience in a Collaborative, Secure, Interoperable and User-friendly Environment",
        "keywords": "",
        "authors": [
            {
                "name": "Alison Kennedy",
                "uuid": "0970b437-74aa-474c-a951-36f4f55dfa71"
            },
            {
                "name": "Gavin Pringle",
                "uuid": "66f4ae16-ad0a-4ab4-ae37-5f844ed07fae"
            }
        ]
    },
    "0b5d9836-316a-4a6b-9388-72fb356fd16f": {
        "id": "0b5d9836-316a-4a6b-9388-72fb356fd16f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/deisadistributed-european-infrastructure-for-supercomputing-applications(0b5d9836-316a-4a6b-9388-72fb356fd16f).html",
        "abstract": "<p>The paper presents an overview of the current research and achievements of the DEISA project, with a focus on the general concept of the infrastructure, the operational model, application projects and science communities, the DEISA Extreme Computing Initiative, user and application support, operations and technology, services, collaborations and interoperability, and the use of standards and policies. The paper concludes with a discussion about the long-term sustainability of the DEISA infrastructure.</p>",
        "title": "DEISA-Distributed European Infrastructure for Supercomputing Applications",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Alison Kennedy",
                "uuid": "0970b437-74aa-474c-a951-36f4f55dfa71"
            }
        ]
    },
    "34f98ca7-985f-48fe-8c84-a28507b7b93c": {
        "id": "34f98ca7-985f-48fe-8c84-a28507b7b93c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/deisa-extreme-computing-initiative-deci-and-science-community-support(34f98ca7-985f-48fe-8c84-a28507b7b93c).html",
        "abstract": "",
        "title": "DEISA Extreme Computing Initiative (DECI) and Science Community Support",
        "keywords": "",
        "authors": [
            {
                "name": "Alison Kennedy",
                "uuid": "0970b437-74aa-474c-a951-36f4f55dfa71"
            }
        ]
    },
    "f494dc4a-84c7-4e21-8520-1a2ad8c65668": {
        "id": "f494dc4a-84c7-4e21-8520-1a2ad8c65668",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/innovative-algorithms-for-extreme-scale-computing(f494dc4a-84c7-4e21-8520-1a2ad8c65668).html",
        "abstract": "",
        "title": "Innovative Algorithms for Extreme Scale Computing",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Lorna Smith",
                "uuid": "5c748338-46b1-485e-95af-511b43c62836"
            }
        ]
    },
    "84ed1e85-4e5b-4ed5-94b5-b0ca2f1afab9": {
        "id": "84ed1e85-4e5b-4ed5-94b5-b0ca2f1afab9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-data-bonanza(84ed1e85-4e5b-4ed5-94b5-b0ca2f1afab9).html",
        "abstract": "This book presents the most up\u2013to\u2013date opportunities and challenges emerging in knowledge discovery, helping readers develop the technical skills to design and develop data\u2013intensive methods and processes. Offering an introduction to the current R and D efforts worldwide, the book includes examples and case studies with strategies for addressing a wide variety of data\u2013intensive challenges. The book includes a discussion of the DISPEL language, its development, enactment, and applications as well as data\u2013intensive beacons of success, focusing on methods in astronomy, interactive interpretation of environment data, and data\u2013driven research in humanities. A must\u2013have resource for researchers in industry, governmental organizations, and academia.",
        "title": "The Data Bonanza",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "9129eefd-be0e-48fa-a0af-0110989a942b": {
        "id": "9129eefd-be0e-48fa-a0af-0110989a942b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/industrial-use-of-highperformance-computing-in-the-united-kingdom(9129eefd-be0e-48fa-a0af-0110989a942b).html",
        "abstract": "Industrial Applications of High-Performance Computing: Best Global Practices offers a global overview of high-performance computing (HPC) for industrial applications, along with a discussion of software challenges, business models, access models (e.g., cloud computing), public-private partnerships, simulation and modeling, visualization, big data analysis, and governmental and industrial influence.<br/><br/>Featuring the contributions of leading experts from 11 different countries, this authoritative book:<br/><br/>- Provides a brief history of the development of the supercomputer<br/>- Describes the supercomputing environments of various government entities in terms of policy and service models<br/>- Includes a case study section that addresses more subtle and technical aspects of industrial supercomputing<br/>- Shows how access to supercomputing matters, and how supercomputing can be used to solve large-scale and complex science and engineering problems<br/>- Emphasizes the need for collaboration between companies, political organizations, government agencies, and entire nations<br/><br/>Industrial Applications of High-Performance Computing: Best Global Practices supplies computer engineers and researchers with a state-of-the-art supercomputing reference. This book also keeps policymakers and industrial decision-makers informed about the economic impact of these powerful technological investments.",
        "title": "Industrial Use of High-Performance Computing in the United Kingdom",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            }
        ]
    },
    "a65ac0c6-182e-44d7-8823-238b5f7a8e8e": {
        "id": "a65ac0c6-182e-44d7-8823-238b5f7a8e8e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/evaluation-methodology-of-an-nvrambased-platform-for-the-exascale(a65ac0c6-182e-44d7-8823-238b5f7a8e8e).html",
        "abstract": "",
        "title": "Evaluation Methodology of an NVRAM-based Platform for the Exascale",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "dfa04927-2a8c-4b14-87db-e5ac69db59f9": {
        "id": "dfa04927-2a8c-4b14-87db-e5ac69db59f9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cryostat-section-assay-of-oestrogen-and-progesterone-receptors-in-meningiomas(dfa04927-2a8c-4b14-87db-e5ac69db59f9).html",
        "abstract": "<p>Oestrogen receptors and progesterone receptors were measured in the cytosols from cryostat sections of 45 meningiomas from 40 patients (12 men, 28 women) using an isoelectric focusing technique. Near fascimile adjacent sections from the same tissue blocks were stained and examined to determine the histological subtype of the neoplasms. Appreciable levels of progesterone receptor (greater than 10 fmol/mg cytosol protein) were present in 24 (53.3%) of of the neoplasms, but no clinically important oestrogen receptor was detected in any of the tumours. Competitive binding studies on control tissue confirmed the specificity of the assay procedures. No correlation was found between progesterone receptor state and the age, sex, or menopausal state of the patients, or the histological subtype and site of the neoplasms. Four of the patients studied had multiple intracranial neoplasms, which in two were of differing progesterone receptor state. The presence of specific progesterone receptor in meningioma cytosols raises the possibility of hormonal manipulation in the treatment of this group of neoplasms.</p>",
        "title": "Cryostat section assay of oestrogen and progesterone receptors in meningiomas",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            }
        ]
    },
    "45b241ee-ba5f-415a-9ed9-0e1c6196540e": {
        "id": "45b241ee-ba5f-415a-9ed9-0e1c6196540e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/healthcare-data-safe-havens-towards-a-logical-architecture-and-experiment-automation(45b241ee-ba5f-415a-9ed9-0e1c6196540e).html",
        "abstract": "In computing science, much attention has been paid to generic methods for sharing data in secure infrastructures. These sorts of methods and  infrastructures are, of course, necessary for sharing healthcare data. We are, however, a long way away from being able to realise the potential of medical and healthcare data to support the sorts of extensive, data-intensive experiments being demanded by precision and stratified medicine. A key architectural problem remaining to be solved is how to maintain control of patient data within the governance of local data jurisdictions while also allowing these jurisdictions to engage with experiment designs that (because of the need to scale to large population sizes) may require analyses across several jurisdictions. This paper provides a snapshot of architectural work underway to provide a clear, effective structure of data safe havens within jurisdictions. It then describes how formally specified experiment designs can be used single jurisdiction could tackle alone. Our current work relates to two jurisdictions (in Scotland and in Italy) but the architecture and methods are general across similar jurisdictions.<br/>",
        "title": "Healthcare Data Safe Havens: Towards a Logical Architecture and Experiment Automation",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            }
        ]
    },
    "e2ff4bb1-2ae9-4f45-a12f-11aafbe5a981": {
        "id": "e2ff4bb1-2ae9-4f45-a12f-11aafbe5a981",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sharing-and-reuse-in-knowledge-discovery(e2ff4bb1-2ae9-4f45-a12f-11aafbe5a981).html",
        "abstract": "This chapter explains why the reuse and shareability of all the types of components that are used in knowledge discovery processes can be useful to improve efficiency and productivity. It illustrates the variety of descriptions that are needed for processing elements - this would be extended to functions and types. This metadata is organized as libraries of components. The chapter also shows that these descriptions can be layered according to different types of vocabularies, which focus on different aspects of the description of components. Data analysis ontologies are domain-independent vocabularies that support the broad description of the data analysis tasks undertaken in the knowledge discovery process. Finally, domain ontologies are one of the most important types of ontologies to be considered in this effort to support shareability and reusability of processing elements, functions, and types.",
        "title": "Sharing and Reuse in Knowledge Discovery",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            }
        ]
    },
    "7d998cb8-7423-4a51-8e38-f18ef12464e2": {
        "id": "7d998cb8-7423-4a51-8e38-f18ef12464e2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/problem-solving-in-dataintensive-knowledge-discovery(7d998cb8-7423-4a51-8e38-f18ef12464e2).html",
        "abstract": "This chapter aims at providing data analysis experts with an overview of the most common strategies in knowledge discovery, highlighting those steps or blocks of steps that are most likely to appear in common problem solving in conventional and data-intensive contexts, as well as giving examples that can be replicated in a range of problems in different domains. The chapter provides the common substrate that data analysis experts must know in order to address systematically their knowledge discovery problems in a data-intensive context. Inexperienced data analysis experts find the chapter useful for understanding and systematizing knowledge discovery, problem-solving procedures beyond individual steps and components for conventional to data-intensive problems. More experienced data analysis experts find the chapter useful to develop their understanding of how the data-intensive context influences conventional data analysis strategies.",
        "title": "Problem Solving in Data-Intensive Knowledge Discovery",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            }
        ]
    },
    "d34e5fe4-0c80-412a-b722-b73391492da5": {
        "id": "d34e5fe4-0c80-412a-b722-b73391492da5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/platforms-for-dataintensive-analysis(d34e5fe4-0c80-412a-b722-b73391492da5).html",
        "abstract": "This chapter looks at the context of tools and platforms for data-intensive engineering. It shows the scope of data-intensive computing relative to distributed computing and knowledge discovery. The key properties of data-intensive computing are that the focus is on data as much as computation and that the data in question are distributed. The data-intensive platform described in this chapter is specialized to address these aspects. In order to engineer such a platform, a number of connected tasks must be orchestrated to create the overall platform, namely, the chapter describes the DISPEL language, the Lingua Franca of the platform, the development tools used to create DISPEL sentences (programs), and the processes involved in enacting a data-intensive computation.",
        "title": "Platforms for Data-Intensive Analysis",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            }
        ]
    },
    "0564e748-da57-450e-9e6c-89cccf221ae4": {
        "id": "0564e748-da57-450e-9e6c-89cccf221ae4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/definition-of-the-dispel-language(0564e748-da57-450e-9e6c-89cccf221ae4).html",
        "abstract": "This chapter presents the data-intensive systems process engineering language (DISPEL) in enough detail for the reader to understand the aims and abilities of the language. DISPEL is a powerful programming language, while at the same time providing a high level of abstraction to ease the development of data-intensive applications. Much of the complexity and detail of a computation is embedded in the processing elements (PEs) themselves, which are created by specialists in their own domains. DISPEL functions and the registry provide further capabilities to abstract development for the user\u2014 for example, a function may encapsulate a complex composition of other constructs so that the resulting PE(s) can be directly used without knowledge of their underlying structure. The registry, empowered by the structural and domain type system, provides the ability to validate a DISPEL script in terms of more than simple syntax and provides a wealth of opportunities for optimization.",
        "title": "Definition of the DISPEL Language",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "0327adec-bc36-41f6-8c3a-d3623f3bf4ba": {
        "id": "0327adec-bc36-41f6-8c3a-d3623f3bf4ba",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/analytical-platform-for-customer-relationship-management(0327adec-bc36-41f6-8c3a-d3623f3bf4ba).html",
        "abstract": "<p>This chapter describes two specific applications of the data-intensive architecture to customer relationship management (CRM) database analysis carried out by a team at Polish IT services firm Comarch SA. Readers are introduced to CRM analysis in the telecoms domain through a scene-setting discussion that assumes no prior knowledge. They are then taken through the process of analyzing customer data to predict whether and when customers may move to a new service provider-a phenomenon known as customer \"churn\". An example in this chapter shows how data can be used to understand how best to offer existing customers complementary services. The chapter offers some thoughts on the effective exploitation of data-intensive methods for business intelligence in a production capacity, including considerations of problem scale. It summarizes the key findings from the author's \"classical\" experiments in CRM data mining.</p>",
        "title": "Analytical Platform for Customer Relationship Management",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            }
        ]
    },
    "156f7e3c-6b40-4eb7-9c06-7df720824151": {
        "id": "156f7e3c-6b40-4eb7-9c06-7df720824151",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/feasibility-study-of-porting-a-particle-transport-code-to-fpga(156f7e3c-6b40-4eb7-9c06-7df720824151).html",
        "abstract": "In this paper we discuss porting a particle transport code, which is based on a wavefront sweep algorithm, to FPGA. The original code is written in Fortran90. We describe the key differences between general purpose CPUs and Field Programmable Gate Arrays (FPGAs) and provide a detailed performance model of the FPGA. We describe the steps we took when porting the Fortran90 code to FPGA. Finally, the paper will present results from an extensive bench- marking exercise using a Virtex 6 FPGA.",
        "title": "Feasibility Study of Porting a Particle Transport Code to FPGA",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "8975df5e-3d8a-4386-a87b-31f1080aaf1f": {
        "id": "8975df5e-3d8a-4386-a87b-31f1080aaf1f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/performance-and-extension-of-a-particle-transport-code-using-hybrid-mpiopenmp-programming-models(8975df5e-3d8a-4386-a87b-31f1080aaf1f).html",
        "abstract": "We describe AWE's HPC benchmark particle transport code, which employs a wavefront sweep algorithm. After almost 4 years collaboration between EPCC and AWE, we present Chimaera-2_3D: a Fortran90 and MPI/OpenMP code which scales well to thousands of cores for large problem sizes. Significant restructuring has increased the degrees of parallelism available to efficiently exploit future many-core exascale systems. For OpenMP, we have introduced slices through the cuboid mesh which present a set of cells which may be computed independently; and computation over the angles within each cell can also be parallelized using OpenMP. Previously, the initial form of Chimaera computed a coupled, inter-dependent iteration over 'Energy Groups'. Our new code now decouples these iterations which, whilst increasing the computational time, permits a new task level of efficient parallelism encoded using MPI. This paper will present results from the extensive benchmarking exercise using a Cray XT4/5 (HECToR) and a Cray XC30 (ARCHER).Wa",
        "title": "Performance and Extension of a Particle Transport Code using Hybrid MPI/OpenMP Programming Models",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            },
            {
                "name": "Gavin Pringle",
                "uuid": "66f4ae16-ad0a-4ab4-ae37-5f844ed07fae"
            }
        ]
    },
    "35300406-c28f-4cc0-bb1e-4d801ebab937": {
        "id": "35300406-c28f-4cc0-bb1e-4d801ebab937",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/profiling-ogsadai-performance-for-common-use-patterns(35300406-c28f-4cc0-bb1e-4d801ebab937).html",
        "abstract": "",
        "title": "Profiling OGSA-DAI Performance for Common Use Patterns",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "bb6b030b-b70c-4a48-baa5-52655919230b": {
        "id": "bb6b030b-b70c-4a48-baa5-52655919230b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-digitaldata-challenge(bb6b030b-b70c-4a48-baa5-52655919230b).html",
        "abstract": "Part I: <em>Strategies for success in the digital-data revolution</em>, provides an executive summary of the whole book to convince strategists, politicians, managers, and educators that our future data-intensive society requires new thinking, new behavior, new culture, and new distribution of investment and effort. This part will introduce the major concepts so that readers are equipped to discuss and steer their organization's response to the opportunities and obligations brought by the growing wealth of data. It will help readers understand the changing context brought about by advances in digital devices, digital communication, and ubiquitous computing. Chapter 1: <em>The digital-data challenge</em>, will help readers to understand the challenges ahead in making good use of the data and introduce ideas that will lead to helpful strategies. A global digital-data revolution is catalyzing change in the ways in which we live, work, relax, govern, and organize. This is a significant change in society, as important as the invention of printing or the industrial revolution, but more challenging because it is happening globally at lnternet speed. Becoming agile in adapting to this new world is essential.",
        "title": "The Digital-Data Challenge",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            }
        ]
    },
    "df8f345e-1e11-4df2-ac50-5ba228dce370": {
        "id": "df8f345e-1e11-4df2-ac50-5ba228dce370",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/software-in-reproducible-research-advice-and-best-practice-collected-from-experiences-at-the-collaborations-workshop(df8f345e-1e11-4df2-ac50-5ba228dce370).html",
        "abstract": "The Collaborations Workshop 2014 (CW14) brought together representatives from across the research community to discuss the issues around software's role in reproducible research. In this paper we summarise the themes, practices and ideas raised at the workshop. We also consider how the \"unconference\" format of the CW14 helps in eliciting information and forming future collaborations around aspects of reproducible research. In particular, we describe three distinct areas of concern which emerged from the event: collaboration readiness, capability enhancement and advocacy.",
        "title": "Software in reproducible research: advice and best practice collected from experiences at the collaborations workshop",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "ff06ad35-f25d-4955-84c3-bece81463f90": {
        "id": "ff06ad35-f25d-4955-84c3-bece81463f90",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/optimising-euroben-kernels-on-maxwell(ff06ad35-f25d-4955-84c3-bece81463f90).html",
        "abstract": "",
        "title": "Optimising Euroben kernels on Maxwell",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            },
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "0b0417db-d239-450d-9c67-67a02e848a18": {
        "id": "0b0417db-d239-450d-9c67-67a02e848a18",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/largescale-dataintensive-computing(0b0417db-d239-450d-9c67-67a02e848a18).html",
        "abstract": "",
        "title": "Large-Scale Data-Intensive Computing",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            }
        ]
    },
    "3545023a-4a32-4e50-b3ee-8111d8f6224d": {
        "id": "3545023a-4a32-4e50-b3ee-8111d8f6224d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ogsadai-30--the-whats-and-the-whys(3545023a-4a32-4e50-b3ee-8111d8f6224d).html",
        "abstract": "OGSA-DAI provides an extensible framework that allows data resources to be incorporated into Grid fabrics. The current OGSA-DAI release, version 3.0, is a complete top-to-bottom redesign and implementation of the OGSA-DAI product. A number of fundamental conceptual and design changes are introduced in this release. In this paper we describe the motivation behind this redesign and provide an overview of OGSA-DAI 3.0, comparing and contrasting it with OGSA-DAI 2.2. We also outline the implications that these changes have for the OGSA-DAI user community.",
        "title": "OGSA-DAI 3.0 \u2013 The Whats and the Whys",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Malcolm Illingworth",
                "uuid": "6ea1f03e-f39e-48a4-8867-a27c471920fa"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "e56a4312-fed7-4d28-997e-f29aadd2e4c2": {
        "id": "e56a4312-fed7-4d28-997e-f29aadd2e4c2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-fpga-highperformance-computing-alliance-parallel-toolkit(e56a4312-fed7-4d28-997e-f29aadd2e4c2).html",
        "abstract": "",
        "title": "The FPGA High-Performance Computing Alliance Parallel Toolkit",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Stephen Booth",
                "uuid": "b1fdf0bf-ae1e-4b47-94f6-a488f8d2f14c"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            },
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            },
            {
                "name": "Alan Simpson",
                "uuid": "edbe5450-e7d0-43d8-8700-4982f415b3e7"
            }
        ]
    },
    "c777ea4a-4067-4629-b046-0a42775e020c": {
        "id": "c777ea4a-4067-4629-b046-0a42775e020c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/maxwell--a-64-fpga-supercomputer(c777ea4a-4067-4629-b046-0a42775e020c).html",
        "abstract": "We present the initial results from the FHPCA Supercomputer project at the University of Edinburgh. The project has successfully built a general-purpose 64 FPGA computer and ported to it three demonstration applications from the oil, medical and finance sectors. This paper describes in brief the machine itself - Maxwell - its hardware and software environment and presents very early benchmark results from runs of the demonstrators.",
        "title": "Maxwell - a 64 FPGA Supercomputer",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Stephen Booth",
                "uuid": "b1fdf0bf-ae1e-4b47-94f6-a488f8d2f14c"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            },
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            },
            {
                "name": "Alan Simpson",
                "uuid": "edbe5450-e7d0-43d8-8700-4982f415b3e7"
            }
        ]
    },
    "85a9706a-d37c-41c3-a996-80552f08d6ed": {
        "id": "85a9706a-d37c-41c3-a996-80552f08d6ed",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/data-management-service-oriented-infrastructures-and-cloud-service-platforms-for-the-enterprise(85a9706a-d37c-41c3-a996-80552f08d6ed).html",
        "abstract": "",
        "title": "Data Management. Service Oriented Infrastructures and Cloud Service Platforms for the Enterprise",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            }
        ]
    },
    "ab6a2bae-c386-4f5e-a2e3-731f7cfdc6e0": {
        "id": "ab6a2bae-c386-4f5e-a2e3-731f7cfdc6e0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/maxwell--64-fpga-supercomputer(ab6a2bae-c386-4f5e-a2e3-731f7cfdc6e0).html",
        "abstract": "We describe the FPGA-based supercomputer Maxwell built by the FPGA High-Performance Computing  Alliance at the University of Edinburgh. Winner of the silver  medal in the BT Flagship Award for Innovation at the 2007 British Computer Society Awards, Maxwell is a general-purpose 64 FPGA computer designed for high-performance parallel computing. This paper describes the machine itself, its hardware and software environment and presents benchmark results from runs of three commercial demonstration applications from the oil, medical and finance <br/>sectors.",
        "title": "Maxwell - 64 FPGA Supercomputer",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Stephen Booth",
                "uuid": "b1fdf0bf-ae1e-4b47-94f6-a488f8d2f14c"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            },
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "1e82e342-0972-41bf-bddd-1b00fec8cde1": {
        "id": "1e82e342-0972-41bf-bddd-1b00fec8cde1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-software-sustainability-institute(1e82e342-0972-41bf-bddd-1b00fec8cde1).html",
        "abstract": "To effect change, the Software Sustainability Institute works with researchers, developers, funders, and infrastructure providers to identify and address key issues with research software.",
        "title": "The Software Sustainability Institute",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Parsons",
                "uuid": "59ec17d6-6f85-4919-a58e-5450c3de1f41"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "49804fad-90af-4ad7-aa30-bcee8aa4d3f8": {
        "id": "49804fad-90af-4ad7-aa30-bcee8aa4d3f8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/interfacing-novel-integrators-and-existing-molecular-dynamics-codes-with-the-mist-library(49804fad-90af-4ad7-aa30-bcee8aa4d3f8).html",
        "abstract": "",
        "title": "Interfacing novel integrators and existing Molecular Dynamics codes with the MIST library",
        "keywords": "",
        "authors": [
            {
                "name": "Antonia Collis",
                "uuid": "2289f0e7-8c0a-4791-b3c1-2024bd519fc4"
            },
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Elena Breitmoser",
                "uuid": "1a2c3c66-ade8-42d7-ae85-85b3e4a84425"
            }
        ]
    },
    "600e0a7f-1da1-4533-a391-383534776d56": {
        "id": "600e0a7f-1da1-4533-a391-383534776d56",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/developing-a-scalable-and-flexible-highresolution-dns-code-for-twophase-flows(600e0a7f-1da1-4533-a391-383534776d56).html",
        "abstract": "We introduce TPLS (Two-Phase Level Set), an MPI-parallel Direct Numerical Simulation code for two-phase flows in channel geometries. Recent developments to the code are discussed which improve the performance of the solvers and I/O by using the PETSc and NetCDF libraries respectively. Usability and functionality improvements enabled by code refactoring and merging of a separate OpenMP-parallelized version are also outlined. The overall scaling behaviour of the code is measured, and good strong scaling up to 1152 cores is observed for a 5.6 million element grid. A comparison is made between the legacy serial text-formatted I/O and new NetCDF implementations, showing speedups of up to 17x. Finally, we explore the effects of output file striping on the Lustre parallel file system on ARCHER, a Cray XC30 supercomputer, finding performance gains of up to 12% over the default striping settings.",
        "title": "Developing a scalable and flexible high-resolution DNS code for two-phase flows",
        "keywords": "",
        "authors": [
            {
                "name": "Antonia Collis",
                "uuid": "2289f0e7-8c0a-4791-b3c1-2024bd519fc4"
            },
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "5c7d48f0-b2a4-4a35-8ff4-65f004174f2f": {
        "id": "5c7d48f0-b2a4-4a35-8ff4-65f004174f2f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/developing-a-scalable-and-flexible-code-for-highresolution-dns-of-twophase-flows(5c7d48f0-b2a4-4a35-8ff4-65f004174f2f).html",
        "abstract": "",
        "title": "Developing a scalable and flexible code for high-resolution DNS of two-phase flows",
        "keywords": "",
        "authors": [
            {
                "name": "Antonia Collis",
                "uuid": "2289f0e7-8c0a-4791-b3c1-2024bd519fc4"
            },
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "6df32d14-8186-49c5-a2cc-19476d87bd63": {
        "id": "6df32d14-8186-49c5-a2cc-19476d87bd63",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/developing-a-scalable-and-flexible-code-for-highresolution-dns-of-twophase-flows(6df32d14-8186-49c5-a2cc-19476d87bd63).html",
        "abstract": "",
        "title": "Developing a scalable and flexible code for high-resolution DNS of two-phase flows",
        "keywords": "",
        "authors": [
            {
                "name": "Antonia Collis",
                "uuid": "2289f0e7-8c0a-4791-b3c1-2024bd519fc4"
            },
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "9b510764-98f3-4981-a69f-bce490a9167f": {
        "id": "9b510764-98f3-4981-a69f-bce490a9167f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/developing-a-scalable-and-flexible-code-for-highresolution-dns-of-twophase-flows(9b510764-98f3-4981-a69f-bce490a9167f).html",
        "abstract": "",
        "title": "Developing a scalable and flexible code for high-resolution DNS of two-phase flows",
        "keywords": "",
        "authors": [
            {
                "name": "Antonia Collis",
                "uuid": "2289f0e7-8c0a-4791-b3c1-2024bd519fc4"
            },
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "176a7e75-f5c6-4cd3-a76b-7e00c085db35": {
        "id": "176a7e75-f5c6-4cd3-a76b-7e00c085db35",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/structure-and-bonding-of-aqueous-glutamic-acid-from-classical-molecular-dynamics-simulations(176a7e75-f5c6-4cd3-a76b-7e00c085db35).html",
        "abstract": "Using classical molecular dynamics we have studied the solution structure of (1 : 1 : 29) glutamate with sodium counter ions and water. We provide a structural description of the system, focusing on glutamate-glutamate interactions and providing further insight into glutamate-water interactions. In particular we have characterised the solution structure using three different water potentials, finding little difference between the structural features they predict. We find key differences in the bonding motifs for the two different carboxyl groups, both in the glutamate-glutamate and glutamate-water interactions. Finally, we have examined the hydration structure of the sodium ions in the solution, showing that 10% of the ions are fully hydrated by water, despite the high glutamate concentration.",
        "title": "Structure and bonding of aqueous glutamic acid from classical molecular dynamics simulations",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Antonia Collis",
                "uuid": "2289f0e7-8c0a-4791-b3c1-2024bd519fc4"
            }
        ]
    },
    "3c94feb8-a5dd-460e-9b2e-a09e7233320e": {
        "id": "3c94feb8-a5dd-460e-9b2e-a09e7233320e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/bringing-the-grid-to-the-biomedical-workbench(3c94feb8-a5dd-460e-9b2e-a09e7233320e).html",
        "abstract": "<p>Modem biological research is data intensive and relies on an efficient informatics infrastructure. Research on the genetic control of embryo development involves large volume image data requiring significant computing resources for reconstruction, mapping and analysis. This poster describes a demonstrator for delivering secure and transparent access to high-performance computing to the laboratory workbench using Grid technologies, in this case for 3D reconstruction from OPT microscopy.</p>",
        "title": "Bringing the grid to the biomedical workbench",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "e8416ad7-750f-442f-9b17-d812b9bb414d": {
        "id": "e8416ad7-750f-442f-9b17-d812b9bb414d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-research-software-engineer(e8416ad7-750f-442f-9b17-d812b9bb414d).html",
        "abstract": "Research is increasingly digital. Twenty-first century research has been characterised by the rise of digital methods, the third and fourth paradigms of science \u2013 computational simulation and data-intensive research. In their turn, these new approaches are both built on a common foundation \u2013 computer software.<br/><br/>Yet despite this increasing reliance on software in research, professional practices for developing research software in academia lag far behind those in the commercial sector. Computational research tools are often fragile, generally not sustainable or usable beyond the lifetime of a given project, and frequently unsuitable for scrutiny. Those trained solely within academia often employ ad-hoc or casual development techniques. Institutions miss out on opportunities to increase the impact of their research by producing robust software deliverables that could be used and cited by their peers.<br/><br/>Computational work must reflect the committed attitude of experimentalists towards caring about precise, professional, repeatable, meticulous work \u2013 no-one with the same casual attitude to experimental instrumentation as many researchers have to code would be allowed anywhere near a lab. This is striking considering how often research results now depend on software.<br/><br/>Software engineering professionals are trained in best practices, and in the best commercial institutions follow a disciplined approach to the design, construction, testing and maintenance of software systems. Attempts to leverage these skills within academia by employing contract programmers typically fail, due to otherwise talented programmers lacking sufficient research experience and a necessary appreciation of the significant cultural differences between business and academia. Software engineers that do have research experience and good knowledge of the underlying domain are, however, in very short supply, due to the lack of appropriate institutional homes and career progression paths for their work.<br/><br/>This paper provides a synthesis of discussions that took place during and after the 2012 Collaborations Workshop organized by the Software Sustainability Institute in Oxford, UK.",
        "title": "The Research Software Engineer",
        "keywords": "",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "7aa3d69c-aed3-45d3-902d-c1bb3e595bde": {
        "id": "7aa3d69c-aed3-45d3-902d-c1bb3e595bde",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/endtoend-bandwidth-allocation-and-reservation-for-grid-applications(7aa3d69c-aed3-45d3-902d-c1bb3e595bde).html",
        "abstract": "<p>Production Grid infrastructure requires end-to-end guarantees on the Quality of Service from the underlying networks. In this paper, we present use cases for advance network resource reservation and then describe a multi-layered architecture that can support them. The architecture presents a single bandwidth broker, called BAR, which sits at the Grid layer. BAR not only provides a single point of access to Grid applications to reserve guaranteed end-to-end bandwidth, but also presents its interface in application terms (instead of networking terms). We expose two guaranteed bandwidth services: the Guaranteed Delivery File Transfer and Virtual Leased Line services. Integrated with the G\u00c9ANT2 bandwidth on demand infrastructure, our bandwidth broker deals with multiple network domains, further insulating the applications from network concerns. We also define additional components required for an end-to-end reservation as well as the interfaces between the components. Our deployed prototype demonstrated the world's first software-based, inter-domain bandwidth reservations based on Premium IP.</p>",
        "title": "End-to-end bandwidth allocation and reservation for grid applications",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Charaka Palansuriya",
                "uuid": "fa7ecedb-db73-44ce-9703-b55c93331e57"
            },
            {
                "name": "Alan Simpson",
                "uuid": "edbe5450-e7d0-43d8-8700-4982f415b3e7"
            }
        ]
    },
    "cbb6de91-4464-4625-8861-715dd355eb02": {
        "id": "cbb6de91-4464-4625-8861-715dd355eb02",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/s135-can-your-mobile-phone-improve-your-asthma(cbb6de91-4464-4625-8861-715dd355eb02).html",
        "abstract": "",
        "title": "S135\u2005Can your mobile phone improve your asthma?",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "a944bbec-2644-4bf1-8e81-fcffd27414cd": {
        "id": "a944bbec-2644-4bf1-8e81-fcffd27414cd",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/quenched-hadrons-using-wilson-and-oaimproved-fermion-actions-at-beta62(a944bbec-2644-4bf1-8e81-fcffd27414cd).html",
        "abstract": "",
        "title": "Quenched Hadrons Using Wilson and O(a)-Improved Fermion Actions at Beta=6.2",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "0a6922d1-3e13-47f5-b4b1-8092c0242e3f": {
        "id": "0a6922d1-3e13-47f5-b4b1-8092c0242e3f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/gaugeinvariant-smearing-and-matrix-correlators-using-wilson-fermions-at-beta62(0a6922d1-3e13-47f5-b4b1-8092c0242e3f).html",
        "abstract": "",
        "title": "Gauge-Invariant Smearing and Matrix Correlators Using Wilson Fermions at Beta=6.2",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "3329a68a-e2f9-4be6-a162-e96cd320cea0": {
        "id": "3329a68a-e2f9-4be6-a162-e96cd320cea0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/quenched-light-hadron-massspectrum-and-decay-constants--the-effects-of-oa-improvement-at-beta62(3329a68a-e2f9-4be6-a162-e96cd320cea0).html",
        "abstract": "",
        "title": "Quenched Light Hadron Mass-Spectrum and Decay Constants - The Effects Of O(a) Improvement at Beta=6.2",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "d3d79c1d-a641-4f51-acea-1de588e2276a": {
        "id": "d3d79c1d-a641-4f51-acea-1de588e2276a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/light-hadron-spectrum-and-decay-constants-in-quenched-lattice-qcd(d3d79c1d-a641-4f51-acea-1de588e2276a).html",
        "abstract": "",
        "title": "Light Hadron Spectrum and Decay Constants in Quenched Lattice QCD",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "9b7bb06b-959c-4f3b-afb1-fb5c57c60dbb": {
        "id": "9b7bb06b-959c-4f3b-afb1-fb5c57c60dbb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/quenched-heavylight-decay-constants(9b7bb06b-959c-4f3b-afb1-fb5c57c60dbb).html",
        "abstract": "",
        "title": "Quenched Heavy-Light Decay Constants",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "dfab14f2-e6ab-4e08-9a64-339f703a2cd7": {
        "id": "dfab14f2-e6ab-4e08-9a64-339f703a2cd7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/eudat-a-new-crossdisciplinary-data-infrastructure-for-science(dfab14f2-e6ab-4e08-9a64-339f703a2cd7).html",
        "abstract": "The EUDAT project is a pan-European data initiative that started in October 2011. The project brings together a unique consortium of 25 partners \u2013 including research communities, national data and high performance computing (HPC) centres, technology providers, and funding agencies \u2013 from 13 countries. EUDAT aims to build a sustainable cross-disciplinary and cross-national data infrastructure that provides a set of shared services for accessing and preserving research data.",
        "title": "EUDAT: A New Cross-Disciplinary Data Infrastructure for Science",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "220e8a5a-df96-4e79-8a71-2295ede0ca8a": {
        "id": "220e8a5a-df96-4e79-8a71-2295ede0ca8a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ogsadai-two-years-on-in-ogsadai(220e8a5a-df96-4e79-8a71-2295ede0ca8a).html",
        "abstract": "",
        "title": "OGSA-DAI: Two Years On in OGSA-DAI",
        "keywords": "",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "6df05941-cac1-4822-9618-0953abbf8150": {
        "id": "6df05941-cac1-4822-9618-0953abbf8150",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-design-and-implementation-of-grid-database-services-in-ogsadai(6df05941-cac1-4822-9618-0953abbf8150).html",
        "abstract": "",
        "title": "The Design and Implementation of Grid Database Services in OGSA-DAI",
        "keywords": "",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Charaka Palansuriya",
                "uuid": "fa7ecedb-db73-44ce-9703-b55c93331e57"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "c239da37-eae7-4a63-8fa0-98cec2fdbe56": {
        "id": "c239da37-eae7-4a63-8fa0-98cec2fdbe56",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ogsadai-usage-scenarios-and-behaviour--determining-good-practice(c239da37-eae7-4a63-8fa0-98cec2fdbe56).html",
        "abstract": "",
        "title": "OGSA-DAI Usage Scenarios and Behaviour \u2013 Determining Good Practice",
        "keywords": "",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "0ec3bdbf-5de6-4607-aba9-862cadf626a4": {
        "id": "0ec3bdbf-5de6-4607-aba9-862cadf626a4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ogsadai-status-report-and-future-directions(0ec3bdbf-5de6-4607-aba9-862cadf626a4).html",
        "abstract": "",
        "title": "OGSA-DAI Status Report and Future Directions",
        "keywords": "",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "fcf85516-32a8-45ae-b942-72cc8b344fcb": {
        "id": "fcf85516-32a8-45ae-b942-72cc8b344fcb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ogsadai-status-and-benchmarks(fcf85516-32a8-45ae-b942-72cc8b344fcb).html",
        "abstract": "",
        "title": "OGSA-DAI Status and Benchmarks",
        "keywords": "",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "75ab99bb-f99d-404a-82ac-121186506851": {
        "id": "75ab99bb-f99d-404a-82ac-121186506851",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-new-architecture-for-ogsadai(75ab99bb-f99d-404a-82ac-121186506851).html",
        "abstract": "",
        "title": "A new Architecture for OGSA-DAI",
        "keywords": "",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "1002be3e-3721-4b33-a80f-1c329b6d1c19": {
        "id": "1002be3e-3721-4b33-a80f-1c329b6d1c19",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/what-can-you-make(1002be3e-3721-4b33-a80f-1c329b6d1c19).html",
        "abstract": "",
        "title": "What can you make?",
        "keywords": "",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "8bfb809c-cb2a-4647-a152-1841ad5324d6": {
        "id": "8bfb809c-cb2a-4647-a152-1841ad5324d6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/unstructured-mesh-libraries-for-the-ap1000(8bfb809c-cb2a-4647-a152-1841ad5324d6).html",
        "abstract": "",
        "title": "Unstructured Mesh Libraries for the AP1000",
        "keywords": "",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "d35c0352-9a00-4ac1-a71e-d56fbfc9c4f6": {
        "id": "d35c0352-9a00-4ac1-a71e-d56fbfc9c4f6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/experiences-in-parallelising-flite3d-on-the-cray-t3d(d35c0352-9a00-4ac1-a71e-d56fbfc9c4f6).html",
        "abstract": "",
        "title": "Experiences in parallelising FLITE3D on the Cray T3D",
        "keywords": "",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "84f4a95e-7640-4d1c-9a20-ec8fc0cd6765": {
        "id": "84f4a95e-7640-4d1c-9a20-ec8fc0cd6765",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/software-engineering-is-software-engineering(84f4a95e-7640-4d1c-9a20-ec8fc0cd6765).html",
        "abstract": "",
        "title": "Software engineering is software engineering",
        "keywords": "",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            }
        ]
    },
    "bae85c37-4188-4736-aa19-9139dbd090af": {
        "id": "bae85c37-4188-4736-aa19-9139dbd090af",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/tracking-community-intelligence-with-trac(bae85c37-4188-4736-aa19-9139dbd090af).html",
        "abstract": "We report on experiences at the Software Sustainability Institute (SSI) in customizing and using the Trac system to provide a single platform for recording, managing and tracking a wide range of community interactions. We note the essential requirement of a lightweight, easy-to-use system for recording \u2018community metadata\u2019 and discuss the pros and cons of using Trac in this way for day-to-day operations within SSI, and more generally as a means to record and track interactions with a wide and potentially very large community.",
        "title": "Tracking Community Intelligence with Trac",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "58b06262-aeb3-4e52-8e1e-efdfc5ff0d86": {
        "id": "58b06262-aeb3-4e52-8e1e-efdfc5ff0d86",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-design-and-implementation-of-grid-database-services-in-ogsadai(58b06262-aeb3-4e52-8e1e-efdfc5ff0d86).html",
        "abstract": "Initially, Grid technologies were principally associated with supercomputer centres and large-scale scientific applications in physics and astronomy. They are now increasingly seen as being relevant to many areas of e-Science and e-Business. The emergence of the Open Grid Services Architecture (OGSA), to complement the ongoing activity on Web Services standards, promises to provide a service-based platform that can meet the needs of both business and scientific applications. Early Grid applications focused principally on the storage, replication and movement of file-based data. Now the need for the full integration of database technologies with Grid middleware is widely recognized. Not only do many Grid applications already use databases for managing metadata, but increasingly many are associated with large databases of domain-specific information (e.g. biological or astronomical data). This paper describes the design and implementation of OGSA-DAI, a service-based architecture for database access over the Grid. The approach involves the design of Grid Data Services that allow consumers to discover the properties of structured data stores and to access their contents. The initial focus has been on support for access to Relational and XML data, but the overall architecture has been designed to be extensible to accommodate different storage paradigms. The paper describes and motivates the design decisions that have been taken, and illustrates how the approach supports a range of application scenarios. The OGSA-DAI software is freely available from http://www.ogsadai.org.uk.",
        "title": "The design and implementation of Grid database services in OGSA-DAI",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Robert Baxter",
                "uuid": "5eb3902e-1edc-4b3b-a3dd-dab09553b420"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "a8dcf458-f10d-4ade-aba7-2bdd399f692a": {
        "id": "a8dcf458-f10d-4ade-aba7-2bdd399f692a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-ness-project(a8dcf458-f10d-4ade-aba7-2bdd399f692a).html",
        "abstract": "Physical modeling sound synthesis, emulating systems of a complexity approaching and even exceeding that of real-world acoustic musical instruments, is becoming possible, thanks to recent theoretical developments in musical acoustics and algorithm design. Severe practical difficulties remain, both at the level of the raw computational resources required, and at the level of user control. An approach to the first difficulty is through the use of large-scale parallelisation, and results for a variety of physical modeling systems are presented here. Any progress with regard to the second requires, necessarily, the experience and advice of professional musicians. A basic interface to a parallelised large-scale physical modeling synthesis system is presented here, accompanied by first-hand descriptions of the working methods of five composers, each of whom generated complete multichannel pieces using the system.",
        "title": "The NESS Project",
        "keywords": "",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            },
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "7c785b89-995c-4356-9f6e-cc277a2eae36": {
        "id": "7c785b89-995c-4356-9f6e-cc277a2eae36",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-alarms-service-for-monitoring-multidomain-grid-networks(7c785b89-995c-4356-9f6e-cc277a2eae36).html",
        "abstract": "Effective monitoring of multi-domain Grid networks is essential to\nsupport large operational Grid infrastructures. Timely detection of\nnetwork problems is an essential part of this monitoring. In order to\ndetect the problems, access to network monitoring data that exists in\nmultiple organisations is necessary. This paper presents an Alarms\nService that supports monitoring of such multi-domain Grid networks. The\nservice allows timely detection of networking problems based on\npre-defined, user-configurable conditions. The requirements gathered\nfrom real users for monitoring the networks are discussed. The paper\nshows how multi-organisation data access is resolved with the use of a\nstandards-based access mechanism. The architecture of the Alarms Service\nis discussed, providing the reasons behind the design decisions where\nappropriate. A description of the current implementation of the Alarms\nService and its deployment is provided.",
        "title": "An Alarms Service for Monitoring Multi-domain Grid Networks",
        "keywords": "",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Charaka Palansuriya",
                "uuid": "fa7ecedb-db73-44ce-9703-b55c93331e57"
            },
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            }
        ]
    },
    "70574ad1-2488-491b-8e8d-3707dcb6c419": {
        "id": "70574ad1-2488-491b-8e8d-3707dcb6c419",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/agreement-signalling-and-network-service-provisioning-for-grids(70574ad1-2488-491b-8e8d-3707dcb6c419).html",
        "abstract": "<p>Resource-sharing is one of the Grid intrinsic properties enabling efficient usage of services by clients from many Virtual Organizations. This is particularly true for network infrastructures, which are typically designed to serve a large number of heterogeneous users. In such an environment, the support of network Quality of Service requires the establishment of Service Level Agreements between users and network service providers, admission control as well as network control planes for automatic or semi-automatic service provisioning. The availability of guarantees allows flexible usage of the distributed infrastructure and enables application-controllable performance. Nevertheless, many network providers today only offer best-effort services and do not support Service Level Agreement signalling. In this paper we analyze requirements and introduce two bandwidth-oriented services for enhanced Grid data transfer: the Guaranteed Delivery File Transfer and Virtual Leased Line services. We propose a complete architecture - fully integrated with Grid middleware - for network Service Level Agreement management and inter-domain network service provisioning. This is based on the functional division into agreement and service provider layers proposed by the Grid Resource Allocation and Agreement Protocol working group of the Global Grid Forum.</p>",
        "title": "Agreement signalling and network service provisioning for grids",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Charaka Palansuriya",
                "uuid": "fa7ecedb-db73-44ce-9703-b55c93331e57"
            }
        ]
    },
    "750d03eb-b419-4063-a411-6ebb4ffd362b": {
        "id": "750d03eb-b419-4063-a411-6ebb4ffd362b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/bridging-network-monitoring-and-the-grid(750d03eb-b419-4063-a411-6ebb4ffd362b).html",
        "abstract": "<p>Several network monitoring frameworks have been successfully deployed in various network domains, but they typically expose proprietary interfaces and feature poor interoperability. In addition, frameworks either focus on end-to-end or on domain edge-to-edge measurements. Consequently, they can only address a partial spectrum of Grid performance characteristics. As Grids are typically largescale infrastructures spanning multiple network domains, the seamless view that is paramount to Grid middleware and operators, can be severely hindered. We analyse the requirements of important Grid middleware components: job scheduling and data transport. We propose a set of services for the publishing, discovery and gathering of information about network performance and framework capabilities. These expose interfaces that follow the Global Grid Forum recommendations. Finally, we review the implementation details of a prototype of the proposed architecture.</p>",
        "title": "Bridging network monitoring and the grid",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            }
        ]
    },
    "816bb56e-ddc9-4bd8-8652-fd6c35856433": {
        "id": "816bb56e-ddc9-4bd8-8652-fd6c35856433",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/applying-the-grid-to-3d-capture-technology(816bb56e-ddc9-4bd8-8652-fd6c35856433).html",
        "abstract": "<p>The PGPGrid project aims to parallelize the process of extracting range data from an experimental 3D scanner using the Grid as a vehicle for accessing necessary resources. The application is potentially highly parallel but has some unusual features such as rapid spawning of processes in real time and a dynamic inter-process network topology. These characteristics are such as to require enhancement of the usual task migration capabilities of the Globus toolkit. The present paper initially discusses attempts to estimate the real parallelizability of the scanner application. It then describes a new Java application programming interface, based on Milner's \u03c0-calculus, which could be used to extend Globus in a manner capable of supporting systems with this kind of dynamic parallel structure. The location of processing resources for the \u03c0-calculus is done using a Web-services-based resource locator. The article also describes the pipeline of processing from initial stereo photogrametry to the final production of animation models. A key step in this is the conformation of animator's models to the data obtained by the real-time scanner. Algorithmic innovations in this process are described.</p>",
        "title": "Applying the grid to 3D capture technology",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            }
        ]
    },
    "752d9767-77ed-42e9-b4a3-446217316191": {
        "id": "752d9767-77ed-42e9-b4a3-446217316191",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/gridweaver-automatic-adaptive-largescale-configuration-for-grid-computing(752d9767-77ed-42e9-b4a3-446217316191).html",
        "abstract": "The Gridweaver project reviewed the management tools and techniques currently available for\nLarge Scale Configuration. We substantiated that these will not be able to sustain the demands\nof the Grid services currently in production, unless there is a paradigm shift towards high-level,\ndeclarative descriptions of fabric configurations. Our prototype configuration architecture offered\nthis power and allowed our research Grid service, GPrint, to demonstrate ease of maintenance,\nadaptability to the demands of the fabric and fault tolerance.\nThis paper introduces system configuration as a major issue to the e-Science community and\npresents the findings of our research. Interviews of representative large-scale installation managers\nand our projected case studies for future use of the Grid are distilled to form the requirements of Grid\nfabrics. We present our prototype architecture, combining the consortium\u2019s background approaches\nto system configuration. We then discuss our GPrint Grid service, which demonstrates the successful\ninvestigation of some of the key configuration deficiencies identified by the consortium.",
        "title": "GridWeaver: automatic, adaptive, large-scale configuration for Grid computing",
        "keywords": "",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            }
        ]
    },
    "ad8ae0a9-73ef-40bb-ac01-2ab7fb7b8b56": {
        "id": "ad8ae0a9-73ef-40bb-ac01-2ab7fb7b8b56",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/bonfire(ad8ae0a9-73ef-40bb-ac01-2ab7fb7b8b56).html",
        "abstract": "<p>BonFIRE is a multi-site test bed that supports testing of Cloud-based and distributed applications. BonFIRE breaks the mould of commercial Cloud offerings by providing unique functionality in terms of observability, control, advanced Cloud features and ease of use for experimentation. A number of successful use cases have been executed on BonFIRE, involving industrial and academic users and delivering impact in diverse areas, such as media, e-health, environment and manufacturing. The BonFIRE user-base is expanding through its free, Open Access scheme, daily carrying out important research, while the consortium is working to sustain the facility beyond 2014.</p>",
        "title": "BonFIRE",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            }
        ]
    },
    "f706488d-4c27-4260-9ad2-9be121bfb577": {
        "id": "f706488d-4c27-4260-9ad2-9be121bfb577",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cloud-and-network-facilities-federation-in-bonfire(f706488d-4c27-4260-9ad2-9be121bfb577).html",
        "abstract": "<p>In recent years we have seen how Cloud Computing is changing the way of doing businesses and how services are delivered over the Internet. This disruption is a major challenge for Service Providers and Independent Software Vendors when creating new services and software applications for the Cloud. BonFIRE offers a federated, multi-site cloud testbed to support large-scale testing of applications, services and systems. This is achieved by federating geographically distributed, heterogeneous clouds testbeds where each exposes unique configuration and/or features while giving to the experimenters (users) an homogeneous way to interact with the facility. All those testbeds are controlled by a central set of services commonly denominated \"Broker\". Additionally, BonFIRE is federated with different network facilities like the Virtual Wall, FEDERICA and AutoBAHN to provide high-level interfaces to network control functionality, in order to simulate diverse network QoS scenarios, enabling vertical federation.</p>",
        "title": "Cloud and network facilities federation in BonFIRE",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            }
        ]
    },
    "3a92e92b-4eaa-4c3c-b0dc-c16ce3dcc7df": {
        "id": "3a92e92b-4eaa-4c3c-b0dc-c16ce3dcc7df",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/large-scale-physical-modeling-sound-synthesis(3a92e92b-4eaa-4c3c-b0dc-c16ce3dcc7df).html",
        "abstract": "Sound synthesis based on physical models of musical instruments is, ultimately, an exercise in numerical simulation. As such, for complex systems of the type seen in musical acoustics, simulation can be a computationally costly undertaking, particularly if simplifying hypotheses, such as those of traveling wave or mode decompositions are not employed. In this paper, large scale time stepping methods, such as the \ufb01nite difference time domain and \ufb01nite volume time domain methods are explored for a variety of systems of interest in musical acoustics, including brass instruments, percussion instruments based on thin plate and shell vibration, and also their embeddings in 3D acoustic spaces. Attention is paid here to implementation issues, particularly on parallel hardware, which is well-suited to time stepping methods operating over regular grids. Sound examples are presented.",
        "title": "Large Scale Physical Modeling Sound Synthesis",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            },
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            },
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "df4469ee-cd2f-4b0c-a300-916faf92271b": {
        "id": "df4469ee-cd2f-4b0c-a300-916faf92271b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-probes-coordination-protocol-periodic-task-coordination-and-control-across-administrative-boundaries(df4469ee-cd2f-4b0c-a300-916faf92271b).html",
        "abstract": "The coordination and scheduling of affiliated tasks to be run at different sites is a challenging problem, specifically in the domain of network performance monitoring. This paper presents a software implementation of the Probes Coordination Protocol (PCP) which provides a solution to this problem. The PCP allows tasks to be executed regularly on a multitude of sites without the need for repeated user or administrator intervention. In addition it provides a robust mechanism for handling site failures, and a VOMS based security model to ensure appropriate usage. The paper provides the original motivation for the PCP, describes the PCP itself and discusses the new software implementation and its application.",
        "title": "The Probes Coordination Protocol: Periodic Task Coordination and Control across Administrative Boundaries",
        "keywords": "",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Charaka Palansuriya",
                "uuid": "fa7ecedb-db73-44ce-9703-b55c93331e57"
            },
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            },
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            }
        ]
    },
    "a3a03519-1a96-4254-9e89-541fc5f54a18": {
        "id": "a3a03519-1a96-4254-9e89-541fc5f54a18",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/building-data-management-components-for-business-applications-in-collaboration-and-the-knowledge-economy-issues-applications-case-studies(a3a03519-1a96-4254-9e89-541fc5f54a18).html",
        "abstract": "",
        "title": "Building Data Management Components for Business Applications, in Collaboration and the Knowledge Economy: Issues, Applications, Case Studies",
        "keywords": "",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            }
        ]
    },
    "40c12050-eddd-43ea-94e4-4e9a69b66d66": {
        "id": "40c12050-eddd-43ea-94e4-4e9a69b66d66",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-standardsbased-alarms-service-for-monitoring-federated-networks(40c12050-eddd-43ea-94e4-4e9a69b66d66).html",
        "abstract": "",
        "title": "A Standards-based Alarms Service for Monitoring Federated Networks",
        "keywords": "",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            }
        ]
    },
    "6fb9567b-db10-404d-a9f2-72e71a453b93": {
        "id": "6fb9567b-db10-404d-a9f2-72e71a453b93",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-probes-coordination-protocol-periodic-task-coordination-and-control-across-administrative-boundaries(6fb9567b-db10-404d-a9f2-72e71a453b93).html",
        "abstract": "",
        "title": "The Probes Co-ordination Protocol: Periodic Task Coordination and Control across Administrative Boundaries",
        "keywords": "",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            },
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            }
        ]
    },
    "81671166-6d07-4aad-9360-ff881cb6a876": {
        "id": "81671166-6d07-4aad-9360-ff881cb6a876",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/standardsbased-network-monitoring-for-the-grid(81671166-6d07-4aad-9360-ff881cb6a876).html",
        "abstract": "As large grid infrastructures, such as Enabling Grids for E-sciencE, mature, they are being used by scientists around the world in their daily work, running thousands of concurrent computational jobs and transferring large amounts of data. The successful and sustainable operation of such grid infrastructures is only possible through the use of monitoring tools. The underlying networks upon which grid infrastructures are built are critical to their operation; therefore, network monitoring becomes an important part of the overall grid monitoring strategy. In this paper, the design and implementation of a set of tools for providing access to federated network monitoring data are presented, based on standards developed within the Open Grid Forum Network Measurements Working Group (NM-WG). These tools give access to data collected by heterogeneous, NM-WG compliant network monitoring tools.",
        "title": "Standards-based network monitoring for the grid",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            }
        ]
    },
    "6826a847-699f-4e4d-a0a8-8e1ffcafd2b5": {
        "id": "6826a847-699f-4e4d-a0a8-8e1ffcafd2b5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/federated-network-performance-monitoring-for-the-grid(6826a847-699f-4e4d-a0a8-8e1ffcafd2b5).html",
        "abstract": "",
        "title": "Federated Network Performance Monitoring for the Grid",
        "keywords": "",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            }
        ]
    },
    "6d6e3902-9de9-4907-aae5-46c232a1eeda": {
        "id": "6d6e3902-9de9-4907-aae5-46c232a1eeda",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/genomewide-association-scan-identifies-a-colorectal-cancer-susceptibility-locus-on-11q23-and-replicates-risk-loci-at-8q24-and-18q21(6d6e3902-9de9-4907-aae5-46c232a1eeda).html",
        "abstract": "In a genome-wide association study to identify loci associated with colorectal cancer (CRC) risk, we genotyped 555,510 SNPs in 1,012 early- onset Scottish CRC cases and 1,012 controls (phase 1). In phase 2, we genotyped the 15,008 highest-ranked SNPs in 2,057 Scottish cases and 2,111 controls. We then genotyped the five highest-ranked SNPs from the joint phase 1 and 2 analysis in 14,500 cases and 13,294 controls from seven populations, and identified a previously unreported association, rs3802842 on 11q23 (OR 1.1; P=5.8 x 10(-10)),showing population differences in risk. We also replicated and fine-mapped associations at 8q24 (rs7014346; OR 1.19; P=8.6x10(-26)) and 18q21 (rs4939827; OR 1.2; P=7.8 x 10(-28)). Risk was greater for rectal than for colon cancer for rs3802842 (P &lt; 0.008) and rs4939827 (P &lt; 0.009). Carrying all six possible risk alleles yielded OR 2.6 (95% CI 1.75-3.89) for CRC. These findings extend our understanding of the role of common genetic variation in CRC etiology.",
        "title": "Genome-wide association scan identifies a colorectal cancer susceptibility locus on 11q23 and replicates risk loci at 8q24 and 18q21",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Konstantinos Kavoussanos-Kavoussanakis",
                "uuid": "36fe46ae-67d0-4580-976d-335ff922b9e5"
            },
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            },
            {
                "name": "Lorna Smith",
                "uuid": "5c748338-46b1-485e-95af-511b43c62836"
            }
        ]
    },
    "7b6826c8-56ab-4b3e-b879-2bfeda26f56b": {
        "id": "7b6826c8-56ab-4b3e-b879-2bfeda26f56b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/implementation-of-dual-resolution-simulation-methodology-in-lammps(7b6826c8-56ab-4b3e-b879-2bfeda26f56b).html",
        "abstract": "",
        "title": "Implementation of Dual Resolution Simulation Methodology in LAMMPS",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "72ffd869-24b6-4b1b-97a7-f1bfcf8f1788": {
        "id": "72ffd869-24b6-4b1b-97a7-f1bfcf8f1788",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cp2kuk-supporting-advances-in-atomistic-simulation-capability(72ffd869-24b6-4b1b-97a7-f1bfcf8f1788).html",
        "abstract": "",
        "title": "CP2K-UK: Supporting Advances in Atomistic Simulation Capability",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "5f9482b1-7479-46b4-87ad-c230e242763f": {
        "id": "5f9482b1-7479-46b4-87ad-c230e242763f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cp2kuk-supporting-advances-in-atomistic-simulation-capability(5f9482b1-7479-46b4-87ad-c230e242763f).html",
        "abstract": "",
        "title": "CP2K-UK: Supporting Advances in Atomistic Simulation Capability",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "e0055f02-73b8-422a-8fb0-4b6250227ea8": {
        "id": "e0055f02-73b8-422a-8fb0-4b6250227ea8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/how-does-blood-regulate-cerebral-temperatures-during-hypothermia(e0055f02-73b8-422a-8fb0-4b6250227ea8).html",
        "abstract": "Macro-modeling of cerebral blood flow can help determine the impact of thermal intervention during instances of head trauma to mitigate tissue damage. This work presents a bioheat model using a 3D fluid-porous domain coupled with intersecting 1D arterial and venous vessel trees. This combined vascular porous (VaPor) model resolves both cerebral blood flow and energy equations, including heat generated by metabolism, using vasculature extracted from MRI data and is extended using a tree generation algorithm. Counter-current flows are expected to increase thermal transfer within the brain and are enforced using either the vascular structure or flow reversal, represented by a flow reversal constant, C R . These methods exhibit larger average brain cooling (from 0.56\u2009\u00b0C\u2009\u00b1\u2009&lt;0.01\u2009\u00b0C to 0.58\u2009\u00b0C\u2009\u00b1\u2009&lt;0.01\u2009\u00b0C) compared with previous models (0.39\u2009\u00b0C) when scalp temperature is reduced. An greater reduction in core brain temperature is observed (from 0.29\u2009\u00b0C\u2009\u00b1\u2009&lt;0.01\u2009\u00b0C to 0.45\u2009\u00b0C\u2009\u00b1\u2009&lt;0.01\u2009\u00b0C) compared to previous models (0.11\u2009\u00b0C) due to the inclusion of counter-current cooling effects. The VaPor model also predicts that a hypothermic average temperature (&lt;36\u2009\u00b0C) can be reached in core regions of neonatal models using scalp cooling alone.",
        "title": "How does blood regulate cerebral temperatures during hypothermia?",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "c35271cf-16a7-41ce-863e-511c54d8b9a2": {
        "id": "c35271cf-16a7-41ce-863e-511c54d8b9a2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/implementation-of-dual-resolution-simulation-methodology-in-lammps(c35271cf-16a7-41ce-863e-511c54d8b9a2).html",
        "abstract": "",
        "title": "Implementation of Dual Resolution Simulation Methodology in LAMMPS",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "1b6a1d8c-471e-4163-aa32-5c65158c1016": {
        "id": "1b6a1d8c-471e-4163-aa32-5c65158c1016",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/bespoke-bone-modelling-with-voxfe(1b6a1d8c-471e-4163-aa32-5c65158c1016).html",
        "abstract": "",
        "title": "Bespoke bone modelling with VOX-FE",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "33f7b74f-11bb-4b0e-a7f0-a3a890687ec7": {
        "id": "33f7b74f-11bb-4b0e-a7f0-a3a890687ec7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cp2kuk-supporting-advances-in-atomistic-simulation-capability(33f7b74f-11bb-4b0e-a7f0-a3a890687ec7).html",
        "abstract": "",
        "title": "CP2K-UK: Supporting Advances in Atomistic Simulation Capability",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "848dbf4f-d846-4073-92e2-6b12a8805267": {
        "id": "848dbf4f-d846-4073-92e2-6b12a8805267",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/implementation-of-dual-resolution-simulation-methodology-in-lammps(848dbf4f-d846-4073-92e2-6b12a8805267).html",
        "abstract": "",
        "title": "Implementation of Dual Resolution Simulation Methodology in LAMMPS",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "cf1b8346-e71a-4ca8-b1eb-7e848a1ab1c3": {
        "id": "cf1b8346-e71a-4ca8-b1eb-7e848a1ab1c3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/molecular-integration-simulation-toolkit--interfacing-novel-integrators-with-molecular-dynamics-codes(cf1b8346-e71a-4ca8-b1eb-7e848a1ab1c3).html",
        "abstract": "",
        "title": "Molecular Integration Simulation Toolkit - interfacing novel integrators with Molecular Dynamics codes",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "f7fbbfdb-418e-490c-88b9-76232b54b285": {
        "id": "f7fbbfdb-418e-490c-88b9-76232b54b285",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/evaluating-cp2k-on-exascale-hardware-intel-xeon-phi(f7fbbfdb-418e-490c-88b9-76232b54b285).html",
        "abstract": "CP2K, a popular open-source European atomistic simulation package has been ported to the Intel Xeon Phi architecture, requiring no code modifications except minor bug fixes. Benchmarking of a small molecular dynamics simulation has been carried out using CP2K\u2019s existing MPI, OpenMP and mixed-mode MPI/OpenMP implementations to achieve full utilisation of the Xeon Phi\u2019s 240 virtual cores. Running on the Xeon Phi in native mode, CP2K is approximately 4x slower than utilising all 16 cores of a Xeon E5-2670 Sandy Bridge dualsocket node. Careful placement of processes and threads on the virtual cores of the Xeon Phi was found to be crucial in achieving good performance. <br/><br/>Analysis of the benchmark results has led to the identification of a number of bottlenecks which must be resolved to achieve competitive performance on the Xeon Phi, which will be carried out as a follow on to the work reported here.",
        "title": "Evaluating CP2K on Exascale Hardware: Intel Xeon Phi",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            }
        ]
    },
    "373b61c9-7db9-4dba-a469-cb13c4de7f66": {
        "id": "373b61c9-7db9-4dba-a469-cb13c4de7f66",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/molecular-integration-simulation-toolkit--interfacing-novel-integrators-with-molecular-dynamics-codes(373b61c9-7db9-4dba-a469-cb13c4de7f66).html",
        "abstract": "",
        "title": "Molecular Integration Simulation Toolkit - interfacing novel integrators with Molecular Dynamics codes",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Elena Breitmoser",
                "uuid": "1a2c3c66-ade8-42d7-ae85-85b3e4a84425"
            }
        ]
    },
    "278f6716-555d-49ea-aca5-c7cccbcc3afa": {
        "id": "278f6716-555d-49ea-aca5-c7cccbcc3afa",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/voxfe-new-functionality-for-new-communities(278f6716-555d-49ea-aca5-c7cccbcc3afa).html",
        "abstract": "",
        "title": "VOX-FE: New functionality for new communities",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "943e91e8-39af-4720-8480-70c77bda5b4d": {
        "id": "943e91e8-39af-4720-8480-70c77bda5b4d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/molecular-integration-simulation-toolkit--interfacing-novel-integrators-with-molecular-dynamics-codes(943e91e8-39af-4720-8480-70c77bda5b4d).html",
        "abstract": "Modern production Molecular Dynamics codes represent a significant investment of effort by the community to develop highly optimised force evaluation routines able to take advantage of state-of-the art hardware such as GPUs and multi-core CPUs. However, this comes at a cost of code complexity which makes it hard for new integration algorithms to be implemented in these packages. This creates a catch-22 for algorithm developement - if new algorithms cannot be implemented and tested in production codes it may be impossible to demonstrate their benefits over existing schemes; conversely, if the community cannot see the benefit of new algorithms, code developers will not spent time implementing them!<br/>The Molecular Integration Simulation Toolkit (MIST) library is a solution to this problem by providing plug-ins to existing optimised MD codes, coupled with a simple interface for the development of new integration methods. MIST currently provides interfaces to GROMACS, Amber and NAMD-Lite, allowing it to benefit from OpenMP and GPU acceleration for force-evaluation. Several standard (Verlet, Leapfrog) and new (Langevin Dynamics based on a BAOAB splitting) integrators have been implemented to date. The MIST library interface results in significant ease-of-development, at negligible loss of performance. New integration algorithms are implemented once, in a code-agnostic manner, and can then be immediately deployed in all the MD codes supported by MIST.<br/>As well as algorithms for sampling the canonical and micro-canonical ensembles, MIST is also a platform for building more advanced schemes. For example, we have implemented an extended-system method for 'Continuous Tempering', which enables computation of free energy maps in systems with large energy barriers.<br/>Several new features are under development in MIST - new constraint solvers for extremely long timesteps and multi-timestep splittings, MPI parallelisation, and support for more MD codes. We welcome the community's input on direction for future development.",
        "title": "Molecular Integration Simulation Toolkit - interfacing novel integrators with Molecular Dynamics codes",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Elena Breitmoser",
                "uuid": "1a2c3c66-ade8-42d7-ae85-85b3e4a84425"
            }
        ]
    },
    "efa33c19-445e-49e1-aa33-75f014a01bc8": {
        "id": "efa33c19-445e-49e1-aa33-75f014a01bc8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/executing-dynamic-heterogeneous-workloads-on-blue-waters-with-radicalpilot(efa33c19-445e-49e1-aa33-75f014a01bc8).html",
        "abstract": "Traditionally HPC systems such as Crays have been designed to support mostly monolithic workloads. How- ever, the workload of many important scientific applications is constructed out of spatially and temporally heterogeneous tasks that are often dynamically inter-related. These workloads can benefit from being executed at scale on HPC resources, but a tension exists between the workloads\u2019 resource utilization requirements and the capabilities of the HPC system software and usage policies. Pilot systems have the potential to relieve this tension. RADICAL-Pilot is a scalable and portable pilot system that enables the execution of such diverse workloads. In this paper we describe the design and characterize the performance of its RADICAL-Pilot\u2019s scheduling and executing components on Crays, which are engineered for efficient resource utilization while maintaining the full generality of the Pilot abstraction. We will discuss four different imple- mentations of support for RADICAL-Pilot on Cray systems and analyze and report on their performance.",
        "title": "Executing dynamic heterogeneous workloads on Blue Waters with RADICAL-Pilot",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "fbb0e846-264d-42a0-807e-ba9f58c746b1": {
        "id": "fbb0e846-264d-42a0-807e-ba9f58c746b1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/pypcazip-a-pcabased-toolkit-for-compression-and-analysis-of-molecular-simulation-data(fbb0e846-264d-42a0-807e-ba9f58c746b1).html",
        "abstract": "The biomolecular simulation community is currently in need of novel and optimised software tools that can analyse and process, in reasonable timescales, the large generated amounts of molecular simulation data. In light of this, we have developed and present here pyPcazip: a suite of software tools for compression and analysis of molecular dynamics (MD) simulation data. The software is compatible with trajectory file formats generated by most contemporary MD engines such as AMBER, CHARMM, GROMACS and NAMD, and is MPI parallelised to permit the efficient processing of very large datasets. pyPcazip is a Unix based open-source software (BSD licenced) written in Python.",
        "title": "pyPcazip: A PCA-based toolkit for compression and analysis of molecular simulation data",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Elena Breitmoser",
                "uuid": "1a2c3c66-ade8-42d7-ae85-85b3e4a84425"
            }
        ]
    },
    "7c64e394-cbff-49f5-aab6-1bcca931d6d1": {
        "id": "7c64e394-cbff-49f5-aab6-1bcca931d6d1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/highperformance-computational-fluid-dynamics-a-customcode-approach(7c64e394-cbff-49f5-aab6-1bcca931d6d1).html",
        "abstract": "We introduce a modified and simplified version of the pre-existing fully parallelized three-dimensional Navier--Stokes flow solver known as TPLS. We demonstrate how the simplified version can be used as a pedagogical tool for the study of computational fluid dynamics and parallel computing. TPLS is at its heart a two-phase flow solver, and uses calls to a range of external libraries to accelerate its performance. However, in the present context we narrow the focus of the study to basic hydrodynamics and parallel computing techniques, and the code is therefore simplified and modified to simulate pressure-driven single-phase flow in a channel, using only relatively simple Fortran 90 code with MPI parallelization, but no calls to any other external libraries. The modified code is analysed in order to both validate its accuracy and investigate its scalability up to 1000 CPU cores. Simulations are performed for several benchmark cases in pressure-driven channel flow, including a turbulent simulation, wherein the turbulence is incorporated via the large-eddy simulation technique. The work may be of use to advanced undergraduate and graduate students as an introductory study in computational fluid dynamics, while also providing insight for those interested in more general aspects of high-performance computing.",
        "title": "High-performance computational fluid dynamics: a custom-code approach",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "7f28c8ad-5918-4136-941b-9d4a7c6f6e5e": {
        "id": "7f28c8ad-5918-4136-941b-9d4a7c6f6e5e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/genefer-programs-for-finding-large-probable-generalized-fermat-primes(7f28c8ad-5918-4136-941b-9d4a7c6f6e5e).html",
        "abstract": "Genefer is a suite of programs for performing Probable Primality (PRP) tests of Generalised Fermat numbers b2n+1 (GFNs) using a Fermat test. Optimised implementations are available for modern CPUs using single instruction, multiple data (SIMD) instructions, as well as for GPUs using CUDA or OpenCL. Genefer has been extensively used by PrimeGrid \u2013 a volunteer computing project searching for large prime numbers of various kinds, including GFNs.<br/>Genefer\u2019s architecture separates the high level logic such as checkpointing and user interface from the architecture-specific performance-critical parts of the implementation, which are suitable for re-use. Genefer is released under the MIT license. Source and binaries are available from www.assembla.com/spaces/genefer.",
        "title": "Genefer: Programs for finding large probable generalized Fermat primes",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "3bcf499b-d5c1-4b17-9ab2-9bd183669465": {
        "id": "3bcf499b-d5c1-4b17-9ab2-9bd183669465",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/developing-a-usercentric-cp2k-benchmark-suite(3bcf499b-d5c1-4b17-9ab2-9bd183669465).html",
        "abstract": "",
        "title": "Developing a User-Centric CP2K Benchmark Suite",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            }
        ]
    },
    "c903cde1-808a-4869-9a13-a1246143a4d4": {
        "id": "c903cde1-808a-4869-9a13-a1246143a4d4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/implementation-of-filter-matrix-diagonalisation(c903cde1-808a-4869-9a13-a1246143a4d4).html",
        "abstract": "",
        "title": "Implementation of Filter Matrix Diagonalisation",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "e59f2639-c0a1-4c64-aee4-4e37f9cd45a1": {
        "id": "e59f2639-c0a1-4c64-aee4-4e37f9cd45a1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/putting-extasy-in-charge-of-an-arduous-computational-challenge(e59f2639-c0a1-4c64-aee4-4e37f9cd45a1).html",
        "abstract": "",
        "title": "Putting ExTASY in charge of an arduous computational challenge",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Elena Breitmoser",
                "uuid": "1a2c3c66-ade8-42d7-ae85-85b3e4a84425"
            }
        ]
    },
    "031354ae-0c6b-495e-870d-db07e09050f0": {
        "id": "031354ae-0c6b-495e-870d-db07e09050f0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cp2kuk-supporting-advances-in-atomistic-simulation-capability(031354ae-0c6b-495e-870d-db07e09050f0).html",
        "abstract": "",
        "title": "CP2K-UK: Supporting Advances in Atomistic Simulation Capability",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            },
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            }
        ]
    },
    "b37b872c-c0d5-4205-ad77-70d3c0e73ddc": {
        "id": "b37b872c-c0d5-4205-ad77-70d3c0e73ddc",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mist-molecular-integration-simulation-toolkit(b37b872c-c0d5-4205-ad77-70d3c0e73ddc).html",
        "abstract": "",
        "title": "MIST: Molecular Integration Simulation Toolkit",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Elena Breitmoser",
                "uuid": "1a2c3c66-ade8-42d7-ae85-85b3e4a84425"
            }
        ]
    },
    "9201d615-dd02-4904-8288-73de3a943bb9": {
        "id": "9201d615-dd02-4904-8288-73de3a943bb9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cp2kuk-supporting-advances-in-atomistic-simulation-capability(9201d615-dd02-4904-8288-73de3a943bb9).html",
        "abstract": "",
        "title": "CP2K-UK: Supporting Advances in Atomistic Simulation Capability",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            },
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            }
        ]
    },
    "04b30090-35f5-4da2-9640-c43536491fd4": {
        "id": "04b30090-35f5-4da2-9640-c43536491fd4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/introduction-to-cp2k-a-first-principles-electronic-structure-simulation-package(04b30090-35f5-4da2-9640-c43536491fd4).html",
        "abstract": "",
        "title": "Introduction to CP2K: a first principles electronic structure simulation package",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "d0408211-be93-4746-9477-2bf9cb7271a1": {
        "id": "d0408211-be93-4746-9477-2bf9cb7271a1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/extasy-a-pythonbased-extensible-toolkit-for-advanced-sampling-and-analysis-in-biomolecular-simulation(d0408211-be93-4746-9477-2bf9cb7271a1).html",
        "abstract": "In this poster we will discuss a python-based toolkit for advanced sampling and analysis in biomolecular simulation providing details on the python scientific libraries used to implement it. We will also show examples of the enhanced sampling provided by one of the workflows of the framework compared to conventional molecular dynamics techniques, for a variety of biomolecular simulation use-cases.",
        "title": "ExTASY: A python-based Extensible Toolkit for Advanced Sampling and Analysis in Biomolecular Simulation",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Elena Breitmoser",
                "uuid": "1a2c3c66-ade8-42d7-ae85-85b3e4a84425"
            }
        ]
    },
    "b1f7d094-331a-4ba9-b460-3addf55a58a7": {
        "id": "b1f7d094-331a-4ba9-b460-3addf55a58a7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/voxelbased-finite-element-modelling-with-voxfe2(b1f7d094-331a-4ba9-b460-3addf55a58a7).html",
        "abstract": "",
        "title": "Voxel-based finite element modelling with VOX-FE2",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "4cc69913-e3d2-4075-b501-ec5da108bc63": {
        "id": "4cc69913-e3d2-4075-b501-ec5da108bc63",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/automated-multiplatform-testing-and-code-coverage-analysis-of-the-cp2k-application(4cc69913-e3d2-4075-b501-ec5da108bc63).html",
        "abstract": "<p>CP2K is a widely used application for atomistic simulation that can execute on a range of architectures. Consisting of more than one million lines of Fortran 95 code, the application is tested for correctness with a set of about 2,500 inputs using a dedicated regression testing environment. CP2K can be built with many compilers and executed on different serial and parallel platforms, thus making comprehensive testing even more challenging. This paper presents an effort to improve the existing testing process of CP2K in order to better support its continuing development. Enhancements have been made to the regression testing environment to support multi-platform testing and a new automated multi-platform testing system has been developed to check the code on a regular basis. Also, tools have been used to gain code coverage information for different test configurations. All the information is aggregated and displayed on the dedicated web page.</p>",
        "title": "Automated multi-platform testing and code coverage analysis of the CP2K application",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "bca245d0-1ec3-4d2f-8983-3420b2cd82a0": {
        "id": "bca245d0-1ec3-4d2f-8983-3420b2cd82a0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cp2k-performance-from-cray-xt3-to-xc30(bca245d0-1ec3-4d2f-8983-3420b2cd82a0).html",
        "abstract": "CP2K is a powerful open-source program for atomistic simulation using a range of methods including Classical potentials, Density Functional Theory based on the Gaussian and Plane Waves approach, and post-DFT methods. CP2K has been designed and optimised for large parallel HPC systems, including a mixed-mode MPI/OpenMP parallelisation, as well as CUDA kernels for particular types of calculations. Developed by an open-source collaboration including Univer- sity of Z\u00fcrich, ETH Z\u00fcrich, EPCC and others, CP2K has been well tested on several generations of Cray supercomputers, beginning with the XT3 in 2006 at CSCS, through XT4, XT5, XT/XE6 and XK7, to Ivy-Bridge and Sandy-Bridge based XC30 systems in 2014. We present a systematic view of benchmark data spanning 9 years and 7 generations of the Cray architecture, and report on recent efforts to carry out comprehensive comparative benchmarking and performance analysis of CP2K on the XE6 and XC30 systems at EPCC. We also describe work to enable CP2K for accelerators, and show performance data from the XK7 and XC30 at CSCS.",
        "title": "CP2K Performance from Cray XT3 to XC30",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            }
        ]
    },
    "7dda4b6b-a3f9-4af2-9c0b-e2247babedd5": {
        "id": "7dda4b6b-a3f9-4af2-9c0b-e2247babedd5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/primegrid-a-volunteer-computing-platform-for-number-theory(7dda4b6b-a3f9-4af2-9c0b-e2247babedd5).html",
        "abstract": "Since 2005, PrimeGrid has grown from a small project factorising RSA numbers by brute force to one of the largest volunteer computing projects in the world. The project has discovered over 60 new million-digit primes, as well as record sized twin and Sophie Germain primes. This paper will present a history of the project, the algorithms and software used by PrimeGrid and how the BOINC distributed computing architecture is used to harness tens of thousands of computers. We also highlight some recent results from several current prime search sub-projects.",
        "title": "PrimeGrid: a Volunteer Computing Platform for Number Theory",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "062accbd-4337-4787-8711-3e54c781c6cb": {
        "id": "062accbd-4337-4787-8711-3e54c781c6cb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/performance-analysis-of-asynchronous-jacobis-method-implemented-in-mpi-shmem-and-openmp(062accbd-4337-4787-8711-3e54c781c6cb).html",
        "abstract": "Ever-increasing core counts create the need to develop parallel algorithms that avoid closely coupled execution across all cores. We present performance analysis of several parallel asynchronous implementations of Jacobi\u2019s method for solving systems of linear equations, using MPI, SHMEM and OpenMP. In particular we have solved systems of over 4 billion unknowns using up to 32,768 processes on a Cray XE6 supercomputer. We show that the precise implementation details of asynchronous algorithms can strongly affect the resulting performance and convergence behaviour of our solvers in unexpected ways, discuss how our specific implementations could be generalised to other classes of problem, and suggest how existing parallel programming models might be extended to allow asynchronous algorithms to be expressed more easily.",
        "title": "Performance analysis of asynchronous Jacobi\u2019s method implemented in MPI, SHMEM and OpenMP",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "401461a3-96c4-44a0-a4c9-3fab464cb259": {
        "id": "401461a3-96c4-44a0-a4c9-3fab464cb259",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/using-rsip-networking-with-parallel-applications-on-archer-phase-2(401461a3-96c4-44a0-a4c9-3fab464cb259).html",
        "abstract": "Instructions on how to use RSIP to enable TCP/IP communications between parallel jobs on the compute nodes and the login nodes (and beyond). Two case study applications are shown: Parallel visualisation using ParaView, and Path Integral Molecular Dynamics with i-PI and CP2K.",
        "title": "Using RSIP Networking with Parallel Applications on ARCHER Phase 2",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "1bc14b1e-bcff-48ab-ad77-f5bbeab8d2d9": {
        "id": "1bc14b1e-bcff-48ab-ad77-f5bbeab8d2d9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/optimising-cp2k-for-the-intel-xeon-phi(1bc14b1e-bcff-48ab-ad77-f5bbeab8d2d9).html",
        "abstract": "CP2K is an important European program for atomistic simulation for many users of the PRACE Research Infrastructure as well as national and local compute resources. In the context of a PRACE Preparatory Access Type C project, we have parallelised several routines in CP2K to allow the code to gain better performance on the Intel Xeon Phi for a materials science application. We have obtained a 50% speedup in the maximum performance of the code on the Xeon Phi, but have not been able to demonstrate better performance than running the same calculation on a Sandy Bridge 16-core CPU node. We present details of the developments made to CP2K, and discuss several lessons, which will be of wider interest to developers considering porting their codes to Xeon Phi.",
        "title": "Optimising CP2K for the Intel Xeon Phi",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            }
        ]
    },
    "20b84c2e-85f0-449d-910c-d6f2f016af5e": {
        "id": "20b84c2e-85f0-449d-910c-d6f2f016af5e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/linear-and-nonlinear-instability-and-ligament-dynamics-in-3d-laminar-twolayer-liquidliquid-flows(20b84c2e-85f0-449d-910c-d6f2f016af5e).html",
        "abstract": "",
        "title": "Linear and nonlinear instability and ligament dynamics in 3D laminar two-layer liquid/liquid flows",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "c1a4bbff-cf67-4970-aecb-31d93647e440": {
        "id": "c1a4bbff-cf67-4970-aecb-31d93647e440",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/linear-instability-nonlinear-instability-and-ligament-dynamics-in-threedimensional-laminar-twolayer-liquidliquid-flows(c1a4bbff-cf67-4970-aecb-31d93647e440).html",
        "abstract": "<p>We consider the linear and nonlinear stability of two-phase density-matched but viscosity-contrasted fluids subject to laminar Poiseuille flow in a channel, paying particular attention to the formation of three-dimensional waves. A combination of Orr-Sommerfeld-Squire analysis (both modal and non-modal) with direct numerical simulation of the three-dimensional two-phase Navier-Stokes equations is used. For the parameter regimes under consideration, under linear theory, the most unstable waves are two-dimensional. Nevertheless, we demonstrate several mechanisms whereby three-dimensional waves enter the system, and dominate at late time. There exists a direct route, whereby three-dimensional waves are amplified by the standard linear mechanism; for certain parameter classes, such waves grow at a rate less than but comparable to that of the most dangerous two-dimensional mode. Additionally, there is a weakly nonlinear route, whereby a purely spanwise wave grows according to transient linear theory and subsequently couples to a streamwise mode in weakly nonlinear fashion. Consideration is also given to the ultimate state of these waves: persistent three-dimensional nonlinear waves are stretched and distorted by the base flow, thereby producing regimes of ligaments, 'sheets' or 'interfacial turbulence'. Depending on the parameter regime, these regimes are observed either in isolation, or acting together.</p>",
        "title": "Linear instability, nonlinear instability and ligament dynamics in three-dimensional laminar two-layer liquid-liquid flows",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "5c35a34c-0ac0-4e63-8309-cb7bd2bc14f1": {
        "id": "5c35a34c-0ac0-4e63-8309-cb7bd2bc14f1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/extending-the-generalized-fermat-prime-search-beyond-one-million-digits(5c35a34c-0ac0-4e63-8309-cb7bd2bc14f1).html",
        "abstract": "Great strides have been made in recent years in the search for ever larger prime Generalized Fermat Numbers (GFN). We briefly review the history of the GFN prime search, and describe new implementations of the \u2018Genefer\u2019 software (now available as open source) using CUDA and optimised CPU assembler which have underpinned this unprecedented progress. The results of the ongoing search are used to extend Gallot and Dubner\u2019s published tables comparing the theoretical predictions with actual distributions of primes, and we report on recent discoveries of GFN primes with over one million digits.",
        "title": "Extending the generalized Fermat prime search beyond one million digits",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "a2f9840f-4a39-440b-97ff-868468494fb0": {
        "id": "a2f9840f-4a39-440b-97ff-868468494fb0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/tpls-flow-solver-high-resolution-direct-numerical-simulation-dns-of-twophase-flows(a2f9840f-4a39-440b-97ff-868468494fb0).html",
        "abstract": "",
        "title": "TPLS Flow Solver: High Resolution Direct Numerical Simulation (DNS) of Two-Phase Flows",
        "keywords": "",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "4994309f-760b-455c-95f2-f7cb0f64b0ad": {
        "id": "4994309f-760b-455c-95f2-f7cb0f64b0ad",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/improving-the-performance-of-cp2k-on-the-cray-xt(4994309f-760b-455c-95f2-f7cb0f64b0ad).html",
        "abstract": "CP2K is a freely available and increasingly popular Density Functional Theory code for the simulation of a wide range of systems. It is heavily used on many Cray XT systems, including \u2018HECToR\u2019 in the UK and \u2018Monte Rosa\u2019 in Switzerland. We describe performance optimisations made to the code in several key areas, including 3D Fourier Transforms, and present the implementation of a load balancing scheme for multi-grids. These result in performance gains of around 30% on 256 cores (for a generally representative benchmark) and up to 300% on 1024 cores (for non-homogeneous systems). Early results from the implementation of hybrid MPI/OpenMP parallelism in the code are also presented.",
        "title": "Improving the Performance of CP2K on the Cray XT",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            }
        ]
    },
    "81cd5160-f3f4-40a3-9ace-765176aa7c4a": {
        "id": "81cd5160-f3f4-40a3-9ace-765176aa7c4a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mapping-application-performance-to-hpc-architecture(81cd5160-f3f4-40a3-9ace-765176aa7c4a).html",
        "abstract": "A suite of application benchmarks, designed to be broadly representative of UK HPC usage, has been developed to stress a broad range of architectural features of large scale parallel HPC resources. A generic methodology to investigate application performance and scaling characteristics has been defined, resulting in a detailed understanding of the performance of these applications. This methodology is transferable to other applications and systems: it is of practical value to developers and users who are aiming for optimal utilisation of HPC resources. An understanding of the performance characteristics of a range of large-scale HPC resources has been obtained using low-level synthetic benchmarks. A relatively simple, qualitative mechanism to assess and predict application performance on current and future architectures using synthetic benchmark results together with application performance analysis results is explored.",
        "title": "Mapping application performance to HPC architecture",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Iain Bethune",
                "uuid": "d8c85d57-e577-41fd-9edd-bde9ad9abb98"
            },
            {
                "name": "Lorna Smith",
                "uuid": "5c748338-46b1-485e-95af-511b43c62836"
            },
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "c288211b-420c-42d9-87c0-e4b04b5d7005": {
        "id": "c288211b-420c-42d9-87c0-e4b04b5d7005",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/introduction-to-ogsadai-services(c288211b-420c-42d9-87c0-e4b04b5d7005).html",
        "abstract": "In today\u2019s large collaborative environments, potentially composed of multiple distinct organisations, uniform controlled access to data has become a key requirement if these organisations are to work together as Virtual Organisations. We refer to such an integrated set of data resources as a virtual data warehouse. The Open Grid Services Architecture \u2013 Data Access and Integration (OGSA-DAI) project was established to produce a common middleware solution, aligned with the Global Grid Forum\u2019s (GGF) OGSA vision [OGSA] to allow uniform access to data resources using a service based architecture. In this paper the service infrastructure provided by OGSA-DAI is presented providing a snapshot of its current state, in an evolutionary process, which is attempting to build infrastructure to allow easy integration and access to distributed data using grids or web services. More information about OGSA-DAI is available from the project web site: www.ogsadai.org.",
        "title": "Introduction to OGSA-DAI Services",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Charaka Palansuriya",
                "uuid": "fa7ecedb-db73-44ce-9703-b55c93331e57"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "516086b2-d14d-4ae4-ba31-500de7e8d988": {
        "id": "516086b2-d14d-4ae4-ba31-500de7e8d988",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/experiences-of-designing-and-implementing-grid-database-services-in-the-ogsadai-project(516086b2-d14d-4ae4-ba31-500de7e8d988).html",
        "abstract": "",
        "title": "Experiences of Designing and Implementing Grid Database Services in the OGSA-DAI project",
        "keywords": "",
        "authors": [
            {
                "name": "Charaka Palansuriya",
                "uuid": "fa7ecedb-db73-44ce-9703-b55c93331e57"
            },
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "d7154742-82dd-482c-a7bc-5b2f792fd0f4": {
        "id": "d7154742-82dd-482c-a7bc-5b2f792fd0f4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/geoparsing-the-historical-gazetteers-of-scotland-accurately-computing-location-in-mass-digitised-texts(d7154742-82dd-482c-a7bc-5b2f792fd0f4).html",
        "abstract": "This paper describes work in progress on devising automatic and parallel methods for geoparsing large digital historical textual data by combining the strengths of three natural language processing (NLP) tools, the Edinburgh Geoparser, spaCy and defoe, and employing different tokenisation and named entity recognition (NER) techniques. We apply these tools to a large collection of nineteenth century Scottish geographical dictionaries, and describe preliminary results obtained when processing this data.",
        "title": "Geoparsing the Historical Gazetteers of Scotland: Accurately Computing Location in Mass Digitised Texts",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "1b773723-fc67-4d6f-a42c-ded7c36a60a9": {
        "id": "1b773723-fc67-4d6f-a42c-ded7c36a60a9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dare-a-reflective-platform-designed-to-enable-agile-datadriven-research-on-the-cloud(1b773723-fc67-4d6f-a42c-ded7c36a60a9).html",
        "abstract": "The DARE platform has been designed to help research developers deliver user-facing applications and solutions over diverse underlying e-infrastructures, data and computational contexts. The platform is Cloud-ready, and relies on the exposure of API, which are suitable for raising the abstraction level and hiding complexity. It implements the cataloguing and execution of fine-grained and Python-based dispel4py workflows as services. Reflection is achieved via a logical knowledge base, comprising multiple internal catalogues, registries and semantics, while it supports persistent and pervasive data provenance. This paper presents design and implementation aspects of the DARE platform, as well as it provides directions for future development.<br/>",
        "title": "DARE: A Reflective Platform Designed to Enable Agile Data-Driven Research on the Cloud",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "a2a897d0-0bc8-4cb2-80ad-dece2a9f1823": {
        "id": "a2a897d0-0bc8-4cb2-80ad-dece2a9f1823",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/comprehensible-control-for-researchers-and-developers-facing-data-challenges(a2a897d0-0bc8-4cb2-80ad-dece2a9f1823).html",
        "abstract": "The  DARE  platform  enables  researchers  and  their developers to exploit more capabilities to handle complexity and scale in data, computation and collaboration. Today\u2019s challenges pose  increasing  and  urgent  demands  for  this  combination  of capabilities.  To  meet  technical,  economic  and  governance  constraints,  application  communities  must  use  use  shared  digital infrastructure  principally  via  virtualisation  and  mapping.  This requires precise abstractions that retain their meaning while their implementations  and  infrastructures  change.  Giving  specialists direct control over these capabilities with detail relevant to each discipline  is  necessary  for  adoption.  Research  agility,  improved power and retained return on intellectual investment incentivise that  adoption.  We  report  on  an  architecture  for  establishing and  sustaining the   necessary   optimised   mappings   and   early evaluations  of  its  feasibility  with  two  application  communities.",
        "title": "Comprehensible Control for Researchers and Developers facing Data Challenges",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "290084f7-3949-4c47-99db-5428ae8abb52": {
        "id": "290084f7-3949-4c47-99db-5428ae8abb52",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/using-simple-pidinspired-controllers-for-online-resilient-resource-management-of-distributed-scientific-workflows(290084f7-3949-4c47-99db-5428ae8abb52).html",
        "abstract": "Scientific workflows have become mainstream for conducting large-scale scientific research. As a result, many workflow applications and Workflow Management Systems (WMSs) have been developed as part of the cyberinfrastructure to allow scientists to execute their applications seamlessly on a range of distributed platforms. Although the scientific community has addressed this challenge from both theoretical and practical approaches, failure prediction, detection, and recovery still raise many research questions. In this paper, we propose an approach inspired by the control theory developed as part of autonomic computing to predict failures before they happen, and mitigated them when possible. The proposed approach is inspired on the <i>proportional\u2013integral\u2013derivative</i> controller (PID controller) control loop mechanism, which is widely used in industrial control systems, where the controller will react to adjust its output to mitigate faults. PID controllers aim to detect the possibility of a non-steady state far enough in advance so that an action can be performed to prevent it from happening. To demonstrate the feasibility of the approach, we tackle two common execution faults of large scale data-intensive workflows\u2014data storage overload and memory overflow. We developed a simulator, which implements and evaluates simple standalone PID-inspired controllers to autonomously manage data and memory usage of a data-intensive bioinformatics workflow that consumes/produces over 4.4 TB of data, and requires over 24 TB of memory to run all tasks concurrently. Experimental results obtained via simulation indicate that workflow executions may significantly benefit from the controller-inspired approach, in particular under online and unknown conditions. Simulation results show that nearly-optimal executions (slowdown of 1.01) can be attained when using our proposed method, and faults are detected and mitigated far in advance of their occurrence.",
        "title": "Using simple PID-inspired controllers for online resilient resource management of distributed scientific workflows",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "0514117b-33ce-4754-bebb-ea2d77e85f27": {
        "id": "0514117b-33ce-4754-bebb-ea2d77e85f27",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/establishing-core-concepts-for-informationpowered-collaborations(0514117b-33ce-4754-bebb-ea2d77e85f27).html",
        "abstract": "Science benefits tremendously from mutual exchanges of information and pooling of effort and resources.The combination of different skills and diverse knowledge is a powerful capacity, source of new intuitions and creative insights. Therefore multidisciplinary approaches can be a great opportunity to explore novel scientific horizons. Collaboration is not only an opportunity, it is essential when tackling today\u2019s global challenges by exploiting our fast growing wealth of data. In this paper we introduce the concept of Information-Powered Collaborations (IPC) \u2014 an abstraction that captures those requirements and opportunities. We propose a conceptual framework that partitions the inherent complexity of such dynamic environments and offers concrete tools and methods to thrive in the data revolution era. Such a framework promotes and enables information sharing from multiple heterogeneous sources that are independently managed. We present the results of assessing our approach as an IPC for solid-Earth sciences: the European Plate Observing System (EPOS).",
        "title": "Establishing Core Concepts for Information-Powered Collaborations",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "81d8e383-960d-46de-b828-74a45c1ac2f4": {
        "id": "81d8e383-960d-46de-b828-74a45c1ac2f4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/iothub-new-iot-dataplatform-for-virtual-research-environments(81d8e383-960d-46de-b828-74a45c1ac2f4).html",
        "abstract": "This paper presents IoT-Hub a new scalable, elastic, efficient, and portable Internet of Things (IoT) data-platform based on microservices for monitoring and analysing large- scale sensor data in real-time. IoT-Hub allows us to collect, process, and store large amounts of data from multiple sensors in distributed locations\u2014which could be deployed as a backend for Virtual Research Environments (VRE) or Science Gateways. In the proposed data-platform, all required software, which involves a variety of state-of-the-art open-source middleware, is packed into containers and deployed in a cloud environment. As a result, the engineering and computational time and costs for deployment and execution is significantly reduced.<br/><br/><i>Keywords</i>\u2014IoT, Science Gateway, Virtual Research Environ- ment, Data-Frameworks, Containers, Data Science, Microservices",
        "title": "IoT-Hub: New IoT Data-Platform for Virtual Research Environments",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "e64fa73b-345d-425e-80eb-8389eddd740a": {
        "id": "e64fa73b-345d-425e-80eb-8389eddd740a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-rise-of-big-crisis-data-and-digitalhumanitarians-observations-and-opportunities-from-an-applied-geohazard-scientists-perspective(e64fa73b-345d-425e-80eb-8389eddd740a).html",
        "abstract": "Applications developed using Web 2.0 technologies, such as social media sites, blogs, wikis etc., have had a profound impact on people's ability to interact and collaborate, and to generate and share content publically through virtual environments. During recent natural disasters there has been an impressive response effort, through web 2.0 technologies, from citizens (digital humanitarians). Tools have been developed overnight to help people find food, shelter or missing relatives or friends. There are examples of how social media, or a mechanism to connect people together, enables people to share feelings and better cope with their situation knowing that others are also experiencing the same problems.",
        "title": "The rise of big (crisis) data and \u2018digital\u2019humanitarians: observations and opportunities from an Applied Geohazard Scientist\u2019s perspective",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "80c5f485-39d8-4d22-a969-3a023503a097": {
        "id": "80c5f485-39d8-4d22-a969-3a023503a097",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/geosocial-exploring-the-usefulness-of-social-media-mining-in-the-applied-natural-geohazard-sciences(80c5f485-39d8-4d22-a969-3a023503a097).html",
        "abstract": "Obtaining real-time information about a geohazard event as it unfolds, such as a flood or earthquake, used to be largely limited to the professional media. Nowadays, obtaining news stories from social media (eg Facebook, Twitter, YouTube, Flickr etc.), directly as they unfold, is becoming the 'norm'for many in society. The Haitian Earthquake in January 2010 and the Great East Japan Earthquake in March 2011, provided some of the first natural hazard examples, to really demonstrate the power of social media over traditional news sources for obtaining, live information from which people and authorities could gain situational awareness.",
        "title": "GeoSocial: exploring the usefulness of social media mining in the applied natural geohazard sciences",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "9692f669-98f9-4a1e-9ceb-68c5a261fee3": {
        "id": "9692f669-98f9-4a1e-9ceb-68c5a261fee3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/automating-environmental-computing-applications-with-scientific-workflows(9692f669-98f9-4a1e-9ceb-68c5a261fee3).html",
        "abstract": "Computational environmental science applications have evolved and become more complex over the last decade. In order to cope with the needs of such applications, computational methods and technologies have emerged to support the execution of these applications on heterogeneous, distributed systems. Among them are workflow management systems such as Pegasus. Pegasus is being used by researchers to model seismic wave propagation, to discover new celestial objects, to study RNA critical to human brain development, and to investigate other important research questions. This paper provides an introduction to scientific workflows and describes Pegasus and its main features. The paper highlights how the environmental science community has used Pegasus to automate their scientific workflow executions on high performance and high throughput computing systems by presenting three use cases: two Earth science workflows, and a climate science workflow.",
        "title": "Automating Environmental Computing Applications with Scientific Workflows",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "794db9ab-1880-47e6-83cf-e2a4730c5347": {
        "id": "794db9ab-1880-47e6-83cf-e2a4730c5347",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-characterization-of-workflow-management-systems-for-extremescale-applications(794db9ab-1880-47e6-83cf-e2a4730c5347).html",
        "abstract": "Automation of the execution of computational tasks is at the heart of improving scientific productivity. Over the last years, scientific workflows have been established as an important abstraction that captures data processing and computation of large and complex scientific applications. By allowing scientists to model and express entire data processing steps and their dependencies, workflow management systems relieve scientists from the details of an application and manage its execution on a computational infrastructure. As the resource requirements of today\u2019s computational and data science applications that process vast amounts of data keep increasing, there is a compelling case for a new generation of advances in high-performance computing, commonly termed as extreme-scale computing, which will bring forth multiple challenges for the design of workflow applications and management systems. This paper presents a novel characterization of workflow management systems using features commonly associated with extreme-scale computing applications. We classify 15 popular workflow management systems in terms of workflow execution models, heterogeneous computing environments, and data access methods. The paper also surveys workflow applications and identifies gaps for future research on the road to extreme-scale workflows and management systems.",
        "title": "A characterization of workflow management systems for extreme-scale applications",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "7b0ba090-4e65-4cd4-aaae-e9a066e6bc53": {
        "id": "7b0ba090-4e65-4cd4-aaae-e9a066e6bc53",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/wfcatalog-a-catalogue-for-seismological-waveform-data(7b0ba090-4e65-4cd4-aaae-e9a066e6bc53).html",
        "abstract": "Abstract This paper reports advances in seismic waveform description and discovery leading to a new seismological service and presents the key steps in its design, implementation and adoption. This service, named WFCatalog, which stands for waveform catalogue, accommodates features of seismological waveform data. Therefore, it meets the need for seismologists to be able to select waveform data based on seismic waveform features as well as sensor geolocations and temporal specifications. We describe the collaborative design methods and the technical solution showing the central role of seismic feature catalogues in framing the technical and operational delivery of the new service. Also, we provide an overview of the complex environment wherein this endeavour is scoped and the related challenges discussed. As multi-disciplinary, multi-organisational and global collaboration is necessary to address today's challenges, canonical representations can provide a focus for collaboration and conceptual tools for agreeing directions. Such collaborations can be fostered and formalised by rallying intellectual effort into the design of novel scientific catalogues and the services that support them. This work offers an example of the benefits generated by involving cross-disciplinary skills (e.g. data and domain expertise) from the early stages of design, and by sustaining the engagement with the target community throughout the delivery and deployment process.",
        "title": "WFCatalog: a catalogue for seismological waveform data",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "de7114ca-8450-4037-b8a0-1d19fe93fcb4": {
        "id": "de7114ca-8450-4037-b8a0-1d19fe93fcb4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/using-simple-pid-controllers-to-prevent-and-mitigate-faults-in-scientific-workflows(de7114ca-8450-4037-b8a0-1d19fe93fcb4).html",
        "abstract": "Scientific workflows have become mainstream for conducting large-scale scientific research. As a result, many workflow applications and Workflow Management Systems (WMSs) have been developed as part of the cyberinfrastructure to allow scientists to execute their applications seamlessly on a range of distributed platforms. In spite of many success stories, a key challenge for running workflows in distributed systems is failure prediction, detection, and recovery. In this paper, we propose an approach to use control theory developed as part of autonomic computing to predict failures before they happen, and mitigated them when possible. The proposed approach apply the proportional-integral-derivative controller (PID controller) control loop mechanism, which is widely used in industrial control systems, to mitigate faults by adjusting the inputs of the mechanism. The PID controller aims at detecting the possibility of a fault far enough in advance so that an action can be performed to prevent it from happening. To demonstrate the feasibility of the approach, we tackle two common execution faults of the Big Data era|data footprint and memory usage. We define, implement, and evaluate simple PID controllers to autonomously manage data and memory usage of a bioinformatics work ow that consumes/produces over 4.4TB of data, and requires over 24TB of memory to run all tasks concurrently. Experimental results indicate that work flow executions may significantly benefit from PID controllers, in particular under online and unknown conditions. Simulation results show that nearly-optimal executions (slowdown of 1.01) can be attained when using our proposed method, and faults are detected and mitigated far in advance.",
        "title": "Using Simple PID Controllers to Prevent and Mitigate Faults in Scientific Workflows",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "931e8e21-496e-483e-ae5a-b6a4dc30dfdb": {
        "id": "931e8e21-496e-483e-ae5a-b6a4dc30dfdb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/asterism-an-integrated-complete-and-opensource-approach-for-running-seismologist-continuous-dataintensive-analysis-on-heterogeneous-systems(931e8e21-496e-483e-ae5a-b6a4dc30dfdb).html",
        "abstract": "",
        "title": "Asterism: an integrated, complete, and open-source approach for running seismologist continuous data-intensive analysis on heterogeneous systems",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "f4c44880-9766-435d-b302-1a77177685be": {
        "id": "f4c44880-9766-435d-b302-1a77177685be",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/diaas-dataintensive-workflows-as-a-service--enabling-easy-composition-and-deployment-of-dataintensive-workflows-on-virtual-research-environments(f4c44880-9766-435d-b302-1a77177685be).html",
        "abstract": "We present the Data-Intensive workflows as a Service (DIaaS) model for enabling easy data-intensive workflow composition and deployment on clouds using containers. DIaaS model backbone is Asterism, an integrated solution for running data-intensive stream-based applications on heterogeneous systems, which combines the benefits of dispel4py with Pegasus workflow systems. The stream-based executions of an Asterism workflow are managed by dispel4py, while the data movement between different e-Infrastructures, and the coordination of the application execution are automatically managed by Pegasus.<br/>DIaaS combines Asterism framework with Docker containers to provide an integrated, complete, easy-to-use, portable approach to run data-intensive workflows on distributed platforms. Three containers integrate the DIaaS model: a Pegasus node, and an MPI and an Apache Storm clusters. Container images are described as Dockerfiles (available online at http://github.com/dispel4py/pegasus_dispel4py), linked to Docker Hub for providing continuous integration (automated image builds), and image storing and sharing. In this model, all required software (workflow systems and execution engines) for running scientific applications are packed into the containers, which significantly reduces the effort (and possible human errors) required by scientists or VRE administrators to build such systems. The most common use of DIaaS will be to act as a backend of VREs or Scientific Gateways to run data-intensive applications, deploying cloud resources upon request.<br/><br/>We have demonstrated the feasibility of DIaaS using the data-intensive seismic ambient noise cross-correlation application (Figure 1). The application preprocesses (Phase1) and cross-correlates (Phase2) traces from several seismic stations. The application is submitted via Pegasus (Container1), and Phase1 and Phase2 are executed in the MPI (Container2) and Storm (Container3) clusters respectively. Although both phases could be executed within the same environment, this setup demonstrates the flexibility of DIaaS to run applications across e-Infrastructures.<br/><br/>In summary, DIaaS delivers specialized software to execute data-intensive applications in a scalable, efficient, and robust manner reducing the engineering time and computational cost.",
        "title": "DIaaS: Data-Intensive workflows as a service - Enabling easy composition and deployment of data-intensive workflows on Virtual Research Environments",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "ef23e85a-55a4-419d-bcc6-5d1d06987b04": {
        "id": "ef23e85a-55a4-419d-bcc6-5d1d06987b04",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/asterism-pegasus-and-dispel4py-hybrid-workflows-for-dataintensive-science(ef23e85a-55a4-419d-bcc6-5d1d06987b04).html",
        "abstract": "We present Asterism, an open source data-intensive framework, which combines the strengths of traditional work-flow management systems with new parallel stream-based data flow systems to run data-intensive applications across<br/>multiple heterogeneous resources, without users having to: re-formulate their methods according to different enactment engines; manage the data distribution across systems; parallelize their methods; co-place and schedule their methods<br/>with computing resources; and store and transfer large/small volumes of data. We also present the Data-Intensive work-flows as a Service (DIaaS) model, which enables easy dataintensive work flow composition and deployment on clouds using containers. The feasibility of Asterism and DIaaS model have been evaluated using a real domain application on the NSF-Chameleon cloud. Experimental results shows how Asterism successfully and eciently exploits combinations of diverse computational platforms, whereas DIaaS delivers specialized software to execute data-intensive applications in a scalable, efficient, and robust way reducing the engineering time and computational cost.",
        "title": "Asterism: Pegasus and dispel4py hybrid workflows for data-intensive science",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "be6e9d0a-0582-4542-a346-d3beab426a91": {
        "id": "be6e9d0a-0582-4542-a346-d3beab426a91",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/rethinking-high-performance-computing-platforms-challenges-opportunities-and-recommendations(be6e9d0a-0582-4542-a346-d3beab426a91).html",
        "abstract": "A growing number of \"second generation\" high-performance computing applications with heterogeneous, dynamic and data-intensive properties have an extended set of requirements, which cover application deployment, resource allocation, -control, and I/O scheduling. These requirements are not met by the current production HPC platform models and policies. This results in a loss of opportunity, productivity and innovation for new computational methods and tools. It also decreases effective system utilization for platform providers due to unsupervised workarounds and \"rogue'\" resource management strategies implemented in application space. In this paper we critically discuss the dominant HPC platform model and describe the challenges it creates for second generation applications because of its asymmetric resource view, interfaces and software deployment policies. We present an extended, more symmetric and application-centric platform model that adds decentralized deployment, introspection, bidirectional control and information flow and more comprehensive resource scheduling. We describe cHPC: an early prototype of a non-disruptive implementation based on Linux Containers (LXC). It can operate alongside existing batch queuing systems and exposes a symmetric platform API without interfering with existing applications and usage modes. We see our approach as a viable, incremental next step in HPC platform evolution that benefits applications and platform providers alike. To demonstrate this further, we layout out a roadmap for future research and experimental evaluation.",
        "title": "Rethinking High Performance Computing Platforms: Challenges, Opportunities and Recommendations",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "e4f5d255-3dab-44b1-8b6b-0face84eed1d": {
        "id": "e4f5d255-3dab-44b1-8b6b-0face84eed1d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/visualisation-methods-for-large-provenance-collections-in-dataintensive-collaborative-platforms(e4f5d255-3dab-44b1-8b6b-0face84eed1d).html",
        "abstract": "",
        "title": "Visualisation methods for large provenance collections in data-intensive collaborative platforms",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "423c2841-d0eb-4c36-914a-2e8243051ff6": {
        "id": "423c2841-d0eb-4c36-914a-2e8243051ff6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/specifying-use-case-behavior-with-interaction-models(423c2841-d0eb-4c36-914a-2e8243051ff6).html",
        "abstract": "",
        "title": "Specifying use case behavior with interaction models",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "ddf4c1a8-50c4-40b8-a8d8-6bcdfbd234dc": {
        "id": "ddf4c1a8-50c4-40b8-a8d8-6bcdfbd234dc",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/optimization-and-evaluation-of-parallel-io-in-bips3d-parallel-irregular-application(ddf4c1a8-50c4-40b8-a8d8-6bcdfbd234dc).html",
        "abstract": "This paper presents the optimization and evaluation of parallel I/O for the BIPS3D parallel irregular application, a 3-dimensional simulation of BJT and HBT bipolar devices. The parallel version of BIPS3D employs Metis, a library for partitioning graphs, finite element meshes, or sparse matrices. First, we show how the partitioning information provided by Metis can be used in order to improve the performance of parallel I/O. Second, we propose a novel technique, called interval data grouping (IDG), which exploits the data replication of mesh nodes for optimizing the scheduling of the parallel file operations. Finally, we evaluate the parallel I/O version of BIPS3D for various existing parallel I/O techniques and present an in-depth analysis of the IDG performance.",
        "title": "Optimization and evaluation of parallel I/O in BIPS3D parallel irregular application",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "375bd668-29ec-4ad8-9292-8147ff363be3": {
        "id": "375bd668-29ec-4ad8-9292-8147ff363be3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/exploiting-data-compression-in-collective-io-techniques(375bd668-29ec-4ad8-9292-8147ff363be3).html",
        "abstract": "This paper presents Two-Phase Compressed I/O (TPC I/O,) an optimization of the Two-Phase collective I/O technique from ROMIO, the most popular MPI-IO implementation. In order to reduce network traffic, TPC I/O employs LZO algorithm to compress and decompress exchanged data in the inter-node communication operations. The compression algorithm has been fully implemented in the MPI collective technique, allowing to dynamically use (or not) compression. Compared with Two-Phase I/O, Two-Phase Compressed I/O obtains important improvements in the overall execution time for many of the considered scenarios.",
        "title": "Exploiting data compression in collective I/O techniques",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "a99bc351-3816-4773-b87f-1d99fcb23aea": {
        "id": "a99bc351-3816-4773-b87f-1d99fcb23aea",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/high-performance-computing-for-computational-science--vecpar-2008-8th-international-conference-toulouse-france-june-2427-2008-revised-selected-papers(a99bc351-3816-4773-b87f-1d99fcb23aea).html",
        "abstract": "This paper presents Locality-Aware Two-Phase (LATP) I/O, an optimization of the Two-Phase collective I/O technique from ROMIO, the most popular MPI-IO implementation. In order to increase the locality of the file accesses, LATP employs the Linear Assignment Problem (LAP) for finding an optimal distribution of data to processes, an aspect that is not considered in the original technique. This assignment is based on the local data that each process stores and has as main purpose the reduction of the number of communication involved in the I/O collective operation and, therefore, the improvement of the global execution time. Compared with Two-Phase I/O, LATP I/O obtains important improvements in most of the considered scenarios.",
        "title": "High Performance Computing for Computational Science - VECPAR 2008: 8th International Conference, Toulouse, France, June 24-27, 2008. Revised Selected Papers",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "aa1524d6-11ce-40d0-a406-984957fa9942": {
        "id": "aa1524d6-11ce-40d0-a406-984957fa9942",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/compi-enhancing-mpi-based-applications-performance-and-scalability-using-runtime-compression(aa1524d6-11ce-40d0-a406-984957fa9942).html",
        "abstract": "This paper presents an optimization of MPI communications, called CoMPI, based on run-time compression of MPI messages exchanged by applications. A broad number of compression algorithms have been fully implemented and tested for both MPI collective and point to point primitives. In addition, this paper presents a study of several compression algorithms that can be used for run-time compression, based on the datatype used by applications. This study has been validated by using several MPI benchmarks and real HPC applications. Show that, in most of the cases, using compression reduces the application communication time enhancing application performance and scalability. In this way, CoMPI obtains important improvements in the overall execution time for many of the considered scenarios.",
        "title": "CoMPI: Enhancing MPI Based Applications Performance and Scalability Using Run-Time Compression",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "d86dcfb0-164d-44c5-90d5-62a038d70899": {
        "id": "d86dcfb0-164d-44c5-90d5-62a038d70899",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dispel4py-a-python-framework-for-dataintensive-scientificcomputing(d86dcfb0-164d-44c5-90d5-62a038d70899).html",
        "abstract": "This paper presents dispel4py, a new Python framework for describing abstract stream-based workflows for distributed data-intensive applications. These combine the familiarity of Python programming with the scalability of workflows. Data streaming is used to gain performance, rapid prototyping and applicability to live observations. dispel4py enables scientists to focus on their scientific goals, avoiding distracting details and retaining flexibility over the computing infrastructure they use. The implementation, therefore, has to map dispel4py abstract workflows optimally onto target platforms chosen dynamically. We present four dispel4py mappings: Apache Storm, MPI, multi-threading and sequential, showing two major benefits: a) smooth transitions from local development on a laptop to scalable execution for production work, and b) scalable enactment on significantly different distributed computing infrastructures. Three application domains are reported and measurements on multiple infrastructures show the optimisations achieved; they have provided demanding real applications and helped us develop effective training. The dispel4py.org is an open-source project to which we invite participation. The effective mapping of dispel4py onto multiple target infrastructures demonstrates exploitation of data-intensive and HPC architectures and consistent scalability.",
        "title": "dispel4py: A Python Framework for Data-Intensive ScientificComputing",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "578aeba7-ab1b-4618-9fed-639872ec2483": {
        "id": "578aeba7-ab1b-4618-9fed-639872ec2483",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dispel4py-an-agile-framework-for-dataintensive-methods-using-hpc(578aeba7-ab1b-4618-9fed-639872ec2483).html",
        "abstract": "Today\u2019s data bonanza and increasing computational power provide many new\nopportunities for combining observations with sophisticated simulation results\nto improve complex models and make forecasts by analyzing their relationships.\nThis should lead to well-presented actionable information that\ncan support decisions and contribute trustworthy knowledge. Practitioners in\nall disciplines: computational scientists, data scientists and decision makers\nneed improved tools to realize such potential. The Python library dispel4py\nis such a tool. It delivers a simple abstract model in familiar development environments\nwith a fluent path to production use that automatically addresses\nscale without its users having to reformulate their methods. This depends on\noptimal mappings to many current HPC and data-intensive platforms.",
        "title": "dispel4py: An Agile Framework for Data-Intensive methods using HPC",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "ab678abc-ca6f-4621-b39b-6512a6450377": {
        "id": "ab678abc-ca6f-4621-b39b-6512a6450377",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dispel4py-an-open-source-python-framework-for-encoding-mapping-and-reusing-seismic-continuous-data-streams-intensive-analysis-and-data-mining(ab678abc-ca6f-4621-b39b-6512a6450377).html",
        "abstract": "",
        "title": "dispel4py: An Open Source Python Framework for Encoding, Mapping and Reusing Seismic Continuous Data Streams: Intensive Analysis and Data Mining",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "78c489d5-ae08-405b-a329-a96eadee0ae1": {
        "id": "78c489d5-ae08-405b-a329-a96eadee0ae1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-verce-platform-enabling-computational-seismology-via-streaming-workflows-and-science-gateways-a-forecasting-model-testing-centre(78c489d5-ae08-405b-a329-a96eadee0ae1).html",
        "abstract": "",
        "title": "The VERCE platform: Enabling Computational Seismology via Streaming Workflows and Science Gateways. A Forecasting Model Testing Centre",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "8ec76f2d-eedc-4008-bd27-01348cf8ad67": {
        "id": "8ec76f2d-eedc-4008-bd27-01348cf8ad67",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dispel4py-an-opensource-python-library-for-dataintensive-seismology(8ec76f2d-eedc-4008-bd27-01348cf8ad67).html",
        "abstract": "",
        "title": "dispel4py: An Open-Source Python library for Data-Intensive Seismology",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "7c0e210c-a2d2-41b4-ba84-11130f60a10a": {
        "id": "7c0e210c-a2d2-41b4-ba84-11130f60a10a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-terracorrelator-a-shared-memory-hpc-facility-for-realtime-seismological-crosscorrelation-analyses(7c0e210c-a2d2-41b4-ba84-11130f60a10a).html",
        "abstract": "",
        "title": "The Terracorrelator: a shared memory HPC facility for real-time seismological cross-correlation analyses",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "e0816f52-0b56-479c-8b6f-ccd10a8671e2": {
        "id": "e0816f52-0b56-479c-8b6f-ccd10a8671e2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dispel4py-a-python-framework-for-dataintensive-escience(e0816f52-0b56-479c-8b6f-ccd10a8671e2).html",
        "abstract": "We present dispel4py, a novel data intensive and high performance computing middleware provided as a standard Python library for describing stream-based workflows. It allows its users to develop their scientific applications locally and then run them on a wide range of HPC-infrastructures without any changes to the code. Moreover, it provides automated and efficient parallel mappings to MPI, multiprocessing, Storm and Spark frameworks, commonly used in big data applications. It builds on the wide availability of Python in many environments and only requires familiarity with basic Python syntax. We will show the dispel4py advantages by walking through an example. We will conclude demonstrating how dispel4py can be employed as an easy-to-use tool for designing scientific applications using real-world scenarios.",
        "title": "Dispel4Py: A Python Framework for Data-intensive eScience",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "9a9ee7d7-ed9e-421c-9520-657538ce03ec": {
        "id": "9a9ee7d7-ed9e-421c-9520-657538ce03ec",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/adaptivecompi-enhancing-mpibased-applications-performance-and-scalability-by-using-adaptive-compression(9a9ee7d7-ed9e-421c-9520-657538ce03ec).html",
        "abstract": "This paper presents an optimization of MPI communication, called Adaptive-CoMPI, based on runtime compression of MPI messages exchanged by applications. The technique developed can be used for any application, because its implementation is transparent for the user, and integrates different compression algorithms for both MPI collective and point-to-point primitives. Furthermore, compression is turned on and off and the most appropriate compression algorithms are selected at runtime, depending on the characteristics of each message, the network behavior, and compression algorithm behavior, following a runtime adaptive strategy. Our system can be optimized for a specific application, through a guided strategy, to reduce the runtime strategy overhead. Adaptive-CoMPI has been validated using several MPI benchmarks and real HPC applications. Results show that, in most cases, by using adaptive compression, communication time is reduced, enhancing application performance and scalability.",
        "title": "Adaptive-CoMPI: Enhancing MPI-based applications\u2019 performance and scalability by using adaptive compression",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "70e2d1d1-a242-4c2a-8180-6af2c5d9f656": {
        "id": "70e2d1d1-a242-4c2a-8180-6af2c5d9f656",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dynamiccompi-dynamic-optimization-techniques-for-mpi-parallel-applications(70e2d1d1-a242-4c2a-8180-6af2c5d9f656).html",
        "abstract": "This work presents an optimization of MPI communications, called Dynamic-CoMPI, which uses two techniques in order to reduce the impact of communications and non-contiguous I/O requests in parallel applications.\nThese techniques are independent of the application and complementaries to each other. The first technique is an optimization\nof the Two-Phase collective I/O technique from ROMIO, called Locality aware strategy for Two-Phase I/O (LA-Two-Phase I/O). In order to increase the locality of the file accesses, LA-Two-Phase I/O employs the Linear Assignment Problem (LAP) for finding an optimal I/O data communication schedule. The main purpose of this\ntechnique is the reduction of the number of communications involved in the I/O collective operation. The second technique,\ncalled Adaptive-CoMPI, is based on run-time compression of MPI messages exchanged by applications. Both techniques can be applied on every application,\nbecause both of them are transparent for the users. Dynamic-CoMPI has been validated by using several MPI benchmarks and real HPC applications. The results show that, for many of the considered\nscenarios, important reductions in the execution time are achieved by reducing the size and the number of the messages. Additional\nbenefits of our approach are the reduction of the total communication time and the network contention, thus enhancing, not\nonly performance, but also scalability.",
        "title": "Dynamic-CoMPI: dynamic optimization techniques for MPI parallel applications",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "09481694-339a-4060-89fe-47a2ed7d728f": {
        "id": "09481694-339a-4060-89fe-47a2ed7d728f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/poster-reservationbased-io-performance-guarantee-for-mpiio-applications-using-shared-storage-systems(09481694-339a-4060-89fe-47a2ed7d728f).html",
        "abstract": "While optimized collective I/O methods are proposed for MPI-IO implementations, a problem in concurrent use of the shared storage system is raised. In order to prevent performance degradation of parallel I/O due to such I/O conflict, we propose an advance reservation approach, including possible integration with existing batch scheduler on HPC clusters. In this work, we use Dynamic-CoMPI as a MPI-IO implementation and Papio as a shared storage system which implements parallel I/O and performance reservation. Then we have been developing the ADIO layer to connect these systems and to evaluate the benefits of the reservation-based performance isolation. Our prototype implementation, Dynamic-CoMPI/Papio, was evaluated using the MPI-IO Test benchmark and the BISP3D application. In our preliminary evaluation, total execution time increased 3~12% with the Dynamic-CoMPI/PVFS2 and 6~40% with the Dynamic-CoMPI/Lustre, under the situation where additional workload affected on MPI execution, however there was no obvious time increase with Dynamic-CoMPI/Papio.",
        "title": "Poster: Reservation-Based I/O Performance Guarantee for MPI-IO Applications Using Shared Storage Systems",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "e22e99bd-057d-4767-af4b-896f2367411b": {
        "id": "e22e99bd-057d-4767-af4b-896f2367411b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dimensioning-scientific-computing-systems-to-improve-performance-of-mapreduce-based-applications(e22e99bd-057d-4767-af4b-896f2367411b).html",
        "abstract": "Map-Reduce is a programming model widely used for processing large data sets on scientific clusters. Most of the efforts and research are focused on enhancing and alleviating the drawbacks of the model proposed by Google. The requirements of Map-Reduce based applications are often unclear because of the difficulty in satisfying the overall system throughput, as well as exploring alternatives to obtain a good tradeoff between the performance of basic systems such as storage, networking and CPU. In this paper we present an evaluation of the compared performance of scaling up scientific computing systems using a Map-Reduce application model. This work is specifically focused on medium-size multi-core systems, frequently used by researchers to compute scientific applications. The scaling process is oriented towards the three main resources: computing power, communications and storage. By performing an extensive set of simulations using iCanCloud simulator, we also show that main bottlenecks of those kinds of applications executed in cluster systems are found in storage and network systems. Thence, in order to increase the overall performance of those applications, the computing power must be scaled up proportionally along the network and storage system.",
        "title": "Dimensioning Scientific Computing systems to improve performance of Map-Reduce based applications",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "640ff564-c30b-44c3-a836-33760f45edab": {
        "id": "640ff564-c30b-44c3-a836-33760f45edab",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-cloud-paradigm-applied-to-ehealth(640ff564-c30b-44c3-a836-33760f45edab).html",
        "abstract": "Background: <br/>Cloud computing is a new paradigm that is changing how enterprises, institutions and people understand, perceive and use current software systems. With this paradigm, the organizations have no need to maintain their own servers, nor host their own software. Instead, everything is moved to the cloud and provided on demand, saving energy, physical space and technical staff. Cloud-based system architectures provide many advantages in terms of scalability, maintainability and massive data processing.<br/><br/>Methods: <br/>We present the design of an e-health cloud system, modelled by an M/M/m queue with QoS capabilities, i.e. maximum waiting time of requests.<br/><br/>Results: <br/>Detailed results for the model formed by a Jackson network of two M/M/m queues from the queueing theory perspective are presented. These results show a significant performance improvement when the number of servers increases.<br/><br/>Conclusions: <br/>Platform scalability becomes a critical issue since we aim to provide the system with high Quality of Service (QoS). In this paper we define an architecture capable of adapting itself to different diseases and growing numbers of patients. This platform could be applied to the medical field to greatly enhance the results of those therapies that have an important psychological component, such as addictions and chronic diseases. <br/><br/>",
        "title": "The cloud paradigm applied to e-Health",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "302c7b88-679e-45e0-8568-6d674a6e1ecd": {
        "id": "302c7b88-679e-45e0-8568-6d674a6e1ecd",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/earthquake-and-failure-forecasting-in-realtime-a-forecasting-model-testing-centre(302c7b88-679e-45e0-8568-6d674a6e1ecd).html",
        "abstract": "Across Europe there are a large number of rock deformation laboratories,\neach of which runs many experiments. Similarly there are a large number\nof theoretical rock physicists who develop constitutive and\ncomputational models both for rock deformation and changes in\ngeophysical properties. Here we consider how to open up opportunities\nfor sharing experimental data in a way that is integrated with multiple\nhypothesis testing. We present a prototype for a new forecasting model\ntesting centre based on e-infrastructures for capturing and sharing data\nand models to accelerate the Rock Physicist (RP) research. This\nproposal is triggered by our work on data assimilation in the NERC\nEFFORT (Earthquake and Failure Forecasting in Real Time) project, using\ndata provided by the NERC CREEP 2 experimental project as a test case.\nEFFORT is a multi-disciplinary collaboration between Geoscientists, Rock\nPhysicists and Computer Scientist. Brittle failure of the crust is\nlikely to play a key role in controlling the timing of a range of\ngeophysical hazards, such as volcanic eruptions, yet the predictability\nof brittle failure is unknown. Our aim is to provide a facility for\ndeveloping and testing models to forecast brittle failure in\nexperimental and natural data. Model testing is performed in real-time,\nverifiably prospective mode, in order to avoid selection biases that are\npossible in retrospective analyses. The project will ultimately\nquantify the predictability of brittle failure, and how this\npredictability scales from simple, controlled laboratory conditions to\nthe complex, uncontrolled real world. Experimental data are collected\nfrom controlled laboratory experiments which includes data from the UCL\nLaboratory and from Creep2 project which will undertake experiments in a\ndeep-sea laboratory. We illustrate the properties of the prototype\ntesting centre by streaming and analysing realistically noisy synthetic\ndata, as an aid to generating and improving testing methodologies in\nimperfect conditions. The forecasting model testing centre uses a\nrepository to hold all the data and models and a catalogue to hold all\nthe corresponding metadata. It allows to: Data transfer: \nUpload experimental data: We have developed FAST \n(Flexible Automated Streaming Transfer) tool to upload data\nfrom RP laboratories to the repository. FAST sets up data\ntransfer requirements and selects automatically the\ntransfer protocol. Metadata are automatically created and \nstored. Web data access: Create synthetic\ndata: Users can choose a generator and supply parameters. \nSynthetic data are automatically stored with corresponding \nmetadata. Select data and models: Search the\nmetadata using criteria design for RP. The metadata of \neach data (synthetic or from laboratory) and models are\nwell-described through their respective catalogues accessible \nby the web portal. Upload models: Upload and store a\nmodel with associated metadata. This provide an opportunity to\nshare models. The web portal solicits and creates metadata\ndescribing each model. Run model and visualise\nresults: Selected data and a model to be submitted to a \nHigh Performance Computational resource hiding technical \ndetails. Results are displayed in accelerated time and stored \nallowing retrieval, inspection and aggregation. The\nforecasting model testing centre proposed could be integrated into EPOS.\nIts expected benefits are: Improved the understanding of \nbrittle failure prediction and its scalability to natural\nphenomena. Accelerated and extensive testing and rapid\nsharing of insights. Increased impact and visibility of RP\nand GeoScience research. Resources for education and\ntraining. A key challenge is to agree the framework for sharing RP\ndata and models. Our work is provocative first step.",
        "title": "Earthquake and failure forecasting in real-time: A Forecasting Model Testing Centre",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "5953fd8d-890a-40a6-aa2f-3eb0b23d0a28": {
        "id": "5953fd8d-890a-40a6-aa2f-3eb0b23d0a28",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/realtime-forecasting-of-sample-failure-in-laboratory-rock-deformation-experiments(5953fd8d-890a-40a6-aa2f-3eb0b23d0a28).html",
        "abstract": "The ability to accurately forecast catastrophic failure in rocks is likely to be a key component in reliable eruption forecasting models. The processes controlling the approach to failure produce highly non-linear behaviour, with a large stochastic component due to material heterogeneity. In the laboratory, mechanical, hydraulic, and rock physical properties are known to change in systematic ways prior to catastrophic failure. The effectiveness of such signals in real-time forecasting has never been tested before in a controlled laboratory setting; previous work has often been qualitative in nature, and subject to retrospective selection bias. Here we describe a collaborative experiment in real-time data assimilation to explore the limits of predictability of rock failure in a best-case scenario. Data are streamed from a remote rock deformation laboratory to a user-friendly portal, where several proposed physical/stochastic models can be analyzed in parallel in real time, using a variety of statistical fitting techniques, including least squares regression, maximum likelihood fitting, Markov-chain Monte-Carlo and Bayesian analysis. The results are posted and regularly updated on the web site prior to catastrophic failure, to ensure a true and verifiable prospective test of forecasting power.",
        "title": "Real-time forecasting of sample failure in laboratory rock deformation experiments",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "60fe14d1-8d14-40b3-8311-029c0dcf9c96": {
        "id": "60fe14d1-8d14-40b3-8311-029c0dcf9c96",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sancomsim-a-scalable-adaptive-and-nonintrusive-framework-to-optimize-performance-in-computational-science-applications(60fe14d1-8d14-40b3-8311-029c0dcf9c96).html",
        "abstract": "Parallel processing has become the most common solution for developing and executing scientific computing applications. Actually, the best way to obtain good performance ratios is to exploit parallelism in both processing and communications. Although the study of computational performance has historically involved CPU power, currently the CPU is not the only concern in the overall performance. Due to the underlying design of parallel applications, communication networks play a very important role in the field of computational science. Despite the fact that networks used in multicore clusters are fast and have low latency, the amount of transferred data may cause a bottleneck in the communication system, as communication- intensive, parallel applications spend a significant amount of their total execution time exchanging data between processes. Moreover, in most cases, several users are executing different parallel applications at the same time in the cluster. In this paper we present SANComSim, a Scalable, Adaptive and Non-intrusive framework, based on simulation techniques, for optimizing the performance of the network system to execute complex applications. The main objective of this framework is to apply run-time compression, to reduce the data sent through the network, in order to increase the overall system performance. The main features of SANComSim are: adaptability, to dynamically adapt to the current state of the system; portability, the framework is neither focused on a specific programming language nor a platform; non-intrusive, since this framework is based on simulation techniques, which does not require exclusive access of the entire cluster system; scalability, any parallel application, independently of the number of processed and computing nodes, can use this framework to improve performance in cluster systems.",
        "title": "SANComSim: A Scalable, Adaptive and Non-intrusive Framework to Optimize Performance in Computational Science Applications",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "1511eac6-a66f-4a5d-9979-575fa4a64fc7": {
        "id": "1511eac6-a66f-4a5d-9979-575fa4a64fc7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/design-of-a-prototype-for-modelling-membrane-computation-based-on-ecosystems-in-a-cloud-environment(1511eac6-a66f-4a5d-9979-575fa4a64fc7).html",
        "abstract": "This paper presents a new I/O technique called Selectively Parallel I/O Compression (SPIOC) for providing high-speed storage and access to data in QoS enabled parallel storage systems. SPIOC reduces the time of I/O operations by applying transparent compression between the computing and the storage systems. SPIOC can predict whether to compress or not at runtime, allowing parallel or sequential compression techniques, guaranteeing QoS and allowing partial and full reading by decompressing the minimum part of the file. SPIOC maximises the measured efficiency of data movement by applying run-time customising compression before storing data in the Papio storage system.",
        "title": "Design of a prototype for modelling membrane computation based on ecosystems in a cloud environment",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "d47977db-24b5-4279-bf4f-80e5fe28363e": {
        "id": "d47977db-24b5-4279-bf4f-80e5fe28363e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/varpy-a-python-library-for-volcanology-and-rock-physics-data-analysis-egu20143699(d47977db-24b5-4279-bf4f-80e5fe28363e).html",
        "abstract": "VarPy is an open-source toolbox which provides a Python framework for analysing volcanology and rock physics data. It provides several functions, which allow users to define their own workflows to develop models, analyses and visualisa- tions. The goal of the VarPy library is to accelerate the uptake of computational methods by researchers in volcanology and rock physics. It does this via two mechanisms:<br/>\u2022 supplying a library of ready-made functions that are generally useful; and<br/>\u2022 providing a context for creating, sharing and comparing additional functions.<br/>We anticipate two groups of VarPy users:<br/>\u2022 the majority who use functions already written and in the library; they will predominantly arrange to use sequences of these functions with their own parameter- isations; and<br/>\u2022 contributors, who, as well as using provided functions, also want to write additional functions for their own use or to add to the library. <br/><br/>",
        "title": "Varpy: A python library for volcanology and rock physics data analysis. EGU2014-3699",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "f400e4f3-4a11-4432-9baf-9fd4790936ad": {
        "id": "f400e4f3-4a11-4432-9baf-9fd4790936ad",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/workflows-in-a-dashboard-a-new-generation-of-usability(f400e4f3-4a11-4432-9baf-9fd4790936ad).html",
        "abstract": "In the last 20 years quite a few mature workflow engines and workflow editors have been developed to support communities in managing workflows. While there is a trend followed by the providers of workflow engines to ease the creation of workflows tailored to their specific workflow system, the management tools still often necessitate much understanding of the workflow concepts and languages. This paper describes the approach targeting various workflow systems and building a single user interface for editing and monitoring workflows under consideration of aspects such as optimization and provenance of data. The design allots agile Web frameworks and novel technologies to build a workflow dashboard offered in a web browser and connecting seamlessly to available workflow systems and external resources like Cloud infrastructures. The user interface eliminates the need to become acquainted with diverse layouts. Thus, the usability is immensely increased for various aspects of managing workflows.",
        "title": "Workflows in a Dashboard: A New Generation of Usability",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "3d8f1666-f9d0-4f1c-a0b5-aeb33bc08008": {
        "id": "3d8f1666-f9d0-4f1c-a0b5-aeb33bc08008",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dispel4py-a-python-framework-for-dataintensive-scientific-computing(3d8f1666-f9d0-4f1c-a0b5-aeb33bc08008).html",
        "abstract": "This paper presents dispel4py, a new Python framework for describing abstract stream-based workflows for distributed data-intensive applications. The main aim of dispel4py is to enable scientists to focus on their computation instead of being distracted by details of the computing infrastructure they use. Therefore, special care has been taken to provide dispel4py with the ability to map abstract workflows to different enactment platforms dynamically, at run time. In this work we present four dispel4py mappings: Apache Storm, MPI, multi-threading and sequential. The results show that dispel4py is successful in enacting on different platforms, while also providing scalable performance.",
        "title": "dispel4py: A Python Framework for Data-Intensive Scientific Computing",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "e154c6fe-3210-4cbb-b079-37266c16aaee": {
        "id": "e154c6fe-3210-4cbb-b079-37266c16aaee",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/varpy-a-python-library-for-volcanology-and-rock-physics-data-analysis(e154c6fe-3210-4cbb-b079-37266c16aaee).html",
        "abstract": "VarPy is an open-source toolbox which provides a Python framework for analysing volcanology and rock physics data. It provides several functions, which allow users to define their own workflows to develop models, analyses and visualisations. The goal of the VarPy library is to accelerate the uptake of computational methods by researchers in volcanology and rock physics. It does this via two mechanisms:<br/>- supplying a library of ready-made functions that are\ngenerally useful; and- providing a context for creating, sharing and comparing\nadditional functions.\u00a0<br/>We anticipate two groups of\nVarPy\nusers:<br/>- the majority who use functions already written and\nin the library; they will predominantly arrange to use\nsequences of these functions with their own parameterisations; and- contributors, who, as well as using provided functions,\nalso want to write additional functions for their own use\nor to add to the library",
        "title": "VarPy: A Python library for volcanology and rock physics data analysis",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "35e91bf9-27cb-469d-8631-5f0dddd27fa2": {
        "id": "35e91bf9-27cb-469d-8631-5f0dddd27fa2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dispel4py-an-userfriendly-framework-for-describing-escience-applications(35e91bf9-27cb-469d-8631-5f0dddd27fa2).html",
        "abstract": "We present dispel4py a versatile data-intensive\nkit presented as a standard Python library. It empowers\nscientists to experiment and test ideas using their familiar\nrapid-prototyping environment. It delivers mappings to diverse\ncomputing infrastructures, including cloud technologies, HPC\narchitectures and specialised data-intensive machines, to move\nseamlessly into production with large-scale data loads. The\nmappings are fully automated, so that the encoded data\nanalyses and data handling are completely unchanged. The\nunderpinning model is lightweight composition of fine-grained\noperations on data, coupled together by data streams that\nuse the lowest cost technology available. These fine-grained\nworkflows are locally interpreted during development and\nmapped to multiple nodes and systems such as MPI and Storm\nfor production.\nWe explain why such an approach is becoming more essential\nin order that data-driven research can innovate rapidly and\nexploit the growing wealth of data while adapting to current\ntechnical trends. We show how provenance management is\nprovided to improve understanding and reproducibility, and\nhow a registry supports consistency and sharing. Three application\ndomains are reported and measurements on multiple\ninfrastructures show the optimisations achieved. Finally we\npresent the next steps to achieve scalability and performance.",
        "title": "dispel4py: An User-friendly Framework for Describing eScience Applications",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "3d2ebdb0-4dcf-48ed-92a6-572bfada6adc": {
        "id": "3d2ebdb0-4dcf-48ed-92a6-572bfada6adc",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/verce-delivers-a-productive-escience-environment-for-seismology-research(3d2ebdb0-4dcf-48ed-92a6-572bfada6adc).html",
        "abstract": "The VERCE project has pioneered an\ne-Infrastructure to support researchers using established\nsimulation codes on high-performance computers in\nconjunction with multiple sources of observational data.\nThis is accessed and organised via the VERCE science\ngateway that makes it convenient for seismologists to use\nthese resources from any location via the Internet. Their data\nhandling is made flexible and scalable by two Python libraries,\nObsPy and dispel4py and by data services delivered by\nORFEUS and EUDAT. Provenance driven tools enable rapid\nexploration of results and of the relationships between data,\nwhich accelerates understanding and method improvement.\nThese powerful facilities are integrated and draw on many\nother e-Infrastructures. This paper presents the motivation for\nbuilding such systems, it reviews how solid-Earth scientists can\nmake significant research progress using them and explains\nthe architecture and mechanisms that make their construction\nand operation achievable. We conclude with a summary of\nthe achievements to date and identify the crucial steps needed\nto extend the capabilities for seismologists, for solid-Earth\nscientists and for similar disciplines.",
        "title": "VERCE delivers a productive e-Science environment for seismology research",
        "keywords": "",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "fc34b644-05cd-4b45-969e-972932a62b7c": {
        "id": "fc34b644-05cd-4b45-969e-972932a62b7c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-adaptive-scalable-and-portable-technique-for-speeding-up-mpibased-applications(fc34b644-05cd-4b45-969e-972932a62b7c).html",
        "abstract": "This paper presents a portable optimization for MPI communications, called PRAcTICaL-MPI (Portable Adaptive Compression Library- MPI). PRAcTICaL-MPI reduces the data volume exchanged among processes by using lossless compression and offers two main advantages. Firstly, it is independent of the MPI implementation and the application used. Secondly, it allows for turning the compression on and off and selecting the most appropriate compression algorithm at run-time, depending on the characteristics of each message and on network performance.<br/><br/>We have validated PRAcTICaL-MPI in different MPI implementations and HPC clusters. The evaluation shows that compressing MPI messages with the best algorithm and only when it is worthwhile, we obtain a great reduction in the overall execution time for many of the scenarios considered.",
        "title": "An Adaptive, Scalable, and Portable Technique for Speeding Up MPI-Based Applications",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "3ef09e30-3b75-442a-98de-bb5181859d78": {
        "id": "3ef09e30-3b75-442a-98de-bb5181859d78",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/applying-selectively-parallel-io-compression-to-parallel-storage-systems(3ef09e30-3b75-442a-98de-bb5181859d78).html",
        "abstract": "This paper presents a new I/O technique called Selectively Parallel I/O Compression (SPIOC) for providing high-speed storage and access to data in QoS enabled parallel storage systems. SPIOC reduces the time of I/O operations by applying transparent compression between the computing and the storage systems. SPIOC can predict whether to compress or not at runtime, allowing parallel or sequential compression techniques, guaranteeing QoS and allowing partial and full reading by decompressing the minimum part of the file. SPIOC maximises the measured efficiency of data movement by applying run-time customising compression before storing data in the Papio storage system.",
        "title": "Applying Selectively Parallel I/O Compression to Parallel Storage Systems",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "435bea29-f2dc-4152-ab4e-33224dcd4980": {
        "id": "435bea29-f2dc-4152-ab4e-33224dcd4980",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/escience-gateway-stimulating-collaboration-in-rock-physics-and-volcanology(435bea29-f2dc-4152-ab4e-33224dcd4980).html",
        "abstract": "<p>Earth scientist observe many facets of the planet's crust and integrate their resulting data to better understand the processes at work. We report on a new data-intensive science gateway designed to bring rock physicists and volcanologists into a collaborative framework that enables them to accelerate their research and integrate well with other Earth scientists. The science gateway supports three major functions: 1) sharing data from laboratories and observatories, experimental facilities and computational model runs, 2) sharing computational model sand methods for analysing experimental and observational data, and 3) supporting recurrent tasks, such as data collection and running application in real time. Our prototype gateway has worked with two exemplar projects giving experience of data gathering, model sharing and data analysis. The geoscientists found that the gateway accelerated their work, triggered new practices and provided a good platform for long-term collaboration.</p>",
        "title": "eScience gateway stimulating collaboration in rock physics and volcanology",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "8385add9-3b15-4ffc-86b8-680b466900c2": {
        "id": "8385add9-3b15-4ffc-86b8-680b466900c2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/fast-flexible-automated-synchronization-transfer(8385add9-3b15-4ffc-86b8-680b466900c2).html",
        "abstract": "This paper presents a new data synchronizing transfer tool called FAST (Flexible Automated Synchronization Transfer) which allows facilities for reliably transferring multi-channel data and metadata periodically from rock physics experiments to a repository and a database located in a remote machine. FAST is compatible with all operating systems, and allows for different types of transfer operations by selecting a different transfer protocol. FAST is very easy to set up and requires little oversight during operation. It copes automatically with interruptions to local operations and communications.",
        "title": "FAST: Flexible Automated Synchronization Transfer",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Rosa Filgueira Vicente",
                "uuid": "e36e60be-cb42-4c61-8151-517e254b280e"
            }
        ]
    },
    "d7507792-27d5-4f1a-8644-6fe09af86b59": {
        "id": "d7507792-27d5-4f1a-8644-6fe09af86b59",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/modular-physical-modeling-synthesis-environments-on-gpu(d7507792-27d5-4f1a-8644-6fe09af86b59).html",
        "abstract": "Physical modeling synthesis is a powerful means of access to a wide variety of synthetic sounds of an acoustic character---one longstanding design principle underlying such methods has been, and continues to be modularity, or the decomposition of a complex instrument into simpler building blocks. In this paper, various modular physical modeling design environments, based on the use of time stepping methods such as finite difference time domain methods are described, with an emphasis on the underlying computational behaviour of such methods, both in the run-time loop and in precomputation. As such methods are computationally intensive, additional emphasis is placed on issues surrounding parallelisation, and implementation in highly parallel hardware such as graphics processing units. This paper is paired with a recently completed multichannel piece, and the composer's perspective on working with such environments is also addressed.",
        "title": "Modular Physical Modeling Synthesis Environments on GPU",
        "keywords": "",
        "authors": [
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            },
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "98336b78-beee-4b9b-a0af-b74973b94c05": {
        "id": "98336b78-beee-4b9b-a0af-b74973b94c05",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-search-for-genegene-interactions-in-colorectal-cancer-using-hpc-to-overcome-computational-barriers(98336b78-beee-4b9b-a0af-b74973b94c05).html",
        "abstract": "UK National Cancer Registration data indicates that some 35,000 people each year are diagnosed with colorectal cancer (cancer of the large bowel and rectum) and 16, 000 die from the disease. The Colon Cancer Genetics Group (CCGG) at the University of Edinburgh investigates the relationship between genetic markers and colorectal cancer by using a significant part (560,000 markers, 1000 cases, 1000 controls) of the biggest genotypic data set for large bowel cancer. However, the analysis is virtually intractable for a PC-based researcher (theoretical runtime of 400 days; 3.3TB of memory and hard disk space). CCGG collaborated with EPCC, the super computing centre of the University of Edinburgh, to optimise and parallelise the analysis code. We achieved a runtime of approximately 5 hours on 512 processor cores on HECToR, the national supercomputer of the UK. The use of EPCC's skills and HPC resources has enabled CCGG to explore new territory for genetic marker analysis in colorectal cancer.",
        "title": "The Search for Gene-Gene Interactions in Colorectal Cancer using HPC to overcome Computational barriers",
        "keywords": "",
        "authors": [
            {
                "name": "Paul Graham",
                "uuid": "668d7161-8efc-4405-b548-a89b0c9ef94e"
            },
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            }
        ]
    },
    "de807d6d-2848-4a3c-9f02-d0707edaf5cc": {
        "id": "de807d6d-2848-4a3c-9f02-d0707edaf5cc",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/numerical-simulations-of-galaxies-on-parallel-computers(de807d6d-2848-4a3c-9f02-d0707edaf5cc).html",
        "abstract": "",
        "title": "Numerical simulations of galaxies on parallel computers",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "84b0157f-d172-42aa-840f-38c516a3ebe2": {
        "id": "84b0157f-d172-42aa-840f-38c516a3ebe2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/sphgravity-on-a-mimd-parallel-computer(84b0157f-d172-42aa-840f-38c516a3ebe2).html",
        "abstract": "Not Available",
        "title": "SPH/Gravity on a MIMD Parallel Computer",
        "keywords": "",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "0d75c897-87b1-4873-aebf-18542df924de": {
        "id": "0d75c897-87b1-4873-aebf-18542df924de",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/numerical-simulations-of-m51(0d75c897-87b1-4873-aebf-18542df924de).html",
        "abstract": "We present computer simulations of the interaction of NGC5194 and 5195\ninvolving the gaseous, stellar and dark matter compnonents of the two\ngalaxies. Several observational features of NGC 5194 are reproduced\nusing orbital parameters close to the best guess from previous\ncalulations, including : 1) Broad stellar spiral arms 2) Narrow gaseous\nspiral arms with strong shock velocity discontinuities 3) A bar-like\noval distortion in the central stellar bulge 4) Sharp bends in the\ngaseous spiral arms 5) A long southern gaseous tail 6) A dense nuclear\ngas ring Points (2), (3), (4) and (6) have not been reported in previous\ncomputer simulations.",
        "title": "Numerical Simulations of M51",
        "keywords": "",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "75c0114b-331a-4372-ae15-cd32dc7023e4": {
        "id": "75c0114b-331a-4372-ae15-cd32dc7023e4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-outline-of-the-global-grid-forum-data-access-and-integration-service-specification(75c0114b-331a-4372-ae15-cd32dc7023e4).html",
        "abstract": "",
        "title": "An Outline of the Global Grid Forum Data Access and Integration Service Specification",
        "keywords": "",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "14bbc72b-b781-4c0d-b67d-bf09000a9032": {
        "id": "14bbc72b-b781-4c0d-b67d-bf09000a9032",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-wsdai-family-of-specifications-for-web-service-data-access-and-integration(14bbc72b-b781-4c0d-b67d-bf09000a9032).html",
        "abstract": "",
        "title": "The WS-DAI family of specifications for web service data access and integration",
        "keywords": "",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "6c104114-4e36-49bd-944b-329c902140d5": {
        "id": "6c104114-4e36-49bd-944b-329c902140d5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/open-standards-for-servicebased-database-access-and-integration(6c104114-4e36-49bd-944b-329c902140d5).html",
        "abstract": "",
        "title": "Open Standards for Service-Based Database Access and Integration",
        "keywords": "",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            }
        ]
    },
    "d7b2b82d-1acc-410b-9f47-b84532532797": {
        "id": "d7b2b82d-1acc-410b-9f47-b84532532797",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/protecting-application-developers--a-client-toolkit-for-ogsadai(d7b2b82d-1acc-410b-9f47-b84532532797).html",
        "abstract": "",
        "title": "Protecting Application Developers \u2013 a Client Toolkit for OGSA-DAI",
        "keywords": "",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "30335eaa-166e-4636-8b65-a0027b165441": {
        "id": "30335eaa-166e-4636-8b65-a0027b165441",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/performance-analysis-of-the-ogsadai-software(30335eaa-166e-4636-8b65-a0027b165441).html",
        "abstract": "",
        "title": "Performance Analysis of the OGSA-DAI Software",
        "keywords": "",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "40d72d9b-bab7-46fb-a8be-3feb60bd97cc": {
        "id": "40d72d9b-bab7-46fb-a8be-3feb60bd97cc",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/building-bridges-between-islands-of-data--an-investigation-into-distributed-data-management-in-the-humani(40d72d9b-bab7-46fb-a8be-3feb60bd97cc).html",
        "abstract": "",
        "title": "Building bridges between islands of data \u2013 an investigation into distributed data management in the humani",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "e3978697-3f83-49bc-9842-456566f227d4": {
        "id": "e3978697-3f83-49bc-9842-456566f227d4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/web-services-data-access-and-integration--the-relational-realisation-wsdair-specification(e3978697-3f83-49bc-9842-456566f227d4).html",
        "abstract": "",
        "title": "Web Services Data Access and Integration \u2013 The Relational Realisation (WS-DAIR) Specification",
        "keywords": "",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "37d2d13f-285b-41df-b2a5-5fed51fd6f8e": {
        "id": "37d2d13f-285b-41df-b2a5-5fed51fd6f8e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/web-services-data-access-and-integration--the-core-wsdai-specification(37d2d13f-285b-41df-b2a5-5fed51fd6f8e).html",
        "abstract": "",
        "title": "Web Services Data Access and Integration \u2013 The Core (WS-DAI) Specification",
        "keywords": "",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "05242df3-ca99-41ee-aba8-c16c5106b351": {
        "id": "05242df3-ca99-41ee-aba8-c16c5106b351",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/accessing-data-in-grids-using-ogsadai(05242df3-ca99-41ee-aba8-c16c5106b351).html",
        "abstract": "The grid provides a vision in which resources, including storage and data, can be shared across organisational boundaries. The original emphasis of grid computing lay in the sharing of computational resources but technological and scientific advances have led to an ongoing data explosion in many fields. How- ever, data is stored in many different storage systems and data formats, with different schema, access rights, metadata attributes, and ontologies all of which are obstacles to the access, integration and management of this information. In this chapter we examine some of the ways in which these differences can be addressed by grid technology to enable the meaningful sharing of data. In particular, we present an overview of the OGSA-DAI (Open Grid Service Ar- chitecture - Data Access and Integration) software, which provides a uniform, extensible framework for accessing structured and semi-structured data and pro- vide some examples of its use in other projects. The open-source OGSA-DAI software is freely available from http://www.ogsadai.org.uk.",
        "title": "Accessing Data in Grids Using OGSA-DAI",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "2bb4dec3-e716-4f41-97c1-9a04f7f4943b": {
        "id": "2bb4dec3-e716-4f41-97c1-9a04f7f4943b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/grid-enabling-your-data-resources-with-ogsadai(2bb4dec3-e716-4f41-97c1-9a04f7f4943b).html",
        "abstract": "OGSA-DAI (Open Grid Services Architecture - Data Access and Integration) provides an extensible software framework allowing data resources, such as files, relational and XML databases, to be exposed through Web services acting within collaborative Grid environments or, more modestly, in stand-alone mode. OGSA-DAI may be deployed to WSRF-based platforms, such as the Globus Toolkit 4, as well as non-WSRF based ones, such as the UK OMII Server or standard versions of Tomcat and axis. Regardless of the platform, the core functionality provided remains the same. OGSA-DAI allows data resources to be accessed and integrated into the main infrastructures presently being used to construct Grids. OGSA-DAI provides a number of optimisations that reduce unnecessary data movement by shifting work to the Web service and encapsulating multiple client-Web service interactions into a single one, and allows for functionality to be added or customised based on the application. OGSA-DAI is widely used and is available from www.ogsadai.org.uk. It is also bundled with the OMII-UK and Globus Toolkit distributions. This paper gives an overview of what OGSA-DAI is, how it works, presents some usage scenarios, and outlines future enhancements.",
        "title": "Grid Enabling Your Data Resources with OGSA-DAI",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "022d67ac-3877-4cb3-83e8-c4700a383b5d": {
        "id": "022d67ac-3877-4cb3-83e8-c4700a383b5d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/distributed-data-management-with-ogsadai(022d67ac-3877-4cb3-83e8-c4700a383b5d).html",
        "abstract": "",
        "title": "Distributed Data Management with OGSA-DAI",
        "keywords": "",
        "authors": [
            {
                "name": "Mario Antonioletti",
                "uuid": "43107f7e-071e-4cff-9fbf-0fa8b3f5636c"
            },
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "b904656a-e4f4-4d3f-9bc0-04d9734c4d0c": {
        "id": "b904656a-e4f4-4d3f-9bc0-04d9734c4d0c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/generalisation-of-recursive-doubling-for-allreduce-now-with-simulation(b904656a-e4f4-4d3f-9bc0-04d9734c4d0c).html",
        "abstract": "The performance of AllReduce is crucial at scale. The recursive doubling with pairwise exchange algorithm theoretically achieves O(log2N) scaling for short messages with N peers, but is limited by improvements in network latency. A multi-way exchange can be implemented using message pipelining, which is easier to improve than latency. Using our method, recursive multiplying, we show reductions in execution time of between 8% and 40% of AllReduce on a Cray XC30 over recursive doubling. Using a custom simulator we further explore the dynamics of recursive multiplying.",
        "title": "Generalisation of Recursive Doubling for AllReduce: Now with Simulation",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Stephen Booth",
                "uuid": "b1fdf0bf-ae1e-4b47-94f6-a488f8d2f14c"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "6f190614-8999-4f38-847a-713b0c29f1c5": {
        "id": "6f190614-8999-4f38-847a-713b0c29f1c5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/textgrid-textvre-and-dariah-sustainability-of-infrastructures-for-textual-scholarship(6f190614-8999-4f38-847a-713b0c29f1c5).html",
        "abstract": "A variety of initiatives for developing virtual research environments, research infrastructures, and cyberinfrastructures have been funded in recent years. The systems produced vary considerably, but they all face the issue of sustainability, namely how to ensure the continued existence of a resource once the project that created it has finished. This paper addresses the sustainability issues faced by the TextGrid and TEXTvre virtual research environments for textual scholarship, examining the inter-project collaboration and cross-fertilization that took place, and investigating how the projects benefited from this exchange. It also examines how their sustainability is being facilitated by the more general-purpose DARIAH infrastructure, and conversely how their existing collaboration can serve as a model for future collaborations within the DARIAH community.",
        "title": "TextGrid, TEXTvre, and DARIAH: Sustainability of Infrastructures for Textual Scholarship",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Malcolm Illingworth",
                "uuid": "6ea1f03e-f39e-48a4-8867-a27c471920fa"
            }
        ]
    },
    "59d316e7-2366-4722-84aa-802edde4d924": {
        "id": "59d316e7-2366-4722-84aa-802edde4d924",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cloudqtl-evolving-a-bioinformatics-application-into-the-clouds(59d316e7-2366-4722-84aa-802edde4d924).html",
        "abstract": "A timeline is presented which shows the stages involved in converting a bioinformatics software application from a set of standalone algorithms through to a simple web based tool then to a web based portal harnessing grid technologies (GridQTL) and on to its latest inception as a cloud based bioinformatics web tool (CloudQTL). The nature of the software is discussed together with a description of its development at various stages and the resulting successful increase in the user base. A discussion is then made detailing the latest idea to achieve a paid for service using cloud technologies.",
        "title": "CloudQTL: Evolving a bioinformatics application into the clouds",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Malcolm Illingworth",
                "uuid": "6ea1f03e-f39e-48a4-8867-a27c471920fa"
            },
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "339c767b-19f2-48d2-8099-b889796a46c7": {
        "id": "339c767b-19f2-48d2-8099-b889796a46c7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cloudqtl-evolving-a-bioinformatics-application-to-the-cloud(339c767b-19f2-48d2-8099-b889796a46c7).html",
        "abstract": "A timeline is presented which shows the stages involved in converting a bioinformatics software application from a set of standalone algorithms through to a<br/>simple web based tool then to a web based portal harnessing Grid technologies and on to its latest inception as a Cloud based bioinformatics web tool. The nature of the software is discussed together with a description of its development at various stages and the resulting successful increase in the user base. A discussion is then made detailing the latest idea to achieve a paid for service using Cloud technologies.",
        "title": "CloudQTL: Evolving a Bioinformatics Application to the Cloud",
        "keywords": "",
        "authors": [
            {
                "name": "Malcolm Illingworth",
                "uuid": "6ea1f03e-f39e-48a4-8867-a27c471920fa"
            },
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "4786c26b-6771-4739-a3ce-5e5fac51725b": {
        "id": "4786c26b-6771-4739-a3ce-5e5fac51725b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mist-a-simple-and-efficient-molecular-dynamics-abstraction-library-for-integrator-development(4786c26b-6771-4739-a3ce-5e5fac51725b).html",
        "abstract": "We present MIST, the Molecular Integration Simulation Toolkit, a lightweight and efficient software library written in C++ which provides an abstract in- terface to common molecular dynamics codes, enabling rapid and portable development of new integration schemes for molecular dynamics. The initial release provides plug-in interfaces to NAMD-Lite, GROMACS and Amber, and includes several standard integration schemes, a constraint solver, tem- perature control using Langevin Dynamics, and two tempering schemes. We describe the architecture and functionality of the library and the C and For- tran APIs which can be used to interface additional MD codes to MIST. We show, for a range of test systems, that MIST introduces negligible overheads for serial, shared-memory parallel, and GPU-accelerated cases, except for Amber where the native integrators run directly on the GPU itself. As a demonstration of the capabilities of MIST, we describe a simulated tempering simulation used to study the free energy landscape of Alanine-12 in both vacuum and detailed solvent conditions.",
        "title": "MIST: A Simple and Efficient Molecular Dynamics Abstraction Library for Integrator Development",
        "keywords": "",
        "authors": [
            {
                "name": "Elena Breitmoser",
                "uuid": "1a2c3c66-ade8-42d7-ae85-85b3e4a84425"
            }
        ]
    },
    "bf203a43-7e02-4456-bc9d-6e7702467d2b": {
        "id": "bf203a43-7e02-4456-bc9d-6e7702467d2b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mesh-inlay-mesh-kit-or-native-tissue-repair-for-women-having-repeat-anterior-or-posterior-prolapse-surgery(bf203a43-7e02-4456-bc9d-6e7702467d2b).html",
        "abstract": "<p>OBJECTIVE: To compare standard (native tissue) repair against synthetic mesh inlays or mesh kits.</p><p>DESIGN: Randomised controlled trial.</p><p>SETTING: 33 UK hospitals.</p><p>POPULATION: Women having surgery for recurrent prolapse.</p><p>METHODS: Women recruited using remote randomisation.</p><p>MAIN OUTCOME MEASURES: Prolapse symptoms, condition specific quality-of-life and serious adverse effects.</p><p>RESULTS: Mean Pelvic Organ Prolapse Symptom Score at 1 year was similar for each comparison (standard 6.6 versus mesh inlay 6.1, mean difference (MD) -0.41, 95% CI [-2.92 to 2.11]: standard 6.6 versus mesh kit 5.9, MD -1.21 [-4.13 to 1.72]) but the confidence intervals did not exclude a minimally important clinical difference. There was no evidence of difference in any other outcome measure at 1 or 2 years. Serious adverse events, excluding mesh exposure, were similar at 1 year (standard 7/55 [13%] versus mesh inlay 5/52 [10%], risk ratio [RR] 1.05, [0.66 to 1.68]: standard 3/25 [12%] versus mesh kit 3/46 [7%], RR 0.49, [0.11 to 2.16]). Cumulative mesh exposure rates over 2 years were 7/52 (13%) in the mesh inlay arm, of whom four women required surgical revision; and 4/46 in the mesh kit arm (9%) of whom two required surgical revision.</p><p>CONCLUSIONS: We did not find evidence of a difference in terms of prolapse symptoms from the use of mesh inlays or mesh kits in women undergoing repeat prolapse surgery. Although the sample size was too small to be conclusive, the results provide a substantive contribution to future meta-analysis.</p>",
        "title": "Mesh inlay, mesh kit or native tissue repair for women having repeat anterior or posterior prolapse surgery",
        "keywords": "",
        "authors": [
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            }
        ]
    },
    "65988a45-45f2-4de6-8054-86c67a47538b": {
        "id": "65988a45-45f2-4de6-8054-86c67a47538b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/porting-of-the-dbcsr-library-for-sparse-matrixmatrix-multiplications-to-intel-xeon-phi-systems(65988a45-45f2-4de6-8054-86c67a47538b).html",
        "abstract": "Multiplication of two sparse matrices is a key operation in the simulation of the electronic structure of systems containing thousands of atoms and electrons. The highly optimized sparse linear algebra library DBCSR (Distributed Block Compressed Sparse Row) has been specifically designed to efficiently perform such sparse matrix-matrix multiplications. This library is the basic building block for linear scaling electronic structure theory and low scaling correlated methods in CP2K. It is parallelized using MPI and OpenMP, and can exploit GPU accelerators by means of CUDA. We describe a performance comparison of DBCSR on systems with Intel Xeon Phi Knights Landing (KNL) processors, with respect to systems with Intel Xeon CPUs (including systems with GPUs).<br/><br/>We find that the DBCSR on Cray XC40 KNL-based systems is 11%-14% slower than on a hybrid Cray XC50 with Nvidia P100 cards, at the same number of nodes. When compared to a Cray XC40 system equipped with dual-socket Intel Xeon CPUs, the KNL is up to 24% faster.<br/><br/>Note: A full version of the article is available as a pre-print at: https://arxiv.org/pdf/1708.03604.pdf",
        "title": "Porting of the DBCSR Library for Sparse Matrix-Matrix Multiplications to Intel Xeon Phi Systems",
        "keywords": "",
        "authors": [
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            }
        ]
    },
    "555f7d8c-796f-4a94-a0e7-83f20aa30289": {
        "id": "555f7d8c-796f-4a94-a0e7-83f20aa30289",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/application-performance-on-the-uks-new-hector-service(555f7d8c-796f-4a94-a0e7-83f20aa30289).html",
        "abstract": "HECToR is the UK\u2019s new high-end computing resource available for research funded by the UK Re- search Councils. The HECToR Cray XT4 system began user service in October 2007 and comprises 5,564 dual core 2.8GHz AMD Opteron processors. The results of running a number of synthetic benchmarks and popular application codes which are used by the UK academic community are presented. The syn- thetic benchmarks include STREAMS and MPI benchmarks. The application benchmarks include fluid dynamics, molecular dynamics, fusion, materials science and environmental science codes. The results are compared with those obtained on the UK\u2019s HPCx service which comprises 160 IBM e-Server p575 16- way SMP nodes each containing 8 dual core 1.5GHz IBM Power5 64-bit RISC chips. Where appropriate, results are also included from the HECToR Test and Development system which has a different memory structure from the main system. It is found that there is not much difference between the systems in terms of comparing similar numbers of processing cores, but HECToR is a much larger system with many more cores and a more scalable interconnect. Memory bandwidth is seen to be a bottleneck for certain applications on both systems, with HECToR more seriously affected.",
        "title": "Application performance on the UK's new HECToR service",
        "keywords": "",
        "authors": [
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            },
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            },
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            },
            {
                "name": "Alan Simpson",
                "uuid": "edbe5450-e7d0-43d8-8700-4982f415b3e7"
            }
        ]
    },
    "83b07c42-e4ce-4dde-8636-71477f6fea4b": {
        "id": "83b07c42-e4ce-4dde-8636-71477f6fea4b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-nemo-ocean-modelling-code-a-case-study(83b07c42-e4ce-4dde-8636-71477f6fea4b).html",
        "abstract": "HECToR is the UK's new high-end computing resource available for research funded by the UK Research Councils. This paper presents a case study of the popular ocean modelling code, NEMO [1], on the HECToR system. The main aims of the study were to investigate and where possible to improve the I/O performance and nested model performance of NEMO.<br/><br/>The paper begins with an introduction to the NEMO code along with some motivation for investigating le I/O and nested model performance. Section 3 describes the architecture of the HECToR system. Section 4 presents the baseline performance of the NEMO code and the results of a number of investigations which resulted in improved performance. In section 4.7 the effects of I/O are investigated and a method for improving the I/O performance is presented in section 5. Nested model performance is described in section 6.",
        "title": "The NEMO Ocean Modelling Code: A Case Study",
        "keywords": "",
        "authors": [
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            }
        ]
    },
    "17cc68f2-ea8c-419e-b20d-d821d4b4f252": {
        "id": "17cc68f2-ea8c-419e-b20d-d821d4b4f252",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-microbenchmark-suite-for-openmp-tasks(17cc68f2-ea8c-419e-b20d-d821d4b4f252).html",
        "abstract": "We present a set of extensions to an existing microbenchmark suite for OpenMP. The new benchmarks measure the overhead of the task construct introduced in the OpenMP 3.0 standard, and associated task synchronisation constructs. We present the results from a variety of compilers and hardware platforms, which demonstrate some signi\ufb01cant di\ufb00erences in performance between di\ufb00erent OpenMP implementations.",
        "title": "A Microbenchmark Suite for OpenMP Tasks",
        "keywords": "",
        "authors": [
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "0f9cc6b6-3b3e-4dbf-b9fd-b2ff2bc60910": {
        "id": "0f9cc6b6-3b3e-4dbf-b9fd-b2ff2bc60910",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-performance-comparison-of-hpcx-and-hector(0f9cc6b6-3b3e-4dbf-b9fd-b2ff2bc60910).html",
        "abstract": "The results from running a range of synthetic and application benchmarks on the HPCx and HECToR<br/>systems are presented and compared. It is found that there is not much difference between the systems in terms of comparing similar numbers of processing cores, but HECToR is a much larger system with many more cores and a more scalable interconnect. Memory bandwidth is seen to be a bottleneck for certain applications on both systems, with HECToR more seriously affected",
        "title": "A Performance Comparison of HPCx and HECToR",
        "keywords": "",
        "authors": [
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            },
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            },
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            },
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "8e24d150-47ad-41c2-b9e2-5cf16977cdbe": {
        "id": "8e24d150-47ad-41c2-b9e2-5cf16977cdbe",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/performance-evaluation-of-mixedmode-openmpmpi-implementations(8e24d150-47ad-41c2-b9e2-5cf16977cdbe).html",
        "abstract": "<p>With the current prevalence of multi-core processors in HPC architectures mixed-mode programming, using both MPI and OpenMP in the same application, is seen as an important technique for achieving high levels of scalability. As there are few standard benchmarks written in this paradigm, it is difficult to assess the likely performance of such programs. To help address this, we examine the performance of mixed-mode OpenMP/MPI on a number of popular HPC architectures, using a synthetic benchmark suite and two large-scale applications. We find performance characteristics which differ significantly between implementations, and which highlight possible areas for improvement, especially when multiple OpenMP threads communicate simultaneously via MPI.</p>",
        "title": "Performance Evaluation of Mixed-Mode OpenMP/MPI Implementations",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            },
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "4e557b92-7da3-4c70-99d0-bfbd42912aa1": {
        "id": "4e557b92-7da3-4c70-99d0-bfbd42912aa1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/4d-signal-enhancement-using-singularvalue-decomposition-application-to-mapping-oilwater-contact-movement-across-the-nelson-field(4e557b92-7da3-4c70-99d0-bfbd42912aa1).html",
        "abstract": "<p>A new method for time-lapse signal separation and enhancement using singular-value decomposition is presented. Singular-value decomposition is used to separate a 4D signal into its constituent parts: common geology, time-lapse response and noise. Synthetic tests which demonstrate the advantages of the singular-value decomposition technique over traditional differencing methods are also presented. This signal separation and enhancement technique is used to map out both the original and moved oil-water contacts across the Nelson Field. The singular-value decomposition technique allows the oil-water contact to be mapped across regions which would have been missed using traditional differencing methods. In particular, areas toward the edges of the field are highlighted by the technique. The oil-water contact is observed to move upwards across the field, with the largest movements being associated, as anticipated, with natural production. The results obtained are broadly consistent with those predicted by the reservoir simulator model. Singular-value decomposition is demonstrated to be a useful tool for enhancing the time-lapse signal and for gaining confidence in areas where traditional differencing fails.</p>",
        "title": "4D signal enhancement using singular-value decomposition: application to mapping oil-water contact movement across the Nelson Field",
        "keywords": "",
        "authors": [
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            }
        ]
    },
    "525aaf90-062d-4268-a9d7-7296bdf7785f": {
        "id": "525aaf90-062d-4268-a9d7-7296bdf7785f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/on-the-performance-of-molecular-dynamics-applications-on-current-highend-systems(525aaf90-062d-4268-a9d7-7296bdf7785f).html",
        "abstract": "<p>The effective exploitation of current high performance computing (HPC) platforms in molecular simulation relies on the ability of the present generation of parallel molecular dynamics code to make effective ritilisation of these platforms and their components, including CPUs and memory. In this paper, we investigate the efficiency and scaling of a series of popular molecular dynamics codes on the UK's national HPC resources, an IBM p690+ cluster and an SGI Altix 3700.</p><p>Focusing primarily on the AMBER, DL_Poly and NAMD simulation codes, we demonstrate the major performance and scalabilitv advantages that arise through a distributed, rather than a replicated data approach.</p>",
        "title": "On the performance of molecular dynamics applications on current high-end systems",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            },
            {
                "name": "Lorna Smith",
                "uuid": "5c748338-46b1-485e-95af-511b43c62836"
            },
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            }
        ]
    },
    "778aa81c-910d-4e55-8717-4073bc5667f1": {
        "id": "778aa81c-910d-4e55-8717-4073bc5667f1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/upper-mantle-attenuation-and-velocity-structure-from-measurements-of-differential-s-phases(778aa81c-910d-4e55-8717-4073bc5667f1).html",
        "abstract": "<p>Although much progress has been made in determining the 3-D distribution of seismic wave velocities in the Earth. substantially less is known about the 3-D distribution of intrinsic attenuation. In this study variations in attenuation and shear velocity of the Earth's mantle are constrained using measurements of differential traveltime and attenuation.</p><p>The data are broad-band displacement SH seismograms filtered to have energy in the period range 8-20 s. The seismograms are obtained from over 600 globally distributed earthquakes of magnitude, M-w, 5.5 or greater.</p><p>Differential traveltimes and differential t* values from multiple S phases are estimated by a waveform-fitting method, resulting in approximately 4300 measurements for SS-S in the distance range 50 degrees -105 degrees and 1000 measurements for SSS-SS in the distance range 90 degrees -179 degrees. Each measurement consists of a differential traveltime and a corresponding differential t*.</p><p>The differential traveltimes and t* values are inverted to obtain models of the lateral variation of shear velocity and lateral variation of q(mu) where q(mu)=1/Q(mu) The models explain the data well but have limited depth resolution. The velocity models show good correlation with previous studies: in particular, low velocities are observed underlying mid-oceanic ridges and convergent margins and high velocities are found for continental regions. The q(mu) models show shield regions to be less attenuating than PREM, with ridges appearing as highly attenuating features. The models have limited depth resolution and to address this problem we also present a shear velocity model obtained from the combination of body wave and surface wave data sets.</p>",
        "title": "Upper mantle attenuation and velocity structure from measurements of differential S phases",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Fiona Reid",
                "uuid": "d4d60fa9-f262-4020-87b2-fcc1bdd8a416"
            }
        ]
    },
    "49d36152-d08a-489e-95e0-1e870d48de73": {
        "id": "49d36152-d08a-489e-95e0-1e870d48de73",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/nitric-oxide-is-generated-on-the-skin-surface-by-reduction-of-sweat-nitrate(49d36152-d08a-489e-95e0-1e870d48de73).html",
        "abstract": "<p>Nitric oxide (NO) is known to be synthesized by mammalian cells from L-arginine by a group of NO synthase enzymes. We now show that NO is generated from human skin and propose a different mechanism of production. Whereas enzymatic NO synthesis is inhibited by monomethyl L-arginine, this arginine analog, when infused into the brachial artery at concentrations sufficient to inhibit endothelial NO synthase activity, has little effect on hand skin NO production. Hand skin NO production is increased by topical acidification of the skin surface and greatly increased by the addition of nitrite solutions. We propose that NO generation from skin derives from sweat nitrite (the concentration of which was found to average 3.4 \u03bcM in six subjects) due to chemical reduction consequent to the acidic nature of sweat. Sweat contains nitrate in appreciable amounts, and skin commensal bacteria can synthesize nitrate reductase enzyme. Patients on long-term tetracycline antibiotics showed significantly reduced skin NO synthesis, although topical antiseptic and antibiotics had little effect on NO generation in the short-term. We propose that NO generation from skin is dependent on bacterial nitrate reduction to nitrite and subsequent reduction by acidification. We speculate that this has a physiologic role in the inhibition of infection by pathogenic fungi and other susceptible microorganisms and may affect cutaneous T-cell function, keratinocyte differentiation, and skin blood flow.</p>",
        "title": "Nitric oxide is generated on the skin surface by reduction of sweat nitrate",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Lorna Smith",
                "uuid": "5c748338-46b1-485e-95af-511b43c62836"
            }
        ]
    },
    "1766b70c-2d4f-4414-8fcc-ca2d88c20c5f": {
        "id": "1766b70c-2d4f-4414-8fcc-ca2d88c20c5f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hpcx-towards-capability-computing(1766b70c-2d4f-4414-8fcc-ca2d88c20c5f).html",
        "abstract": "",
        "title": "HPCx: towards capability computing",
        "keywords": "",
        "authors": [
            {
                "name": "Lorna Smith",
                "uuid": "5c748338-46b1-485e-95af-511b43c62836"
            }
        ]
    },
    "c9601455-ee8f-469d-ba0c-c2800d3d6d7d": {
        "id": "c9601455-ee8f-469d-ba0c-c2800d3d6d7d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/terascale-materials-modelling-on-high-performance-system-hpcx(c9601455-ee8f-469d-ba0c-c2800d3d6d7d).html",
        "abstract": "",
        "title": "Tera-scale materials modelling on high performance system HPCx",
        "keywords": "",
        "authors": [
            {
                "name": "Lorna Smith",
                "uuid": "5c748338-46b1-485e-95af-511b43c62836"
            }
        ]
    },
    "aaa753df-a1b1-4c85-ac4b-fa38104cbe61": {
        "id": "aaa753df-a1b1-4c85-ac4b-fa38104cbe61",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/firegrid-integrated-emergency-response-and-fire-safety-engineering-for-the-future-built-environment(aaa753df-a1b1-4c85-ac4b-fa38104cbe61).html",
        "abstract": "Analyses of disasters such as the Piper Alpha explosion (Sylvester-Evans and Drysdale, 1998), the World Trade Centre collapse (Torero et al, 2002, Usmani et al, 2003) and the fires at Kings Cross (Drysdale et al, 1992) and the Mont Blanc tunnel (Rapport Commun, 1999) have revealed many mistaken decisions, such as that which sent 300 fire-fighters to their deaths in the World Trade Centre. Many of these mistakes have been attributed to a lack of information about the conditions within the fire and the imminent consequences of the event. E-Science offers an opportunity to significantly improve the intervention in fire emergencies. The FireGrid Consortium is working on a mixture of research projects to make this vision a reality. This paper describes the research challenges and our plans for solving them.",
        "title": "FireGrid: Integrated emergency response and fire safety engineering for the future built environment",
        "keywords": "",
        "authors": [
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "cfec463e-3ba6-4996-b962-bcd10db0bd55": {
        "id": "cfec463e-3ba6-4996-b962-bcd10db0bd55",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/expert-programmer-versus-parallelizing-compiler-a-comparative-study-of-two-approaches-for-distributed-shared-memory(cfec463e-3ba6-4996-b962-bcd10db0bd55).html",
        "abstract": "This article critically examines current parallel programming practice and optimizing compiler development. The general strategies employed by compiler and programmer to optimize a Fortran program are described, and then illustrated for a specific case by applying them to a well-known scientific program, TRED2, using the KSR-1 as the target architecture. Extensive measurement is applied to the resulting versions of the program, which are compared with a version produced by a commercial optimizing compiler, KAP. The compiler strategy significantly outperforms KAP and does not fall far short of the performance achieved by the programmer. Following the experimental section each approach is critiqued by the other. Perceived flaws, advantages, and common ground are outlined, with an eye to improving both schemes.",
        "title": "Expert Programmer versus Parallelizing Compiler: A Comparative Study of Two Approaches for Distributed Shared Memory",
        "keywords": "",
        "authors": [
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "985bc2af-f3c7-465a-b75c-7c3d255abe8f": {
        "id": "985bc2af-f3c7-465a-b75c-7c3d255abe8f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-efficient-algorithm-for-the-calculation-of-reserves-for-nonunit-linked-life-policies(985bc2af-f3c7-465a-b75c-7c3d255abe8f).html",
        "abstract": "<p>The underlying stochastic nature of the requirements for the Solvency II regulations has introduced significant challenges if the required calculations are to be performed correctly, without resorting to excessive approximations, within practical timescales. It is generally acknowledged by practising actuaries within UK life offices that it is currently impossible to correctly fulfil the requirements imposed by Solvency II using existing computational techniques based on commercially available valuation packages. Our work has already shown that it is possible to perform profitability calculations at a far higher rate than is achievable using commercial packages. One of the key factors in achieving these gains is to calculate reserves using recurrence relations that scale linearly with the number of time steps. Here, we present a general vector recurrence relation which can be used for a wide range of non-unit linked policies that are covered by Solvency II; such contracts include annuities, term assurances, and endowments. Our results suggest that by using an optimised parallel implementation of this algorithm, on an affordable hardware platform, it is possible to perform the 'brute force' approach to demonstrating solvency in a realistic timescale (of the order of a few hours).</p>",
        "title": "An efficient algorithm for the calculation of reserves for non-unit linked life policies",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "c1af030d-8998-471e-bcc3-ec174bb2ae24": {
        "id": "c1af030d-8998-471e-bcc3-ec174bb2ae24",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/detection-and-impacts-of-leakage-from-subseafloor-deep-geological-carbon-dioxide-storage(c1af030d-8998-471e-bcc3-ec174bb2ae24).html",
        "abstract": "<p>Fossil fuel power generation and other industrial emissions of carbon dioxide are a threat to global climate, yet many economies will remain reliant on these technologies for several decades. Carbon dioxide capture and storage (CCS) in deep geological formations provides an effective option to remove these emissions from the climate system. In many regions storage reservoirs are located offshore, over a kilometre or more below societally important shelf seas. Therefore, concerns about the possibility of leakage and potential environmental impacts, along with economics, have contributed to delaying development of operational CCS. Here we investigate the detectability and environmental impact of leakage from a controlled sub-seabed release of CO<sub>2</sub> . We show that the biological impact and footprint of this small leak analogue (&lt;1 tonne CO<sub>2</sub> d \u00e2 '1) is confined to a few tens of metres. Migration of CO<sub>2</sub> through the shallow seabed is influenced by near-surface sediment structure, and by dissolution and re-precipitation of calcium carbonate naturally present in sediments. Results reported here advance the understanding of environmental sensitivity to leakage and identify appropriate monitoring strategies for full-scale carbon storage operations.</p>",
        "title": "Detection and impacts of leakage from sub-seafloor deep geological carbon dioxide storage",
        "keywords": "",
        "authors": [
            {
                "name": "Jonathan Bull",
                "uuid": "74a6df89-ca2e-47fd-86d0-bfec559e3b7f"
            }
        ]
    },
    "dd4e4589-0cb0-483b-8cd5-20d5523215e7": {
        "id": "dd4e4589-0cb0-483b-8cd5-20d5523215e7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/erratum(dd4e4589-0cb0-483b-8cd5-20d5523215e7).html",
        "abstract": "<p>The reported strengths of newly discovered resonances in original Letter were affected by an error in the analysis. The energy straggling of the ion beam was erroneously neglected. When taking this effect into account, 18-19% higher values are found for the resonance strengths. The astrophysical implications are unchanged. The astrophysical consequences shown in original Letter and [2] used a previous calculation [8] and remain valid. For newer astrophysical work, see Ref. [9], which is also unaffected by the present correction. (Formula Presented). (Table Presented).</p>",
        "title": "Erratum",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "d21e7bf4-b1e0-484b-9118-417eab7236b6": {
        "id": "d21e7bf4-b1e0-484b-9118-417eab7236b6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dust-attenuation-in-2--z--3-starforming-galaxies-from-deep-alma-observations-of-the-hubble-ultra-deep-field(d21e7bf4-b1e0-484b-9118-417eab7236b6).html",
        "abstract": "We present the results of a new study of the relationship betweeninfrared excess (IRX\u2261 LIR/LUV), UV spectralslope (\u03b2) and stellar mass at redshifts 2 &lt;z &lt;3, based on adeep Atacama Large Millimeter Array (ALMA) 1.3-mm continuum mosaic ofthe Hubble Ultra Deep Field (HUDF). Excluding the most heavily-obscuredsources, we use a stacking analysis to show that z \u2243 2.5star-forming galaxies in the mass range 9.25\u2264 log (M_{\\ast}/M_{\u2299}) \u2264 10.75 are fully consistent with the IRX-\u03b2relation expected for a relatively grey attenuation curve, similar tothe commonly adopted Calzetti law. Based on a large, mass complete,sample of 2 \u2264 z \u2264 3 star-forming galaxies drawn from multiplesurveys, we proceed to derive a new empirical relationship between\u03b2 and stellar mass, making it possible to predict UV attenuation(A1600) and IRX as a function of stellar mass, for anyassumed attenuation law. Once again, we find that z \u2243 2.5star-forming galaxies follow A1600-M* andIRX-M* relations consistent with a relatively greyattenuation law, and find no compelling evidence that star-forminggalaxies at this epoch follow a reddening law as steep as the SmallMagellanic Cloud (SMC) extinction curve. In fact, we use a simplesimulation to demonstrate that previous determinations of the IRX-\u03b2relation may have been biased toward low values of IRX at red values of\u03b2, mimicking the signature expected for an SMC-like dust law. Weshow that this provides a plausible mechanism for reconciling apparentlycontradictory results in the literature and that, based on typicalmeasurement uncertainties, stellar mass provides a cleaner prediction ofUV attenuation than \u03b2. Although the situation at lower stellarmasses remains uncertain, we conclude that for 2 &lt;z &lt;3star-forming galaxies with log (M_{\\ast }/M_{\u2299}) \u2265 9.75, both theIRX-\u03b2 and IRX-M* relations are well described by aCalzetti-like attenuation law.",
        "title": "Dust attenuation in 2 &lt; z &lt; 3 star-forming galaxies from deep ALMA observations of the Hubble Ultra Deep Field",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "9583aae6-6a55-40bc-90ab-309bcd14dc8d": {
        "id": "9583aae6-6a55-40bc-90ab-309bcd14dc8d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hermes(9583aae6-6a55-40bc-90ab-309bcd14dc8d).html",
        "abstract": "<p>We present measurements of the auto- and cross-frequency power spectra of the cosmic infrared background (CIB) at 250, 350, and 500 \u03bcm (1200, 860, and 600 GHz) from observations totaling 70 deg<sup>2</sup> made with the SPIRE instrument aboard the Herschel Space Observatory. We measure a fractional anisotropy \u03b4I/I = 14% \u00b1 4%, detecting signatures arising from the clustering of dusty star-forming galaxies in both the linear (2-halo) and nonlinear (1-halo) regimes; and that the transition from the 2- to 1-halo terms, below which power originates predominantly from multiple galaxies within dark matter halos, occurs at k \u03b8 0.10-0.12 arcmin<sup>-1</sup> (\u2113 2160-2380), from 250 to 500 \u03bcm. New to this paper is clear evidence of a dependence of the Poisson and 1-halo power on the flux-cut level of masked sources - suggesting that some fraction of the more luminous sources occupy more massive halos as satellites, or are possibly close pairs. We measure the cross-correlation power spectra between bands, finding that bands which are farthest apart are the least correlated, as well as hints of a reduction in the correlation between bands when resolved sources are more aggressively masked. In the second part of the paper, we attempt to interpret the measurements in the framework of the halo model. With the aim of fitting simultaneously with one model the power spectra, number counts, and absolute CIB level in all bands, we find that this is achievable by invoking a luminosity-mass relationship, such that the luminosity-to-mass ratio peaks at a particular halo mass scale and declines toward lower and higher mass halos. Our best-fit model finds that the halo mass which is most efficient at hosting star formation in the redshift range of peak star-forming activity, z 1-3, is log(M<sub>peak</sub>/M <sub>\u2299</sub>) 12.1 \u00b1 0.5, and that the minimum halo mass to host infrared galaxies is log(M<sub>\u2299</sub>min/M<sub>\u2299</sub>) 10.1 \u00b1 0.6.</p>",
        "title": "HerMES",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "a344bc6c-37c2-45dc-8bf8-525e3a772c28": {
        "id": "a344bc6c-37c2-45dc-8bf8-525e3a772c28",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-deepest-herschel-pacs-farinfrared-survey(a344bc6c-37c2-45dc-8bf8-525e3a772c28).html",
        "abstract": "<p>We present results from the deepest Herschel-Photodetector Array Camera and Spectrometer (PACS) far-infrared blank field extragalactic survey, obtained by combining observations of the Great Observatories Origins Deep Survey (GOODS) fields from the PACS Evolutionary Probe (PEP) and GOODS-Herschel key programmes. We describe data reduction and theconstruction of images and catalogues. In the deepest parts of the GOODS-S field, the catalogues reach 3\u03c3 depths of 0.9, 0.6 and 1.3 mJy at 70, 100 and 160 \u03bcm, respectively, and resolve ~75% of the cosmic infrared background at 100 \u03bcm and 160 \u03bcm into individually detected sources. We use these data to estimate the PACS confusion noise, to derive the PACS number counts down to unprecedented depths, and to determine the infrared luminosity function of galaxies down to L<sub>IR</sub> = 10 <sup>11</sup> L<sub>\u00e2\u0160\u2122</sub> at z ~ 1 and L<sub>IR</sub> = 10<sup>12</sup> L<sub>\u00e2\u0160\u2122</sub> at z ~ 2, respectively. For the infrared luminosity function of galaxies, our deep Herschel far-infrared observations are fundamental because they provide more accurate infrared luminosity estimates than those previously obtained from mid-infrared observations. Maps and source catalogues (&gt;3\u03c3) are now publicly released. Combined with the large wealth of multi-wavelength data available for the GOODS fields, these data provide a powerful new tool for studying galaxy evolution over a broad range of redshifts.</p>",
        "title": "The deepest Herschel -PACS far-infrared survey",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "cc21c6e9-cdf0-4786-8b56-4922a0be2488": {
        "id": "cc21c6e9-cdf0-4786-8b56-4922a0be2488",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hermes(cc21c6e9-cdf0-4786-8b56-4922a0be2488).html",
        "abstract": "<p>We present a list of 13 candidate gravitationally lensed submillimeter galaxies (SMGs) from 95 deg<sup>2</sup> of the Herschel Multi-tiered Extragalactic Survey, a surface density of 0.14 \u00b1 0.04 deg<sup>-2</sup>. The selected sources have 500 \u03bcm flux densities (S <sub>500</sub>) greater than 100 mJy. Gravitational lensing is confirmed by follow-up observations in 9 of the 13 systems (70%), and the lensing status of the four remaining sources is undetermined. We also present a supplementary sample of 29 (0.31 \u00b1 0.06 deg<sup>-2</sup>) gravitationally lensed SMG candidates with S <sub>500</sub> = 80-100 mJy, which are expected to contain a higher fraction of interlopers than the primary candidates. The number counts of the candidate lensed galaxies are consistent with a simple statistical model of the lensing rate, which uses a foreground matter distribution, the intrinsic SMG number counts, and an assumed SMG redshift distribution. The model predicts that 32%-74% of our S <sub>500</sub> \u2265 100 mJy candidates are strongly gravitationally lensed (\u03bc \u2265 2), with the brightest sources being the most robust; this is consistent with the observational data. Our statistical model also predicts that, on average, lensed galaxies with S <sub>500</sub> = 100 mJy are magnified by factors of \u223c9, with apparently brighter galaxies having progressively higher average magnification, due to the shape of the intrinsic number counts. 65% of the sources are expected to have intrinsic 500 \u03bcm flux densities less than 30 mJy. Thus, samples of strongly gravitationally lensed SMGs, such as those presented here, probe below the nominal Herschel detection limit at 500 \u03bcm. They are good targets for the detailed study of the physical conditions in distant dusty, star-forming galaxies, due to the lensing magnification, which can lead to spatial resolutions of \u223c0.\u203301 in the source plane.</p>",
        "title": "HerMES",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "a0c497bc-ec96-4d84-9eb4-c2c478f13d7d": {
        "id": "a0c497bc-ec96-4d84-9eb4-c2c478f13d7d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/environment-of-the-submillimeterbright-massive-starburst-hfls3-at-z--634(a0c497bc-ec96-4d84-9eb4-c2c478f13d7d).html",
        "abstract": "<p>We describe the search for Lyman break galaxies (LBGs) near the submillimeter-bright starburst galaxy HFLS3 at z = 6.34 and a study on the environment of this massive galaxy during the end of reionization. We performed two independent selections of LBGs on images obtained with the Gran Telescopio Canarias (GTC) and the Hubble Space Telescope (HST) by combining nondetections in bands blueward of the Lyman break and color selection. A total of 10 objects fulfilling the LBG selection criteria at were selected over the 4.54 and 55.5 arcmin<sup>2</sup> covered by our HST and GTC images, respectively. The photometric redshift, UV luminosity, and star formation rate of these sources were estimated with models of their spectral energy distribution. These candidates have physical properties and number densities in agreement with previous results. The UV luminosity function at z \u223c 6 and a Voronoi tessellation analysis of this field show no strong evidence for an overdensity of relatively bright objects ( 25.9) associated with HFLS3. However, the overdensity parameter deduced from this field and the surface density of objects cannot exclude definitively the LBG overdensity hypothesis. Moreover, we identified three faint objects at less than 3\u2033 from HFLS3 with color consistent with those expected for z \u223c 6 galaxies. Deeper data are needed to confirm their redshifts and to study their association with HFLS3 and the galaxy merger that may be responsible for the massive starburst.</p>",
        "title": "Environment of the submillimeter-bright massive starburst hfls3 at z \u223c 6.34",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "d875d067-533c-44c9-9833-602929a51e21": {
        "id": "d875d067-533c-44c9-9833-602929a51e21",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hermes(d875d067-533c-44c9-9833-602929a51e21).html",
        "abstract": "<p>The Herschel Multi-tiered Extragalactic Survey (HERMES) has identified large numbers of dusty star-forming galaxies (DSFGs) over a wide range in redshift. A detailed understanding of these DSFGs is hampered by the limited spatial resolution of Herschel. We present 870 \u03bcm 0.\u203345 resolution imaging obtained with the Atacama Large Millimeter/submillimeter Array (ALMA) of a sample of 29 HERMES DSFGs that have far-infrared (FIR) flux densities that lie between the brightest of sources found by Herschel and fainter DSFGs found via ground-based surveys in the submillimeter region. The ALMA imaging reveals that these DSFGs comprise a total of 62 sources (down to the point-source sensitivity limit in our ALMA sample; ). Optical or near-infrared imaging indicates that 36 of the ALMA sources experience a significant flux boost from gravitational lensing (), but only six are strongly lensed and show multiple images. We introduce and make use of uvmcmcfit, a general-purpose and publicly available Markov chain Monte Carlo visibility-plane analysis tool to analyze the source properties. Combined with our previous work on brighter Herschel sources, the lens models presented here tentatively favor intrinsic number counts for DSFGs with a break near at and a steep fall-off at higher flux densities. Nearly 70% of the Herschel sources break down into multiple ALMA counterparts, consistent with previous research indicating that the multiplicity rate is high in bright sources discovered in single-dish submillimeter or FIR surveys. The ALMA counterparts to our Herschel targets are located significantly closer to each other than ALMA counterparts to sources found in the LABOCA ECDFS Submillimeter Survey. Theoretical models underpredict the excess number of sources with small separations seen in our ALMA sample. The high multiplicity rate and small projected separations between sources seen in our sample argue in favor of interactions and mergers plausibly driving both the prodigious emission from the brightest DSFGs as well as the sharp downturn above .</p>",
        "title": "HERMES",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "e04d106c-512e-45c9-bddc-6023ae8e7213": {
        "id": "e04d106c-512e-45c9-bddc-6023ae8e7213",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-hermes-submillimetre-local-and-lowredshift-luminosity-functions(e04d106c-512e-45c9-bddc-6023ae8e7213).html",
        "abstract": "<p>We used wide-area surveys over 39 deg<sup>2</sup> by the HerMES (Herschel Multi-tiered Extragalactic Survey) collaboration, performed with the Herschel Observatory SPIRE multiwavelength camera, to estimate the low-redshift, 0.02 &lt; z &lt; 0.5, monochromatic luminosity functions (LFs) of galaxies at 250, 350 and 500 \u03bcm. Within this redshift interval, we detected 7087 sources in five independent sky areas, ~40 per cent of which have spectroscopic redshifts, while for the remaining objects photometric redshifts were used. The SPIRE LFs in different fields did not show any field-to-field variations beyond the small differences to be expected from cosmic variance. SPIRE flux densities were also combined with Spitzer photometry and multiwavelength archival data to perform a complete spectral energy distribution fitting analysis of SPIRE detected sources to calculate precise k-corrections, as well as the bolometric infrared (IR; 8-1000 \u03bcm) LFs and their low-z evolution from a combination of statistical estimators. Integration of the latter prompted us to also compute the local luminosity density and the comoving star formation rate density (SFRD) for our sources, and to compare them with theoretical predictions of galaxy formation models. The LFs show significant and rapid luminosity evolution already at low redshifts, 0.02 &lt; z &lt; 0.2, with Lz.ast;<sub>IR</sub> \u03b1 (1 + z)6.0\u00b10.4 and \u03a6*<sub>IR</sub> \u03b1 (1 + z)<sup>-2.1\u00b10.4</sup>, L*<sub>250</sub> \u03b1 (1 + z)<sub>5.3\u00b10.2</sub> and \u03a6*<sub>250</sub> \u03b1 (1 + z)<sup>-0.6\u00b10.4</sup> estimated using the IR bolometric and the 250 \u03bcm LFs, respectively. Converting our IR LD estimate into an SFRD assuming a standard Salpeter initial mass function and including the unobscured contribution based on the UV dust-uncorrected emission from local galaxies, we estimate an SFRD scaling of SFRD<sub>0</sub> + 0.08z, where SFRD<sub>0</sub> \u2243 (1.9 \u00b1 0.03) \u00d7 10<sup>-2</sup> [Mo\u02d9 Mpc<sup>-3</sup>] is our total SFRD estimate at z ~ 0.02.</p>",
        "title": "The HerMES submillimetre local and low-redshift luminosity functions*",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "fd642468-47ee-4c3e-89d2-2d99d0a995fa": {
        "id": "fd642468-47ee-4c3e-89d2-2d99d0a995fa",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/candidate-gravitationally-lensed-dusty-starforming-galaxies-in-the-herschel-wide-area-surveys(fd642468-47ee-4c3e-89d2-2d99d0a995fa).html",
        "abstract": "<p>We present a list of candidate gravitationally lensed dusty star-forming galaxies (DSFGs) from the HerMES Large Mode Survey and the Herschel Stripe 82 Survey. Together, these partially overlapping surveys cover 372 deg<sup>2</sup> on the sky. After removing local spiral galaxies and known radio-loud blazars, our candidate list of lensed DSFGs is composed of 77 sources with 500 \u03bcm flux densities (S <sub>500</sub>) greater than 100 mJy. Such sources are dusty starburst galaxies similar to the first bright sub-millimeter galaxies (SMGs) discovered with SCUBA. We expect a large fraction of this list to be strongly lensed, with a small fraction made up of bright SMG-SMG mergers that appear as hyper-luminous infrared galaxies (). Thirteen of the 77 candidates have spectroscopic redshifts from CO spectroscopy with ground-based interferometers, putting them at and well above the redshift of the foreground lensing galaxies. The surface density of our sample is 0.21 \u00ef\u00bf\u00bd 0.03 deg<sup>-2</sup>. We present follow-up imaging of a few of the candidates to confirm their lensing nature. The sample presented here is an ideal tool for higher-resolution imaging and spectroscopic observations to understand the detailed properties of starburst phenomena in distant galaxies.</p>",
        "title": "CANDIDATE GRAVITATIONALLY LENSED DUSTY STAR-FORMING GALAXIES in the HERSCHEL WIDE AREA SURVEYS",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "6657365d-4d43-4b3d-a713-ee8e1214b085": {
        "id": "6657365d-4d43-4b3d-a713-ee8e1214b085",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hermes(6657365d-4d43-4b3d-a713-ee8e1214b085).html",
        "abstract": "<p>Selecting sources with rising flux densities towards longerwavelengths from Herschel/Spectral and Photometric Imaging Receiver (SPIRE) maps is an efficient way to produce a catalogue rich in high-redshift (z &gt; 4) dusty star-forming galaxies. The effectiveness of this approach has already been confirmed by spectroscopic follow-up observations, but the previously available catalogues made this way are limited by small survey areas. Here we apply a map-based search method to 274 deg<sup>2</sup> of the Herschel Multi-tiered Extragalactic Survey (HerMES) Large Mode Survey and create a catalogue of 477 objects with SPIRE flux densities S<sub>500</sub> &gt; S<sub>350</sub> &gt; S<sub>250</sub> and a 5\u03c3 cut-offS<sub>500</sub> &gt; 52 mJy. From this catalogue we determine that the total number of these 'red' sources is at least an order of magnitude higher than predicted by galaxy evolution models. These results are in agreement with previous findings in smaller HerMES fields; however, due to our significantly larger sample size we are also able to investigate the shape of the red source counts for the first time. We have obtained spectroscopic redshift measurements for two of our sources using the Atacama Large Millimeter/submillimeter Array. The redshifts z = 5.1 and 3.8 confirm that with our selection method we can indeed find high-redshift dusty star-forming galaxies.</p>",
        "title": "HerMES",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "62e1e367-a184-43d9-be46-e5044ccb58d1": {
        "id": "62e1e367-a184-43d9-be46-e5044ccb58d1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/scuba2-ultra-deep-imaging-eao-survey-studies(62e1e367-a184-43d9-be46-e5044ccb58d1).html",
        "abstract": "<p>The SCUBA-2 Ultra Deep Imaging EAO Survey (STUDIES) is a three-year JCMT Large Program aiming to reach the 450 \u03bcm confusion limit in the COSMOS-CANDELS region to study a representative sample of the high-redshift far-infrared galaxy population that gives rise to the bulk of the far-infrared background. We present the first-year data from STUDIES. We reached a 450 \u03bcm noise level of 0.91 mJy for point sources at the map center, covered an area of 151 arcmin<sup>2</sup>, and detected 98 and 141 sources at 4.0\u03c3 and 3.5\u03c3, respectively. Our derived counts are best constrained in the 3.5-25 mJy regime using directly detected sources. Below the detection limits, our fluctuation analysis further constrains the slope of the counts down to 1 mJy. The resulting counts at 1-25 mJy are consistent with a power law having a slope of -2.59 (\u00b10.10 for 3.5-25 mJy, and for 1-3.5 mJy). There is no evidence of a faint-end termination or turnover of the counts in this flux density range. Our counts are also consistent with previous SCUBA-2 blank-field and lensing-cluster surveys. The integrated surface brightness from our counts down to 1 mJy is 90.0 \u00b1 17.2 Jy deg<sup>-2</sup>, which can account for up to of the COBE 450 \u03bcm background. We show that Herschel counts at 350 and 500 \u03bcm are significantly higher than our 450 \u03bcm counts, likely caused by its large beam and source clustering. High angular resolution instruments like SCUBA-2 at 450 \u03bcm are therefore highly beneficial for measuring the luminosity and spatial density of high-redshift dusty galaxies.</p>",
        "title": "SCUBA-2 Ultra Deep Imaging EAO Survey (STUDIES)",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "3d0a8bca-9857-4bdb-8708-3af1fa4ecdf6": {
        "id": "3d0a8bca-9857-4bdb-8708-3af1fa4ecdf6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/rise-of-the-titans(3d0a8bca-9857-4bdb-8708-3af1fa4ecdf6).html",
        "abstract": "<p>We report the detection of ADFS-27, a dusty, starbursting major merger at a redshift of z = 5.655, using the Atacama Large Millimeter/submillimeter Array (ALMA). ADFS-27 was selected from Herschel/Spectral and Photometric Imaging Receiver (SPIRE) and APEX/LABOCA data as an extremely red \"870 \u03bcm riser\" (i.e., ) S<sub>250</sub> \u03bcm &lt; S<sub>350</sub> \u03bcm &lt; S<sub>500</sub> \u03bcm &lt; S<sub>870</sub> \u03bcm, demonstrating the utility of this technique to identify some of the highest-redshift dusty galaxies. A scan of the 3 mm atmospheric window with ALMA yields detections of CO(J = 5 \u2192 4) and CO(J = 6 \u2192 5) emission, and a tentative detection of H<sub>2</sub>O(2<sub>11</sub> \u2192 2<sub>02</sub>) emission, which provides an unambiguous redshift measurement. The strength of the CO lines implies a large molecular gas reservoir with a mass of M<sub>gas</sub> = 2.5 \u00d7 10<sup>11</sup> M<sub>\u2299</sub>, sufficient to maintain its \u223c2400 M<sub>\u2299</sub> yr<sup>-1</sup> starburst for at least \u223c100 Myr. The 870 \u03bcm dust continuum emission is resolved into two components, 1.8 and 2.1 kpc in diameter, separated by 9.0 kpc, with comparable dust luminosities, suggesting an ongoing major merger. The infrared luminosity of L<sub>IR</sub> \u2243 2.4 \u00d7 10<sup>13</sup> L<sub>\u2299</sub> implies that this system represents a binary hyper-luminous infrared galaxy, the most distant of its kind presently known. This also implies star formation rate surface densities of \u2211<sub>SFR</sub> and 750 M<sub>\u2299</sub> yr<sup>-1</sup> kpc<sup>2</sup>, consistent with a binary \"maximum starburst.\" The discovery of this rare system is consistent with a significantly higher space density than previously thought for the most luminous dusty starbursts within the first billion years of cosmic time, easing tensions regarding the space densities of z \u223c 6 quasars and massive quiescent galaxies at z \u2273 3.</p>",
        "title": "Rise of the Titans",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "d17f13f7-d4dd-4a6b-b491-b5bcfb52365d": {
        "id": "d17f13f7-d4dd-4a6b-b491-b5bcfb52365d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-scuba2-cosmology-legacy-survey(d17f13f7-d4dd-4a6b-b491-b5bcfb52365d).html",
        "abstract": "<p>Submillimetre galaxies (SMGs) are among the most luminous dusty galaxies in the Universe, but their true nature remains unclear; are SMGs the progenitors of the massive elliptical galaxies we see in the local Universe, or are they just a short-lived phase among more typical star-forming galaxies? To explore this problem further, we investigate the clustering of SMGs identified in the SCUBA-2 Cosmology Legacy Survey. We use a catalogue of submillimetre (850 \u03bcm) source identifications derived using a combination of radio counterparts and colour/infrared selection to analyse a sample of 610 SMG counterparts in the United Kingdom Infrared Telescope (UKIRT) Infrared Deep Survey (UKIDSS) Ultra Deep Survey (UDS), making this the largest high-redshift sample of these galaxies to date. Using angular cross-correlation techniques, we estimate the halo masses for this large sample of SMGs and compare them with passive and star-forming galaxies selected in the same field. We find that SMGs, on average, occupy high-mass dark matter haloes (M<sub>halo</sub> &gt; 10<sup>13</sup> M<sub>\u2299</sub>) at redshifts z &gt; 2.5, consistent with being the progenitors of massive quiescent galaxies in present-day galaxy clusters. We also find evidence of downsizing, in which SMG activity shifts to lower mass haloes at lower redshifts. In terms of their clustering and halo masses, SMGs appear to be consistent with other star-forming galaxies at a given redshift.</p>",
        "title": "The SCUBA-2 Cosmology Legacy Survey",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "daafd94e-7722-4fe5-9ba5-80b108bd1973": {
        "id": "daafd94e-7722-4fe5-9ba5-80b108bd1973",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-scuba2-cosmology-legacy-survey(daafd94e-7722-4fe5-9ba5-80b108bd1973).html",
        "abstract": "<p>We present a multi-wavelength analysis of 52 submillimeter galaxies (SMGs), identified using ALMA 870 \u03bcm continuum imaging in a pilot program to precisely locate bright SCUBA-2-selected submillimeter sources in the UKIDSS Ultra Deep Survey (UDS) field. Using the available deep (especially near-infrared) panoramic imaging of the UDS field at optical-to-radio wavelengths we characterize key properties of the SMG population. The median photometric redshift of the bright ALMA/SCUBA-2 UDS (AS2UDS) SMGs that are detected in a sufficient number of wavebands to derive a robust photometric redshift is z = 2.65 0.13. However, similar to previous studies, 27% of the SMGs are too faint at optical-to-near-infrared wavelengths to derive a reliable photometric redshift. Assuming that these SMGs lie at z3 raises the median redshift of the full sample to z = 2.9 0.2. A subset of 23 unlensed, bright AS2UDS SMGs have sizes measured from resolved imaging of their rest-frame far-infrared emission. We show that the extent and luminosity of the far-infrared emission are consistent with the dust emission arising from regions that are, on average, optically thick at a wavelength of (1\u03c3 dispersion of 55-90 \u03bcm). Using the dust masses derived from our optically thick spectral energy distribution models, we determine that these galaxies have a median hydrogen column density of N <sub>H</sub> = 9.8 \u00d7 10<sup>23</sup> cm<sup>-2</sup>, or a corresponding median V-band obscuration of A <sub>v</sub> = 540 mag, averaged along the line of sight to the source of their rest-frame \u223c200 \u03bcm emission. We discuss the implications of this extreme attenuation by dust for the multi-wavelength study of dusty starbursts and reddening-sensitive tracers of star formation.</p>",
        "title": "The SCUBA-2 Cosmology Legacy Survey",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "747c8834-d4df-48b1-a39c-35324274f7da": {
        "id": "747c8834-d4df-48b1-a39c-35324274f7da",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/origin-of-meteoritic-stardust-unveiled-by-a-revised-protoncapture-rate-of-17o(747c8834-d4df-48b1-a39c-35324274f7da).html",
        "abstract": "Stardust grains recovered from meteorites provide high-precision snapshots of the isotopic composition of the stellar environment in which they formed1. Attributing their origin to specific types of stars, however, often proves difficult. Intermediate-mass stars of 4\u20138 solar masses are expected to have contributed a large fraction of meteoritic stardust2,3. Yet, no grains have been found with the characteristic isotopic compositions expected for such stars4,5. This is a long-standing puzzle, which points to serious gaps in our understanding of the lifecycle of stars and dust in our Galaxy. Here we show that the increased proton-capture rate of 17O reported by a recent underground experiment6 leads to 17O/16O isotopic ratios that match those observed in a population of stardust grainsfor proton-burning temperatures of 60\u201380 MK. These temperatures are achieved at the base of the convective envelope during the late evolution of intermediate-mass stars of 4\u20138 solar masses7\u20139, which reveals them as the most likely site of origin of the grains. This result provides direct evidence that these stars contributed to the dust inventory from which the Solar System formed.",
        "title": "Origin of meteoritic stardust unveiled by a revised proton-capture rate of 17O",
        "keywords": "",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "b4d1673f-aaf9-4d4c-89b9-befed6171dd0": {
        "id": "b4d1673f-aaf9-4d4c-89b9-befed6171dd0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/big-bang-6-li-nucleosynthesis-studied-deep-underground-luna-collaboration(b4d1673f-aaf9-4d4c-89b9-befed6171dd0).html",
        "abstract": "<p>The correct prediction of the abundances of the light nuclides produced during the epoch of Big Bang Nucleosynthesis (BBN) is one of the main topics of modern cosmology. For many of the nuclear reactions that are relevant for this epoch, direct experimental cross section data are available, ushering the so-called \u201cage of precision\u201d. The present work addresses an exception to this current status: the <sup>2</sup>H(\u03b1,\u03b3)<sup>6</sup>Li reaction that controls <sup>6</sup>Li production in the Big Bang. Recent controversial observations of <sup>6</sup>Li in metal-poor stars have heightened the interest in understanding primordial <sup>6</sup>Li production. If confirmed, these observations would lead to a second cosmological lithium problem, in addition to the well-known <sup>7</sup>Li problem. In the present work, the direct experimental cross section data on <sup>2</sup>H(\u03b1,\u03b3)<sup>6</sup>Li in the BBN energy range are reported. The measurement has been performed deep underground at the LUNA (Laboratory for Underground Nuclear Astrophysics) 400 kV accelerator in the Laboratori Nazionali del Gran Sasso, Italy. The cross section has been directly measured at the energies of interest for Big Bang Nucleosynthesis for the first time, at E<sub>cm</sub>=80, 93, 120, and 133 keV. Based on the new data, the <sup>2</sup>H(\u03b1,\u03b3)<sup>6</sup>Li thermonuclear reaction rate has been derived. Our rate is even lower than previously reported, thus increasing the discrepancy between predicted Big Bang <sup>6</sup>Li abundance and the amount of primordial <sup>6</sup>Li inferred from observations.</p>",
        "title": "Big Bang 6 Li nucleosynthesis studied deep underground (LUNA collaboration)",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "62838c81-8ab3-48a6-aa26-1d905f8bcb69": {
        "id": "62838c81-8ab3-48a6-aa26-1d905f8bcb69",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/vla-and-alma-imaging-of-intense-galaxywide-star-formation-in-z--2-galaxies(62838c81-8ab3-48a6-aa26-1d905f8bcb69).html",
        "abstract": "We present $\\simeq$0$.\\!\\!^{\\prime\\prime}4$-resolution\nextinction-independent distributions of star formation and dust in 11\nstar-forming galaxies (SFGs) at $z = 1.3-3.0$. These galaxies are\nselected from sensitive, blank-field surveys of the $2' \\times 2'$\nHubble Ultra-Deep Field at $\\lambda = 5$ cm and 1.3 mm using the Karl G.\nJansky Very Large Array (VLA) and Atacama Large Millimeter/submillimeter\nArray (ALMA). They have star-formation rates (SFRs), stellar masses, and\ndust properties representative of massive main-sequence SFGs at $z \\sim\n2$. Morphological classification performed on spatially-resolved stellar\nmass maps indicates a mixture of disk and morphologically disturbed\nsystems; half of the sample harbor X-ray active galactic nuclei (AGN),\nthereby representing a diversity of $z \\sim 2$ SFGs undergoing vigorous\nmass assembly. We find that their intense star formation most frequently\noccurs at the location of stellar-mass concentration and extends over an\narea comparable to their stellar-mass distribution, with a median\ndiameter of $4.2 \\pm 1.8$ kpc. This provides direct evidence for\ngalaxy-wide star formation in distant, blank-field-selected\nmain-sequence SFGs. The typical galactic-average SFR surface density is\n2.5 M$_{\\odot}$yr$^{-1}$kpc$^{-2}$, sufficiently high to drive outflows.\nIn X-ray-selected AGN where radio emission is enhanced over the level\nassociated with star formation, the radio excess pinpoints the AGN,\nwhich are found to be co-spatial with star formation. The median\nextinction-independent size of main-sequence SFGs is two times larger\nthan those of bright submillimeter galaxies whose SFRs are $3-8$ times\nlarger, providing a constraint on the characteristic SFR ($\\sim300$\nM$_{\\odot}$yr$^{-1}$) above which a significant population of more\ncompact star-forming galaxies appears to emerge.",
        "title": "VLA and ALMA Imaging of Intense, Galaxy-Wide Star Formation in z ~ 2 Galaxies",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "a376e5bd-25bc-44db-aa24-c70ab910ded2": {
        "id": "a376e5bd-25bc-44db-aa24-c70ab910ded2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ultrasensitive-ray-spectroscopy-setup-for-investigating-primordial-lithium-problem(a376e5bd-25bc-44db-aa24-c70ab910ded2).html",
        "abstract": "<p>To precisely determine BBN <sup>6</sup>Li production, the cross-section of the nuclear reaction <sup>2</sup>H(\u03b1, \u03b3)<sup>6</sup>Li must be directly measured within the astrophysical energy range of 30-400keV. This measure requires an ultra-low \u03b3-ray background in the experimental set-up. We have realized the conditions matching these very strict requirements at LUNA, the deep underground accelerator laboratory active in the INFN Gran Sasso National Laboratory (LNGS), Italy: the \u03b3-ray spectrometer background has been reduced down to reach unmatched low levels, comparable to the good ones experienced in dedicated off-line underground ultra low \u03b3 counting rate. We present and discuss the \u03b3-ray background reduction reached in the HpGe spectrometer, where most of the remaining \u03b3-ray background seen in the spectra are coming from the energetic deuterons scattered in the gas target by the \u03b1 beam. Thanks to the low neutron environmental background at LUNA, the effect of this weak flux of 2-3MeV neutrons on HpGe detectors has been studied in details and the results are presented and discussed.</p>",
        "title": "Ultra-sensitive \u03b3-ray spectroscopy set-up for investigating primordial lithium problem",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "3fe0b791-5ea2-4478-8886-f4be17496d8c": {
        "id": "3fe0b791-5ea2-4478-8886-f4be17496d8c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/resonance-strengths-in-the-1718op-1415n-reactions-and-background-suppression-underground(3fe0b791-5ea2-4478-8886-f4be17496d8c).html",
        "abstract": "<p>We report on measurements of resonance strengths and energies for the and 193 keV resonances in the O-18(p,)N-15 and O-17(p,)N-14 reactions, respectively, obtained during commissioning of a new setup for alpha-particle detection studies at the LUNA underground laboratory. Our values, meV and meV, are in excellent agreement with those reported in the literature. New values of resonance energies are keV and keV, respectively, this latter with the highest precision to date. Comparative background measurements in silicon detectors overground and underground were also carried out, yielding up to a factor of 15 in background suppression at LUNA at energies around 200keV. This clearly demonstrates the usefulness of underground measurements in charged-particles experiments, especially at low detection energies.</p>",
        "title": "Resonance strengths in the 17,18O(p, \u03b1)14,15N reactions and background suppression underground",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "a490fec1-ebb1-448b-8868-871d047a294a": {
        "id": "a490fec1-ebb1-448b-8868-871d047a294a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/vascular-plug-for-ica-occlusion-in-cavernous-carotid-aneurysms(a490fec1-ebb1-448b-8868-871d047a294a).html",
        "abstract": "<p>INTRODUCTION: Large, symptomatic aneurysms of the cavernous internal carotid artery (ICA) can be successfully treated by a combination of aneurysm coiling and occlusion of the parent vessel.</p><p>CASE PRESENTATION: We describe the use of an Amplatzer (AGA medical corporation, Plymouth, MA, USA) detachable nitinol vascular plug to occlude the ICA in four patients with symptomatic cavernous ICA aneurysms.</p>",
        "title": "Vascular plug for ICA occlusion in cavernous carotid aneurysms",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "506dca07-e240-49a2-afbe-07b6b8c00a79": {
        "id": "506dca07-e240-49a2-afbe-07b6b8c00a79",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-new-study-of-the-22nep-23na-reaction-deep-underground(506dca07-e240-49a2-afbe-07b6b8c00a79).html",
        "abstract": "<p>The Ne-22(p, gamma)Na-23 reaction takes part in the neon-sodium cycle of hydrogen burning. This cycle is active in asymptotic giant branch stars as well as in novae and contributes to the nucleosythesis of neon and sodium isotopes. In order to reduce the uncertainties in the predicted nucleosynthesis yields, new experimental efforts to measure the Ne-22(p, gamma)Na-23 cross section directly at the astrophysically relevant energies are needed. In the present work, a feasibility study for a Ne-22(p, gamma)Na-23 experiment at the Laboratory for Underground Nuclear Astrophysics (LUNA) 400 kV accelerator deep underground in the Gran Sasso laboratory, Italy, is reported. The ion-beam-induced.-ray background has been studied. The feasibility study led to the first observation of the E-p = 186 keV resonance in a direct experiment. An experimental lower limit of 0.12 x 10(-6) eV has been obtained for the resonance strength. Informed by the feasibility study, a dedicated experimental setup for the Ne-22(p, gamma)Na-23 experiment has been developed. The new setup has been characterized by a study of the temperature and pressure profiles. The beam heating effect that reduces the effective neon gas density due to the heating by the incident proton beam has been studied using the resonance scan technique, and the size of this effect has been determined for a neon gas target.</p>",
        "title": "A new study of the 22Ne(p, \u03b3)23Na reaction deep underground",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "a00da3a7-b103-4953-8391-b93e78d1c442": {
        "id": "a00da3a7-b103-4953-8391-b93e78d1c442",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/first-direct-measurement-of-the-2halphagamma6li-cross-section-at-big-bang-energies-and-the-primordial-lithium-problem(a00da3a7-b103-4953-8391-b93e78d1c442).html",
        "abstract": "Recent observations of 6Li in metal poor stars suggest a large production of this isotope during big bang nucleosynthesis (BBN). In standard BBN calculations, the 2H(\u03b1,\u03b3)6Li reaction dominates 6Li production.This reaction has never been measured inside the BBN energy region because its cross section drops exponentially at low energy and because the electric dipole transition is strongly suppressed for the isoscalar particles 2H and \u03b1 at energies below the Coulomb barrier. Indirect measurements using the Coulomb dissociation of 6Li only give upper limits owing to the dominance of nuclear breakup processes.Here, we report on the results of the first measurement of the 2H(\u03b1,\u03b3)6Li cross section at big bang energies. The experiment was performed deep underground at the LUNA 400 kV accelerator in Gran Sasso, Italy.The primordial 6Li/7Li isotopic abundance ratio has been determined to be (1.5 +- 0.3) \u00d7 10\u22125, from ourexperimental data and standard BBN theory. The much higher 6Li=7Li values reported for halo stars willlikely require a nonstandard physics explanation, as discussed in the literature.",
        "title": "First Direct Measurement of the 2H(alpha,gamma)6Li Cross Section at Big Bang energies and the Primordial Lithium Problem",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "2c4f660c-13f2-43ef-b652-5f46dc34b8ab": {
        "id": "2c4f660c-13f2-43ef-b652-5f46dc34b8ab",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/tpd52-and-nfkb1-gene-expression-levels-correlate-with-g2-chromosomal-radiosensitivity-in-lymphocytes-of-women-with-and-at-risk-of-hereditary-breast-cancer(2c4f660c-13f2-43ef-b652-5f46dc34b8ab).html",
        "abstract": "To evaluate a transcriptomic approach to identify healthy women at increased risk of breast cancer due to G2-radiosensitivity and look at transcripts that are differentially expressed between individuals.",
        "title": "TPD52 and NFKB1 gene expression levels correlate with G2 chromosomal radiosensitivity in lymphocytes of women with and at risk of hereditary breast cancer",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "26e2cd35-4e7d-4e17-8ad5-5194dc2a5b3e": {
        "id": "26e2cd35-4e7d-4e17-8ad5-5194dc2a5b3e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/wwox-mrna-expression-profile-in-epithelial-ovarian-cancer-supports-the-role-of-wwox-variant-1-as-a-tumour-suppressor-although-the-role-of-variant-4-remains-unclear(26e2cd35-4e7d-4e17-8ad5-5194dc2a5b3e).html",
        "abstract": "WWOX is a candidate tumour suppressor gene that exhibits LOH or homozygous deletion in several tumour types. As well as the predominant full-length transcript (variant 1) there also exist alternatively spliced transcripts found previously only in malignant tissue. It has been suggested that proteins encoded by these variants may interfere with normal WWOX function in a dominant negative fashion. The most prevalent alternate transcript demonstrated in ovarian cancer is variant 4, which lacks exons 6-8. Here, we report the first comparison of the mRNA expression of WWOX variants 1 and 4 in human ovarian tumours and normal ovaries, and correlate expression with clinical data. We demonstrate significantly lower WWOX variant 1 expression in tumours than in normal ovaries. This reduction was not associated with any specific clinical subgroup. Variant 4 was expressed at low levels, and significantly associated with high grade and advanced stage ovarian cancer. Furthermore, tumours co-expressing variant 4 and relatively high levels of variant 1 showed significantly worse survival than tumours expressing variant 1 alone. However, variant 4 was also frequently identified in non-malignant ovarian tissue. These results support the role of WWOX variant 1 as a suppressor of ovarian tumourigenesis, but the role of variant 4 remains speculative.",
        "title": "WWOX mRNA expression profile in epithelial ovarian cancer supports the role of WWOX variant 1 as a tumour suppressor, although the role of variant 4 remains unclear",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "db1fc71f-71eb-4322-bf0f-9821bf8f1c2c": {
        "id": "db1fc71f-71eb-4322-bf0f-9821bf8f1c2c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/goodsherschel-measurements-of-the-dust-attenuation-of-typical-starforming-galaxies-at-high-redshift-observations-of-ultravioletselected-galaxies-at-z-similar-to-2(db1fc71f-71eb-4322-bf0f-9821bf8f1c2c).html",
        "abstract": "<p>We take advantage of the sensitivity and resolution of the Herschel Space Observatory at 100 and 160 mu m to directly image the thermal dust emission and investigate the infrared luminosities (L-IR) and dust obscuration of typical star-forming (L*) galaxies at high redshift. Our sample consists of 146 UV-selected galaxies with spectroscopic redshifts 1.5 </p>",
        "title": "GOODS-HERSCHEL MEASUREMENTS OF THE DUST ATTENUATION OF TYPICAL STAR-FORMING GALAXIES AT HIGH REDSHIFT: OBSERVATIONS OF ULTRAVIOLET-SELECTED GALAXIES AT z similar to 2",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "a85ca0a3-472b-429d-88c6-8d81714c7c6b": {
        "id": "a85ca0a3-472b-429d-88c6-8d81714c7c6b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/neutroninduced-background-by-an-beam-incident-on-a-deuterium-gas-target-and-its-implications-for-the-study-of-the-h-li-reaction-at-luna(a85ca0a3-472b-429d-88c6-8d81714c7c6b).html",
        "abstract": "The production of the stable isotope Li in standard Big Bang nucleosynthesis has recently attracted much interest. Recent observations in metal-poor stars suggest that a cosmological Li plateau may exist. If true, this plateau would come in addition to the well-known Spite plateau of Li abundances and would point to a predominantly primordial origin of Li, contrary to the results of standard Big Bang nucleosynthesis calculations. Therefore, the nuclear physics underlying Big Bang Li production must be revisited. The main production channel for Li in the Big Bang is the H(\u03b1, \u03b3)Li reaction. The present work reports on neutron-induced effects in a high-purity germanium detector that were encountered in a new study of this reaction. In the experiment, an \u03b1-beam from the underground accelerator LUNA in Gran Sasso, Italy, and a windowless deuterium gas target are used. A low neutron flux is induced by energetic deuterons from elastic scattering and, subsequently, the H(d, n)He reaction. Due to the ultra-low laboratory neutron background at LUNA, the effect of this weak flux of 2-3MeV neutrons on well-shielded high-purity germanium detectors has been studied in detail. Data have been taken at 280 and 400 keV \u03b1-beam energy and for comparison also using an americium-beryllium neutron source.",
        "title": "Neutron-induced background by an \u03b1-beam incident on a deuterium gas target and its implications for the study of the H(\u03b1, \u03b3)Li reaction at LUNA",
        "keywords": "",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "8b7c496c-738f-42db-85a5-3a358965167f": {
        "id": "8b7c496c-738f-42db-85a5-3a358965167f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/herschelatlas-counterparts-from-the-ultravioletnearinfrared-in-the-science-demonstration-phase-catalogue(8b7c496c-738f-42db-85a5-3a358965167f).html",
        "abstract": "<p>We present a technique to identify optical counterparts of 250-mu m-selected sources from the Herschel-ATLAS survey. Of the 6621 250 mu m &gt; 32-mJy sources in our science demonstration catalogue we find that similar to 60 per cent have counterparts brighter than r = 22.4 mag in the Sloan Digital Sky Survey. Applying a likelihood ratio technique we are able to identify 2423 of the counterparts with a reliability R &gt; 0.8. This is approximately 37 per cent of the full 250-mu m catalogue. We have estimated photometric redshifts for each of these 2423 reliable counterparts, while 1099 also have spectroscopic redshifts collated from several different sources, including the GAMA survey. We estimate the completeness of identifying counterparts as a function of redshift, and present evidence that 250-mu m-selected Herschel-ATLAS galaxies have a bimodal redshift distribution. Those with reliable optical identifications have a redshift distribution peaking at z approximate to 0.25 +/- 0.05, while submillimetre colours suggest that a significant fraction with no counterpart above the r-band limit have z &gt; 1. We also suggest a method for selecting populations of strongly lensed high-redshift galaxies. Our identifications are matched to UV-NIR photometry from the GAMA survey, and these data are available as part of the Herschel-ATLAS public data release.</p>",
        "title": "Herschel-ATLAS: counterparts from the ultraviolet-near-infrared in the science demonstration phase catalogue",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "824d5995-453d-4a5f-95a5-d1bd5787343c": {
        "id": "824d5995-453d-4a5f-95a5-d1bd5787343c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-scuba-halfdegree-extragalactic-survey--i-survey-motivation-design-and-data-processing(824d5995-453d-4a5f-95a5-d1bd5787343c).html",
        "abstract": "The Submillimetre Common-User Bolometer Array (SCUBA) Half-Degree Extragalactic Survey (SHADES) is a major new blank-field extragalactic submillimetre (submm) survey currently underway at the James Clerk Maxwell Telescope (JCMT). Ultimately, SHADES aims to cover half a square degree at 450 and 850 \u03bcm to a 4\u03c3 depth of \u2243 8 mJy at 850 \u03bcm. Two fields are being observed, the Subaru/XMM\u2014Newton Deep Field (SXDF) (02h18m\u221205\u00b0) and the Lockman Hole East (10h52m+ 57\u00b0). The survey has three main aims: (i) to investigate the population of high-redshift submm galaxies and the cosmic history of massive dust-enshrouded star formation activity; (ii) to investigate the clustering properties of submm-selected galaxies in order to determine whether these objects could be progenitors of present-day massive ellipticals; and (iii) to investigate the fraction of submm-selected sources that harbour active galactic nuclei. To achieve these aims requires that the submm data be combined with co-spatial information spanning the radio-to-X-ray frequency range. Accordingly, SHADES has been designed to benefit from ultra-deep radio imaging obtained with the Very Large Array (VLA), deep mid-infrared observations from the Spitzer Space Telescope, submm mapping by the Balloon-borne Large Aperture Submillimetre Telescope (BLAST), deep near-infrared imaging with the United Kingdom Infrared Telescope, deep optical imaging with the Subaru Telescope and deep X-ray observations with the XMM\u2014Newton observatory. It is expected that the resulting extensive multiwavelength data set will provide complete photometric redshift information accurate to  as well as detailed spectral energy distributions for the vast majority of the submm-selected sources. In this paper, the first of a series on SHADES, we present an overview of the motivation for the survey, describe the SHADES survey strategy, provide a detailed description of the primary data-analysis pipeline and demonstrate the superiority of our adopted matched-filter source-extraction technique over, for example, Emerson-II style methods. We also report on the progress of the survey. As of 2004 February, 720 arcmin2 had been mapped with SCUBA (about 40 per cent of the anticipated final total area) to a median 1\u03c3 depth of 2.2 mJy per beam at 850 \u03bcm (25 mJy per beam at 450 \u03bcm), and the source-extraction routines give a source density of 650 \u00b1 50 sources deg\u22122 &gt; 3\u03c3 at 850 \u03bcm. Although uncorrected for Eddington bias, this source density is more than sufficient for providing enough sources to answer the science goals of SHADES, once half a square degree is observed. A refined reanalysis of the original 8-mJy survey Lockman hole data was carried out in order to evaluate the new data-reduction pipeline. Of the 17 most secure sources in the original sample, 12 have been reconfirmed, including 10 of the 11 for which radio identifications were previously secured.",
        "title": "The SCUBA Half-Degree Extragalactic Survey \u2014 I. Survey motivation, design and data processing",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "8da4b221-4759-4241-ab9f-d20a44721a15": {
        "id": "8da4b221-4759-4241-ab9f-d20a44721a15",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/linked-data-for-humanities-research--the-spqr-experiment(8da4b221-4759-4241-ab9f-d20a44721a15).html",
        "abstract": "",
        "title": "Linked Data for Humanities Research - The SPQR experiment",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "c1437493-13bb-4c28-8f85-76755bea9317": {
        "id": "c1437493-13bb-4c28-8f85-76755bea9317",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hermes-far-infrared-properties-of-known-agn-in-the-hermes-fields(c1437493-13bb-4c28-8f85-76755bea9317).html",
        "abstract": "<p>Nuclear and starburst activity are known to often occur concomitantly. Herschel-SPIRE provides sampling of the far-infrared (FIR) spectral energy distributions (SEDs) of type 1 and type 2 AGN, allowing for the separation between the hot dust (torus) and cold dust (starburst) emission. We study large samples of spectroscopically confirmed type 1 and type 2 AGN lying within the Herschel Multi-tiered Extragalactic Survey (HerMES) fields observed during the science demonstration phase, aiming to understand their FIR colour distributions and constrain their starburst contributions. We find that one third of the spectroscopically confirmed AGN in the HerMES fields have 5 sigma detections at 250 mu m, in agreement with previous (sub) mm AGN studies. Their combined Spitzer-MIPS and Herschel-SPIRE colours (specifically S-250/S-70 vs S-70/S-24) quite clearly separate them from the non-AGN, star forming galaxy population, as their 24 mu m flux is dominated by the hot torus emission. However, their SPIRE colours alone do not differ from those of non-AGN galaxies. SED fitting shows that all those AGN need a starburst component to fully account for their FIR emission. For objects at z &gt; 2 we find a correlation between the infrared luminosity attributed to the starburst component, L-SB, and the AGN accretion luminosity, L-acc, with L-SB alpha L-acc(0.35). Type 2 AGN detected at 250 mu m show on average higher L-SB than type 1 objects but their number is still too low to establish whether this trend indicates stronger star formation activity.</p>",
        "title": "HerMES: Far infrared properties of known AGN in the HerMES fields",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "David Scott",
                "uuid": "4344842c-1a8c-4370-9952-6edc964c2590"
            }
        ]
    },
    "fb89175c-18e8-4a8a-89cd-72225e320fcb": {
        "id": "fb89175c-18e8-4a8a-89cd-72225e320fcb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/rederivation-and-further-assessment-of-the-let-theory-of-isotropic-turbulence-as-applied-to-passive-scalar-convection(fb89175c-18e8-4a8a-89cd-72225e320fcb).html",
        "abstract": "<p>A simpler and more rigorous derivation is presented for the LET (Local Energy Transfer) theory, which generalizes the theory to the non-stationary case and which corrects some minor errors in the original formulation (McComb 1978), Previously, ad hoc generalizations of the LET theory (McComb &amp; Shanmugasundaram 1984) gave good numerical results for the free decay of isotropic turbulence. The quantitative aspects of these previous computations are not significantly affected by the present corrections, although there are some important qualitative improvements.</p><p>The revised LET theory is also extended to the problem of passive scalar convection, and numerical results have been obtained for freely decaying isotropic turbulence, with Taylor-Reynolds numbers in the range 5 less-than-or-equal-to R(lambda) less-than-or-equal-to 1060, and for Prandtl numbers of 0.1, 0.5 and 1.O. At sufficiently high values of the Reynolds number, both velocity and scalar spectra are found to exhibit Kolmogorov-type power laws, with the Kolmogorov spectral constant taking the value alpha = 2.5 and the Corrsin-Oboukhov constant taking a value of beta = 1.1.</p>",
        "title": "REDERIVATION AND FURTHER ASSESSMENT OF THE LET THEORY OF ISOTROPIC TURBULENCE, AS APPLIED TO PASSIVE SCALAR CONVECTION",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "4fcdaa84-fd24-4687-bee3-2c42683fe028": {
        "id": "4fcdaa84-fd24-4687-bee3-2c42683fe028",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-uars-and-eos-microwave-limb-sounder-mls-experiments(4fcdaa84-fd24-4687-bee3-2c42683fe028).html",
        "abstract": "<p>The Microwave Limb Sounder (MLS) experiments obtain measurements of atmospheric composition, temperature, and pressure by observations of millimeter- and submillimeter-wavelength thermal emission as the instrument field of view is scanned through the atmospheric limb. Features of the measurement technique include the ability to measure many atmospheric gases as well as temperature and pressure, to obtain measurements even in the presence of dense aerosol and cirrus, and to provide near-global coverage on a daily basis at all times of day and night from an orbiting platform. The composition measurements are relatively insensitive to uncertainties in atmospheric temperature. An accurate spectroscopic database is available, and the instrument calibration is also very accurate and stable. The first MLS experiment in space, launched on the (NASA) Upper Atmosphere Research Satellite (UARS) in September 1991, was designed primarily to measure stratospheric profiles of ClO, O-3, H2O, and atmospheric pressure as a vertical reference. Global measurement of ClO, the predominant radical in chlorine destruction of ozone, was an especially important objective of UARS MLS. Ail objectives of UARS MLS have been accomplished and additional geophysical products beyond those for which the experiment was designed have been obtained, including measurement of upper-tropospheric water vapor, which is important for climate change studies. A follow-on MLS experiment is being developed for NASA's Earth Observing System (EOS) and is scheduled to be launched on the EOS CHEMISTRY platform in late 2002. EOS MLS is designed for many stratospheric measurements, including HO, radicals, which could not be measured by UARS because adequate technology was not available, and better and more extensive upper-tropospheric and lower-stratospheric measurements.</p>",
        "title": "The UARS and EOS microwave limb sounder (MLS) experiments",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "b3ebfc5b-98b6-4f3c-97c0-51f5575875f6": {
        "id": "b3ebfc5b-98b6-4f3c-97c0-51f5575875f6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/studies-of-upper-tropospheric-processes-including-the-radiation-budget(b3ebfc5b-98b6-4f3c-97c0-51f5575875f6).html",
        "abstract": "<p>Meteosat Second Generation (MSG) data will be used for two connected strands of research. The first strand is to enhance the on-going studies of meteorological processes near the tropopause by using MSG cloud and profile measurements. These studies involve calculation of particle trajectories in the region of the tropical tropopause. To obtain the vertical velocities for these trajectories diabatic heating rates need to be calculated. MSG data will be used to improve the specification of cloud and water vapour fields required in these calculations. In addition the cloud fields will be used to indicate where convective mixing processes affect the trajectories.</p><p>The second strand will combine high horizontal resolution MSG data with high vertical resolution EOSMLS data to improve estimates of the radiation budget. EOSMLS is an improved version of the highly successful UARSMLS instrument. UARSMLS proved successful in measuring water vapour in the upper troposphere and lower stratosphere. EOSMLS has been designed with greatly improved capabilities for such measurements. EOSMLS will be launched on the EOS Aura satellite in December 2002.</p>",
        "title": "Studies of upper tropospheric processes including the radiation budget",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "45f54b49-206e-4ef4-943d-13c3d6d1eeeb": {
        "id": "45f54b49-206e-4ef4-943d-13c3d6d1eeeb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/convective-outflow-of-south-asian-pollution-a-global-ctm-simulation-compared-with-eos-mls-observations(45f54b49-206e-4ef4-943d-13c3d6d1eeeb).html",
        "abstract": "<p>A global 3-D chemical transport model is used to analyze observations of carbon monoxide (CO) and upper tropospheric clouds from the EOS Microwave Limb Sounder (MLS). MLS observations during 25 August-6 September 2004 reveal elevated CO and dense high clouds in the upper troposphere over the Tibetan plateau and southwest China, collocating with the upper level Tibetan anticyclone. Model simulations indicate the transport of boundary layer pollution by Asian summer monsoon (ASM) convection and orographic lifting to the upper troposphere over South Asia, where simulated distributions of CO resemble MLS observations. Model results also show elevated aerosols in the anticyclone region. Analysis of model simulated CO and aerosols indicate that the Tibetan anticyclone could 'trap' anthropogenic emissions lifted from northeast India and southwest China. These aerosols may be responsible for the formation of some of the dense high clouds.</p>",
        "title": "Convective outflow of South Asian pollution: A global CTM simulation compared with EOS MLS observations",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "c6f0eb5c-d269-42ce-8595-22d2bf54bfc6": {
        "id": "c6f0eb5c-d269-42ce-8595-22d2bf54bfc6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/intercomparisons-of-trace-gases-profiles-from-the-odinsmr-and-auramls-limb-sounders(c6f0eb5c-d269-42ce-8595-22d2bf54bfc6).html",
        "abstract": "<p>This paper presents the intercomparison of O-3, HNO3, ClO, N2O and CO profiles measured by the two spaceborne microwave instruments MLS ( Microwave Limb Sounder) and SMR ( Submillimetre Radiometer) on board the Aura and Odin satellites, respectively. We compared version 1.5 level 2 data from MLS with level 2 data produced by the French data processor version 222 and 225 and by the Swedish data processor version 2.0 for several days in September 2004 and in March 2005. For the five gases studied, an overall good agreement is found between both instruments. Most of the observed discrepancies between SMR and MLS are consistent with results from other intercomparison studies involving MLS or SMR. O-3 profiles retrieved from the SMR 501.8 GHz band are noisier than MLS profiles but mean biases between both instruments do not exceed 10%. SMR HNO3 profiles are biased low relative to MLS's by similar to 30% above the profile peak. In the lower stratosphere, MLS ClO profiles are biased low by up to 0.3 ppbv relative to coincident SMR profiles, except in the Southern Hemisphere polar vortex in the presence of chlorine activation. N2O profiles from both instruments are in very good agreement with mean biases not exceeding 15%. Finally, the intercomparison between SMR and MLS CO profiles has shown a good agreement from the middle stratosphere to the middle mesosphere in spite of strong oscillations in the MLS profiles. In the upper mesosphere, MLS CO concentrations are biased high relative to SMR while negative values in the MLS retrievals are responsible for a negative bias in the tropics around 30 hPa.</p>",
        "title": "Intercomparisons of trace gases profiles from the Odin/SMR and Aura/MLS limb sounders",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "49209803-0786-4f23-9313-6c96200e723f": {
        "id": "49209803-0786-4f23-9313-6c96200e723f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/validation-of-aura-microwave-limb-sounder-ozone-by-ozonesonde-and-lidar-measurements(49209803-0786-4f23-9313-6c96200e723f).html",
        "abstract": "<p>[1] We present validation studies of MLS version 2.2 upper tropospheric and stratospheric ozone profiles using ozonesonde and lidar data as well as climatological data. Ozone measurements from over 60 ozonesonde stations worldwide and three lidar stations are compared with coincident MLS data. The MLS ozone stratospheric data between 150 and 3 hPa agree well with ozonesonde measurements, within 8% for the global average. MLS values at 215 hPa are biased high compared to ozonesondes by similar to 20% at middle to high latitude, although there is a lot of variability in this altitude region. Comparisons between MLS and ground-based lidar measurements from Mauna Loa, Hawaii, from the Table Mountain Facility, California, and from the Observatoire de Haute-Provence, France, give very good agreement, within similar to 5%, for the stratospheric values. The comparisons between MLS and the Table Mountain Facility tropospheric ozone lidar show that MLS data are biased high by similar to 30% at 215 hPa, consistent with that indicated by the ozonesonde data. We obtain better global average agreement between MLS and ozonesonde partial column values down to 215 hPa, although the average MLS values at low to middle latitudes are higher than the ozonesonde values by up to a few percent. MLS v2.2 ozone data agree better than the MLS v1.5 data with ozonesonde and lidar measurements. MLS tropical data show the wave one longitudinal pattern in the upper troposphere, with similarities to the average distribution from ozonesondes. High upper tropospheric ozone values are also observed by MLS in the tropical Pacific from June to November.</p>",
        "title": "Validation of Aura Microwave Limb Sounder Ozone by ozonesonde and lidar measurements",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "0191fbc9-b5c9-44ef-b9f9-b176dce36100": {
        "id": "0191fbc9-b5c9-44ef-b9f9-b176dce36100",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/validation-of-middleatmosphere-carbon-monoxide-retrievals-from-the-microwave-limb-sounder-on-aura(0191fbc9-b5c9-44ef-b9f9-b176dce36100).html",
        "abstract": "<p>The Microwave Limb Sounder on Aura has produced an extensive set of measurements of CO in the middle atmosphere. The measurements are usable for scientific studies from the upper troposphere up to 90 km altitude. We describe these measurements and validate them by demonstrating their internal consistency and by comparing them to other remotely sounded measurements and to 2-D model simulations. Comparisons with other measurements suggest that MLS has a positive bias of 25-50% in the mesosphere and a negative bias of up to 70% in the ( almost CO-free) lower stratosphere. The geophysical features observed in the MLS CO field show excellent qualitative agreement with other measurements.</p>",
        "title": "Validation of middle-atmosphere carbon monoxide retrievals from the Microwave Limb Sounder on Aura",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "99049246-3075-4047-bdd1-fad2f121fdf0": {
        "id": "99049246-3075-4047-bdd1-fad2f121fdf0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/validation-of-aura-microwave-limb-sounder-stratospheric-ozone-measurements(99049246-3075-4047-bdd1-fad2f121fdf0).html",
        "abstract": "<p>The Earth Observing System (EOS) Microwave Limb Sounder (MLS) aboard the Aura satellite has provided essentially daily global measurements of ozone (O-3) profiles from the upper troposphere to the upper mesosphere since August of 2004. This paper focuses on validation of the MLS stratospheric standard ozone product and its uncertainties, as obtained from the 240 GHz radiometer measurements, with a few results concerning mesospheric ozone. We compare average differences and scatter from matched MLS version 2.2 profiles and coincident ozone profiles from other satellite instruments, as well as from aircraft lidar measurements taken during Aura Validation Experiment (AVE) campaigns. Ozone comparisons are also made between MLS and balloon-borne remote and in situ sensors. We provide a detailed characterization of random and systematic uncertainties for MLS ozone. We typically find better agreement in the comparisons using MLS version 2.2 ozone than the version 1.5 data. The agreement and the MLS uncertainty estimates in the stratosphere are often of the order of 5%, with values closer to 10% (and occasionally 20%) at the lowest stratospheric altitudes, where small positive MLS biases can be found. There is very good agreement in the latitudinal distributions obtained from MLS and from coincident profiles from other satellite instruments, as well as from aircraft lidar data along the MLS track.</p>",
        "title": "Validation of Aura Microwave Limb Sounder stratospheric ozone measurements",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "f214761c-3d40-4c3c-ae26-9e10b6497d8d": {
        "id": "f214761c-3d40-4c3c-ae26-9e10b6497d8d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/fourdimensional-variational-assimilation-of-ozone-profiles-from-the-microwave-limb-sounder-on-the-aura-satellite(f214761c-3d40-4c3c-ae26-9e10b6497d8d).html",
        "abstract": "<p>Ozone profiles from the Microwave Limb Sounder (MLS) onboard the Aura satellite of the NASA's Earth Observing System (EOS) were experimentally added to the European Centre for Medium-range Weather Forecasts (ECMWF) four-dimensional variational (4D-var) data assimilation system of version CY30R1, in which total ozone columns from Scanning Imaging Absorption Spectrometer for Atmospheric CHartographY (SCIAMACHY) onboard the Envisat satellite and partial profiles from the Solar Backscatter Ultraviolet (SBUV/2) instrument onboard the NOAA-16 satellite have been operationally assimilated. As shown by results for the autumn of 2005, additional constraints from MLS data significantly improved the agreement of the analyzed ozone fields with independent observations throughout most of the stratosphere, owing to the daily near-global coverage and good vertical resolution of MLS observations. The largest impacts were seen in the middle and lower stratosphere, where model deficiencies could not be effectively corrected by the operational observations without the additional information on the ozone vertical distribution provided by MLS. Even in the upper stratosphere, where ozone concentrations are mainly determined by rapid chemical processes, dense and vertically resolved MLS data helped reduce the biases related to model deficiencies. These improvements resulted in a more realistic and consistent description of spatial and temporal variations in stratospheric ozone, as demonstrated by cases in the dynamically and chemically active regions. However, combined assimilation of the often discrepant ozone observations might lead to underestimation of tropospheric ozone. In addition, model deficiencies induced large biases in the upper stratosphere in the medium-range (5-day) ozone forecasts.</p>",
        "title": "Four-dimensional variational assimilation of ozone profiles from the Microwave Limb Sounder on the Aura satellite",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "50e1a409-d031-4773-9745-e2beaac4f067": {
        "id": "50e1a409-d031-4773-9745-e2beaac4f067",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-empirical-model-for-the-statistics-of-sea-surface-diurnal-warming(50e1a409-d031-4773-9745-e2beaac4f067).html",
        "abstract": "<p>A statistical model is derived relating the diurnal variation of sea surface temperature (SST) to the net surface heat flux and surface wind speed from a numerical weather prediction (NWP) model. The model is derived using fluxes and winds from the European Centre for Medium-Range Weather Forecasting (ECMWF) NWP model and SSTs from the Spinning Enhanced Visible and Infrared Imager (SEVIRI). In the model, diurnal warming has a linear dependence on the net surface heat flux integrated since (approximately) dawn and an inverse quadratic dependence on the maximum of the surface wind speed in the same period. The model coefficients are found by matching, for a given integrated heat flux, the frequency distributions of the maximum wind speed and the observed warming. Diurnal cooling, where it occurs, is modelled as proportional to the integrated heat flux divided by the heat capacity of the seasonal mixed layer. The model reproduces the statistics (mean, standard deviation, and 95-percentile) of the diurnal variation of SST seen by SEVIRI and reproduces the geographical pattern of mean warming seen by the Advanced Microwave Scanning Radiometer (AMSR-E). We use the functional dependencies in the statistical model to test the behaviour of two physical model of diurnal warming that display contrasting systematic errors.</p>",
        "title": "An empirical model for the statistics of sea surface diurnal warming",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "53715350-222d-4556-89fe-fc076ca2d0a1": {
        "id": "53715350-222d-4556-89fe-fc076ca2d0a1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/qbo-and-annual-cycle-variations-in-tropical-lower-stratosphere-trace-gases-from-haloe-and-aura-mls-observations(53715350-222d-4556-89fe-fc076ca2d0a1).html",
        "abstract": "<p>We have analyzed thirteen years ( 1993 to 2005) of HALOE and over two years of EOS MLS observations ( September 2004 to December 2006) for QBO and annual cycle trace variations in tropical H2O, HCl, ozone, N2O, CO, HF, and CH4. We use these results to develop the theory explaining both Brewer-Dobson circulation (BDC) and QBO driven fluctuations in tropical trace gases. For H2O, BDC variations drive part of the tropopause annual forcing through annual variations in the temperature as has been shown previously. For CO, the annual variations in the BDC amplify the annual fluctuations in CO at the tropopause as has recently been shown by Randel et al (2007). In both cases, the tropopause signal is carried upward by the mean BDC. For ozone, N2O, HCl and other gases, photochemical processes force fluctuations in the trace gases to be synchronized with annual and QBO variations in the zonal mean residual vertical velocity as is shown using lag correlations.</p>",
        "title": "QBO and annual cycle variations in tropical lower stratosphere trace gases from HALOE and Aura MLS observations",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "4e37e086-9a94-4d12-8dad-bbbcf99b3e20": {
        "id": "4e37e086-9a94-4d12-8dad-bbbcf99b3e20",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/validation-of-aura-microwave-limb-sounder-o3-and-co-observations-in-the-upper-troposphere-and-lower-stratosphere(4e37e086-9a94-4d12-8dad-bbbcf99b3e20).html",
        "abstract": "<p>Global satellite observations of ozone and carbon monoxide from the Microwave Limb Sounder (MLS) on the EOS Aura spacecraft are discussed with emphasis on those observations in the 215-100 hPa region (the upper troposphere and lower stratosphere). The precision, resolution and accuracy of the data produced by the MLS \"version 2.2'' processing algorithms are discussed and quantified. O-3 accuracy is estimated at similar to 40 ppbv + 5% (similar to 20 ppbv + 20% at 215 hPa) while the CO accuracy is estimated at similar to 30 ppbv + 30% for pressures of 147 hPa and less. Comparisons with expectations and other observations show good agreements for the O3 product, generally consistent with the systematic errors quoted above. In the case of CO, a persistent factor of similar to 2 high bias is seen at 215 hPa. However, the morphology is shown to be realistic, consistent with raw MLS radiance data, and useful for scientific study. The MLS CO data at higher altitudes are shown to be consistent with other observations.</p>",
        "title": "Validation of Aura Microwave Limb Sounder O-3 and CO observations in the upper troposphere and lower stratosphere",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "0dce8ab5-339a-405c-a37c-a8b1e713c03f": {
        "id": "0dce8ab5-339a-405c-a37c-a8b1e713c03f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-allsky-survey-at-230-ghz-by-mls-on-aura(0dce8ab5-339a-405c-a37c-a8b1e713c03f).html",
        "abstract": "<p>The Microwave Limb Sounder (MLS) instrument is a small satellite-borne radio telescope. Its purpose is to make limb-scanning measurements of atmospheric composition. One of the gases to which it is sensitive is carbon monoxide (CO), detected via the J = 2 -&gt; 1 rotational transition at 230 GHz. CO is present in molecular gas clouds in the Milky Way. Although it was not designed for the purpose, MLS can detect emissions from galactic CO, allowing a map of the 230 GHz radio sky to be constructed. We report the MLS measurements of galactic radio emission and discuss their effect on the atmospheric mission of MLS. The region of the Milky Way with emissions strong enough to significantly affect MLS observations of atmospheric CO is identified. Ground-based radio astronomers have been mapping the sky using CO emission for many years. However, the MLS data are the first such survey to be carried out from space. The MLS survey covers a larger area of the sky than any other 230 GHz survey, but no previously unknown gas clouds are observed. (C) 2008 COSPAR. Published by Elsevier Ltd. All rights reserved.</p>",
        "title": "An all-sky survey at 230 GHz by MLS on Aura",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "9148ec02-e34f-4fe6-93b1-bbcd8caf4ffb": {
        "id": "9148ec02-e34f-4fe6-93b1-bbcd8caf4ffb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-impact-of-diurnal-variability-in-sea-surface-temperature-on-the-central-atlantic-airsea-co2-flux(9148ec02-e34f-4fe6-93b1-bbcd8caf4ffb).html",
        "abstract": "<p>The effect of diurnal variations in sea surface temperature (SST) on the air-sea flux of CO2 over the central Atlantic ocean and Mediterranean Sea (60 S-60 N, 60 W-45 E) is evaluated for 2005-2006. We use high spatial resolution hourly satellite ocean skin temperature data to determine the diurnal warming (Delta SST). The CO2 flux is then computed using three different temperature fields - a foundation temperature (T-f, measured at a depth where there is no diurnal variation), T-f plus the hourly Delta SST and T-f plus the monthly average of the Delta SSTs. This is done in conjunction with a physically-based parameterisation for the gas transfer velocity (NOAA-COARE). The differences between the fluxes evaluated for these three different temperature fields quantify the effects of both diurnal warming and diurnal covariations. We find that including diurnal warming increases the CO2 flux out of this region of the Atlantic for 2005 2006 from 9.6 Tg C a(-1) to 30.4 Tg C a(-1) (hourly Delta SST) and 31.2 Tg C a(-1) (monthly average of Delta SST measurements). Diurnal warming in this region, therefore, has a large impact on the annual net CO2 flux but diurnal covariations are negligible. However, in this region of the Atlantic the uptake and outgassing of CO2 is approximately balanced over the annual cycle, so although we find diurnal warming has a very large effect here, the Atlantic as a whole is a very strong carbon sink (e. g. -920 Tg C a(-1) Takahashi et al., 2002) making this is a small contribution to the Atlantic carbon budget.</p>",
        "title": "The impact of diurnal variability in sea surface temperature on the central Atlantic air-sea CO2 flux",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "becccc83-c1da-4ef1-b2ae-85e509e92517": {
        "id": "becccc83-c1da-4ef1-b2ae-85e509e92517",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-reprocessing-for-climate-of-sea-surface-temperature-from-the-alongtrack-scanning-radiometers-basis-in-radiative-transfer(becccc83-c1da-4ef1-b2ae-85e509e92517).html",
        "abstract": "<p>We present new radiative transfer simulations to support determination of sea surface temperature (SST) from Along Track Scanning Radiometer (ATSR) imagery. The simulations are to be used within the ATSR Reprocessing for Climate project. The simulations are based on the \"Reference Forward Model\" line-by-line model linked with a sea surface emissivity model that accounts for wind speed and temperature, and with a discrete ordinates scattering model (DISORT). Input to the forward model is a revised atmospheric profile dataset, based on full resolution ERA-40, with a wider range of high-latitude profiles to address known retrieval biases in those regions. Analysis of the radiative impacts of atmospheric trace gases shows that geographical and temporal variation of N2O, CH4, HNO3. and CFC-11 and CFC-12 have effects of order 0.05, 0.2, 0.1 K on the 3.7, 11, 12 mu m channels respectively. In addition several trace gases, neglected in previous studies, are included using fixed profiles contributing similar to 0.04 K to top-of-atmosphere BTs. Comparison against observations for ATSR2 and AATSR indicates that forward model biases have been reduced from 0.2 to 0.5 K for previous simulations to similar to 0.1 K. (C) 2011 Elsevier Inc. All rights reserved.</p>",
        "title": "A reprocessing for climate of sea surface temperature from the along-track scanning radiometers: Basis in radiative transfer",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "6718bf14-b9d2-40c4-9192-4111cc10e288": {
        "id": "6718bf14-b9d2-40c4-9192-4111cc10e288",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/carbon-monoxide-measured-by-the-eos-microwave-limb-sounder-on-aura-first-results(6718bf14-b9d2-40c4-9192-4111cc10e288).html",
        "abstract": "<p>Atmospheric carbon monoxide (CO) is measured by the EOS Microwave Limb Sounder (MLS) on NASA's recently-launched Aura satellite. Descent has been observed in the 2004-2005 Northern Hemisphere winter polar mesosphere and upper stratosphere. During August and September 2004 enhanced CO was observed in the upper troposphere over India and Tibet. The MLS CO measurements are described and the radiance signal due to the enhanced CO in the upper troposphere is demonstrated.</p>",
        "title": "Carbon monoxide measured by the EOS Microwave Limb Sounder on Aura: First results",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "18b9facc-468d-48be-84e3-d5c25ffc8102": {
        "id": "18b9facc-468d-48be-84e3-d5c25ffc8102",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/short-circuit-of-water-vapor-and-polluted-air-to-the-global-stratosphere-by-convective-transport-over-the-tibetan-plateau(18b9facc-468d-48be-84e3-d5c25ffc8102).html",
        "abstract": "<p>During boreal summer, much of the water vapor and CO entering the global tropical stratosphere is transported over the Asian monsoon/Tibetan Plateau (TP) region. Studies have suggested that most of this transport is carried out either by tropical convection over the South Asian monsoon region or by extratropical convection over southern China. By using measurements from the newly available National Aeronautics and Space Administration Aura Microwave Limb Sounder, along with observations from the Aqua and Tropical Rainfall-Measuring Mission satellites, we establish that the TP provides the main pathway for cross-tropopause transport in this region. Tropospheric moist convection driven by elevated surface heating over the TIP is deeper and detrains more water vapor, CO, and ice at the tropopause than over the monsoon area. Warmer tropopause temperatures and slower-failing, smaller cirrus cloud particles in less saturated ambient air at the tropopause also allow more water vapor to travel into the lower stratosphere over the TP, effectively short-circuiting the slower ascent of water vapor across the cold tropical tropopause over the monsoon area. Air that is high in water vapor and CO over the Asian monsoon/TP region enters the lower stratosphere primarily over the TP, and it is then transported toward the Asian monsoon area and disperses into the large-scale upward motion of the global stratospheric circulation. Thus, hydration of the global stratosphere could be especially sensitive to changes of convection over the TP.</p>",
        "title": "Short circuit of water vapor and polluted air to the global stratosphere by convective transport over the Tibetan Plateau",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "50fc3601-abdb-4547-baa0-51971e014512": {
        "id": "50fc3601-abdb-4547-baa0-51971e014512",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/early-validation-analyses-of-atmospheric-profiles-from-eos-mls-on-the-aura-satellite(50fc3601-abdb-4547-baa0-51971e014512).html",
        "abstract": "<p>We present results of early validation studies using retrieved atmospheric profiles from the Earth Observing System Microwave Limb Sounder (MLS) instrument on the Aura satellite. \"Global\" results are presented for MLS measurements of atmospheric temperature, ozone, water vapor, hydrogen chloride, nitrous oxide, nitric acid, and carbon monoxide, with a focus on the January-March 2005 time period. These global comparisons are made using long-standing global satellites and meteorological datasets, as well as some measurements from more recently launched satellites. Comparisons of MLS data with measurements from the Ft. Sumner, NM, September 2004 balloon flights are also presented. Overall, good agreement is obtained, often within 5% to 10%, but we point out certain issues to resolve and some larger systematic differences; some artifacts in the first publicly released MLS (version 1.5) dataset are noted. We comment briefly on future plans for validation and software improvements.</p>",
        "title": "Early validation analyses of atmospheric profiles from EOS MLS on the Aura satellite",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "827b8dfe-68d1-4177-9c0f-aa86f3e3c1f5": {
        "id": "827b8dfe-68d1-4177-9c0f-aa86f3e3c1f5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-earth-observing-system-microwave-limb-sounder-eos-mls-on-the-aura-satellite(827b8dfe-68d1-4177-9c0f-aa86f3e3c1f5).html",
        "abstract": "<p>The Earth Observing System Microwave Limb Sounder measures several atmospheric chemical species (OH, HO2, H2O, O-3, HCl, ClO, HOCl, BrO, HNO3, N2O, CO, HCN, CH3CN, volcanic SO2), cloud ice, temperature, and geopotential height to improve our understanding of stratospheric ozone chemistry, the interaction of composition and climate, and pollution in the upper troposphere. All measurements are made simultaneously and continuously, during both day and night. The instrument uses heterodyne radiometers that observe thermal emission from the atmospheric limb in broad spectral regions centered near 118, 190, 240, and 640 GHz, and 2.5 THz. It was launched July 15, 2004 on the National Aeronautics and Space Administration's Aura satellite and started full-up science operations on August 13, 2004. An atmospheric limb scan and radiometric calibration for all bands are performed routinely every 25 s. Vertical profiles are retrieved every 165 km along the suborbital track, covering 82 degrees S to 82 degrees N latitudes on each orbit. Instrument performance to date has been excellent; data have been made publicly available; and initial science results have been obtained.</p>",
        "title": "The Earth Observing System Microwave Limb Sounder (EOS MLS) on the Aura satellite",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "70421356-3c78-44a5-b6bf-60469d121fb3": {
        "id": "70421356-3c78-44a5-b6bf-60469d121fb3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-carbon-monoxide-tape-recorder(70421356-3c78-44a5-b6bf-60469d121fb3).html",
        "abstract": "<p>Using Aura MLS data we have identified the stratospheric 'tape recorder' in carbon monoxide ( CO). Unlike the water vapor tape recorder, which is forced by the upper tropospheric seasonal variation in dehydration processes, the CO tape recorder is linked to seasonal changes in biomass burning. Since CO has a chemical lifetime of only a few months, the CO tape recorder barely extends above 20 km. The tape head for CO appears to be close to 360 K near the same location as the water vapor tape head ( Read et al., 2004). Both tape heads are below the equatorial cold point tropopause but above the base of the tropical tropopause layer. The Global Modeling Initiative chemical transport model forced by the climatology of biomass burning reproduces the CO tape recorder. The tape recorder signal in the GMI model becomes more distinct from 360 K to 380 K suggesting that convective detrainment plays a decreasingly important role with altitude.</p>",
        "title": "The carbon monoxide tape recorder",
        "keywords": "",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "e990813f-53f0-4163-82fc-edf563aa6550": {
        "id": "e990813f-53f0-4163-82fc-edf563aa6550",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/diurnal-warmlayer-events-in-the-western-mediterranean-and-european-shelf-seas(e990813f-53f0-4163-82fc-edf563aa6550).html",
        "abstract": "<p>We characterize near-surface ocean diurnal warm-layer events, using satellite observations and fields from numerical weather forecasting. The study covers April to September, 2006, over the area 11 degrees W to 17 degrees E and 35 degrees N to 57 degrees N, with 0.1 degrees cells. We use hourly satellite SSTs from which peak amplitudes of diurnal cycles in SST (dSSTs) can be estimated with error similar to 0.3 K. The diurnal excursions of SST observed are spatially and temporally coherent. The largest dSSTs exceed 6 K, affect 0.01% of the surface, and are seen in the Mediterranean, North and Irish Seas. There is an anti-correlation between the magnitude and the horizontal length scale of dSST events. Events wherein dSST exceeds 4 K have length scales of &lt;= 40 km. From the frequency distribution of different measures of wind-speed minima, we infer that extreme dSST maxima arise where conditions of low wind speed are sustained from early morning to mid afternoon.</p>",
        "title": "Diurnal warm-layer events in the western Mediterranean and European shelf seas",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Mark Filipiak",
                "uuid": "7fb933f2-e8ff-4659-853f-af1e744c64b3"
            }
        ]
    },
    "dbae068c-7346-4da6-88a7-28e7f455137e": {
        "id": "dbae068c-7346-4da6-88a7-28e7f455137e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/measurement-of-the-w-boson-mass-and-width-at-lep2(dbae068c-7346-4da6-88a7-28e7f455137e).html",
        "abstract": "<p>The measurement of the mass of the W boson at the LEP2 collider is described, in particular the technique of direct reconstruction. Preliminary results are presented using data collected at centre of mass energies up to 207 GeV.</p>",
        "title": "Measurement of the W boson mass and width at LEP2",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Jeremy Nowell",
                "uuid": "e49ae91a-da25-4b77-b84d-f231a8b0615a"
            }
        ]
    },
    "3ba77b42-9ac6-445f-8bbc-b7d5eb33d059": {
        "id": "3ba77b42-9ac6-445f-8bbc-b7d5eb33d059",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/practical-steps-to-digital-organism-models-from-laboratory-model-species-to-crops-in-silico(3ba77b42-9ac6-445f-8bbc-b7d5eb33d059).html",
        "abstract": "A recent initiative named '<i>Crops in silico'</i>\u00a0proposes that multi-scale models \u201chave the potential to fill in missing mechanistic details and generate new hypotheses to prioritize directed engineering efforts\u201d in plant science, particularly directed to crop species. To that end, the group called for \u201ca paradigm shift in plant modelling, from largely isolated efforts to a connected community\u201d (Marshall-Colon et al., 2017). \u2018Wet\u2019 (experimental) research has been especially productive in plant science, since the adoption of <i>Arabidopsis thaliana</i> as a laboratory model species allowed the emergence of an Arabidopsis research community. Parts of this community invested in \u2018dry\u2019 (theoretical) research, under the rubric of Systems Biology. Our past research combined concepts from systems biology and crop modelling (Chew et al., 2017; Chew et al., 2014b). Here we outline the approaches that seem most relevant to connected, \u2018digital organism\u2019 initiatives. We illustrate the scale of experimental research required, by collecting the kinetic parameter values that are required for a quantitative, dynamic model of a gene regulatory network. By comparison to the SBML community, we note computational resources and community structures that will help to realise the potential for plant systems biology to connect with a broader crop science community.",
        "title": "Practical steps to digital organism models, from laboratory model species to \u2018Crops <i>in silico</i>\u2019",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            }
        ]
    },
    "9df9ffb3-7068-447e-bcf1-05c2fb9687ec": {
        "id": "9df9ffb3-7068-447e-bcf1-05c2fb9687ec",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-multimodel-framework-for-the-arabidopsis-life-cycle(9df9ffb3-7068-447e-bcf1-05c2fb9687ec).html",
        "abstract": "Linking our understanding of biological processes at different scales is a major conceptual challenge in biology, which is aggravated by differences in research methods. Modelling can be a useful approach to consolidating our understanding across traditional research domains. The laboratory model species Arabidopsis thaliana is very widely used to study plant growth processes and has also been tested more recently in eco-physiology and population genetics. However, approaches from crop modelling that might link these domains are rarely applied to Arabidopsis. Here, we combine plant growth models with phenology models from eco-physiology, using the agent-based modelling language Chromar. We introduce a simpler Framework Model of vegetative growth for Arabidopsis, FM-lite. By extending this model to include inflorescence and fruit growth and seed dormancy, we present a whole-life-cycle, multi-model FM-life, which allows us to simulate at the population level in various genotype x environment scenarios. Environmental effects on plant growth distinguish between the simulated life history strategies that were compatible with previously-described Arabidopsis phenology. Our results simulate reproductive success that is founded on the broad range of physiological processes familiar from crop models and suggest an approach to simulate evolution directly in future.",
        "title": "A multi-model Framework for the Arabidopsis life cycle",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            }
        ]
    },
    "a7f1df10-24be-4d97-890b-a33d8db1a341": {
        "id": "a7f1df10-24be-4d97-890b-a33d8db1a341",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-multimodel-framework-for-the-arabidopsis-life-cycle(a7f1df10-24be-4d97-890b-a33d8db1a341).html",
        "abstract": "Linking our understanding of biological processes at different scales is a major conceptual challenge in biology, which is aggravated by differences in research methods. Modelling can be a useful approach to consolidating our understanding across traditional research domains. The laboratory model species Arabidopsis thaliana is very widely used to study plant growth processes and has also been tested more recently in eco-physiology and population genetics. However, approaches from crop modelling that might link these domains are rarely applied to Arabidopsis. Here, we combine plant growth models with phenology models from eco-physiology, using the agent-based modelling language Chromar. We introduce a simpler Framework Model of vegetative growth for Arabidopsis, FM-lite. By extending this model to include inflorescence and fruit growth and seed dormancy, we present a whole-life-cycle, multi-model FM-life, which allows us to simulate at the population level in various genotype x environment scenarios. Environmental effects on plant growth distinguish between the simulated life history strategies that were compatible with previously-described Arabidopsis phenology. Our results simulate reproductive success that is founded on the broad range of physiological processes familiar from crop models and suggest an approach to simulate evolution directly in future.",
        "title": "A multi-model Framework for the Arabidopsis life cycle",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            }
        ]
    },
    "d72e0a0f-0564-4f05-b0d8-9daab7370c98": {
        "id": "d72e0a0f-0564-4f05-b0d8-9daab7370c98",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/service-infrastructure-for-crossmatching-distributed-datasets-using-ogsadai-and-tap(d72e0a0f-0564-4f05-b0d8-9daab7370c98).html",
        "abstract": "",
        "title": "Service Infrastructure for Cross-Matching Distributed Datasets Using OGSA-DAI and TAP",
        "keywords": "",
        "authors": [
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            }
        ]
    },
    "b04f905c-911b-41eb-a7e9-88e74ecc6439": {
        "id": "b04f905c-911b-41eb-a7e9-88e74ecc6439",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/defining-the-robust-behaviour-of-the-plant-clock-gene-circuit-with-absolute-rna-timeseries-and-open-infrastructure(b04f905c-911b-41eb-a7e9-88e74ecc6439).html",
        "abstract": "<p>Our understanding of the complex, transcriptional feedback loops in the circadian clock mechanism has depended upon quantitative, timeseries data from disparate sources. We measure clock gene RNA profiles in Arabidopsis thaliana seedlings, grown with or without exogenous sucrose, or in soil-grown plants and in wild-type and mutant backgrounds. The RNA profiles were strikingly robust across the experimental conditions, so current mathematical models are likely to be broadly applicable in leaf tissue. In addition to providing reference data, unexpected behaviours included co-expression of PRR9 and ELF4, and regulation of PRR5 by GI. Absolute RNA quantification revealed low levels of PRR9 transcripts (peak approx. 50 copies cell(-1)) compared with other clock genes, and threefold higher levels of LHY RNA (more than 1500 copies cell(-1)) than of its close relative CCA1. The data are disseminated from BioDare, an online repository for focused timeseries data, which is expected to benefit mechanistic modelling. One data subset successfully constrained clock gene expression in a complex model, using publicly available software on parallel computers, without expert tuning or programming. We outline the empirical and mathematical justification for data aggregation in understanding highly interconnected, dynamic networks such as the clock, and the observed design constraints on the resources required to make this approach widely accessible.</p>",
        "title": "Defining the robust behaviour of the plant clock gene circuit with absolute RNA timeseries and open infrastructure",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "fe9561da-52bf-47d8-92eb-05a979654db3": {
        "id": "fe9561da-52bf-47d8-92eb-05a979654db3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dataintensive-methods-in-astronomy(fe9561da-52bf-47d8-92eb-05a979654db3).html",
        "abstract": "<p>This chapter first briefly outlines the concept of the virtual observatory as a science response to the growing wealth of astronomical data and the increasing requirement to answer scientific questions using astronomical data from multiple sources. Then, it describes two examples of data-intensive applications from astronomy. The first example centers on running photometric classification algorithms on two existing sky survey databases to generate a catalog of quasars, while the second example outlines the derivation of constraints on cosmological parameters via weak gravitational lensing, which is one of the main science drivers for the next generation of sky surveys. This pair of examples illustrates some of the problems faced by modern astronomy, which require the development of new data-intensive methods and the availability of a computational infrastructure on which to run them.</p>",
        "title": "Data-Intensive Methods in Astronomy",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            }
        ]
    },
    "e8eeb874-bfdc-4b9a-9083-f57cd4f00f2a": {
        "id": "e8eeb874-bfdc-4b9a-9083-f57cd4f00f2a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/grid-services-and-microsoft-net(e8eeb874-bfdc-4b9a-9083-f57cd4f00f2a).html",
        "abstract": "",
        "title": "Grid Services and Microsoft .NET",
        "keywords": "",
        "authors": [
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "e9b5045c-3c56-4d86-94b3-147b3c78cf79": {
        "id": "e9b5045c-3c56-4d86-94b3-147b3c78cf79",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/bonfire(e9b5045c-3c56-4d86-94b3-147b3c78cf79).html",
        "abstract": "BonFIRE offers a Future Internet, multi-site, cloud testbed, targeted at the Internet of Services community, that supports large scale testing of applications, services and systems over multiple, geographically distributed, heterogeneous cloud testbeds. The aim of BonFIRE is to provide an infrastructure that gives experimenters the ability to control and monitor the execution of their experiments to a degree that is not found in traditional cloud facilities. The BonFIRE architecture has been designed to support key functionalities such as: resource management; monitoring of virtual and physical infrastructure metrics; elasticity; single document experiment descriptions; and scheduling. As for January 2012 BonFIRE release 2 is operational, supporting seven pilot experiments. Future releases will enhance the offering, including the interconnecting with networking facilities to provide access to routers, switches and bandwidth-on-demand systems. BonFIRE will be open for general use late 2012.",
        "title": "BonFIRE",
        "keywords": "",
        "authors": [
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            }
        ]
    },
    "74aab48b-c707-4e69-a3a9-0e5597d01085": {
        "id": "74aab48b-c707-4e69-a3a9-0e5597d01085",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/tap-service-federation-factory(74aab48b-c707-4e69-a3a9-0e5597d01085).html",
        "abstract": "This paper descriibes a prototype federation service for multiple TAP end-points. Users can create a new TAP resource that allows them to query the federation as it all tables were in a single database.",
        "title": "TAP Service Federation Factory",
        "keywords": "",
        "authors": [
            {
                "name": "Alastair Hume",
                "uuid": "d60b7709-7a8c-48b8-8bd0-8c90f9d0fc6c"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "08143f82-a0f9-45eb-8480-3eaac3a45f86": {
        "id": "08143f82-a0f9-45eb-8480-3eaac3a45f86",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/software-engineering-for-science(08143f82-a0f9-45eb-8480-3eaac3a45f86).html",
        "abstract": "Software Engineering for Science provides an in-depth collection of peer-reviewed chapters that describe experiences with applying software engineering practices to the development of scientific software. It provides a better understanding of how software engineering is and should be practiced, and which software engineering practices are effective for scientific software.<br/><br/>The book starts with a detailed overview of the Scientific Software Lifecycle, and a general overview of the scientific software development process. It highlights key issues commonly arising during scientific software development, as well as solutions to these problems.<br/><br/>The second part of the book provides examples of the use of testing in scientific software development, including key issues and challenges. The chapters then describe solutions and case studies aimed at applying testing to scientific software development efforts.<br/><br/>The final part of the book provides examples of applying software engineering techniques to scientific software, including not only computational modeling, but also software for data management and analysis. The authors describe their experiences and lessons learned from developing complex scientific software in different domains.",
        "title": "Software Engineering for Science",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "07a03497-8e4c-4887-8645-7fe78129524a": {
        "id": "07a03497-8e4c-4887-8645-7fe78129524a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/software-and-data-citation(07a03497-8e4c-4887-8645-7fe78129524a).html",
        "abstract": "This special issue is intended to inform the scientific computing community about recent advances and the current state of the art in software and data citation. Initial work has been done elsewhere to define standards and principles for software and data citation, and the basic required infrastructure is now in place. The challenge now is to adopt these practices. As their uptake increases, we believe that our professional culture will increasingly encourage production and sharing of software and data, leading to better and more reproducible and reusable results. The articles in this special issue discuss how software, data, and related digital objects are cited and otherwise mentioned in publications today, how to best cite them to make them accessible in the future, and what we can learn from the citations.",
        "title": "Software and Data Citation",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "f7e502b4-ddd7-4954-aaf1-30a0257a28b2": {
        "id": "f7e502b4-ddd7-4954-aaf1-30a0257a28b2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/general-chairs-welcome-message(f7e502b4-ddd7-4954-aaf1-30a0257a28b2).html",
        "abstract": "I am delighted to welcome you to Brussels for Grid 2010, the 11th IEEE/ACM International Conference on Grid Computing. The Grid conference series is an annual international meeting that brings together a community of researchers, developers, practitioners, and users involved with Grid and related technology. This meeting serves as both the premier venue for presenting foremost research results in the area and as a forum for introducing and exploring new concepts.",
        "title": "General chair's welcome message",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "ea2bda83-d08c-40e6-a957-fe72880927c5": {
        "id": "ea2bda83-d08c-40e6-a957-fe72880927c5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/towards-fair-principles-for-research-software(ea2bda83-d08c-40e6-a957-fe72880927c5).html",
        "abstract": "The FAIR Guiding Principles, published in 2016, aim to improve the findability, accessibility, interoperability and reusability of digital research objects for both humans and machines. Until now the FAIR principles have been mostly applied to research data. The ideas behind these principles are, however, also directly relevant to research software. Hence there is a distinct need to explore how the FAIR principles can be applied to software. In this work, we aim to summarize the current status of the debate around FAIR and software, as a basis for the development of definite community-agreed principles for FAIR research software in the future. We discuss what makes software different from data with respect to the application of the FAIR principles, present an analysis of where the existing principles can directly be applied to software, where they need to be adapted or reinterpreted, and where the definition of additional principles is required. Furthermore, we discuss desired characteristics of research software that go beyond FAIR.",
        "title": "Towards FAIR principles for research software",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "526a3a50-d78a-42eb-ab0c-933d49beac12": {
        "id": "526a3a50-d78a-42eb-ab0c-933d49beac12",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-four-pillars-of-research-software-engineering(526a3a50-d78a-42eb-ab0c-933d49beac12).html",
        "abstract": "Software is now of great importance in almost all areas of research. With the growing complexity of software and computer hardware, the individuals who write research software have increasingly specialist skill sets that take time to develop and maintain. These individuals are generally unable to follow a standard academic career path since their focus on software does not provide the necessary research credit to enable this. The Research Software Engineering movement, which started in the UK and has been built up over the last few years, aims to recognise and support these individuals. We believe that an effective and sustainable model for providing Research Software Engineering capabilities is about more than just building software. In this article we present a model, along with supporting evidence of real-world activities, that defines the aspects that we believe are key to providing comprehensive and sustainable support for Research Software Engineering.",
        "title": "The Four Pillars of Research Software Engineering",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "ee908f7c-d9bb-4423-902f-d5885702176d": {
        "id": "ee908f7c-d9bb-4423-902f-d5885702176d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/building-a-sustainable-structure-for-research-software-engineering-activities(ee908f7c-d9bb-4423-902f-d5885702176d).html",
        "abstract": "The profile of research software engineering has been greatly enhanced by developments at institutions around the world to form groups and communities that can support effective, sustainable development of research software. We observe, however, that there is still a long way to go to build a clear understanding about what approaches provide the best support for research software developers in different contexts, and how such understanding can be used to suggest more formal structures, models or frameworks that can help to further support the growth of research software engineering. This paper sets out some preliminary thoughts and proposes an initial high- level model based on discussions between the authors around the concept of a set of pillars representing key activities and processes that form the core structure of a successful research software engineering offering.",
        "title": "Building a Sustainable Structure for Research Software Engineering Activities",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "16e0db96-0510-412d-938c-00de737187d1": {
        "id": "16e0db96-0510-412d-938c-00de737187d1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/to-achieve-the-goals-of-escience-we-must-change-research-culture-globally(16e0db96-0510-412d-938c-00de737187d1).html",
        "abstract": "The e-Science programme was initiated in the United Kingdom in the early 2000\u2019s with the aim of bringing together researchers in large scale, collaborative projects involving software and computation to solve grand challenges. A legacy of this programme has been an understanding of the importance of the people behind the software, the researchers and research software engineers, as well as the challenges of developing and maintaining code that is reusable given the problems of software decay.<br/><br/>The Software Sustainability Institute has been established in the United Kingdom to provide support and direction for the research software community through consultancy, training, engagement and policy campaigns. Through this it has worked with an international community of collaborators, in the UK, in Europe and across the world to support reusability, research integrity and transparency recognising that to achieve the goals of e-Science, we must change research culture globally.",
        "title": "To achieve the goals of e-Science, we must change research culture globally",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "e9bf65e2-6e8f-4a1c-aa6a-20b5e4b17299": {
        "id": "e9bf65e2-6e8f-4a1c-aa6a-20b5e4b17299",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/community-organizations-changing-the-culture-in-which-research-software-is-developed-and-sustained(e9bf65e2-6e8f-4a1c-aa6a-20b5e4b17299).html",
        "abstract": "Software is the key crosscutting technology that enables advances in mathematics, computer science, and domain-specific science and engineering to achieve robust simulations and analysis for science, engineering, and other research fields. However, software itself has not traditionally received focused attention from research communities; rather, software has evolved organically and inconsistently, with its development largely as by-products of other initiatives. Moreover, challenges in scientific software are expanding due to disruptive changes in computer hardware, increasing scale and complexity of data, and demands for more complex simulations involving multiphysics, multiscale modeling and outer-loop analysis. In recent years, community members have established a range of grass-roots organizations and projects to address these growing technical and social challenges in software productivity, quality, reproducibility, and sustainability. This article provides an overview of such groups and discusses opportunities to leverage their synergistic activities while nurturing work toward emerging software ecosystems.",
        "title": "Community Organizations: Changing the Culture in Which Research Software Is Developed and Sustained",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "17a0f7f2-58d3-4b14-97df-97249aa729cb": {
        "id": "17a0f7f2-58d3-4b14-97df-97249aa729cb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/software-citation-in-theory-and-practice(17a0f7f2-58d3-4b14-97df-97249aa729cb).html",
        "abstract": "In most fields, computational models and data analysis have become a significant part of how research is performed, in addition to the more traditional theory and experiment. Mathematics is no exception to this trend. While the system of publication and credit for theory and experiment (journals and books, often monographs) has developed and has become an expected part of the culture, how research is shared and how candidates for hiring, promotion are evaluated, software (and data) do not have the same history. A group working as part of the FORCE11 community developed a set of principles for software citation that fit software into the journal citation system, allow software to be published and then cited, and there are now over 50,000 DOIs that have been issued for software. However, some challenges remain, including: promoting the idea of software citation to developers and users; collaborating with publishers to ensure that systems collect and retain required metadata; ensuring that the rest of the scholarly infrastructure, particularly indexing sites, include software; working with communities so that software efforts \u201ccount\u201d; and understanding how best to cite software that has not been published.",
        "title": "Software Citation in Theory and Practice",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "9545e678-3674-4870-925d-8d6c64ea4dfb": {
        "id": "9545e678-3674-4870-925d-8d6c64ea4dfb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-4th-international-workshop-on-software-engineering-for-hpc-in-computational-science-and-engineering(9545e678-3674-4870-925d-8d6c64ea4dfb).html",
        "abstract": "<p>Despite the increasing demand for utilizing high-performance computing (HPC) for CSE applications, software development for HPC historically attracted little attention from the software engineering (SE) community. Paradoxically, the HPC CSE community has increasingly been adopting SE techniques and tools. Indeed, the development of CSE software for HPC differs significantly from the development of more traditional business information systems, from which many SE best practices and tools have been drawn. The workshop summarized in this column, the fourth in the series to be collocated with the Supercomputing conference series, examined two main topics: testing and tradeoffs. Through presentations of work in this area and structured group discussions, the participants highlighted some of the key issues, as well as indicated the direction the community needs to go. In particular, there is a need for more high-quality research in this area that we can use as an evidence base to help developers of CSE applications change practice and benefit from advances in software engineering.</p>",
        "title": "The 4th International Workshop on Software Engineering for HPC in Computational Science and Engineering",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "11961d5c-0da6-4372-9e17-6fb9b27a91a5": {
        "id": "11961d5c-0da6-4372-9e17-6fb9b27a91a5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-global-impact-of-science-gateways-virtual-research-environments-and-virtual-laboratories(11961d5c-0da6-4372-9e17-6fb9b27a91a5).html",
        "abstract": "Science gateways, virtual laboratories and virtual research environments are all terms used to refer to community-developed digital environments that are de- signed to meet a set of needs for a research community. Specifically, they refer to integrated access to research community resources including software, data, col- laboration tools, workflows, instrumentation and high-performance computing, usually via Web and mobile applications. Science gateways, virtual laboratories and virtual research environments are enabling significant contributions to many research domains, facilitating more efficient, open, reproducible research in bold new ways. This paper explores the global effect of these programs in increasing research impact, demonstrates their value in the broader digital landscape and discusses future opportunities.<br/>",
        "title": "The Global Impact of Science Gateways, Virtual Research Environments and Virtual Laboratories",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "2e55d157-d549-47ff-bb97-4a1485eeb277": {
        "id": "2e55d157-d549-47ff-bb97-4a1485eeb277",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/why-do-we-need-to-compare-research-software-and-how-should-we-do-it(2e55d157-d549-47ff-bb97-4a1485eeb277).html",
        "abstract": "How can we measure research software? Is it possible to compare it, given the myriad different research domains, practices and pieces of software? Do we even need to do this, and what benefits might it bring? This position paper sets out the reasons for why different stakeholders, from users to developers to funders, might wish to undertake this difficult task, and describes a proposed framework for doing so (based around measures of accessibility, usability, maintainability and portability) which takes into account the possibility of variation between different communities about how they prioritise different aspects of research software.",
        "title": "Why do we need to compare research software, and how should we do it?",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "1938a4c1-f371-48d7-8b8b-2bda979519e5": {
        "id": "1938a4c1-f371-48d7-8b8b-2bda979519e5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/fourth-workshop-on-sustainable-software-for-science-practice-and-experiences-wssspe4(1938a4c1-f371-48d7-8b8b-2bda979519e5).html",
        "abstract": "This article summarizes motivations, organization, and activities of the Fourth Workshop on Sustainable Software for Science: Practice and Experiences (WSSSPE4). The WSSSPE series promotes sustainable research software by positively impacting principles and best practices, careers, learning, and credit. This article discusses the code of conduct; the mission and vision statements that were drafted at the workshop and finalized shortly after it; the keynote and idea papers, position papers, experience papers, demos, and lightning talks presented during the workshop; and a panel discussion on best practices. The main part of the article discusses the set of working groups that formed during the meeting, along with contact information for readers who may want to join a group. Finally, it discusses a survey of the workshop attendees.",
        "title": "Fourth Workshop on Sustainable Software for Science: Practice and Experiences (WSSSPE4)",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "c55b1d91-2ad5-4f6a-8df7-bc319994aa2e": {
        "id": "c55b1d91-2ad5-4f6a-8df7-bc319994aa2e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/four-simple-recommendations-to-encourage-best-practices-in-research-software-version-1-referees-3-approved(c55b1d91-2ad5-4f6a-8df7-bc319994aa2e).html",
        "abstract": "<p>Scientific research relies on computer software, yet software is not always developed following practices that ensure its quality and sustainability. This manuscript does not aim to propose new software development best practices, but rather to provide simple recommendations that encourage the adoption of existing best practices. Software development best practices promote better quality software, and better quality software improves the reproducibility and reusability of research. These recommendations are designed around Open Source values, and provide practical suggestions that contribute to making research software and its source code more discoverable, reusable and transparent. This manuscript is aimed at developers, but also at organisations, projects, journals and funders that can increase the quality and sustainability of research software by encouraging the adoption of these recommendations.</p>",
        "title": "Four simple recommendations to encourage best practices in research software  [version 1; referees: 3 approved]",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "dd22bf2b-cfd5-4c3e-88ec-ab1fad813d0b": {
        "id": "dd22bf2b-cfd5-4c3e-88ec-ab1fad813d0b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/message-from-the-workshop-chairs-se4science-2017(dd22bf2b-cfd5-4c3e-88ec-ab1fad813d0b).html",
        "abstract": "",
        "title": "Message from the Workshop Chairs SE4Science 2017",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "f6fda77c-6cc4-497d-bf69-17062619503d": {
        "id": "f6fda77c-6cc4-497d-bf69-17062619503d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/introducing-distributed-dynamic-dataintensive-d3-science-understanding-applications-and-infrastructure(f6fda77c-6cc4-497d-bf69-17062619503d).html",
        "abstract": "A common feature across many science and engineering applications is the amount and diversity of data and computation that must be integrated to yield insights. Datasets are growing larger and becoming distributed; their location, availability, and properties are often time-dependent. Collectively, these characteristics give rise to dynamic distributed data-intensive applications. While \u201cstatic\u201d data applications have received significant attention, the characteristics, requirements, and software systems for the analysis of large volumes of dynamic, distributed data, and data-intensive applications have received relatively less attention. This paper surveys several representative dynamic distributed data-intensive application scenarios, provides a common conceptual framework to understand them, and examines the infrastructure used in support of applications.",
        "title": "Introducing distributed dynamic data-intensive (D3) science: Understanding applications and infrastructure",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "97ad23d6-1e56-4d75-a35e-ae1c3428d20d": {
        "id": "97ad23d6-1e56-4d75-a35e-ae1c3428d20d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/making-it-easier-to-understand-research-software-impact(97ad23d6-1e56-4d75-a35e-ae1c3428d20d).html",
        "abstract": "<p>How can we make it easier to understand research software impact? Is it easy for new researchers to start research in this area? In particular, are the tools available that would let them generate the research that we as the research software community require to convince our funders, fellow researchers and the public at large that having sustainable, open-use research software is important?</p>",
        "title": "Making it easier to understand research software impact",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "db705b6b-a43e-4afe-8705-e26bb46826e9": {
        "id": "db705b6b-a43e-4afe-8705-e26bb46826e9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/message-from-the-workshop-chairs(db705b6b-a43e-4afe-8705-e26bb46826e9).html",
        "abstract": "",
        "title": "Message from the workshop chairs",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "2e1411fb-a6a4-439b-b085-99d563231bd6": {
        "id": "2e1411fb-a6a4-439b-b085-99d563231bd6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/top-10-metrics-for-life-science-software-good-practices-version-1-referees-2-approved(2e1411fb-a6a4-439b-b085-99d563231bd6).html",
        "abstract": "Metrics for assessing adoption of good development practices are a useful way to ensure that software is sustainable, reusable and functional. Sustainability means that the software used today will be available - and continue to be improved and supported - in the future.<br/>We report here an initial set of metrics that measure good practices in software development. This initiative differs from previously developed efforts in being a community-driven grassroots approach where experts from different organisations propose good software practices that have reasonable potential to be adopted by the communities they represent. We not only focus our efforts on understanding and prioritising good practices, we assess their feasibility for implementation and publish them here.",
        "title": "Top 10 metrics for life science software good practices [version 1; referees: 2 approved]",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "e4fb8e09-a266-4fa1-a066-5a8ad6b36a7a": {
        "id": "e4fb8e09-a266-4fa1-a066-5a8ad6b36a7a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/preliminary-analysis-of-a-survey-of-research-software-engineers-in-the-uk(e4fb8e09-a266-4fa1-a066-5a8ad6b36a7a).html",
        "abstract": "This paper presents results from a survey conducted on a new role in academia: the Research Software Engineer (RSE). The survey provides much needed demographic information about the education, field, gender, job satisfaction and career plans of the people of RSEs. The community is found to be highly educated, derive mainly from the hard sciences, and to be predominantly male. Respondents report satisfaction in their jobs, but indicate that career progression is both difficult and opaque.<br/><br/>This paper supports a continued discussion about the experience of RSEs and recommends further investigation into this important community.",
        "title": "Preliminary analysis of a survey of Research Software Engineers in the UK",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "935263cd-5a53-4949-96fd-a1b7e9e08de9": {
        "id": "935263cd-5a53-4949-96fd-a1b7e9e08de9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/se4hpcs15(935263cd-5a53-4949-96fd-a1b7e9e08de9).html",
        "abstract": "<p>HPC software is developed and used in a wide variety of scientific domains including nuclear physics, computational chemistry, crash simulation, satellite data processing, fluid dynamics, climate modeling, bioinformatics, and vehicle development. The increase in the importance of this software motivates the need to identify and understand appropriate software engineering (SE) practices for HPC architectures. Because of the variety of the scientific domains addressed using HPC, existing SE tools and techniques developed for the business/IT community are often not efficient or effective. Appropriate SE solutions must account for the salient characteristics of the HPC, research oriented development environment. This situation creates a need for members of the SE community to interact with members of the scientific and HPC communities to address this need. This workshop facilitates that collaboration by bringing together members of the SE, the scientific, and the HPC communities to share perspectives and present findings relevant to research, practice, and education. A significant portion of the workshop is devoted to focused interaction among the participants with the goal of generating a research agenda to improve tools, techniques, and experimental methods regarding SE for HPC science.</p>",
        "title": "SE4HPCS'15",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "d7944207-d8f0-42c7-b740-9ca3be4268cd": {
        "id": "d7944207-d8f0-42c7-b740-9ca3be4268cd",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/gridbased-metadata-services(d7944207-d8f0-42c7-b740-9ca3be4268cd).html",
        "abstract": "Data sets being managed in grid environments today are growing at a rapid rate, expected to reach 100s of petabytes in the near future. Managing such large data sets poses challenges for efficient data access, data publication and data discovery. In this paper we focus on the data publication and discovery process through the use of descriptive metadata. This metadata describe the properties of individual data items and collections. We discuss issues of metadata services in service rich environments, such as the grid. We describe the requirements and the architecture for such services in the context of grid and the available grid services. We present a data model that can capture the complexity of the data publication and discovery process. Based on that model we identify a set of interfaces and operations that need to be provided to support metadata management. We present a particular implementation of a grid metadata service, basing it on existing grid services technologies. Finally we examine alternative implementations of that service.",
        "title": "Grid-based metadata services",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "e23f5838-1ef9-42eb-9857-b1fe2e67aec0": {
        "id": "e23f5838-1ef9-42eb-9857-b1fe2e67aec0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hapbin-an-efficient-program-for-performing-haplotype-based-scans-for-positive-selection-in-large-genomic-datasets(e23f5838-1ef9-42eb-9857-b1fe2e67aec0).html",
        "abstract": "Understanding how the genome is shaped by selective processes forms an integral part of modern biology. However, as genomic datasets continue to grow larger it is becoming increasingly difficult to apply traditional statistics for detecting signatures of selection to these cohorts. There is therefore a pressing need for the development of the next generation of computational and analytical tools for detecting signatures of selection in large genomic datasets. Here we present hapbin, an efficient multi-threaded implementation of extended haplotype homzygosity based statistics for detecting selection, which is up to 3,400 times faster than the current fastest implementations of these algorithms.",
        "title": "hapbin: An efficient program for performing haplotype based scans for positive selection in large genomic datasets.",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "418fc26d-55ab-440f-8845-57887c4ed3fe": {
        "id": "418fc26d-55ab-440f-8845-57887c4ed3fe",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-open-science-peer-review-oath(418fc26d-55ab-440f-8845-57887c4ed3fe).html",
        "abstract": "One of the foundations of the scientific method is to be able to reproduce experiments and corroborate the results of research that has been done before. However, with the increasing complexities of new technologies and techniques, coupled with the specialisation of experiments, reproducing research findings has become a growing challenge. Clearly, scientific methods must be conveyed succinctly, and with clarity and rigour, in order for research to be reproducible. Here, we propose steps to help increase the transparency of the scientific method and the reproducibility of research results: specifically, we introduce a peer-review oath and accompanying manifesto. These have been designed to offer guidelines to enable reviewers (with the minimum friction or bias) to follow and apply open science principles, and support the ideas of transparency, reproducibility and ultimately greater societal impact. Introducing the oath and manifesto at the stage of peer review will help to check that the research being published includes everything that other researchers would need to successfully repeat the work. Peer review is the lynchpin of the publishing system: encouraging the community to consciously (and conscientiously) uphold these principles should help to improve published papers, increase confidence in the reproducibility of the work and, ultimately, provide strategic benefits to authors and their institutions.",
        "title": "An Open Science Peer Review Oath",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "6fdc09b0-1283-4124-a0bb-a86a86d4b895": {
        "id": "6fdc09b0-1283-4124-a0bb-a86a86d4b895",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/software-the-hidden-infrastructure-behind-the-worlds-largest-scientific-facilities(6fdc09b0-1283-4124-a0bb-a86a86d4b895).html",
        "abstract": "",
        "title": "Software: the hidden infrastructure behind the world's largest scientific facilities",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "ab933c42-a792-4d25-9bfb-140956dbbeac": {
        "id": "ab933c42-a792-4d25-9bfb-140956dbbeac",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cough-up-money-for-software-or-fall-behind-in-science-ranks(ab933c42-a792-4d25-9bfb-140956dbbeac).html",
        "abstract": "",
        "title": "Cough up money for software or fall behind in science ranks",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "ecb31402-e1d3-4b17-841d-9fad15d5ec9c": {
        "id": "ecb31402-e1d3-4b17-841d-9fad15d5ec9c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dealing-with-software-the-research-data-issues(ecb31402-e1d3-4b17-841d-9fad15d5ec9c).html",
        "abstract": "Software underpins much of the scientific research undertaken today. As well as the \u201ctraditional\u201d use of software for modelling and simulation, it is used to manage and control instruments, and analyse and visualise data. This permeation of the use of software into the mainstream of research across all disciplines has meant that it is increasingly difficult to reproduce and reuse the work of other researchers. The reproducible research principle requires the full computational environment to be published as well as the paper where the results are reported. This raises the question of whether the current data management policies and infrastructure provided by universities such as Edinburgh are capable of handling software as a digital research output through its lifecycle.",
        "title": "Dealing With Software: the Research Data Issues",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "1f08b875-5366-40ed-b57a-ee730e84bc1d": {
        "id": "1f08b875-5366-40ed-b57a-ee730e84bc1d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/digital-preservation-and-curation-the-danger-of-overlooking-software(1f08b875-5366-40ed-b57a-ee730e84bc1d).html",
        "abstract": "",
        "title": "Digital preservation and curation: the danger of overlooking software",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "1db79b21-67bc-4fda-9909-22dcedf26a3f": {
        "id": "1db79b21-67bc-4fda-9909-22dcedf26a3f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/minimal-information-for-reusable-scientific-software(1db79b21-67bc-4fda-9909-22dcedf26a3f).html",
        "abstract": "One of the biggest challenges for developers of scientific software is understanding how best to make the software reusable. A particular problem is that the concept of reusability combines many different concerns, including whether the software can be reused, how it can be reused, and by whom. This paper looks at the concept of software reusability from the perspective of the software engineer and the researcher. It proposes a multi-level framework for improving the reusability of scientific software, which minimises the information and effort required such that it is easier for scientific software developers, who are often researchers, to provide appropriate levels of information to support reuse.",
        "title": "Minimal information for reusable scientific software",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "0cf8bbae-e5ee-4832-9b5a-36c755372da1": {
        "id": "0cf8bbae-e5ee-4832-9b5a-36c755372da1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-roadmap-for-cagrid-an-enterprise-grid-architecture-for-biomedical-research(0cf8bbae-e5ee-4832-9b5a-36c755372da1).html",
        "abstract": "CaGrid is a middleware system which combines the Grid computing, the service oriented architecture, and the model driven architecture paradigms to support development of interoperable data and analytical resources and federation of such resources in a Grid environment. The functionality provided by caGrid is an essential and integral component of the cancer Biomedical Informatics Grid (caBIG) program. This program is established by the National Cancer Institute as a nationwide effort to develop enabling informatics technologies for collaborative, multi-institutional biomedical research with the overarching goal of accelerating translational cancer research. Although the main application domain for caGrid is cancer research, the infrastructure provides a generic framework that can be employed in other biomedical research and healthcare domains. The development of caGrid is an ongoing effort, adding new functionality and improvements based on feedback and use cases from the community. This paper provides an overview of potential future architecture and tooling directions and areas of improvement for caGrid and caGrid-like systems. This summary is based on discussions at a roadmap workshop held in February with participants from biomedical research, Grid computing, and high performance computing communities.",
        "title": "A roadmap for caGrid, an enterprise Grid architecture for biomedical research.",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "1fc5e2c7-6318-440a-b2e1-eb5bcf1c2fd8": {
        "id": "1fc5e2c7-6318-440a-b2e1-eb5bcf1c2fd8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/software-papers-improving-the-reusability-and-sustainability-of-scientific-software(1fc5e2c7-6318-440a-b2e1-eb5bcf1c2fd8).html",
        "abstract": "In this paper, we describe the Journal of Open Research Software, <br/>a software metajournal which features peer reviewed software <br/>papers describing research software with high reuse potential. We <br/>posit that the use of software papers improves the sustainability of <br/>scientific software by making them discoverable and citable, as <br/>well as asking them questions about the metadata required to use <br/>and reuse the software easily. <br/>",
        "title": "Software Papers: improving the reusability and sustainability of scientific software",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "8e6f3e01-6689-465b-abec-303878f763c3": {
        "id": "8e6f3e01-6689-465b-abec-303878f763c3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/best-practices-for-scientific-computing(8e6f3e01-6689-465b-abec-303878f763c3).html",
        "abstract": "Scientists spend an increasing amount of time building and using software. However, most scientists are never taught how to do this efficiently. As a result, many are unaware of tools and practices that would allow them to write more reliable and maintainable code with less effort. We describe a set of best practices for scientific software development that have solid foundations in research and experience, and that improve scientists' productivity and the reliability of their software.",
        "title": "Best Practices for Scientific Computing",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "01d687d9-42eb-4bf1-a147-cc11431a990e": {
        "id": "01d687d9-42eb-4bf1-a147-cc11431a990e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/eirg-policy-paper-on-scientific-software(01d687d9-42eb-4bf1-a147-cc11431a990e).html",
        "abstract": "With the successful establishment of a European e-Infrastructure ecosystem, the question of how to maintain and improve the scientific software base has become an urgent issue. This ecosystem has been built through recent leadership projects such as EGI and PRACE, combined with significant efforts on national levels. Many applications depend on legacy software that is difficult to maintain and difficult to run efficiently on current and future e-Infrastructures. There is a clear need for a coherent process and major efforts targeted towards enhancing the European software base for efficient use of European e-Infrastructures to increase the scientific output while ensuring the best value for money. The need for actions in this area has also been acknowledged globally and, e.g. in the US, significant funding programs targeting scientific software have been initiated.",
        "title": "e-IRG Policy Paper on Scientific Software",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "1a64b910-c29b-457e-aa7a-2656674edd3f": {
        "id": "1a64b910-c29b-457e-aa7a-2656674edd3f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/doingscienceproperlyinthedigital-age(1a64b910-c29b-457e-aa7a-2656674edd3f).html",
        "abstract": "",
        "title": "Doing\u00a0Science\u00a0Properly\u00a0in\u00a0the\u00a0Digital Age",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "ab6130c6-aee6-4972-9256-8ea0eb1862c9": {
        "id": "ab6130c6-aee6-4972-9256-8ea0eb1862c9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/where-does-it-go-from-here-the-place-of-software-in-digital-repositories(ab6130c6-aee6-4972-9256-8ea0eb1862c9).html",
        "abstract": "The open repositories community has made great strides in recent years in addressing interoperability, policy and providing the arguments for open access and sharing. One aspect of open research which has come to prominence is the importance of software as a fundamental part of reproducible research, which in turn raises issues around the preservation of software.<br/><br/>In this short paper, I will describe some of the work that the Software Sustainability Institute (SSI) has been doing to address the structural and policy issues which currently present a barrier to the deposit and use of software in open repositories.",
        "title": "Where does it go from here? The place of software in digital repositories",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "200ad653-3e21-49d2-beae-4dcb581ea934": {
        "id": "200ad653-3e21-49d2-beae-4dcb581ea934",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/digital-preservation-and-curation-the-danger-of-overlooking-software(200ad653-3e21-49d2-beae-4dcb581ea934).html",
        "abstract": "Software is often overlooked when considering the wider requirements for preserving digital outputs. A key challenge in digital preservation is being able to articulate, and ideally prove, the need for preservation. The Software Sustainability Institute in partnership with Curtis+Cartwright Consulting have published a series of outputs to support the sector by raising awareness of software sustainability and preservation issues. This chapter summarises some of the advice set out in the Software Preservation Benefits Framework that has been developed which can help groups understand and gauge the benefits or drawbacks of allocating effort to ensuring that preservation measures are built into processes and to promote actively preserving legacy software. This identifies four key purposes, and seven different approaches, to preserving software. In this way, important software can be preserved for future generations.",
        "title": "Digital Preservation and Curation: The Danger of Overlooking Software",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "6c76074a-db4f-42f8-ae16-e483953f1fec": {
        "id": "6c76074a-db4f-42f8-ae16-e483953f1fec",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/rapport-running-scientific-highperformance-computing-applications-on-the-cloud(6c76074a-db4f-42f8-ae16-e483953f1fec).html",
        "abstract": "<p>Cloud computing infrastructure is now widely used in many domains, but one area where there has been more limited adoption is research computing, in particular for running scientific high-performance computing (HPC) software. The Robust Application Porting for HPC in the Cloud (RAPPORT) project took advantage of existing links between computing researchers and application scientists in the fields of bioinformatics, high-energy physics (HEP) and digital humanities, to investigate running a set of scientific HPC applications from these domains on cloud infrastructure. In this paper, we focus on the bioinformatics and HEP domains, describing the applications and target cloud platforms. We conclude that, while there are many factors that need consideration, there is no fundamental impediment to the use of cloud infrastructure for running many types of HPC applications and, in some cases, there is potential for researchers to benefit significantly from the flexibility offered by cloud platforms.</p>",
        "title": "RAPPORT: running scientific high-performance computing applications on the cloud",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "0e55d36f-d55f-4369-bc7b-3d8ac9dda321": {
        "id": "0e55d36f-d55f-4369-bc7b-3d8ac9dda321",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/evaluating-the-suitability-of-mapreduce-for-surface-temperature-analysis-codes(0e55d36f-d55f-4369-bc7b-3d8ac9dda321).html",
        "abstract": "Processing large volumes of scientific data requires an efficient and scalable parallel computing framework to obtain meaningful information quickly. In this paper,  we evaluate a scientific application from the environmental sciences for its suitability to use the MapReduce framework. We consider cccgistemp  \u2013  a Python reimplementation of the original NASA GISS model for estimating global temperature change  \u2013 which takes land and ocean temperature records from different sites, removes duplicate records, and adjusts for urbanisation effects before calculating the 12 month running mean global temperature. The application consists of several stages, each displaying differing characteristics, and three stages have been ported to use Hadoop with the mrjob library. We note performance bottlenecks encountered while porting and suggest possible solutions, including modification of data access patterns to overcome uneven distribution of input data.",
        "title": "Evaluating the suitability of MapReduce for surface temperature analysis codes",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "a3c74ca7-0eeb-41bb-b72a-f10c27b93877": {
        "id": "a3c74ca7-0eeb-41bb-b72a-f10c27b93877",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-workshop-series-for-gridrepository-integration(a3c74ca7-0eeb-41bb-b72a-f10c27b93877).html",
        "abstract": "",
        "title": "A Workshop Series for Grid/Repository Integration",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "acb9ec8f-9557-43c6-b88c-324d70a5de15": {
        "id": "acb9ec8f-9557-43c6-b88c-324d70a5de15",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/einfrastructure-tool-for-the-elite-or-tool-for-everybody-uk-escience-technical-report-series(acb9ec8f-9557-43c6-b88c-324d70a5de15).html",
        "abstract": "A Birds of a Feather (BoF) meeting brought together more than 70 interested participants of the e Science All Hands Meeting 2008 to consider questions and issues arising from the proposition: \u201ce-Infrastructure: tool for the elite or tool for everybody?\u201d Contrasting position statements from two practitioners in the field set the scene for multiple break-out groups to debate several questions derived from the proposition, concerning the nature, use and evolution of e-Infrastructure. Results showed considerable commonality of thought among the break-out groups, with 7 broad categories of response emerging. These categories were: i) There is no single common e-Infrastructure; ii) Ease of use is the initial barrier; iii) Dealing with complexity is complex; iv) Trust is important; v) Open development is necessary; vi) Give credit for digital creation; and vii) Attitudes must be changed. Within each of the categories a number of detailed points were collected. The results accord well with findings from interviews conducted by the ENGAGE project; namely that people will tend to prioritise ease of use, support and continued development over a complete feature set. This requires a sustainable community around the software and trust by the users in the e-Infrastructure providers (and vice-versa).",
        "title": "e-Infrastructure: tool for the elite or tool for everybody? UK e-Science Technical Report Series",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "a001f761-d658-475f-ade1-da7806ef2b53": {
        "id": "a001f761-d658-475f-ade1-da7806ef2b53",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cyberinfrastructure-software-sustainability-and-reusability-report-from-an-nsffunded-workshop-held-27--28-march-2009(a001f761-d658-475f-ade1-da7806ef2b53).html",
        "abstract": "The National Science Foundation's strategy for 21st century innovation depends on creation of scientific and engineering software. During March of 2009, Indiana University hosted an NSF-funded workshop to examine issues related to creating and maintaining this type of software. This report reflects the activities, discussion, and consensus of the two-day workshop and subsequent research and writing on specific points raised at the workshop.",
        "title": "Cyberinfrastructure Software Sustainability and Reusability: Report from an NSF-funded workshop held 27 &amp; 28 March 2009",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "c6eb8499-db69-4056-b262-ad27026d1a39": {
        "id": "c6eb8499-db69-4056-b262-ad27026d1a39",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/why-good-software-sometimes-dies--and-how-to-save-it(c6eb8499-db69-4056-b262-ad27026d1a39).html",
        "abstract": "This paper explores what it takes to develop digital objects (software but also other products such as workflows or data collections), which are both sustainable and achieve demonstrable uptake and usage. We focus in particular on objects produced in the context of e-Research and on the specific conditions this context brings with it.",
        "title": "Why Good Software Sometimes Dies \u2013 And How to Save It",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "4cef0daf-1b43-4aaa-bf00-24dcd231e261": {
        "id": "4cef0daf-1b43-4aaa-bf00-24dcd231e261",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/software-preservation-benefits-framework(4cef0daf-1b43-4aaa-bf00-24dcd231e261).html",
        "abstract": "An investigation of software preservation has been carried out by Curtis+Cartwright Consulting Limited, in partnership with the Software Sustainability Institute (SSI), on behalf of the JISC. The aim of the study was to raise awareness and build capacity throughout the Further and Higher Education (FE/HE) sector to engage with preservation issues as part of the process of software development. Part of this involved examining the purpose and benefits of employing preservation measures in relation to software, both at the development stage and retrospectively to legacy software. The study built on the JISC-funded \u2018Significant Properties of Software\u2019 study that produced an excellent introduction and comprehensive framework to software preservation. This is a framework document that assists developer groups and their sponsoring bodies to understand and gauge the benefits or disbenefits of allocating effort to: \u2013 ensuring that preservation measures are built into software development processes; \u2013 actively preserving legacy software.",
        "title": "Software Preservation Benefits Framework",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "6d378fa0-b835-47fa-864d-85c1481e3adf": {
        "id": "6d378fa0-b835-47fa-864d-85c1481e3adf",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/managing-and-analysing-genomic-data-using-hpc-and-clouds(6d378fa0-b835-47fa-864d-85c1481e3adf).html",
        "abstract": "Database management techniques using distributed processing services have evolved to address the issues of distributed, heterogeneous data collections held across dynamic, virtual organisations [1-3]. These techniques, originally developed for data grids in domains such as high-energy particle physics [4], have been adapted to make use of the emerging cloud infrastructures [5].",
        "title": "Managing and Analysing Genomic Data using HPC and Clouds",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            },
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "190544c3-9b79-4336-ab79-bba761b12960": {
        "id": "190544c3-9b79-4336-ab79-bba761b12960",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/data-preprocessing-using-ogsadai(190544c3-9b79-4336-ab79-bba761b12960).html",
        "abstract": "",
        "title": "Data Pre-Processing Using OGSA-DAI",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "84ff1e9d-4edf-4d7b-a7b2-5722e154fbc6": {
        "id": "84ff1e9d-4edf-4d7b-a7b2-5722e154fbc6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/software-citation-principles(84ff1e9d-4edf-4d7b-a7b2-5722e154fbc6).html",
        "abstract": "Software is a critical part of modern research and yet there is little support across the scholarly ecosystem for its acknowledgement and citation. Inspired by the activities of the FORCE11 working group focused on data citation, this document summarizes the recommendations of the FORCE11 Software Citation Working Group and its activities between June 2015 and April 2016. Based on a review of existing community practices, the goal of the working group was to produce a consolidated set of citation principles that may encourage broad adoption of a consistent policy for software citation across disciplines and venues. Our work is presented here as a set of software citation principles, a discussion of the motivations for developing the principles, reviews of existing community practice, and a discussion of the requirements these principles would place upon different stakeholders. Working examples and possible technical solutions for how these principles can be implemented will be discussed in a separate paper.",
        "title": "Software citation principles",
        "keywords": "",
        "authors": [
            {
                "name": "Neil Chue Hong",
                "uuid": "ccbc9e4a-d25e-41fd-9a73-9f16e6c418dd"
            }
        ]
    },
    "c71abe02-ac27-4570-99f0-93b62ea34aa0": {
        "id": "c71abe02-ac27-4570-99f0-93b62ea34aa0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/associations-of-mitochondrial-and-nuclear-mitochondrial-variants-and-genes-with-seven-metabolic-traits(c71abe02-ac27-4570-99f0-93b62ea34aa0).html",
        "abstract": "Mitochondria (MT), the major site of cellular energy production, are under dual genetic control by 37 mitochondrial DNA (mtDNA) genes and numerous nuclear genes (MT-nDNA). In the CHARGEmtDNA+ Consortium, we studied genetic associations of mtDNA and MT-nDNA associations with body mass index (BMI), waist-hip-ratio (WHR), glucose, insulin, HOMA-B, HOMA-IR, and HbA1c. This 45-cohort collaboration comprised 70,775 (insulin) to 170,202 (BMI) pan-ancestry individuals. Validation and imputation of mtDNA variants was followed by single-variant and gene-based association testing. We report two significant common variants, one in MT-ATP6 associated (p \u2264 5E\u221204) with WHR and one in the D-loop with glucose. Five rare variants in MT-ATP6, MT-ND5, and MT-ND6 associated with BMI, WHR, or insulin. Gene-based meta-analysis identified MT-ND3 associated with BMI (p \u2264 1E\u221203). We considered 2,282 MT-nDNA candidate gene associations compiled from online summary results for our traits (20 unique studies with 31 dataset consortia\u2019s genome-wide associations [GWASs]). Of these, 109 genes associated (p \u2264 1E\u221206) with at least 1 of our 7 traits. We assessed regulatory features of variants in the 109 genes, cis- and trans-gene expression regulation, and performed enrichment and protein-protein interactions analyses. Of the identified mtDNA and MT-nDNA genes, 79 associated with adipose measures, 49 with glucose/insulin, 13 with risk for type 2 diabetes, and 18 with cardiovascular disease, indicating for pleiotropic effects with health implications. Additionally, 21 genes related to cholesterol, suggesting additional important roles for the genes identified. Our results suggest that mtDNA and MT-nDNA genes and variants reported make important contributions to glucose and insulin metabolism, adipocyte regulation, diabetes, and cardiovascular disease.",
        "title": "Associations of mitochondrial and nuclear mitochondrial variants and genes with seven metabolic traits",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "13f8a3ba-60a5-4dd9-bf5a-32d65bb3e2a2": {
        "id": "13f8a3ba-60a5-4dd9-bf5a-32d65bb3e2a2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hybrid-communication-medium-for-adaptive-soc-architectures(13f8a3ba-60a5-4dd9-bf5a-32d65bb3e2a2).html",
        "abstract": "",
        "title": "Hybrid Communication Medium for Adaptive SoC Architectures",
        "keywords": "",
        "authors": [
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "75defd37-ce20-4a31-b50a-cc1a73d9874e": {
        "id": "75defd37-ce20-4a31-b50a-cc1a73d9874e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/qcdgrid-a-grid-resource-for-quantum-chromodynamics(75defd37-ce20-4a31-b50a-cc1a73d9874e).html",
        "abstract": "",
        "title": "QCDgrid: A Grid Resource for Quantum Chromodynamics",
        "keywords": "",
        "authors": [
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "2f96b29c-9071-4c78-b273-759b3f2c438b": {
        "id": "2f96b29c-9071-4c78-b273-759b3f2c438b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/gridpp-development-of-the-uk-computing-grid-for-particle-physics(2f96b29c-9071-4c78-b273-759b3f2c438b).html",
        "abstract": "",
        "title": "GridPP: development of the UK computing Grid for particle physics",
        "keywords": "",
        "authors": [
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "fc382577-46e3-41fc-aaf9-b3cfeddfbdc7": {
        "id": "fc382577-46e3-41fc-aaf9-b3cfeddfbdc7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-algorithm-for-a-valved-brass-instrument-synthesis-environment-using-finitedifference-timedomain-methods-with-performance-optimisation(fc382577-46e3-41fc-aaf9-b3cfeddfbdc7).html",
        "abstract": "This paper presents a physical modelling sound synthesis environment for the production of valved brass instrument sounds. The governing equations of the system are solved using finite-difference time-domain (FDTD) methods and the environment is implemented in the C programming language. Users of the environment can create their own custom instruments and are able to control player parameters such as lip frequency, mouth pressure and valve openings through the use of instrument and score files.<br/><br/>The algorithm for sound synthesis is presented in detail along with a discussion of optimisation methods used to reduce run time. Binaries for the environment are available for download online for multiple platforms.",
        "title": "An algorithm for a valved brass instrument synthesis environment using finite-difference time-domain methods with performance optimisation",
        "keywords": "",
        "authors": [
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "65f9e7a0-9ce1-40cb-8334-ff4b0a4ddb35": {
        "id": "65f9e7a0-9ce1-40cb-8334-ff4b0a4ddb35",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-environment-for-physical-modeling-of-articulated-brass-instruments(65f9e7a0-9ce1-40cb-8334-ff4b0a4ddb35).html",
        "abstract": "This article presents a physical modeling synthesis environment for valved brass instrument sounds. Synthesis is performed using finite-difference time-domain methods which allow for flexible simulation of time varying systems. Users have control over the instrument configuration as well as player parameters such as mouth pressure, lip dynamics and valve depressions which can be varied over the duration of a gesture. This article introduces the model used in the environment, the development of code from prototyping in MATLAB and optimisation in C and then incorporation of the executable file in the Soundloom interface of the Composers Desktop project. Planned additions to the environment are then discussed. The environment binaries are available to download online along with example sounds and input files.",
        "title": "An Environment for Physical Modeling of Articulated Brass Instruments",
        "keywords": "",
        "authors": [
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "f956eeb7-776e-47fa-be1c-45529cb7aa8c": {
        "id": "f956eeb7-776e-47fa-be1c-45529cb7aa8c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hierarchical-parallelism-in-a-physical-modelling-synthesis-code(f956eeb7-776e-47fa-be1c-45529cb7aa8c).html",
        "abstract": "Modern computer hardware provides parallelism at various dierent levels - most obviously, multiple multicore processors allow many independent threads to execute at once. At a ner-grained level, each core contains a vector unit allowing multiple integer or <br/>oating point calculations to be performed with a single instruction. Additionally, GPU hardware is highly parallel and performs<br/>best when processing large numbers of independent threads. At the same time, tools such as CUDA have become steadily more abundant and mature, allowing more of this parallelism to be exploited.<br/>In this paper we describe the process of optimising a physical modelling sound synthesis code, the Multiplate 3D code, which models the acoustic response of a number of metal plates embedded within a box of air. This code presented a number of challenges and no single optimisation technique was applicable to all of these. However, by exploiting parallelism at several dierent levels (multithreading, GPU acceleration, and vectorisation), as well as applying other optimisations, it was possible to speed up the  simulation very signicantly.",
        "title": "Hierarchical parallelism in a physical modelling synthesis code",
        "keywords": "",
        "authors": [
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "31b0a44a-bdc3-430f-ac34-4b76fae24fe5": {
        "id": "31b0a44a-bdc3-430f-ac34-4b76fae24fe5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/building-a-scientific-data-grid-with-digs(31b0a44a-bdc3-430f-ac34-4b76fae24fe5).html",
        "abstract": "We provide an insight into the challenge of building and supporting a scientific data infrastructure with reference to our experience working with scientists from computational particle physics and molecular biology. We illustrate how, with modern high-performance computing resources, even small scientific groups can generate huge volumes (petabytes) of valuable scientific data and explain how grid technology can be used to manage, publish, share and curate these data. We describe the DiGS software application, which we have developed to meet the needs of smaller communities and we have highlighted the key elements of its functionality.",
        "title": "Building a scientific data grid with DiGS",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "James Perry",
                "uuid": "f121e169-3702-4cb6-a511-df77d894c0b1"
            }
        ]
    },
    "07e04892-0e5f-4f3b-b7b6-c8be889bba90": {
        "id": "07e04892-0e5f-4f3b-b7b6-c8be889bba90",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/optimising-plink(07e04892-0e5f-4f3b-b7b6-c8be889bba90).html",
        "abstract": "Every year the amount of genetic data increases greatly, creating the need for the tool capable of analysing large data sets in a fast and efficient manner. One such software package, providing a wide range of functionality required in whole-genome association studies is PLINK. Although, it does not limit the size of the data sets, the time needed to process them is often a bottleneck. This master project was focused on improving the performance of two functionality options: epistasis analysis and haplotype blocks estimation. It has been determined that the g++ compiler and \u2013O2flag provide the optimal performance for both options. The epistasis analysis has been parallelised using OpenMP. The parallel for schedule directive has been used and dynamic schedule with the chunk size of the size 128 provided the best scaling. When executed on 12 threads the epistasis analysis was 10.5 times faster than when executed on 1 thread. Haplotype blocks option has been serially optimised. Introduced optimisations improved the execution time by about 30%.<br/><br/>",
        "title": "Optimising PLINK",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "8d5eac36-f098-4c5a-9d0d-5176e820d405": {
        "id": "8d5eac36-f098-4c5a-9d0d-5176e820d405",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/problem-formulation-in-the-environmental-risk-assessment-for-genetically-modified-plants(8d5eac36-f098-4c5a-9d0d-5176e820d405).html",
        "abstract": "<p>Problem formulation is the first step in environmental risk assessment (ERA) where policy goals, scope, assessment endpoints, and methodology are distilled to an explicitly stated problem and approach for analysis. The consistency and utility of ERAs for genetically modified (GM) plants can be improved through rigorous problem formulation (PF), producing an analysis plan that describes relevant exposure scenarios and the potential consequences of these scenarios. A properly executed PF assures the relevance of ERA outcomes for decision-making. Adopting a harmonized approach to problem formulation should bring about greater uniformity in the ERA process for GM plants among regulatory regimes globally. This paper is the product of an international expert group convened by the International Life Sciences Institute (ILSI) Research Foundation.</p>",
        "title": "Problem formulation in the environmental risk assessment for genetically modified plants",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "edbffde4-6b9d-406f-95bf-c1c187de8916": {
        "id": "edbffde4-6b9d-406f-95bf-c1c187de8916",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/invertastic-largescale-dense-matrix-inversion(edbffde4-6b9d-406f-95bf-c1c187de8916).html",
        "abstract": "Linear algebraic techniques are widely used in scientific computing, often requir- ing large-scale parallel resources such as those provided by the ARCHER service. Libraries exist to facilitate the development of appropriate parallel software, but use of these involves intricacies in decomposition of the problem, managing parallel in- put and output, passing messages and the execution of the linear algebra operations themselves. In this paper a relatively simple application, Invertastic, is presented. This is designed to perform a real operation: the inversion of a dense symmetric positive definite matrix using multiple processors in parallel. The inversion of ar- bitrarily large matrices is demonstrated, with the only constraint being the size of compute resource available. Inversion cost is known to have O(N3) complexity, which the results confirm allowing for some parallel communication overhead. In- version of a 2,097,152 x 2,097,152 matrix (of size 32TB) took 6.4 hours on 2,048 compute nodes (49,152 cores). The Invertastic software is freely available online and installed as a central package on ARCHER. It can be used directly (e.g. for genomic studies where the matrix represents the genetic relationships between mul- tiple individuals), or instead as a reference or template for the development of more complex algorithms.",
        "title": "Invertastic: Large-scale Dense Matrix Inversion",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "40d2b0ac-a803-4e19-8ffd-35dc785171dd": {
        "id": "40d2b0ac-a803-4e19-8ffd-35dc785171dd",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/shared-activity-patterns-arising-at-genetic-susceptibility-loci-reveal-underlying-genomic-and-cellular-architecture-of-human-disease(40d2b0ac-a803-4e19-8ffd-35dc785171dd).html",
        "abstract": "<p>Genetic variants underlying complex traits, including disease susceptibility, are enriched within the transcriptional regulatory elements, promoters and enhancers. There is emerging evidence that regulatory elements associated with particular traits or diseases share similar patterns of transcriptional activity. Accordingly, shared transcriptional activity (coexpression) may help prioritise loci associated with a given trait, and help to identify underlying biological processes. Using cap analysis of gene expression (CAGE) profiles of promoter- and enhancer-derived RNAs across 1824 human samples, we have analysed coexpression of RNAs originating from trait-associated regulatory regions using a novel quantitative method (network density analysis; NDA). For most traits studied, phenotype-associated variants in regulatory regions were linked to tightly-coexpressed networks that are likely to share important functional characteristics. Coexpression provides a new signal, independent of phenotype association, to enable fine mapping of causative variants. The NDA coexpression approach identifies new genetic variants associated with specific traits, including an association between the regulation of the OCT1 cation transporter and genetic variants underlying circulating cholesterol levels. NDA strongly implicates particular cell types and tissues in disease pathogenesis. For example, distinct groupings of disease-associated regulatory regions implicate two distinct biological processes in the pathogenesis of ulcerative colitis; a further two separate processes are implicated in Crohn's disease. Thus, our functional analysis of genetic predisposition to disease defines new distinct disease endotypes. We predict that patients with a preponderance of susceptibility variants in each group are likely to respond differently to pharmacological therapy. Together, these findings enable a deeper biological understanding of the causal basis of complex traits.</p>",
        "title": "Shared activity patterns arising at genetic susceptibility loci reveal underlying genomic and cellular architecture of human disease",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "59683bff-3146-45b2-a9e1-00769cdceba2": {
        "id": "59683bff-3146-45b2-a9e1-00769cdceba2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/performance-portability-for-room-acoustics-simulations(59683bff-3146-45b2-a9e1-00769cdceba2).html",
        "abstract": "",
        "title": "Performance portability for room acoustics simulations",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "cca1d7ff-34e7-4334-bcf5-e296e2f4047d": {
        "id": "cca1d7ff-34e7-4334-bcf5-e296e2f4047d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-lightweight-approach-to-performance-portability-with-targetdp(cca1d7ff-34e7-4334-bcf5-e296e2f4047d).html",
        "abstract": "Leading HPC systems achieve their status through use of highly parallel devices such as NVIDIA GPUs or Intel Xeon Phi many-core CPUs. The concept of performance portability across such architectures, as well as traditional CPUs, is vital for the application programmer. In this paper we describe targetDP, a lightweight abstraction layer which allows grid-based applications to target data parallel hardware in a platform agnostic manner. We demonstrate the effectiveness of our pragmatic approach by presenting performance results for a complex fluid application (with which the model was co-designed), plus a separate lattice QCD particle physics code. For each application, a single source code base is seen to achieve portable performance, as assessed within the context of the Roofline model. TargetDP can be combined with MPI to allow use on systems containing multiple nodes: we demonstrate this through provision of scaling results on traditional and GPU-accelerated large scale supercomputers.",
        "title": "A Lightweight Approach to Performance Portability with targetDP",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "4a757f4f-9933-4b87-961e-45b9088eaf87": {
        "id": "4a757f4f-9933-4b87-961e-45b9088eaf87",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/large-colloids-in-cholesteric-liquid-crystals(4a757f4f-9933-4b87-961e-45b9088eaf87).html",
        "abstract": "<p>We describe a coarse-grained Landau-de Gennes model of liquid crystals (LCs) including hydrodynamics based on the Beris\u2013Edwards equations. The model is employed to study the impact of large colloids on the long range LC defect structure in the cholesteric LC blue phases. \u2018Large\u2019 here means that the particle size is comparable to the cholesteric pitch, the length scale on which the LC order undergoes a helical twist. We investigate the case of a single particle, with either normal or degenerate planar anchoring, placed initially in an equilibrium blue phase LC. It is found that in some cases, well defined steady disclination structure emerges at the particle surface, while in other cases no clear steady state is reached in the simulations, and disclination reorganisation appears to proliferate through the bulk LC. These systems are of potential interest in the context of using LCs to template self-assembly of colloid structure, e.g., for opto-electronic devices. Computationally, we demonstrate a parallel approach using mixed message-passing and threaded model on graphical processing units allows effective and efficient progress for this problem.</p>",
        "title": "Large Colloids in Cholesteric Liquid Crystals",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "b5f556d5-05d7-4610-9608-f8db3cbce4ac": {
        "id": "b5f556d5-05d7-4610-9608-f8db3cbce4ac",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/compositional-compilation-for-sparse-irregular-data-parallelism(b5f556d5-05d7-4610-9608-f8db3cbce4ac).html",
        "abstract": "While contemporary GPU architectures are heavily biased towards the execution of predictably regular data parallelism, many real application domains are based around data structures which are naturally sparse and irregular. In this paper we demonstrate that high level programming and high performance GPU execution for sparse, irregular problems are not mutually exclusive. Our insight is that this can be achieved by capturing sparsity and irregularity friendly implementations within the target space of a <br/>pattern-oriented, high-level compilation and transformation system. By working in a language rather than a library, we benefit from the ability to generate implementations by program-specific composition of building blocks which capture detailed, low-level implementation choices. Using sparse matrix-vector multiplication as a case study, we show that the resulting system produces implementations for which the performance is competitive with, and sometimes outperforms that obtained with leading ad-hoc approaches. We show that there are correlations between good implementation choices and simple measurable properties of the irregularity present in problem instances. These can be used to design heuristics which navigate the implementation space effectively.<br/><br/>In a case study, we implement a number of versions of sparse matrix-vector multiplication, and achieve promising preliminary performance results. On very regular sparse matrices we are able to achieve up to 1.8x the performance of the state-of-the-art sparse matrix-vector implementation from the clSPARSE libray, and up to 0.7x the performance on very irregular applications.",
        "title": "Compositional Compilation for Sparse, Irregular Data Parallelism",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "38b7949e-f518-4393-9b1e-bec08b996751": {
        "id": "38b7949e-f518-4393-9b1e-bec08b996751",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-new-tool-called-dissect-for-analyzing-large-genomic-datasets-using-a-big-data-approach(38b7949e-f518-4393-9b1e-bec08b996751).html",
        "abstract": "Large-scale genetic and genomic data are increasingly available and the major bottleneck in their analysis is a lack of sufficiently scalable computational tools. To address this problem in the context of complex traits analysis, we present DISSECT. DISSECT is a new and freely available software that is able to exploit the distributed-memory parallel computational architectures of compute clusters, to perform a wide range of genomic and epidemiologic analyses, which currently can only be carried out on reduced sample sizes or under restricted conditions. We demonstrate the usefulness of our new tool by addressing the challenge of predicting phenotypes from genotype data in human populations using mixed-linear model analysis. We analyse simulated traits from 470,000 individuals genotyped for 590,004 SNPs in \u223c4\u2009h using the combined computational power of 8,400 processor cores. We find that prediction accuracies in excess of 80% of the theoretical maximum could be achieved with large sample sizes.",
        "title": "A new tool called DISSECT for analyzing large genomic datasets using a Big Data approach",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "6c81d158-ea54-4b3b-b4b1-bc9fc40baf68": {
        "id": "6c81d158-ea54-4b3b-b4b1-bc9fc40baf68",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/large-stencil-operations-for-gpubased-3d-acoustics-simulations(6c81d158-ea54-4b3b-b4b1-bc9fc40baf68).html",
        "abstract": "Stencil operations are often a key component when performing acoustics simulations, for which the specific choice of implementation can have a significant effect on both accuracy and computational performance. This paper presents a detailed investigation of computational performance for GPU-based stencil operations in two-step finite difference schemes, using stencils of varying shape and size (ranging from seven to more than 450 points in<br/>size). Using an Nvidia K20 GPU, it is found that as the stencil size increases, compute times increase less than that naively expected by considering only the number of computational operations involved, because performance is instead determined by data transfer times throughout the GPU memory architecture. With regards to the effects of stencil shape, performance obtained with stencils that are compact in space is mainly due to efficient use of the read-only data (texture) cache on the K20, and performance obtained with standard high-order stencils is due to increased memory bandwidth usage, compensating for lower cache hit rates. Also in this study, a brief comparison is made with performance results from a related, recent study that used a shared memory approach on a GTX 670 GPU device. It is found that by making efficient use of a GTX 660Ti GPU\u2014whose computational performance is generally lower than that of a GTX 670\u2014similar or better performance to those results can be achieved without the use of shared memory.",
        "title": "Large Stencil Operations for GPU-based 3-D Acoustics Simulations",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "534423c8-fcbf-4ac6-b7e0-b95118161e9c": {
        "id": "534423c8-fcbf-4ac6-b7e0-b95118161e9c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ludwig-multiple-gpus-for-a-complex-fluid-lattice-boltzmann-application(534423c8-fcbf-4ac6-b7e0-b95118161e9c).html",
        "abstract": "",
        "title": "Ludwig: multiple GPUs for a complex fluid lattice Boltzmann application",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "bfd6b9c8-1b4d-47ce-8fa5-e97992f49c44": {
        "id": "bfd6b9c8-1b4d-47ce-8fa5-e97992f49c44",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/lattice-boltzmann-for-largescale-gpu-systems(bfd6b9c8-1b4d-47ce-8fa5-e97992f49c44).html",
        "abstract": "<p>We describe the enablement of the Ludwig lattice Boltzmann parallel fluid dynamics application, designed specifically for complex problems, for massively parallel GPU-accelerated architectures. NVIDIA CUDA is introduced into the existing C/MPI framework, and we have given careful consideration to maintainability in addition to performance. Significant performance gains are realised on each GPU through restructuring of the data layout to allow memory coalescing and the adaptation of key loops to reduce off-chip memory accesses. The halo-swap communication phase has been designed to efficiently utilise many GPUs in parallel: included is the overlapping of several stages using CUDA stream functionality. The new GPU adaptation is seen to retain the good scaling behaviour of the original CPU code, and scales well up to 256 NVIDIA Fermi GPUs (the largest resource tested). The performance on the NVIDIA Fermi GPU is observed to be up to a factor of 4 greater than the (12-core) AMD Magny-Cours CPU (with all cores utilised) for a binary fluid benchmark.</p>",
        "title": "Lattice Boltzmann for Large-Scale GPU Systems",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "66fc52e7-4423-4bfa-8dbf-2f13fc273589": {
        "id": "66fc52e7-4423-4bfa-8dbf-2f13fc273589",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/targetdp-an-abstraction-of-lattice-based-parallelism-with-portable-performance(66fc52e7-4423-4bfa-8dbf-2f13fc273589).html",
        "abstract": "",
        "title": "targetDP: an Abstraction of Lattice Based Parallelism with Portable Performance",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            },
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "1a66d066-09d7-4f74-889b-578d117cbdb1": {
        "id": "1a66d066-09d7-4f74-889b-578d117cbdb1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/in-pursuit-of-an-accurate-spatial-and-temporal-model-of-biomolecules-at-the-atomistic-level(1a66d066-09d7-4f74-889b-578d117cbdb1).html",
        "abstract": "<p>Despite huge advances in the computational techniques available for simulating biomolecules at the quantum-mechanical, atomistic and coarse-grained levels, there is still a widespread perception amongst the experimental community that these calculations are highly specialist and are not generally applicable by researchers outside the theoretical community. In this article, the successes and limitations of biomolecular simulation and the further developments that are likely in the near future are discussed. A brief overview is also provided of the experimental biophysical methods that are commonly used to probe biomolecular structure and dynamics, and the accuracy of the information that can be obtained from each is compared with that from modelling. It is concluded that progress towards an accurate spatial and temporal model of biomacromolecules requires a combination of all of these biophysical techniques, both experimental and computational.</p>",
        "title": "In pursuit of an accurate spatial and temporal model of biomolecules at the atomistic level",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "8687d1a0-73ac-4112-aba3-f3a624a66d2c": {
        "id": "8687d1a0-73ac-4112-aba3-f3a624a66d2c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/b-semileptonic-decays-with-21-dynamical-quark-flavors(8687d1a0-73ac-4112-aba3-f3a624a66d2c).html",
        "abstract": "We study semileptonic B decays, using MILC dynamical configurations with $N_f=2+1$. NRQCD heavy and AsqTad light quark actions are used. We obtain the semileptonic form factors $f_+(q^2)$ and $f_0(q^2)$ in the chiral limit.",
        "title": "B semileptonic decays with 2+1 dynamical quark flavors",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "17e0c18a-995e-4ada-bd08-7fed4ddd3d0c": {
        "id": "17e0c18a-995e-4ada-bd08-7fed4ddd3d0c",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/nrqcd-results-on-the-milc-extra-coarse-ensemble(17e0c18a-995e-4ada-bd08-7fed4ddd3d0c).html",
        "abstract": "We present preliminary results using NRQCD to describe heavy quarks on the MILC 2+1 flavour dynamical extra coarse ensemble. We calculate the spectra of low lying states in bottomonium to complement earlier results on the finer MILC ensembles. We then exploit the coarseness of the lattices to calculate charm propagators using NRQCD. These are used to examine the charmonium spectrum and to calclate the mass of the $B_c$ using NRQCD. Finally we look breifly at the $B_d$ and $B_s$ systems using the imporoved staggered formalism to describe the light valence quarks.",
        "title": "NRQCD results on the MILC extra coarse ensemble",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "ab5d66ea-14b3-43e8-b4f4-490e906704ef": {
        "id": "ab5d66ea-14b3-43e8-b4f4-490e906704ef",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/predictive-lattice-qcd(ab5d66ea-14b3-43e8-b4f4-490e906704ef).html",
        "abstract": "In the past year, we calculated with lattice QCD three quantities that were unknown or poorly known. They are the $q^2$ dependence of the form factor in semileptonic $D\\to Kl\\nu$ decay, the decay constant of the $D$ meson, and the mass of the $B_c$ meson. In this talk, we summarize these calculations, with emphasis on their (subsequent) confirmation by experiments.",
        "title": "Predictive Lattice QCD",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "cf35be4c-b907-459c-987e-5cbb2e42cc0e": {
        "id": "cf35be4c-b907-459c-987e-5cbb2e42cc0e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mass-of-the-bc-meson-in-threeflavor-lattice-qcd(cf35be4c-b907-459c-987e-5cbb2e42cc0e).html",
        "abstract": "We use lattice QCD to predict the mass of the $B_c$ meson. We use the MILC Collaboration's ensembles of lattice gauge fields, which have a quark sea with two flavors much lighter than a third. Our final result is $m_{B_c}=6304\\pm12^{+18}_{- 0} MeV$. The first error bar is a sum in quadrature of statistical and systematic uncertainties, and the second is an estimate of heavy-quark discretization effects.",
        "title": "Mass of the B_c Meson in Three-Flavor Lattice QCD",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "836f3b1c-2cbb-443d-af0f-8779dd56a6c8": {
        "id": "836f3b1c-2cbb-443d-af0f-8779dd56a6c8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-precise-determination-of-the-bc-mass-from-dynamical-lattice-qcd(836f3b1c-2cbb-443d-af0f-8779dd56a6c8).html",
        "abstract": "We perform a precise calculation of the mass of the B_c meson using unquenched configurations from the MILC collaboration including 2+1 flavours of improved staggered quarks. Lattice NRQCD and the Fermilab formalism are used to describe the b and c quarks respectively. We find the mass of the B_c meson to be 6.304(16) GeV",
        "title": "A precise determination of the Bc mass from dynamical lattice QCD",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "75708011-d065-463c-bc61-f05c4e22c463": {
        "id": "75708011-d065-463c-bc61-f05c4e22c463",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-determination-ofs-from-lattice-qcd-with-21-flavors-of-dynamical-quarks(75708011-d065-463c-bc61-f05c4e22c463).html",
        "abstract": "We describe the first lattice determination of the strong coupling constant with 3 flavors of dynamical quarks. The method follows previous analyses in using a perturbative expansion for the plaquette and Upsilon spectroscopy to set the scale. Using dynamical configurations from the MILC collaboration with 2+1 flavors of dynamical quarks we are able to avoid previous problems of having to extrapolate to 3 light flavors from 0 and 2. Our results agree with our previous work: alpha_s_MSbar(M_Z) = 0.121(3).",
        "title": "The determination of\u03b1s from lattice QCD with 2+1 flavors of dynamical quarks",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            },
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            }
        ]
    },
    "07ef564c-bcac-4215-b662-3587d0272534": {
        "id": "07ef564c-bcac-4215-b662-3587d0272534",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-upsilon-spectrum-and-mb-from-full-lattice-qcd(07ef564c-bcac-4215-b662-3587d0272534).html",
        "abstract": "We show results for the Upsilon spectrum calculated in lattice QCD including for the first time vacuum polarization effects for light u and d quarks as well as s quarks. We use gluon field configurations generated by the MILC collaboration. The calculations compare the results for a variety of u and d quark masses, as well as making a comparison to quenched results (in which quark vacuum polarisation is ignored) and results with only u and d quarks. The b quarks in the Upsilon are treated in lattice Nonrelativistic QCD through NLO in an expansion in the velocity of the b quark. We concentrate on accurate results for orbital and radial splittings where we see clear agreement with experiment once u, d and s quark vacuum polarisation effects are included. This now allows a consistent determination of the parameters of QCD. We demonstrate this consistency through the agreement of the Upsilon and B spectrum using the same lattice bare b quark mass. A one-loop matching to continuum QCD gives a value for the b quark mass in full lattice QCD for the first time. We obtain m_b^{\\bar{MS}}(m_b^{\\bar{MS}}) = 4.4(3) GeV. We are able to give physical results for the heavy quark potential parameters, r_0 = 0.469(7) fm and r_1 = 0.321(5) fm. Results for the fine structure in the spectrum and the Upsilon leptonic width are also presented. We predict the Upsilon - eta_b splitting to be 61(14) MeV, the Upsilon^{\\prime} - eta_b^{\\prime} splitting as 30(19) MeV and the splitting between the h_b and the spin-average of the chi_b states to be less than 6 MeV. Improvements to these calculations that will be made in the near future are discussed.",
        "title": "The Upsilon spectrum and m_b from full lattice QCD",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "ee6be71b-c38c-4643-9ccb-0bb8310e2a47": {
        "id": "ee6be71b-c38c-4643-9ccb-0bb8310e2a47",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/first-determination-of-the-strange-and-light-quark-masses-from-full-lattice-qcd(ee6be71b-c38c-4643-9ccb-0bb8310e2a47).html",
        "abstract": "We compute the strange quark mass $m_s$ and the average of the $u$ and $d$ quark masses $\\hat m$ using full lattice QCD with three dynamical quarks combined with experimental values for the pion and kaon masses. The simulations have degenerate $u$ and $d$ quarks with masses $m_u=m_d\\equiv \\hat m$ as low as $m_s/8$, and two different values of the lattice spacing. The bare lattice quark masses obtained are converted to the $\\msbar$ scheme using perturbation theory at $O(alpha_s)$. Our results are: $m_s^\\msbar$(2 GeV) = 76(0)(3)(7)(0) MeV, $\\hat m^\\msbar$(2 GeV) = 2.8(0)(1)(3)(0) MeV and $m_s/\\hat m$ = 27.4(1)(4)(0)(1), where the errors are from statistics, simulation, perturbation theory, and electromagnetic effects, respectively.",
        "title": "First determination of the strange and light quark masses from full lattice QCD",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            },
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            }
        ]
    },
    "f192ba34-239a-4c57-8f6a-105e154eff4e": {
        "id": "f192ba34-239a-4c57-8f6a-105e154eff4e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/b-meson-semileptonic-form-factors-from-unquenched-lattice-qcd(f192ba34-239a-4c57-8f6a-105e154eff4e).html",
        "abstract": "The semileptonic process, B --&gt; \\pi l \\nu, is studied via full QCD Lattice simulations. We use unquenched gauge configurations generated by the MILC collaboration. These include the effect of vacuum polarization from three quark flavors: the $s$ quark and two very light flavors ($u/d$) of variable mass allowing extrapolations to the physical chiral limit. We employ Nonrelativistic QCD to simulate the $b$ quark and a highly improved staggered quark action for the light sea and valence quarks. We calculate the form factors $f_+(q^2)$ and $f_0(q^2)$ in the chiral limit for the range 16 GeV$^2 \\leq q^2 (HFAG05) of recent branching fraction data for exclusive B semileptonic decays from the BaBar, Belle and CLEO collaborations, leads to $|V_{ub}| = 4.22(30)(51) \\times 10^{-3}$. PLEASE NOTE APPENDIX B with an ERRATUM, to appear in Physical Review D, to the published version of this e-print (Phys.Rev.D 73, 074502 (2006)). Results for the form factor $f_+(q^2)$ in the chiral limit have changed significantly. The last two sentences in this abstract should now read; \"We calculate the form factor $f_+(q^2)$ and $f_0(q^2)$ in the chiral limit for the range 16 Gev$^2 \\leq q^2 10^{-3}$.",
        "title": "B Meson Semileptonic Form Factors from Unquenched Lattice QCD",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "e13b1bcf-cadf-424e-9c7e-1a0b11f7d372": {
        "id": "e13b1bcf-cadf-424e-9c7e-1a0b11f7d372",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/b-decays-on-the-lattice-and-results-for-phenomenology(e13b1bcf-cadf-424e-9c7e-1a0b11f7d372).html",
        "abstract": "Lattice Monte Carlo simulations now include the effects of 2 light sea quarks and 1 strange sea quark through the use of an improved staggered fermion action. Consequently, results important to phenomenology are free of the approximate 10% errors inherent in the quenched approximation. This talk reports on calculations of the B and Bs decay constants and B -&gt; pi l nu form factors. Accurate determinations of these quantities will lead to tighter constraints on CKM matrix elements.",
        "title": "B Decays on the Lattice and Results for Phenomenology",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "20c03c5a-608d-4ba8-91a9-7546d07dbb2f": {
        "id": "20c03c5a-608d-4ba8-91a9-7546d07dbb2f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-bs-and-ds-decay-constants-in-3-flavor-lattice-qcd(20c03c5a-608d-4ba8-91a9-7546d07dbb2f).html",
        "abstract": "Capitalizing on recent advances in lattice QCD, we present a calculation of the leptonic decay constants f_{B_s} and f_{D_s} that includes effects of one strange sea quark and two light sea quarks. The discretization errors of improved staggered fermion actions are small enough to simulate with 3 dynamical flavors on lattices with spacings around 0.1 fm using present computer resources. By shedding the quenched approximation and the associated lattice scale ambiguity, lattice QCD greatly increases its predictive power. NRQCD is used to simulate heavy quarks with masses between 1.5 m_c and m_b. We arrive at the following results: f_{B_s} = 260 \\pm 7 \\pm 26 \\pm 8 \\pm 5 MeV and f_{D_s} = 290 \\pm 20 \\pm 29 \\pm 29 \\pm 6 MeV. The first quoted error is the statistical uncertainty, and the rest estimate the sizes of higher order terms neglected in this calculation. All of these uncertainties are systematically improvable by including another order in the weak coupling expansion, the nonrelativistic expansion, or the Symanzik improvement program.",
        "title": "The B_s and D_s decay constants in 3 flavor lattice QCD",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "e3f6aef6-e473-4d49-a54b-fb687ecc52d0": {
        "id": "e3f6aef6-e473-4d49-a54b-fb687ecc52d0",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/accurate-determinations-of-s-from-realistic-lattice-qcd(e3f6aef6-e473-4d49-a54b-fb687ecc52d0).html",
        "abstract": "We obtain a new value for the QCD coupling constant by combining lattice QCD simulations with experimental data for hadron masses. Our lattice analysis is the first to: 1) include vacuum polarization effects from all three light-quark flavors (using MILC configurations); 2) include third-order terms in perturbation theory; 3) systematically estimate fourth and higher-order terms; 4) use an unambiguous lattice spacing; and 5) use an $\\order(a^2)$-accurate QCD action. We use 28~different (but related) short-distance quantities to obtain $\\alpha_{\\bar{\\mathrm{MS}}}^{(5)}(M_Z) = 0.1170(12)$.",
        "title": "Accurate Determinations of $\u03b1_s$ from Realistic Lattice QCD",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "df4bf97a-d936-4fec-96c3-a094f63e22c4": {
        "id": "df4bf97a-d936-4fec-96c3-a094f63e22c4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/highprecision-lattice-qcd-confronts-experiment(df4bf97a-d936-4fec-96c3-a094f63e22c4).html",
        "abstract": "We argue that high-precision lattice QCD is now possible, for the first time, because of a new improved staggered quark discretization. We compare a wide variety of nonperturbative calculations in QCD with experiment, and find agreement to within statistical and systematic errors of 3% or less. We also present a new determination of alpha_msbar(Mz); we obtain 0.121(3). We discuss the implications of this breakthrough for phenomenology and, in particular, for heavy-quark physics.",
        "title": "High-Precision Lattice QCD Confronts Experiment",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "87d06a17-c1ed-4563-b281-1e57ac1d82b5": {
        "id": "87d06a17-c1ed-4563-b281-1e57ac1d82b5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-b-meson-decay-constant-from-unquenched-lattice-qcd(87d06a17-c1ed-4563-b281-1e57ac1d82b5).html",
        "abstract": "We present determinations of the B meson decay constant f_B and of the ratio f_{B_s}/f_B using the MILC collaboration unquenched gauge configurations which include three flavors of light sea quarks. The mass of one of the sea quarks is kept around the strange quark mass, and we explore a range in masses for the two lighter sea quarks down to m_s/8. The heavy b quark is simulated using Nonrelativistic QCD, and both the valence and sea light quarks are represented by the highly improved (AsqTad) staggered quark action. The good chiral properties of the latter action allow for a much smoother chiral extrapolation to physical up and down quarks than has been possible in the past. We find f_B = 216(9)(19)(4) (6) MeV and f_{B_s} /f_B = 1.20(3)(1).",
        "title": "The B Meson Decay Constant from Unquenched Lattice QCD",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "9f551267-6a42-4619-b5d3-910f74be1a38": {
        "id": "9f551267-6a42-4619-b5d3-910f74be1a38",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/semileptonic-b-decays-with-nf21-dynamical-quarks(9f551267-6a42-4619-b5d3-910f74be1a38).html",
        "abstract": "Semileptonic, B --&gt; pi l,nu, decays are studied on the MILC dynamical configurations using NRQCD heavy and Asqtad light quarks. We work with light valence quark masses ranging between m_s and m_s/8. Preliminary simple linear chiral extrapolations have been carried out for form factors f_para and f_perp at fixed E_pi. The chirally extrapolated results for the form factors f_+(q^2) and f_0(q^2) are then fit to the Becirevic-Kaidalov (BK) ansatz. Preliminary estimates of the CKM matrix element |V_{ub}| are presented based on the recently published branching fractions for B exclusive semileptonic decays by the CLEO collaboration.",
        "title": "Semileptonic B Decays with Nf=2+1 Dynamical Quarks",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "754ee8d6-659e-4615-88ea-8d1d5475f819": {
        "id": "754ee8d6-659e-4615-88ea-8d1d5475f819",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/progress-calculating-decay-constants-with-nrqcd-and-asqtad-actions(754ee8d6-659e-4615-88ea-8d1d5475f819).html",
        "abstract": "We combine a light AsqTad antiquark with a nonrelativistic heavy quark to compute the decay constants of heavy-light pseudoscalar mesons using the ensemble of 3-flavor gauge field configurations generated by the MILC collaboration. Preliminary results for $f_{B_s}$ and $f_{D_s}$ are given and status of the chiral extrapolation to $f_B$ is reported. We also touch upon results of the perturbative calculation which matches matrix elements in the effective theory to the full theory at 1-loop order.",
        "title": "Progress Calculating Decay Constants with NRQCD and AsqTad Actions",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "72f78f9e-4cc7-407c-84dd-61bb9b98b337": {
        "id": "72f78f9e-4cc7-407c-84dd-61bb9b98b337",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/b-leptonic-decays-and-b-bar-b-mixing-with-21-flavors-of-dynamical-quarks(72f78f9e-4cc7-407c-84dd-61bb9b98b337).html",
        "abstract": "Calculations of B leptonic decays and B- bar B mixing using NRQCD heavy and Asqtad light valence quarks on the MILC dynamical configurations are described. Smearing has been implemented to substantially reduce the statistical errors of the matrix elements needed for the determination of f_B. The four-fermion matrix elements needed for the determination of f_{B_s}^2B_{B_s} have been calculated and a preliminary result is given.",
        "title": "B Leptonic Decays and B- bar B Mixing with 2+1 Flavors of Dynamical Quarks",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "acde0778-106b-43e6-9945-39ab2cbf204d": {
        "id": "acde0778-106b-43e6-9945-39ab2cbf204d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the--spectrum-from-lattice-qcd-with-2--1-flavors-of-dynamical-quarks(acde0778-106b-43e6-9945-39ab2cbf204d).html",
        "abstract": "We describe the bottomonium spectrum obtained on the MILC configurations which incorporate 2+1 flavors of dynamical quarks. We compare to quenched and 2 flavor results also on MILC configurations. We show that the lattice spacing determination using different quantities shows clear signs of convergence with 2+1 flavors and give results for the leptonic width and hyperfine splitting, in the form of the ratio of the 1st excited state of the Upsilon to that of the ground state.",
        "title": "The \u03a8 spectrum from lattice QCD with 2 + 1 flavors of dynamical quarks",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            },
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            }
        ]
    },
    "4d18454b-e4e6-409a-b1c7-ce12c148603a": {
        "id": "4d18454b-e4e6-409a-b1c7-ce12c148603a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/heavylight-meson-semileptonic-decays-with-staggered-light-quarks(4d18454b-e4e6-409a-b1c7-ce12c148603a).html",
        "abstract": "We report on exploratory studies of heavy-light meson semileptonic decays using Asqtad light quarks, NRQCD heavy quarks and Symanzik improved glue on coarse quenched lattices. Oscillatory contributions to three-point correlators coming from the staggered light quarks are found to be handled well by Bayesian fitting methods. B meson decays to both the Goldstone pion and to one of the point-split non-Goldstone pions are investigated. One-loop perturbative matching of NRQCD/Asqtad heavy-light currents is incorporated.",
        "title": "Heavy-Light Meson Semileptonic Decays with Staggered Light Quarks",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "519b0902-4b44-4938-a4d5-d7eeb7eb4ef1": {
        "id": "519b0902-4b44-4938-a4d5-d7eeb7eb4ef1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/b0s--barb0s-mixing-parameters-from-unquenched-lattice-qcd(519b0902-4b44-4938-a4d5-d7eeb7eb4ef1).html",
        "abstract": "We determine hadronic matrix elements relevant for the mass and width differences, $\\Delta M_s$ &amp; $\\Delta \\Gamma_s$ in the $B^0_s - \\bar{B^0_s}$ meson system using fully unquenched lattice QCD. We employ the MILC collaboration gauge configurations that include $u$, $d$ and $s$ sea quarks using the improved staggered quark (AsqTad) action and a highly improved gluon action. We implement the valence $s$ quark also with the AsqTad action and use Nonrelativistic QCD for the valence $b$ quark. For the nonperturbative QCD input into the Standard Model expression for $\\Delta M_s$ we find $f_{B_s} \\sqrt{\\hat{B}_{B_s}} = 0.281(21)$GeV. Results for four-fermion operator matrix elements entering Standard Model formulas for $\\Delta \\Gamma_s$ are also presented.",
        "title": "$B^0_s - \\bar{B^0_s}$ Mixing Parameters from Unquenched Lattice QCD",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "0d451278-b4f5-4bce-987a-587711b6782d": {
        "id": "0d451278-b4f5-4bce-987a-587711b6782d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/improved-automated-lattice-perturbation-theory-in-background-field-gauge(0d451278-b4f5-4bce-987a-587711b6782d).html",
        "abstract": "We present an algorithm to automatically derive Feynman rules for lattice perturbation theory in background field gauge. Vertices with an arbitrary number of both background and quantum legs can be derived automatically from both gluonic and fermionic actions. The algorithm is a generalisation of our earlier algorithm based on prior work by L\\\"uscher and Weisz. We also present techniques allowing for the parallelisation of the evaluation of the often rather complex lattice Feynman rules that should allow for efficient implementation on GPUs, but also give a significant speed-up when calculating the derivatives of Feynman diagrams with respect to external momenta.",
        "title": "Improved automated lattice perturbation theory in background field gauge",
        "keywords": "",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "c5af486d-047d-4530-8ff6-3da892f0be9b": {
        "id": "c5af486d-047d-4530-8ff6-3da892f0be9b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/porting-and-scaling-openacc-applications-on-massivelyparallel-gpuaccelerated-supercomputers(c5af486d-047d-4530-8ff6-3da892f0be9b).html",
        "abstract": "An increasing number of massively-parallel supercomputers are based on heterogeneous node architectures combining traditional, powerful multicore CPUs with energy-efficient GPU accelerators. Such systems offer high computational performance with modest power consumption. As the industry trend of closer integration of CPU and GPU silicon continues, these architectures are a possible template for future exascale systems. Given the longevity of large-scale parallel HPC applications, it is important that there is a mechanism for easy migration to such hybrid systems. The OpenACC programming model offers a directive-based method for porting existing codes to run on hybrid architectures. In this paper, we describe our experiences in porting the Himeno benchmark to run on the Cray XK6 hybrid supercomputer. We describe the OpenACC programming model and the changes needed in the code, both to port the functionality and to tune the performance. Despite the additional PCIe-related overheads when transferring data from one GPU to another over the Cray Gemini interconnect, we find the application gives very good performance and scales well. Of particular interest is the facility to launch OpenACC kernels and data transfers asynchronously, which speeds the Himeno benchmark by 5%\u201310%. Comparing performance with an optimised code on a similar CPU-based system (using 32 threads per node), we find the OpenACC GPU version to be just under twice the speed in a node-for-node comparison. This speed-up is limited by the computational simplicity of the Himeno benchmark and is likely to be greater for more complicated applications.",
        "title": "Porting and scaling OpenACC applications on massively-parallel, GPU-accelerated supercomputers",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "43064c57-e1c5-4384-8ec0-80e2ada0545e": {
        "id": "43064c57-e1c5-4384-8ec0-80e2ada0545e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/advanced-complex-trait-analysis(43064c57-e1c5-4384-8ec0-80e2ada0545e).html",
        "abstract": "MOTIVATION: The Genome-wide Complex Trait Analysis (GCTA) software package can quantify the contribution of genetic variation to phenotypic variation for complex traits. However, as those data sets of interest continue to increase in size, GCTA becomes increasingly computationally prohibitive. We present an adapted version, Advanced Complex Trait Analysis (ACTA), demonstrating dramatically improved performance. RESULTS: We restructure the GRM estimation phase of the code and introduce the highly optimized parallel BLAS library combined with manual parallelization and optimization. We introduce the LAPACK library into the REML analysis stage. For a testcase with 8999 individuals and 279,435 SNPs we reduce the total runtime, using a compute node with 2 multi-core Intel Nehalem CPUs, from around 17 hours to around 11 minutes. AVAILABILITY: The source code is fully available under the GNU Public License, along with Linux binaries. For more information see http://www.epcc.ed.ac.uk/software-products/acta. CONTACT: a.gray@ed.ac.uk.",
        "title": "Advanced Complex Trait Analysis",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Alan Gray",
                "uuid": "e57944c2-0837-49ad-b21a-058a5cdd2d5f"
            }
        ]
    },
    "eabb1b20-8ada-4c60-9899-040c3c8e0acc": {
        "id": "eabb1b20-8ada-4c60-9899-040c3c8e0acc",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/centori-a-global-toroidal-electromagnetic-twofluid-plasma-turbulence-code(eabb1b20-8ada-4c60-9899-040c3c8e0acc).html",
        "abstract": "A new global two-fluid electromagnetic turbulence code, CENTORI, has been developed for the purpose of studying magnetically-confined fusion plasmas on energy confinement timescales. This code is used to evolve the combined system of electron and ion fluid equations and Maxwell equations in toroidal configurations with axisymmetric equilibria. Uniquely, the equilibrium is co-evolved with the turbulence, and is thus modified by it. CENTORI is applicable to tokamaks of arbitrary aspect ratio and high plasma beta. A predictor\u2013corrector, semi-implicit finite difference scheme is used to compute the time evolution of fluid quantities and fields. Vector operations and the evaluation of flux surface averages are speeded up by choosing the Jacobian of the transformation from laboratory to plasma coordinates to be a function of the equilibrium poloidal magnetic flux. A subroutine, GRASS, is used to co-evolve the plasma equilibrium by computing the steady-state solutions of a diffusion equation with a pseudo-time derivative. The code is written in Fortran 95 and is efficiently parallelised using Message Passing Interface (MPI). Illustrative examples of output from simulations of a tearing mode in a large aspect ratio tokamak plasma and of turbulence in an elongated conventional aspect ratio tokamak plasma are provided.",
        "title": "CENTORI: A global toroidal electromagnetic two-fluid plasma turbulence code",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Joachim Hein",
                "uuid": "9e55c4a7-ba74-4a5a-8912-e9f1a635b051"
            }
        ]
    },
    "ddb7dc9c-35cb-4b4e-ade8-c8a59ea4c7bb": {
        "id": "ddb7dc9c-35cb-4b4e-ade8-c8a59ea4c7bb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dataintensive-architecture-for-scientific-knowledge-discovery(ddb7dc9c-35cb-4b4e-ade8-c8a59ea4c7bb).html",
        "abstract": "This paper presents a data-intensive architecture that demonstrates the ability to support applications from a wide range of application domains, and support the different types of users involved in defining, designing and executing data-intensive processing tasks. The prototype architecture is introduced, and the pivotal role of DISPEL as a canonical language is explained. The architecture promotes the exploration and exploitation of distributed and heterogeneous data and spans the complete knowledge discovery process, from data preparation, to analysis, to evaluation and reiteration. The architecture evaluation included large-scale applications from astronomy, cosmology, hydrology, functional genetics, imaging processing and seismology.",
        "title": "Data-intensive architecture for scientific knowledge discovery",
        "keywords": "",
        "authors": [
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "ac92f573-dd69-4637-b896-c37039b596c4": {
        "id": "ac92f573-dd69-4637-b896-c37039b596c4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dispel-enactment(ac92f573-dd69-4637-b896-c37039b596c4).html",
        "abstract": "<p>This chapter describes the processing of DISPEL requests, which is called as DISPEL enactment. The chapter is targeted at the data-intensive engineers who work on the implementation of the data-intensive platforms. The first section of the chapter addresses DISPEL language processing, which includes parsing and validating a DISPEL scripts and creating its corresponding dataflow graph-usually annotated with the information deduced during this phase. The second section outlines optimization, which includes selection of processing elements (PEs), transformation of the dataflow graph, substitution of PEs, identification of available resources, and the mapping of PEs to resources. The third section outlines deployment, which includes compiling the graphical representation into platform specific executable graphs and setting up resource and dataflow connections. The fourth section addresses execution and control phase, which includes instrumentation and performance measurement, failure management, results delivery, termination, and clean up.</p>",
        "title": "DISPEL Enactment",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "eddc649e-85e9-4823-937d-d9c4d43ee650": {
        "id": "eddc649e-85e9-4823-937d-d9c4d43ee650",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/ogsadai-extension-for-executing-external-jobs-in-workflows(eddc649e-85e9-4823-937d-d9c4d43ee650).html",
        "abstract": "<p>Because of the nature of Grid to be heterogeneous and distributed environment, the database systems which should works on Grid must support this architecture. OGSA-DAI is an example of such extensible service based framework that allow data resources to be incorporated into Grid fabrics. On the other side, many algorithms (for example, for data mining) are not built in Java, they aren't open source projects and can't be easily incorporated in OGSA-DAI workflows. For that reason, we propose OGSA-DAI extension with new computational resources and activities that allow executing of external jobs, and returning data into OGSA DAI workflow. In this paper, we introduce heterogeneous and distributed databases, then we discuss our proposed model, and finally, we report our initial implementation.</p>",
        "title": "OGSA-DAI extension for executing external jobs in workflows",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "020321c1-444e-42cc-83d6-796a8a1895c4": {
        "id": "020321c1-444e-42cc-83d6-796a8a1895c4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/advanced-data-mining-and-integration-research-for-europe(020321c1-444e-42cc-83d6-796a8a1895c4).html",
        "abstract": "This is an extended abstract, so please see the document attached",
        "title": "Advanced Data Mining and Integration Research for Europe",
        "keywords": "",
        "authors": [
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "6ac48ac5-1e7e-474e-b0d7-6c1d606878c8": {
        "id": "6ac48ac5-1e7e-474e-b0d7-6c1d606878c8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/towards-addressing-cpuintensive-seismological-applications-in-europe(6ac48ac5-1e7e-474e-b0d7-6c1d606878c8).html",
        "abstract": "Advanced application environments for seismic analysis help geoscientists to execute complex simulations to predict the behaviour of a geophysical system and potential surface observations. At the same time data collected from seismic stations must be processed comparing recorded signals with predictions. The EU-funded project VERCE ( http://verce.eu/ ) aims to enable specific seismological use-cases and, on the basis of requirements elicited from the seismology community, provide a service-oriented infrastructure to deal with such challenges. In this paper we present VERCE\u2019s architecture, in particular relating to forward and inverse modelling of Earth models and how the, largely file-based, HPC model can be combined with data streaming operations to enhance the scalability of experiments. We posit that the integration of services and HPC resources in an open, collaborative environment is an essential medium for the advancement of sciences of critical importance, such as seismology.",
        "title": "Towards Addressing CPU-Intensive Seismological Applications in Europe",
        "keywords": "",
        "authors": [
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "ff957168-2426-43bd-9f7f-fb63af7176ec": {
        "id": "ff957168-2426-43bd-9f7f-fb63af7176ec",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/expression-of-the-cd2-activation-epitope-t113-cd2r-on-t-cells-in-rheumatoid-arthritis-juvenile-rheumatoid-arthritis-systemic-lupus-erythematosus-ankylosing-spondylitis-and-lyme-disease(ff957168-2426-43bd-9f7f-fb63af7176ec).html",
        "abstract": "<p>CD2R is an activation-associated epitope unmasked by a conformational change of the CD2 cell-surface glycoprotein. In spite of elaborate studies on the role of CD2 and CD2R in adhesion and stimulation of T cells in vitro, no instances of CD2R expression in vivo were known to date. We report high levels of CD2R observed on blood and synovial fluid T cells in rheumatoid arthritis and on peripheral blood T cells in juvenile rheumatoid arthritis, systemic lupus erythematosus, ankylosing spondylitis, and Lyme disease. In vivo, expression of CD2R was restricted to T cells, not limited to a particular T-cell subset and not correlated with the expression of p55 interleukin 2R (IL-2R) (CD25) or major histocompatibility complex (MHC) class II molecules. When stimulated to proliferation via CD2 or CD3, ex vivo CD2R+ T cells showed the same basic activation requirements as CD2R-T cells.</p>",
        "title": "Expression of the CD2 activation epitope T11-3 (CD2R) on T cells in rheumatoid arthritis, juvenile rheumatoid arthritis, systemic lupus erythematosus, ankylosing spondylitis, and Lyme disease",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "b91b3576-299b-4f04-a2e5-fb77bd7fd45f": {
        "id": "b91b3576-299b-4f04-a2e5-fb77bd7fd45f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/towards-a-living-earth-simulator(b91b3576-299b-4f04-a2e5-fb77bd7fd45f).html",
        "abstract": "The Living Earth Simulator (LES) is one of the core components of the FuturICT architecture. It will work as a federation of methods, tools, techniques and facilities supporting all of the FuturICT simulation-related activities to allow and encourage interactive exploration and understanding of societal issues. Society-relevant problems will be targeted by leaning on approaches based on complex systems theories and data science in tight interaction with the other components of FuturICT. The LES will evaluate and provide answers to real-world questions by taking into account multiple scenarios. It will build on present approaches such as agent-based simulation and modeling, multiscale modelling, statistical inference, and data mining, moving beyond disciplinary borders to achieve a new perspective on complex social systems.",
        "title": "Towards a living earth simulator",
        "keywords": "",
        "authors": [
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "56a48a70-15b2-4ede-ac94-172eab3f36da": {
        "id": "56a48a70-15b2-4ede-ac94-172eab3f36da",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-integrated-view-of-aromatase-and-its-inhibition(56a48a70-15b2-4ede-ac94-172eab3f36da).html",
        "abstract": "Aromatase inhibition has become a major treatment strategy for postmenopausal women with oestrogen-dependent breast cancer. Its optimal application is, however, dependent upon (i) the accurate identification of cancers which are ultimately dependent upon the activity of the aromatase enzyme, (ii) the use of the best method/inhibitor by which to blockade aromatase activity. The single best predictor of response to aromatase inhibitors is the presence of tumour oestrogen receptors; receptor-negative cancers rarely respond whereas those with high levels seem particularly likely to benefit. However, there is a need for additional discriminatory markers. The use of microarray technology coupled with neoadjuvant therapy is likely to yield promising candidate genes. The finding that, amongst peripheral tissues, the tumour itself may have high activity has led to the suggestion that the tumour aromatase measurements may be predictive; however, in situ studies and the lack of robust assays for tumour aromatase suggest that tumour aromatase may not be an influential marker. Whilst drugs such as anastrozole, exemestane, formestane and letrozole are all effective and specific inhibitors of aromatase, they differ in structure, potency and mechanism of action. Thus, differential sensitivity of tissues/tumours and non-cross resistance mean inhibitors are not equivalent and individual agents may have differing roles according to the setting in which they will be used. Aromatase inhibitors have evolved as key endocrine agents in the treatment of breast cancer. They offer the promise of rational treatment management based on the accurate identification of individual cohorts of tumours responsive to specific drugs.",
        "title": "An integrated view of aromatase and its inhibition",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "b8fe61e4-4733-45dd-9843-0652d258dccf": {
        "id": "b8fe61e4-4733-45dd-9843-0652d258dccf",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/aromatase-inhibitors(b8fe61e4-4733-45dd-9843-0652d258dccf).html",
        "abstract": "Marked cellular and molecular changes may occur in breast cancers following treatment of postmenopausal breast cancer patients with aromatase inhibitors. Neoadjuvant protocols, in which treatment is given with the primary tumour still within the breast, are particularly illuminating. In Edinburgh, we have shown that 3 months treatment with either anastrozole, exemestane or letrozole produces pathological responses in the majority of oestrogen receptor (ER)-rich tumours (39/59) as manifested by reduced cellularity/increased fibrosis. Changes in histological grading may also take place, most notably a reduction in mitotic figures. This probably reflects an influence on proliferation as most tumours (82%) show a marked decrease in the proliferation marker, Ki67. These effects are generally more dramatic than seen with tamoxifen given in the same setting. Differences between aromatase inhibitors and tamoxifen are also apparent in changes in steroid hormone expression. Thus, immuno-staining for progesterone receptor (PgR) is reduced in almost all cases by aromatase inhibitors, becoming undetectable in many. This contrasts with effects of tamoxifen in which the most common change on PgR is to increase expression. Changes in proliferation occur rapidly following the onset of exposure to aromatase inhibitors. Thus, neoadjuvant studies with letrozole in which tumour was sampled before and after 14 days and 3 months treatment show that decreased expression of Ki67 occur at 14 days and, in many cases, the effect is greater at 14 days than 3 months. These early changes precede evidence of clinical response but do not predict for it. However, this study design has allowed RNA analysis of sequential biopsies taken during the neoadjuvant therapy. Based on clustering techniques, it has been possible to subdivide tumours into groups showing distinct patterns of molecular changes. These changes in tumour gene expression may allow definition of tumour cohorts with differing sensitivity to aromatase inhibitors and permit early recognition of response and resistance.",
        "title": "Aromatase inhibitors",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "d628c0d8-3a19-49f2-a616-dd4efea25730": {
        "id": "d628c0d8-3a19-49f2-a616-dd4efea25730",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/growth-factor-signalling-in-clinical-breast-cancer-and-its-impact-on-response-to-conventional-therapies(d628c0d8-3a19-49f2-a616-dd4efea25730).html",
        "abstract": "Neoadjuvant endocrine treatment in which therapy is given while the primary tumour is still in the breast provides a highly useful model system by which to identify mechanisms associated with de novo resistance and signs of early acquired resistance. Most importantly, the model is clinically relevant. It has been confirmed that the absence of tumour oestrogen receptors confers resistance to endocrine therapy. Early changes in tumour cell proliferation following neoadjuvant treatment with the third-generation aromatase inhibitor, letrozole, do not predict accurately for subsequent clinical response. Additionally, changes in proliferation seen at later times can be the consequence of response and may be associated with early resistance. High expression of c-erbB2 does not reduce tumour responses to neoadjuvant treatment with aromatase inhibitors, but is associated with high tumour proliferation before and during treatment. It remains to be determined whether these characteristics confer subsequent resistance to treatment and early relapse in the adjuvant setting.",
        "title": "Growth factor signalling in clinical breast cancer and its impact on response to conventional therapies",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Amrey Krause",
                "uuid": "b0e3c991-6aac-4f97-9e6e-275d20b5ce91"
            }
        ]
    },
    "90ba9e95-7696-4c60-b8c9-508ad37b3cf2": {
        "id": "90ba9e95-7696-4c60-b8c9-508ad37b3cf2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/preface(90ba9e95-7696-4c60-b8c9-508ad37b3cf2).html",
        "abstract": "",
        "title": "Preface",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "3e1f866e-b804-45b4-8b0d-a4c985385b76": {
        "id": "3e1f866e-b804-45b4-8b0d-a4c985385b76",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/preface(3e1f866e-b804-45b4-8b0d-a4c985385b76).html",
        "abstract": "",
        "title": "Preface",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "03b6c666-89c5-4c9e-a584-780b832d5735": {
        "id": "03b6c666-89c5-4c9e-a584-780b832d5735",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/a-study-on-the-performance-of-reproducible-computations(03b6c666-89c5-4c9e-a584-780b832d5735).html",
        "abstract": "Parallel computations are intrinsically non-reproducible, due to a combined effect of non-deterministic parallel reductions and nonassociative floating point operations. Different strategies have been proposed in literature to alleviate this issue or eliminate it altogether, however at present there is no study on the performance impact of associative floating point operations on large scale applications. In this work, we implement associative operations using binned doubles in MiniFE, and perform various performance tests on Cirrus and Fulhame, two state-ofthe-art HPC systems.",
        "title": "A study on the performance of reproducible computations",
        "keywords": "",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "71f980c2-42bc-4803-84bd-3b3e2d32a519": {
        "id": "71f980c2-42bc-4803-84bd-3b3e2d32a519",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/deep-memory-hierarchies-and-performance-portability(71f980c2-42bc-4803-84bd-3b3e2d32a519).html",
        "abstract": "",
        "title": "Deep memory hierarchies and performance portability",
        "keywords": "",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "ab319658-9572-43ee-aa23-b955f2b834bb": {
        "id": "ab319658-9572-43ee-aa23-b955f2b834bb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/progressive-load-balancing-of-asynchronous-algorithms(ab319658-9572-43ee-aa23-b955f2b834bb).html",
        "abstract": "Synchronisation in the presence of noise and hardware performance variability is a key challenge that prevents applications from scaling to large problems and machines. Using asynchronous or semi-synchronous algorithms can help overcome this issue, but at the cost of reduced stability or convergence rate. In this paper we propose progressive load balancing to manage progress imbalance in asynchronous algorithms dynamically. In our technique the balancing is done over time, not instantaneously.<br/><br/>Using Jacobi iterations as a test case, we show that, with CPU performance variability present, this approach leads to higher iteration rate and lower progress imbalance between parts of the solution space. We also show that under these conditions the balanced asynchronous method outperforms synchronous, semi-synchronous and totally asynchronous implementations in terms of time to solution.",
        "title": "Progressive load balancing of asynchronous algorithms",
        "keywords": "",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "2b530060-1d94-480f-8b59-6fc6a8107455": {
        "id": "2b530060-1d94-480f-8b59-6fc6a8107455",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/learning-musical-pitch-structures-with-hierarchical-hidden-markov-models(2b530060-1d94-480f-8b59-6fc6a8107455).html",
        "abstract": "In this paper we attempt to demonstrate the strengths of\nHierarchical Hidden Markov Models (HHMMs) in the\nrepresentation and modelling of musical structures. We\nshow how relatively simple HHMMs, containing a minimum\nof expert knowledge, use their advantage of having\nmultiple layers to perform well on tasks where flat Hidden\nMarkov Models (HMMs) struggle. The examples in this\npaper show a HHMM\u2019s performance at extracting higherlevel\nmusical properties through the construction of simple\npitch sequences, correctly representing the data set on\nwhich it was trained.",
        "title": "Learning musical pitch structures with hierarchical hidden Markov models",
        "keywords": "",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "3e522b15-fb21-4630-b8a7-ed4ddcecfc55": {
        "id": "3e522b15-fb21-4630-b8a7-ed4ddcecfc55",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/profile-of-scientific-applications-on-hpc-architectures-using-the-deisa-benchmark-suite(3e522b15-fb21-4630-b8a7-ed4ddcecfc55).html",
        "abstract": "The European HPC infrastructure is composed of a wide range of architectures. In this paper, we discuss the usage of the DEISA Benchmark Suite, a selection of widely used HPC applications in a range of scientific areas, to un- derstand and quantify the relationship between a system\u2019s theoretical peak performance and its actual performance for the applications in the Benchmark Suite. The results show that for some applications relative performance can vary greatly between systems, underlining the fact that maintain- ing diversity in the HPC infrastructure in the future will be beneficial to scientific progress in Europe.",
        "title": "Profile of scientific applications on HPC architectures using the DEISA Benchmark Suite",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "9b1e5f94-3240-46ea-9791-12dc1702a5fc": {
        "id": "9b1e5f94-3240-46ea-9791-12dc1702a5fc",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/developing-a-scalable-hybrid-mpiopenmp-unstructured-finite-element-model(9b1e5f94-3240-46ea-9791-12dc1702a5fc).html",
        "abstract": "The trend of all modern computer architectures, and the path to exascale, is towards increasing numbers of lower power cores, with a decreasing memory to core ratio. This imposes a strong evolutionary pressure on algorithms and software to efficiently utilise all levels of parallelism available on a given platform while minimising data movement. Unstructured finite elements codes have long been effectively parallelised using domain decomposition methods, implemented using libraries such as the Message Passing Interface (MPI). However, there are many optimisation opportunities when threading is used for intra-node parallelisation for the latest multi-core/many-core platforms. The benefits include increased algorithmic freedom, reduced memory requirements, cache sharing, reduced number of parti- tions, less MPI communication and I/O overhead.<br/>In this paper, we report progress in implementing a hybrid OpenMP\u2013MPI version of the unstructured finite element code Fluidity. For matrix assembly kernels, the OpenMP parallel algorithm uses graph colouring to identify independent sets of elements that can be assembled concurrently with no race conditions. In this phase there are no MPI overheads as each MPI process only assembles its own local part of the global matrix. We use an OpenMP threaded fork of PETSc to solve the resulting sparse linear systems of equations. We experiment with a range of preconditioners, including HYPRE which provides the algebraic multigrid preconditioner BoomerAMG where the smoother is also threaded. Since unstruc- tured finite element codes are well known to be memory latency bound, particular attention is paid to ccNUMA architectures where data locality is particularly important to achieve good intra-node scaling characteristics. We also demonstrate that utilising non-blocking algorithms and libraries are critical to mixed-mode application so that it can achieve better parallel performance than the pure MPI version.",
        "title": "Developing a scalable hybrid MPI/OpenMP unstructured finite element model",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "7436c407-54be-4cf3-b803-86e4694066b2": {
        "id": "7436c407-54be-4cf3-b803-86e4694066b2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/modelling-largescale-seismic-problems-using-highperformance-computing(7436c407-54be-4cf3-b803-86e4694066b2).html",
        "abstract": "",
        "title": "Modelling large-scale seismic problems using high-performance computing",
        "keywords": "",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "a5f667d7-08ed-4179-b43f-a9ca61b66aac": {
        "id": "a5f667d7-08ed-4179-b43f-a9ca61b66aac",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/chapel--fortress-and-x10--novel-languages-for-hpc(a5f667d7-08ed-4179-b43f-a9ca61b66aac).html",
        "abstract": "Chapel, Fortress and X10 are novel languages focussed on the HPC community.<br/>They have been developed with the aim to facilitate the programming of large next- generation parallel systems and increase both the productivity of the programs\u2019 developers and the scalability of the developed codes. This report introduces these languages by offering on overview of the design and specification of each language. The report will focus on each language\u2019s way of handling task and data parallelism. At the time of writing, all three languages are still in early development stages and any available compilers are experimental. For this reason (in part also for licensing reasons), the report does not touch on language or code performance.",
        "title": "Chapel , Fortress and X10 : novel languages for HPC",
        "keywords": "",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "fffd0148-7ff2-4080-b484-cf96c84b3703": {
        "id": "fffd0148-7ff2-4080-b484-cf96c84b3703",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/performance-evaluation-of-chapels-task-parallel-features(fffd0148-7ff2-4080-b484-cf96c84b3703).html",
        "abstract": "Chapel, Cray\u2019s new parallel programming language, is specifically designed to provide built-in support for high-level task and data parallelism. This paper investigates the performance of the task parallel features offered by Chapel, using benchmarks such as N-Queens and Strassen\u2019s algorithm, on a range of different architectures, including a multi-core Linux system, an SMP cluster and MPP.",
        "title": "Performance Evaluation of Chapel\u2019s Task Parallel Features",
        "keywords": "",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "0bbea1f3-276b-46c1-8a55-7b508ce03ac5": {
        "id": "0bbea1f3-276b-46c1-8a55-7b508ce03ac5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/performance-tuning-of-scientific-applications-on-hpc-systems(0bbea1f3-276b-46c1-8a55-7b508ce03ac5).html",
        "abstract": "The HPC landscape is undergoing significant changes and will become increasingly complex over the coming years. The assessment of the real-life performance of HPC systems through application benchmarking is thus becoming ever more important. The Distributed European Infrastructure for Supercomputing Applications (DEISA) is an EU-funded project that tightly couples high performance computing resources in eleven supercomputing centres in Europe. In a collaboration between DEISA, Cray and IBM, this study investigates the effect of performance tuning of selected scientific applications from the DEISA Benchmark Suite on current hardware. The aim is to highlight current knowledge gaps and find the focus for training and education going forward. This includes understanding both science- and user-driven requirements for default machine configurations.",
        "title": "Performance Tuning of Scientific Applications on HPC Systems",
        "keywords": "",
        "authors": [
            {
                "name": "Michele Weiland",
                "uuid": "5cc53924-c9cf-4f7f-9c0e-a02673f5fba4"
            }
        ]
    },
    "846111c7-d2bc-4ba6-b614-23bdbc60390e": {
        "id": "846111c7-d2bc-4ba6-b614-23bdbc60390e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dynamic-clustering-and-redispersion-in-concentrated-colloidactive-gel-composites(846111c7-d2bc-4ba6-b614-23bdbc60390e).html",
        "abstract": "We study the dynamics of quasi-two-dimensional concentrated suspensions of colloidal particles in active gels by computer simulations. Remarkably, we find that activity induces a dynamic clustering of colloids even in the absence of any preferential anchoring of the active nematic director at the particle surface. When such an anchoring is present, active stresses instead compete with elastic forces and re-disperse the aggregates observed in passive colloid-liquid crystal composites. Our quasi-two-dimensional ``inverse'' dispersions of passive particles in active fluids (as opposed to the more common ``direct'' suspensions of active particles in passive fluids) provide a promising route towards the self-assembly of new soft materials.",
        "title": "Dynamic clustering and re-dispersion in concentrated colloid-active gel composites",
        "keywords": "",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "9c9efb5a-798e-4dd9-8204-e3e9000fc84a": {
        "id": "9c9efb5a-798e-4dd9-8204-e3e9000fc84a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/dlmonte(9c9efb5a-798e-4dd9-8204-e3e9000fc84a).html",
        "abstract": "<p>DL_MONTE is an open-source, general-purpose software package for performing Monte Carlo (MC) simulations. It includes a wide variety of force fields and MC techniques, and thus is applicable to a broad range of problems in molecular simulation. Here we provide an overview of DL_MONTE, focussing on key features recently added to the package. These include the ability to treat systems confined to a planar pore (i.e. \u2018slit\u2019 or \u2018slab\u2019 boundary conditions); the lattice-switch Monte Carlo (LSMC) method for evaluating precise free energy differences between competing polymorphs; various commonly used methods for evaluating free energy profiles along transition pathways (including umbrella sampling, Wang\u2013Landau and transition matrix); and a supplementary Python toolkit for simulation management and application of the histogram reweighting analysis method. We provide two \u2018real-world\u2019 examples to elucidate the use of these methods in DL_MONTE. In particular, we apply umbrella sampling to calculate the free energy profile associated with the translocation of a lipid through a bilayer. Moreover, we employ LSMC to examine the thermodynamic stability of two plastic crystal phases of water at high pressure. Beyond this, we provide instructions on how to access DL_MONTE and point to additional information valuable to existing and prospective users.</p>",
        "title": "DL_MONTE",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "078b89ce-10ee-4457-af58-80add3cbe5b2": {
        "id": "078b89ce-10ee-4457-af58-80add3cbe5b2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/frictional-sinking-of-the-dense-water-overflow-in-a-z-coordinate-ogcm-of-the-mediterranean-sea(078b89ce-10ee-4457-af58-80add3cbe5b2).html",
        "abstract": "<p>The overflow and subsequent spreading of dense water formed in the Adriatic Sea is studied in a high resolution z-coordinate ocean general circulation model (OGCM) of the Mediterranean Sea via simulations of chlorofluorocarbons (CFC12). Frictional sinking is investigated using different parametrisations of the mean bottom stress in term of the mean currents. A series of model integrations shows that increasing the strength of the bottom stress allows the dense overflow to descend the continental slope at a steeper angle, as would be expected on the basis of theoretical streamtube models. The use of a linear drag, which can be thought of as parametrising unresolved time-varying motions, greatly improves the model's ability to capture a realistic dense water pathway and hence realistic CFC12 distributions.</p>",
        "title": "Frictional sinking of the dense water overflow in a z- coordinate OGCM of the Mediterranean Sea",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "464bc849-7c2c-4f4f-9431-2790f2d79ed3": {
        "id": "464bc849-7c2c-4f4f-9431-2790f2d79ed3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/modelling-nutrient-cycling-during-the-eastern-mediterranean-transient-event-19871995-and-beyond(464bc849-7c2c-4f4f-9431-2790f2d79ed3).html",
        "abstract": "<p>Recent observations in the eastern Mediterranean have revealed not only significant changes to the temperature and salinity structure of the deep waters, but an uplifting of the thermocline which has been accompanied by altered distributions of biogeochemical species such as dissolved nutrients and oxygen. This letter presents results from a fully coupled high resolution physical and biogeochemical cycling model which reproduces the eastern Mediterranean transient event. The impact of the event on both biogeochemical tracer distributions and modelled export production between 1987 and 1995 is investigated and compared with available observations. When run on with climatological conditions after 1995, the model suggests the transient event has little impact on export production in the basin.</p>",
        "title": "Modelling nutrient cycling during the eastern Mediterranean transient event 1987-1995 and beyond",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "5bd512e3-b208-47e4-9567-5bc584db7b91": {
        "id": "5bd512e3-b208-47e4-9567-5bc584db7b91",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/large-simulations-of-shear-flow-in-mixtures-via-the-lattice-boltzmann-equation(5bd512e3-b208-47e4-9567-5bc584db7b91).html",
        "abstract": "<p>In this paper we describe the implementation of Lees-Edwards sliding periodic boundary conditions used to perform simulations of sheared binary fluids. In conjunction with domain decomposition and parallelism using the message passing interface, we are able to perform shear simulations of significant size and duration. We discuss the scaling and performance of these large calculations on the IBM Blue Gene/L architecture.</p>",
        "title": "Large simulations of shear flow in mixtures via the lattice boltzmann equation",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "4b1d67d6-e6fc-4133-890f-a2c13b165325": {
        "id": "4b1d67d6-e6fc-4133-890f-a2c13b165325",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mixtures-of-blue-phase-liquid-crystal-with-simple-liquids(4b1d67d6-e6fc-4133-890f-a2c13b165325).html",
        "abstract": "We investigate numerically the behaviour of a phase-separating mixture of a blue phase I liquid crystal with an isotropic fluid. The resulting morphology is primarily controlled by an inverse capillary number, $\\chi$, setting the balance between interfacial and elastic forces. When $\\chi$ and the concentration of the isotropic component are both low, the blue phase disclination lattice templates a cubic array of fluid cylinders. For larger $\\chi$, the isotropic phase arranges primarily into liquid emulsion droplets which coarsen very slowly, rewiring the blue phase disclination lines into an amorphous elastic network. Our blue phase/simple fluid composites can be externally manipulated: an electric field can trigger a morphological transition between cubic fluid cylinder phases with different topologies.",
        "title": "Mixtures of blue phase liquid crystal with simple liquids",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "5f2367ac-78c5-4ab6-8e6a-be9461c3d1a1": {
        "id": "5f2367ac-78c5-4ab6-8e6a-be9461c3d1a1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/lattice-boltzmann-for-binary-fluids-with-suspended-colloids(5f2367ac-78c5-4ab6-8e6a-be9461c3d1a1).html",
        "abstract": "<p>A new description of the binary fluid problem via the lattice Boltzmann method is presented which highlights the use of the moments in constructing two equilibrium distribution functions. This offers a number of benefits, including better isotropy, and a more natural route to the inclusion of multiple relaxation times for the binary fluid problem. In addition, the implementation of solid colloidal particles suspended in the binary mixture is addressed, which extends the solid-fluid boundary conditions for mass and momentum to include a single conserved compositional order parameter. A number of simple benchmark problems involving a single particle at or near a fluid-fluid interface are undertaken and show good agreement with available theoretical or numerical results.</p>",
        "title": "Lattice Boltzmann for binary fluids with suspended colloids",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "c5dd3e69-b3d2-44a7-9b09-6e7eb67aad5a": {
        "id": "c5dd3e69-b3d2-44a7-9b09-6e7eb67aad5a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/modelling-changes-in-mediterranean-thermohaline-circulation-19871995(c5dd3e69-b3d2-44a7-9b09-6e7eb67aad5a).html",
        "abstract": "<p>The observed changes in the eastern Mediterranean thermobaline circulation between 1987 and 1995 are investigated using an ocean general circulation model. A number of different surface forcing regimes are imposed to investigate the possible causes of the formation of new Aegean deep water. The formation and spreading of the Aegean deep water is assessed in terms of chlorofluorocarbon distributions and the changes in salt content in comparison with observation. It is found that three observed cold winters (of 1987, 1992 and 1993) are enough to generate new Aegean deep water in the model. The addition of anomalous winter wind stresses for the period 1988-1995 increases the southward transport of cool north Aegean water, but does not lead to a significant extra outflow of deep water. The modelled water properties agree well with the observation, but the overall volume of the new deep water is too low and there is no outflow at the straits to the west of Crete. The salt budget is examined to highlight the roles of both vertical redistribution and net inflow of salt at Sicily. (C) 2002 Elsevier Science B.V. All rights reserved.</p>",
        "title": "Modelling changes in Mediterranean thermohaline circulation 1987-1995",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "06c3c0db-29d2-4e3f-b052-04d28cf72b18": {
        "id": "06c3c0db-29d2-4e3f-b052-04d28cf72b18",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/impact-of-the-circulation-on-sapropel-formation-in-the-eastern-mediterranean(06c3c0db-29d2-4e3f-b052-04d28cf72b18).html",
        "abstract": "<p>The role of the thermohaline circulation in controlling export production, oxygenation of deep waters, and hence possible sapropel formation in the eastern Mediterranean is examined using a simple nutrient-cycling model. The model is driven by velocity fields from a general circulation model and receives fluxes of nutrient from river run-off and atmospheric deposition. The model is used to study three scenarios: a strong anti-estuarine circulation, a weakened anti-estuarine circulation, and a weak estuarine circulation. Nutrient transports, ventilation of oxygen, and deposition of organic matter are investigated in each case. With a present-day circulation the model provides reasonable agreement with observed phosphate and oxygen profiles and for export production. With the weakened anti-estuarine circulation, consistent with surface salinity reconstructions for the most recent sapropel S(1), there is a modest increase in export production and reduced ventilation leading to anoxia in intermediate and deep waters. Sapropel formation is possible near the coastal margins, particularly if there is enhanced river run-off. With an estuarine circulation, there is significant increase in export production in addition to anoxia below a shallow winter mixed layer. While both the latter circulations allow sapropel formation in the model, the estuarine case is distinguished by higher organic carbon deposition and anoxia in the near-surface waters.</p>",
        "title": "Impact of the circulation on sapropel formation in the eastern Mediterranean",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "64663b72-f7e5-4ced-8fdb-7e424403a825": {
        "id": "64663b72-f7e5-4ced-8fdb-7e424403a825",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hydrodynamics-defines-the-stable-swimming-direction-of-spherical-squirmers-in-a-nematic-liquid-crystal(64663b72-f7e5-4ced-8fdb-7e424403a825).html",
        "abstract": "<p>We present a study of the hydrodynamics of an active particle-a model squirmer-in an environment with a broken rotational symmetry: a nematic liquid crystal. By combining simulations with analytic calculations, we show that the hydrodynamic coupling between the squirmer flow field and liquid crystalline director can lead to reorientation of the swimmers. The preferred orientation depends on the exact details of the squirmer flow field. In a steady state, pushers are shown to swim parallel with the nematic director while pullers swim perpendicular to the nematic director. This behavior arises solely from hydrodynamic coupling between the squirmer flow field and anisotropic viscosities of the host fluid. Our results suggest that an anisotropic swimming medium can be used to characterize and guide spherical microswimmers in the bulk.</p>",
        "title": "Hydrodynamics Defines the Stable Swimming Direction of Spherical Squirmers in a Nematic Liquid Crystal",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "265c5460-8be4-4a4d-9582-2648efab0a72": {
        "id": "265c5460-8be4-4a4d-9582-2648efab0a72",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hydrodynamic-oscillations-and-variable-swimming-speed-in-squirmers-close-to-repulsive-walls(265c5460-8be4-4a4d-9582-2648efab0a72).html",
        "abstract": "We present a lattice Boltzmann study of the hydrodynamics of a fully resolved squirmer, confined in a slab of fluid between two no-slip walls. We show that the coupling between hydrodynamics and short-range repulsive interactions between the swimmer and the surface can lead to hydrodynamic trapping of both pushers and pullers at the wall, and to hydrodynamic oscillations in the case of a pusher. We further show that a pusher moves significantly faster when close to a surface than in the bulk, whereas a puller undergoes a transition between fast motion and a dynamical standstill according to the range of the repulsive interaction. Our results critically require near-field hydrodynamics and demonstrate that far-field hydrodynamics is insufficient to give even a qualitatively correct account of swimmer behaviour near walls. Finally our simulations suggest that it should be possible to control the density and speed of squirmers at a surface by tuning the range of steric and electrostatic swimmer\u2013wall interactions.",
        "title": "Hydrodynamic oscillations and variable swimming speed in squirmers close to repulsive walls",
        "keywords": "",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "5c9dc795-f448-48c1-ab37-e57f2967b1a3": {
        "id": "5c9dc795-f448-48c1-ab37-e57f2967b1a3",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/quantitative-morphological-characterization-of-bicontinuous-pickering-emulsions-via-interfacial-curvatures(5c9dc795-f448-48c1-ab37-e57f2967b1a3).html",
        "abstract": "Bicontinuous Pickering emulsions (bijels) are a physically interesting class of soft materials with many potential applications including catalysis, microfluidics and tissue engineering.  They are created by arresting the spinodal decomposition of a partially-miscible liquid with a (jammed) layer of interfacial colloids.  Porosity L (average interfacial separation) of the bijel is controlled by varying the radius (r) and volume fraction (f) of the colloids (L ~ r/f).  However, to optimize the bijel structure with respect to other parameters, e.g. quench rate, characterizing by L alone is insufficient.  Hence, we have used confocal microscopy and X-ray CT to characterize a range of bijels in terms of local and area-averaged interfacial curvatures; we further demonstrate that bijels are bicontinuous using an image-analysis technique known as `region growing'.  In addition, the curvatures of bijels have been monitored as a function of time, which has revealed an intriguing evolution up to 60 minutes after bijel formation, contrary to previous understanding.",
        "title": "Quantitative Morphological Characterization of Bicontinuous Pickering Emulsions via Interfacial Curvatures",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "6f4e3c45-bdde-4b16-a790-e068339d4a9f": {
        "id": "6f4e3c45-bdde-4b16-a790-e068339d4a9f",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/quantifying-flow-in-variably-wet-microporous-carbonates-using-objectbased-geological-modelling-and-both-latticeboltzmann-and-pore-network-fluid-flow-simulations(6f4e3c45-bdde-4b16-a790-e068339d4a9f).html",
        "abstract": "Chalky microporosity can constitute up to 100% of the total porosity within carbonate reservoirs, but its contribution to both single- and multi-phase flow is poorly quantified. We present a flexible, object-based algorithm to construct 3D computational rock representations that reproduce micritic fabrics of chalky microporous carbonates based on calcite crystal fabrics observed in 2D SEM images. By methodologically altering model parameters we begin to explore the state-space of microporous carbonates to quantify single- and multi-phase flow using both lattice-Boltzmann and network flow models.<br/>Micropore size has little to no effect on single-phase permeability, while differences in multi-phase flow properties are observed for microporous fabrics with pores no smaller than 0.50\u03bcm3 suggesting a change in the pore-scale controls on flow. Single-phase permeability increases by an order of magnitude within fabrics of varying total microporosity (18% to 35%), but minimal effect on multi-phase flow is observed. Similarly, multi-phase flow properties are unaltered by micrite rounding due to burial dissolution, suggesting no alteration in pore-network topology. Micrite rounding, however, notably increases porosity and single-phase permeability in comparison to original rhombic micrite fabrics. The presence of moldic mesopores impacts flow but only when there is a direct connection between them. Otherwise, single-phase permeability is controlled by<br/>micropores. Importantly, recovery is dependent on wetting scenario and pore-network homogeneity. Under water-wet imbibition, an increase in pore homogeneity (more micropores) yields a lower residual oil saturation. Together, these results quantify the importance of microporosity in contributing to, or controlling, overall flow and sweep characteristics in carbonate reservoirs.",
        "title": "Quantifying flow in variably wet microporous carbonates using object-based geological modelling and both lattice-Boltzmann and pore network fluid flow simulations",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "ceb6a838-5f70-4c2a-b99a-ad7e49d4790e": {
        "id": "ceb6a838-5f70-4c2a-b99a-ad7e49d4790e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/bulk-rheology-and-microrheology-of-active-fluids(ceb6a838-5f70-4c2a-b99a-ad7e49d4790e).html",
        "abstract": "We simulate macroscopic shear experiments in active nematics and compare them with microrheology simulations where a spherical probe particle is dragged through an active fluid. In both cases we define an effective viscosity: in the case of bulk shear simulations this is the ratio between shear stress and shear rate, whereas in the microrheology case it involves the ratio between the friction coefficient and the particle size. We show that this effective viscosity, rather than being solely a property of the active fluid, is affected by the way chosen to measure it, and strongly depends on details such as the anchoring conditions at the probe surface and on both the system size and the size of the probe particle.",
        "title": "Bulk rheology and microrheology of active fluids",
        "keywords": "",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "51f8c7be-f05a-4817-ae4b-8ba7e21d55e6": {
        "id": "51f8c7be-f05a-4817-ae4b-8ba7e21d55e6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/colloidal-templating-at-a-cholestericoil-interface-assembly-guided-by-an-array-of-disclination-lines(51f8c7be-f05a-4817-ae4b-8ba7e21d55e6).html",
        "abstract": "<p>We simulate colloids (radius R similar to 1 mu m) trapped at the interface between a cholesteric liquid crystal and an immiscible oil at which the helical order (pitch p) in the bulk conflicts with the orientation induced at the interface, stabilizing an ordered array of disclinations. For a weak anchoring strength W of the director field at the colloidal surface, this creates a template, favoring particle positions either on top of or midway between defect lines, depending on alpha = R/p. For small alpha, optical microscopy experiments confirm this picture, but for larger alpha no templating is seen. This may stem from the emergence at moderate W of a rugged energy landscape associated with defect reconnections.</p>",
        "title": "Colloidal Templating at a Cholesteric-Oil Interface: Assembly Guided by an Array of Disclination Lines",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "cdf81dfd-f30d-46c9-a428-db5964cac328": {
        "id": "cdf81dfd-f30d-46c9-a428-db5964cac328",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mathematical-model-of-the-arabidopsis-circadian-clock(cdf81dfd-f30d-46c9-a428-db5964cac328).html",
        "abstract": "The model is published in Mol. Syst. Biol. 2010: \"Data assimilation constrains new connections and components in a complex, eukaryotic circadian clock model\", A. Pokhilko, S. K. Hodge, K. Stratford, K. Knox, K. D. Edwards, A. W. Thomson, T. Mizuno,  A. J. Millar. PMID: 20865009.",
        "title": "Mathematical model of the Arabidopsis circadian clock",
        "keywords": "",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "8d6a3f3f-b25f-41ee-9a74-53dc4dc739cb": {
        "id": "8d6a3f3f-b25f-41ee-9a74-53dc4dc739cb",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-input-signal-step-function-issf-a-standard-method-to-encode-input-signals-in-sbml-models-with-software-support-applied-to-circadian-clock-models(8d6a3f3f-b25f-41ee-9a74-53dc4dc739cb).html",
        "abstract": "Time-dependent light input is an important feature of computational models of the circadian clock. However, publicly available models encoded in standard representations such as the Systems Biology Markup Language (SBML) either do not encode this input or use different mechanisms to do so, which hinders reproducibility of published results as well as model reuse. The authors describe here a numerically continuous function suitable for use in SBML for models of circadian rhythms forced by periodic light-dark cycles. The Input Signal Step Function (ISSF) is broadly applicable to encoding experimental manipulations, such as drug treatments, temperature changes, or inducible transgene expression, which may be transient, periodic, or mixed. It is highly configurable and is able to reproduce a wide range of waveforms. The authors have implemented this function in SBML and demonstrated its ability to modify the behavior of publicly available models to accurately reproduce published results. The implementation of ISSF allows standard simulation software to reproduce specialized circadian protocols, such as the phase-response curve. To facilitate the reuse of this function in public models, the authors have developed software to configure its behavior without any specialist knowledge of SBML. A community-standard approach to represent the inputs that entrain circadian clock models could particularly facilitate research in chronobiology.",
        "title": "The Input Signal Step Function (ISSF), a Standard Method to Encode Input Signals in SBML Models with Software Support, Applied to Circadian Clock Models",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "9626be62-e0d2-4413-907f-5cc42a6be4ee": {
        "id": "9626be62-e0d2-4413-907f-5cc42a6be4ee",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/colloids-in-active-fluids(9626be62-e0d2-4413-907f-5cc42a6be4ee).html",
        "abstract": "<p>We simulate an experiment in which a colloidal probe is pulled through an active nematic fluid. We find that the drag on the particle is non-Stokesian (not proportional to its radius). Strikingly, a large enough particle in contractile fluid (such as an actomyosin gel) can show negative viscous drag in steady state: the particle moves in the opposite direction to the externally applied force. We explain this, and the qualitative trends seen in our simulations, in terms of the disruption of orientational order around the probe particle and the resulting modifications to the active stress.</p>",
        "title": "Colloids in Active Fluids",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "99c0e15c-b5cc-4be8-aa3c-8ae562bf0f27": {
        "id": "99c0e15c-b5cc-4be8-aa3c-8ae562bf0f27",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/simulating-colloid-hydrodynamics-with-lattice-boltzmann-methods(99c0e15c-b5cc-4be8-aa3c-8ae562bf0f27).html",
        "abstract": "<p>We present a progress report on our work on lattice Boltzmann methods for colloidal suspensions. We focus on the treatment of colloidal particles in binary solvents and on the inclusion of thermal noise. For a benchmark problem of colloids sedimenting and becoming trapped by capillary forces at a horizontal interface between two fluids, we discuss the criteria for parameter selection, and address the inevitable compromise between computational resources and simulation accuracy.</p>",
        "title": "Simulating colloid hydrodynamics with lattice Boltzmann methods",
        "keywords": "",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "b1b2f695-5123-4f22-a075-080d2d73c012": {
        "id": "b1b2f695-5123-4f22-a075-080d2d73c012",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/fluctuating-lattice-boltzmann(b1b2f695-5123-4f22-a075-080d2d73c012).html",
        "abstract": "<p>The lattice Boltzmann algorithm efficiently simulates the Navier-Stokes equation of isothermal fluid flow, but ignores thermal fluctuations of the fluid, important in mesoscopic flows. We show how to adapt the algorithm to include noise, satisfying a fluctuation-dissipation theorem (FDT) directly at lattice level: this gives correct fluctuations for mass and momentum densities, and for stresses, at all wave vectors k. Unlike previous work, which recovers FDT only as k --&gt; 0, our algorithm offers full statistical mechanical consistency in mesoscale simulations of, e.g., fluctuating colloidal hydrodynamics.</p>",
        "title": "Fluctuating lattice Boltzmann",
        "keywords": "",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "e038c568-e09d-4d34-9108-c86cc5b45dd5": {
        "id": "e038c568-e09d-4d34-9108-c86cc5b45dd5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/physical-and-computational-scaling-issues-in-lattice-boltzmann-simulations-of-binary-fluid-mixtures(e038c568-e09d-4d34-9108-c86cc5b45dd5).html",
        "abstract": "<p>We describe some scaling issues that arise when using lattice Boltzmann (LB) methods to simulate binary fluid mixtures-both in the presence and absence of colloidal particles. Two types of scaling problem arise: physical and computational. Physical scaling concerns how to relate simulation parameters to those of the real world. To do this effectively requires careful physics, because (in common with other methods) LB cannot fully resolve the hierarchy of length, energy and time-scales that arise in typical flows of complex fluids. Care is needed in deciding what physics to resolve and what to leave unresolved, particularly when colloidal particles are present in one or both of two fluid phases. This influences steering of simulation parameters such as fluid viscosity and interfacial tension. When the physics is anisotropic (for example, in systems under shear) careful adaptation of the geometry of the simulation box may be needed, an example of this, relating to our study of the effect of colloidal particles on the Rayleigh-Plateau instability of a fluid cylinder, is described. The second and closely related set of scaling issues are computational in nature: how do you scale-up simulations to very large lattice sizes? The problem is acute for system undergoing shear flow. Here one requires a set of blockwise co-moving frames to the fluid, each connected to the next by a Lees-Edwards like boundary condition. These matching planes lead to small numerical errors whose cumulative effects can become severe; strategies for minimizing such effects are discussed.</p>",
        "title": "Physical and computational scaling issues in lattice Boltzmann simulations of binary fluid mixtures",
        "keywords": "",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "8e38c327-62f6-49cf-b656-1f02bc612860": {
        "id": "8e38c327-62f6-49cf-b656-1f02bc612860",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/colloidal-arrest-by-capillary-forces(8e38c327-62f6-49cf-b656-1f02bc612860).html",
        "abstract": "<p>Three situations are compared in which capillary forces, arising at a solid-fluid-fluid contact line, can lead to an arrested state. In the first, an isotropic fluid that enters a biphasic isotropic/nematic coexistence is arrested in its phase separation by the presence of colloids. In the second, colloids coating an interface between two fluids can inhibit the Rayleigh-Plateau instability. In the third case, capillary stresses acting at the surface of a droplet of dense colloidal suspension, surrounded by air, can explain the observed bistability between a fluid droplet and a jammed ' granule '. Common features between these problems are emphasized.</p>",
        "title": "Colloidal arrest by capillary forces",
        "keywords": "",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "2ccd10bd-0f1a-4eb8-88d7-bb13b98c67a7": {
        "id": "2ccd10bd-0f1a-4eb8-88d7-bb13b98c67a7",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/nonequilibrium-steady-states-in-sheared-binary-fluids(2ccd10bd-0f1a-4eb8-88d7-bb13b98c67a7).html",
        "abstract": "<p>We simulate by lattice Boltzmann the steady shearing of a binary fluid mixture undergoing phase separation with full hydrodynamics in two dimensions. Contrary to some theoretical scenarios, a dynamical steady state is attained with finite domain lengths L-x,L-y in the directions (x,y) of velocity and velocity gradient. Apparent scaling exponents are estimated as L-x similar to gamma(-2/3) and L-y similar to gamma(-3/4). We discuss the relative roles of diffusivity and hydrodynamics in attaining steady state.</p>",
        "title": "Nonequilibrium steady states in sheared binary fluids",
        "keywords": "",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "46219f54-cf14-4b76-9a47-56fe3ad93633": {
        "id": "46219f54-cf14-4b76-9a47-56fe3ad93633",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/colloidal-jamming-at-interfaces-a-route-to-fluidbicontinuous-gels(46219f54-cf14-4b76-9a47-56fe3ad93633).html",
        "abstract": "<p>Colloidal particles or nanoparticles, with equal affinity for two fluids, are known to adsorb irreversibly to the fluid-fluid interface. We present large-scale computer simulations of the demixing of a binary solvent containing such particles. The newly formed interface sequesters the colloidal particles; as the interface coarsens, the particles are forced into close contact by interfacial tension. Coarsening is markedly curtailed, and the jammed colloidal layer seemingly enters a glassy state, creating a multiply connected, solidlike film in three dimensions. The resulting gel contains percolating domains of both fluids, with possible uses as, for example, a microreaction medium.</p>",
        "title": "Colloidal jamming at interfaces: A route to fluid-bicontinuous gels",
        "keywords": "",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "87267b3d-ec00-4f61-813b-42090685f547": {
        "id": "87267b3d-ec00-4f61-813b-42090685f547",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/binary-fluids-under-steady-shear-in-three-dimensions(87267b3d-ec00-4f61-813b-42090685f547).html",
        "abstract": "<p>We simulate by the lattice Boltzmann method the steady shearing of a binary fluid mixture with full hydrodynamics in three dimensions. Contrary to some theoretical scenarios, a dynamical steady state is attained with finite correlation lengths in all three spatial directions. Using large simulations, we obtain at moderately high Reynolds numbers apparent scaling exponents comparable to those found by us previously in two dimensions (2D). However, in 3D there may be a crossover to different behavior at low Reynolds number: accessing this regime requires even larger computational resources than used here.</p>",
        "title": "Binary fluids under steady shear in three dimensions",
        "keywords": "",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "e33c44a9-0073-48fc-a75f-745f3c11c417": {
        "id": "e33c44a9-0073-48fc-a75f-745f3c11c417",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/fieldinduced-breakup-of-emulsion-droplets-stabilized-by-colloidal-particles(e33c44a9-0073-48fc-a75f-745f3c11c417).html",
        "abstract": "<p>We simulate the response of a particle-stabilized emulsion droplet in an external force field, such as gravity, acting equally on all N particles. We show that the field strength required for breakup (at fixed initial area fraction) decreases markedly with droplet size, because the forces act cumulatively, not individually, to detach the interfacial particles. The breakup mode involves the collective destabilization of a solidified particle raft occupying the lower part of the droplet, leading to a critical force per particle that scales approximately as N-1/2.</p>",
        "title": "Field-induced breakup of emulsion droplets stabilized by colloidal particles",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "c2548937-48fd-4b69-9948-daae88acde9e": {
        "id": "c2548937-48fd-4b69-9948-daae88acde9e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/cultural-hitchhiking-on-the-wave-of-advance-of-beneficial-technologies(c2548937-48fd-4b69-9948-daae88acde9e).html",
        "abstract": "<p>The wave-of-advance model was introduced to describe the spread of advantageous genes in a population. It can be adapted to model the uptake of any advantageous technology through a population, such as the arrival of neolithic farmers in Europe, the domestication of the horse, and the development of the wheel, iron tools, political organization, or advanced weaponry. Any trait that preexists alongside the advantageous one could be carried along with it, such as genetics or language, regardless of any intrinsic superiority. Decoupling of the advantageous trait from other \"hitchhiking\" traits depends on its adoption by the preexisting population. Here, we adopt a similar wave-of-advance model based on food production on a heterogeneous landscape with multiple populations. Two key results arise from geographic inhomogeneity: the \"subsistence boundary,\" land so poor that the wave of advance is halted, and the temporary \"diffusion boundary\" where the wave cannot move into poorer areas until its gradient becomes sufficiently large. At diffusion boundaries, farming technology may pass to indigenous people already in those poorer lands, allowing their population to grow and resist encroachment by farmers. Ultimately, this adoption of technology leads to the halt in spread of the hitchhiking trait and establishment of a permanent \"cultural boundary\" between distinct cultures with equivalent technology.</p>",
        "title": "Cultural hitchhiking on the wave of advance of beneficial technologies",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "7dea49aa-2d8c-48aa-b964-361c40e602b4": {
        "id": "7dea49aa-2d8c-48aa-b964-361c40e602b4",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/parallel-simulation-of-particle-suspensions-with-the-lattice-boltzmann-method(7dea49aa-2d8c-48aa-b964-361c40e602b4).html",
        "abstract": "<p>A description of the steps taken to produce a massively parallel code for particle suspension problems using the lattice Boltzmann method is presented. A number of benchmarks based on a binary fluid lattice Boltzmann model are used to assess the performance of the code in terms of the computational overhead required for the particle problem compared with the fluid-only problem, and for the scaling of the code to large processor numbers. On the Blue Gene/L architecture, the additional computational cost of particle suspensions Of LIP to 40% solid volume fraction (here over a million particles) is negligible compared with the fluid-only code. (c) 2007 Elsevier Ltd. All rights reserved.</p>",
        "title": "Parallel simulation of particle suspensions with the lattice Boltzmann method",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "7704e74a-3256-422b-aed1-763f4cca3aee": {
        "id": "7704e74a-3256-422b-aed1-763f4cca3aee",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/arrest-of-fluid-demixing-by-nanoparticles-a-computer-simulation-study(7704e74a-3256-422b-aed1-763f4cca3aee).html",
        "abstract": "<p>We use lattice Boltzmann simulations to investigate the formation of arrested structures upon demixing of a binary solvent containing neutrally wetting colloidal particles. Previous simulations for symmetric fluid quenches pointed to the formation of \"bijels\": bicontinuous interfacially jammed emulsion gels. These should be created when a glassy monolayer of particles forms at the fluid-fluid interface, arresting further demixing and rigidifying the structure. Experimental work has broadly confirmed this scenario, but it shows that bijels can also be formed in volumetrically asymmetric quenches. Here, we present new simulation results for such quenches, compare these to the symmetric case, and find a crossover to an arrested droplet phase at strong asymmetry. We then make extensive new analyses of the postarrest dynamics in our simulated bijel and droplet structures, on time scales comparable to the Brownian time for colloid motion. Our results suggest that, on these intermediate time scales, the effective activation barrier to ejection of particles from the fluid-fluid interface is smaller by at least 2 orders of magnitude than the corresponding barrier for an isolated particle on a flat interface.</p>",
        "title": "Arrest of fluid demixing by nanoparticles: A computer simulation study",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "238d54a4-7d93-42d5-9022-03012f26d6e5": {
        "id": "238d54a4-7d93-42d5-9022-03012f26d6e5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/bijels-containing-magnetic-particles-a-simulation-study(238d54a4-7d93-42d5-9022-03012f26d6e5).html",
        "abstract": "<p>Bicontinuous, interfacially jammed emulsion gels (bijels) represent a class of soft solid materials in which interpenetrating domains of two immiscible fluids are stabilized by an interfacial colloidal monolayer. Such structures can be formed by arrested spinodal decomposition from an initially single-phase colloidal suspension. Here, we explore by lattice Boltzmann simulation the possible effects of using magnetic colloids in bijels. This may allow additional control over the structure, during or after formation, by application of-a magnetic field or Field gradient. These effects are modest for typical parameters based on the magnetic nanoparticles used in conventional ferrofluids, although significantly larger particles might be appropriate here. Field gradient effects, which are cumulative across a sample. could then allow a route for controlled breakdown of bijels as they do for particle-stabilized droplet emulsions.</p>",
        "title": "Bijels Containing Magnetic Particles: A Simulation Study",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "8127b293-d6c8-4dc6-9978-1b2d69e8d6d2": {
        "id": "8127b293-d6c8-4dc6-9978-1b2d69e8d6d2",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/data-assimilation-constrains-new-connections-and-components-in-a-complex-eukaryotic-circadian-clock-model(8127b293-d6c8-4dc6-9978-1b2d69e8d6d2).html",
        "abstract": "<p>Circadian clocks generate 24-h rhythms that are entrained by the day/night cycle. Clock circuits include several light inputs and interlocked feedback loops, with complex dynamics. Multiple biological components can contribute to each part of the circuit in higher organisms. Mechanistic models with morning, evening and central feedback loops have provided a heuristic framework for the clock in plants, but were based on transcriptional control. Here, we model observed, post-transcriptional and post-translational regulation and constrain many parameter values based on experimental data. The model's feedback circuit is revised and now includes PSEUDO-RESPONSE REGULATOR 7 (PRR7) and ZEITLUPE. The revised model matches data in varying environments and mutants, and gains robustness to parameter variation. Our results suggest that the activation of important morning-expressed genes follows their release from a night inhibitor (NI). Experiments inspired by the new model support the predicted NI function and show that the PRR5 gene contributes to the NI. The multiple PRR genes of Arabidopsis uncouple events in the late night from light-driven responses in the day, increasing the flexibility of rhythmic regulation.</p>",
        "title": "Data assimilation constrains new connections and components in a complex, eukaryotic circadian clock model",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "2031af04-8d05-4eff-8505-58a0c0572020": {
        "id": "2031af04-8d05-4eff-8505-58a0c0572020",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/colloids-in-cholesterics-sizedependent-defects-and-nonstokesian-microrheology(2031af04-8d05-4eff-8505-58a0c0572020).html",
        "abstract": "<p>We simulate a colloidal particle (radius R) in a cholesteric liquid crystal (pitch p) with tangential order parameter alignment at the particle surface. The local defect structure evolves from a dipolar pair of surface defects (boojums) at small R/p to a pair of twisted disclination lines wrapping around the particle at larger values. On dragging the colloid with small velocity v through the medium along the cholesteric helix axis (an active microrheology measurement), we find a hydrodynamic drag force that scales linearly with v but superlinearly with R-in striking violation of Stokes' law, as generally used to interpret such measurements.</p>",
        "title": "Colloids in Cholesterics: Size-Dependent Defects and Non-Stokesian Microrheology",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "3567a504-924e-4331-b14c-1652433ac250": {
        "id": "3567a504-924e-4331-b14c-1652433ac250",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/colloids-in-liquid-crystals-a-lattice-boltzmann-study(3567a504-924e-4331-b14c-1652433ac250).html",
        "abstract": "<p>We propose a hybrid lattice Boltzmann algorithm to simulate the hydrodynamics of colloidal particles inside a liquid crystalline host. To validate our algorithm, we study the static and the microrheology of a colloid in a nematic, with tangential anchoring of the director field at the particle surface, and we confirm theories and experiments showing that the drag force in a nematic is markedly anisotropic. We then apply our method to consider the case of a colloid inside a cholesteric, and with normal anchoring at the surface. We show that by tuning the ratio between particle size and cholesteric pitch it is possible to control the defect configuration around the particle, and to stabilise novel figure-of-eight or highly twisted loops close to the colloid surface.</p>",
        "title": "Colloids in liquid crystals: a lattice Boltzmann study",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "66243d62-6648-4d97-9b73-21df38525a97": {
        "id": "66243d62-6648-4d97-9b73-21df38525a97",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-moldy-shortrange-molecular-dynamics-package(66243d62-6648-4d97-9b73-21df38525a97).html",
        "abstract": "<p>We describe a parallelised version of the MOLDY molecular dynamics program. This Fortran code is aimed at systems which may be described by short-range potentials and specifically those which may be addressed with the embedded atom method. This includes a wide range of transition metals and alloys. MOLDY provides a range of options in terms of the molecular dynamics ensemble used and the boundary conditions which may be applied. A number of standard potentials are provided, and the modular structure of the code allows new potentials to be added easily. The code is parallelisecl using OpenMP and can therefore be run on shared memory systems, including modern multicore processors. Particular attention is paid to the updates required in the main force loop, where synchronisation is often required in OpenMP implementations of molecular dynamics. We examine the performance of the parallel code in detail and give some examples of applications to realistic problems, including the dynamic compression of copper and carbon migration in an iron-carbon alloy.</p><p>Program summary</p><p>Program title: MOLDY</p><p>Catalogue identifier: AEJU_v1_0</p><p>Program summary URL: http://cpc.cs.qub.ac.uk/summaries/AEJU_v1_0.html</p><p>Program obtainable from: CPC Program Library, Queen's University, Belfast, N. Ireland</p><p>Licensing provisions: GNU General Public License version 2</p><p>No. of lines in distributed program, including test data, etc.: 382 881</p><p>No. of bytes in distributed program, including test data, etc.: 6 705 242</p><p>Distribution format: tar.gz</p><p>Programming language: Fortran 95/OpenMP</p><p>Computer: Any</p><p>Operating system: Any</p><p>Has the code been vectorised or parattelized?: Yes. OpenMP is required for parallel execution</p><p>RAM: 100 MB or more</p><p>Classification: 7.7</p><p>Nature of problem: Moldy addresses the problem of many atoms (of order 106) interacting via a classical interatomic potential on a timescale of microseconds. It is designed for problems where statistics must be gathered over a number of equivalent runs, such as measuring thermodynamic properities, diffusion, radiation damage, fracture. twinning deformation, nucleation and growth of phase transitions, sputtering etc. In the vast majority of materials, the interactions are non-pairwise, and the code must be able to deal with many-body forces.</p><p>Solution method: Molecular dynamics involves integrating Newton's equations of motion. MOLDY uses verlet (for good energy conservation) or predictor-corrector (for accurate trajectories) algorithms. It is parallelised using open MP. It also includes a static minimisation routine to find the lowest energy structure. Boundary conditions for surfaces, clusters, grain boundaries, thermostat (Nose), barostat (Parrinello-Rahman), and externally applied strain are provided. The initial configuration can be either a repeated unit cell or have all atoms given explictly. Initial velocities are generated internally, but it is also possible to specify the velocity of a particular atom. A wide range of interatomic force models are implemented, including embedded atom, Morse or Lennard-Jones. Thus the program is especially well suited to calculations of metals.</p><p>Restrictions: The code is designed for short-ranged potentials, and there is no Ewald sum. Thus for long range interactions where all particles interact with all others, the order-N scaling will fail. Different interatomic potential forms require recompilation of the code.</p><p>Additional comments: There is a set of associated open-source analysis software for postprocessing and visualisation. This includes local crystal structure recognition and identification of topological defects.</p><p>Running time: A set of test modules for running time are provided. The code scales as order N. The parallelisation shows near-linear scaling with number of processors in a shared memory environment. A typical run of a few tens of nanometers for a few nanoseconds will run on a timescale of days on a multiprocessor desktop. (C) 2011 Elsevier B.V. All rights reserved.</p>",
        "title": "The MOLDY short-range molecular dynamics package",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "45850ac6-9b77-4461-bc1b-d76edbf3fb05": {
        "id": "45850ac6-9b77-4461-bc1b-d76edbf3fb05",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/selfassembly-and-nonlinear-dynamics-of-dimeric-colloidal-rotors-in-cholesterics(45850ac6-9b77-4461-bc1b-d76edbf3fb05).html",
        "abstract": "<p>We study by simulation the physics of two colloidal particles in a cholesteric liquid crystal with tangential order parameter alignment at the particle surface. The effective force between the pair is attractive at short range and favors assembly of colloid dimers at specific orientations relative to the local director field. When pulled through the fluid by a constant force along the helical axis, we find that such a dimer rotates, either continuously or stepwise with phase-slip events. These cases are separated by a sharp dynamical transition and lead, respectively, to a constant or an ever-increasing phase lag between the dimer orientation and the local nematic director.</p>",
        "title": "Self-Assembly and Nonlinear Dynamics of Dimeric Colloidal Rotors in Cholesterics",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "d1542d76-7b3a-45ce-bfe0-564f8ea119c5": {
        "id": "d1542d76-7b3a-45ce-bfe0-564f8ea119c5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/hydrodynamic-interactions-in-colloidal-ferrofluids-a-lattice-boltzmann-study(d1542d76-7b3a-45ce-bfe0-564f8ea119c5).html",
        "abstract": "<p>We use lattice Boltzmann simulations, in conjunction with Ewald summation methods, to investigate the role of hydrodynamic interactions in colloidal suspensions of dipolar particles, such as ferrofluids. Our work addresses volume fractions phi of up to 0.20 and dimensionless dipolar interaction parameters lambda of up to 8. We compare quantitatively with Brownian dynamics simulations, in which many-body hydrodynamic interactions are absent. Monte Carlo data are also used to check the accuracy of static properties measured with the lattice Boltzmann technique. At equilibrium, hydrodynamic interactions slow down both the long-time and the short-time decays of the intermediate scattering function S(q, t), for wavevectors close to the peak of the static structure factor S(q), by a factor of roughly two. The long-time slowing is diminished at high interaction strengths, whereas the short-time slowing (quantified via the hydrodynamic factor H(q)) is less affected by the dipolar interactions, despite their strong effect on the pair distribution function arising from cluster formation. Cluster formation is also studied in transient data following a quench from lambda = 0; hydrodynamic interactions slow the formation rate, again by a factor of roughly two.</p>",
        "title": "Hydrodynamic Interactions in Colloidal Ferrofluids: A Lattice Boltzmann Study",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Kevin Stratford",
                "uuid": "bfb89141-96c1-4077-a136-69b0181071fd"
            }
        ]
    },
    "810a6a36-80c6-4ad8-97e4-8870e237af5e": {
        "id": "810a6a36-80c6-4ad8-97e4-8870e237af5e",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/endogenous-pulmonary-antibiotics(810a6a36-80c6-4ad8-97e4-8870e237af5e).html",
        "abstract": "<p>The human lung produces a variety of peptides and proteins which have intrinsic antimicrobial activity. In general these molecules have broad spectra of antimicrobial activity, kill micro-organisms rapidly, and evade resistance generated by pathogens. In recent years it has become increasingly apparent that the antimicrobial peptides (AMPs) simultaneously possess immunomodulatory functions, suggesting complex roles for these molecules in regulating the clearance of, and immune response to, invading pathogens. These collective properties have stimulated considerable interest in the potential clinical application of endogenous AMPs. This article outlines the biology of AMPs, their pattern of expression in the lung, and their functions, with reference to both antimicrobial and immunomodulatory activity. We then consider the biological importance of AMPs, before concentrating on the potential to use AMPs to therapeutic effect. The principles discussed in the article apply to innate immune defence throughout the body, but particular emphasis is placed on AMPs in the lung and the potential application to pulmonary infection.</p>",
        "title": "Endogenous pulmonary antibiotics",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alan Simpson",
                "uuid": "edbe5450-e7d0-43d8-8700-4982f415b3e7"
            }
        ]
    },
    "310db4d1-99f8-4489-bc14-7af800cd7db8": {
        "id": "310db4d1-99f8-4489-bc14-7af800cd7db8",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/the-microbial-diversity-of-volcanic-rocks(310db4d1-99f8-4489-bc14-7af800cd7db8).html",
        "abstract": "",
        "title": "The Microbial Diversity of Volcanic Rocks",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Alan Simpson",
                "uuid": "edbe5450-e7d0-43d8-8700-4982f415b3e7"
            }
        ]
    },
    "275fc818-ca14-4840-a2c0-37ea59e1f36b": {
        "id": "275fc818-ca14-4840-a2c0-37ea59e1f36b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/software-deposit-guidance-for-researchers-version-10(275fc818-ca14-4840-a2c0-37ea59e1f36b).html",
        "abstract": "Research software is an integral part of the modern research ecosystem. Taken together, research software, alongside data, facilities, equipment and an overarching research question can be viewed as a research activity or experiment, worthy to be published. Conversely, a publication can be considered as a narrative that describes how the research objects are used together to reply to the research question.<br/><br/>Depositing research software into a digital repository can offer significant benefits. By depositing not just papers, but software, and data sets, as well, researchers can store a more complete record of this ecosystem for future use to both the researchers who undertook the research and also the wider research community. Making research software available allows other researchers to inspect, replicate, reproduce and reuse the research, as manifested in the software, in the short term and to inspect, for the historical record, in the long term. It allows research software to remain available beyond the lifetime of any current project, or a researcher's current employment at a specific institution. Digital repositories can also provide unique persistent digital identifiers for software which can be cited and help researchers to get attribution and credit for their research software when it is used by others.<br/><br/>The Software Sustainability Institute, funded by Jisc have developed a set of complementary guides covering the main aspects of depositing software into digital repositories. These guides are intended for researchers, principal investigators and research leaders and research data and digital repository managers. This document provides an overview of the content covered by the guides.",
        "title": "Software Deposit: Guidance for Researchers (Version 1.0)",
        "keywords": "",
        "authors": [
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "57871cf6-bab9-4bfe-acc8-56a05dc41151": {
        "id": "57871cf6-bab9-4bfe-acc8-56a05dc41151",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/checklist-for-a-software-management-plan-version-10(57871cf6-bab9-4bfe-acc8-56a05dc41151).html",
        "abstract": "When developing research software, it is easy to focus only on goals and activities such as collaborating with other researchers, writing papers, attending conferences and applying for funding. Together, the demands of daily research practice can all conspire to prevent proper planning for the development of research software.<br/><br/>A Software Management Plan (SMP) can help you to define a set of structures and goals to understand your research software including what you are going to develop; who the software is for (even if it is just for yourself); how you will deliver your software to its intended users; how it will help them; and how you will assess whether it has helped them, and contributed to research, in the ways that you intended. An SMP also helps you to understand how you can support those who wish to, or do, use your research software; how your software relates to other artefacts in your research ecosystem; and how you will ensure that your software remains available beyond the lifetime of your current project.<br/><br/>This checklist will help you to write an SMP. It consists of sections that cover the key elements that an SMP should include.",
        "title": "Checklist for a Software Management Plan (Version 1.0)",
        "keywords": "",
        "authors": [
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "15d31414-5ce1-4d4f-b2d1-b6cdb9784d53": {
        "id": "15d31414-5ce1-4d4f-b2d1-b6cdb9784d53",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/mice-online-data-quality(15d31414-5ce1-4d4f-b2d1-b6cdb9784d53).html",
        "abstract": "",
        "title": "MICE online data quality",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "0a308d64-73e4-4c73-a9a8-70174c1bffed": {
        "id": "0a308d64-73e4-4c73-a9a8-70174c1bffed",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-open-source-linked-data-framework-for-publishing-environmental-data-under-the-uk-location-strategy(0a308d64-73e4-4c73-a9a8-70174c1bffed).html",
        "abstract": "",
        "title": "An Open Source Linked Data Framework for Publishing Environmental Data under the UK Location Strategy",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "ec150ac4-00a9-49bc-bb83-0bcef23e6412": {
        "id": "ec150ac4-00a9-49bc-bb83-0bcef23e6412",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/interactive-proof-critics(ec150ac4-00a9-49bc-bb83-0bcef23e6412).html",
        "abstract": "",
        "title": "Interactive Proof Critics",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "ee4b4880-4a6d-4b63-a893-c8cd9f496cd6": {
        "id": "ee4b4880-4a6d-4b63-a893-c8cd9f496cd6",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/engineering-mathematics-education-using-java-learning-environments(ee4b4880-4a6d-4b63-a893-c8cd9f496cd6).html",
        "abstract": "The Java language has been used in the construction of a number of learning environments to enable students to explore mathematical concepts without the barrier of mathematical manipulation. The applets are designed to be flexible for educators, and flexible in usage to encourage exploration and experimentation, yet are compact to minimize download time. The use of the developed environments in a practical education scenario is described, showing how the tools are used for class instruction, tutoring support, and individual learning. Subjective and qualitative evidence is presented showing that where the environments are used by students there is a discernible improvement in understanding of the concepts that the environments address. The results of this process are generalized to show the type of concept that is suitable for such treatment, and those for which improvements are not discernible.",
        "title": "Engineering Mathematics Education using Java Learning Environments",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "9066c59c-c877-44f2-841f-534ee220dd7b": {
        "id": "9066c59c-c877-44f2-841f-534ee220dd7b",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/supporting-dsp-education-using-java(9066c59c-c877-44f2-841f-534ee220dd7b).html",
        "abstract": "This paper describes the atuhors' research into using Java to develop tools to support hte teaching of Digital Signal Processing. Focusing on the application of concepts of Human-Computer Interaction allows the formulation of design requirements which facilitate the development of tools that are both usable and useful. Developing tools meeting these requirements yields teaching aids endowed with a novel characteristic lacking from comparable Java tools - flexibility. An exemplar of this flexibility is tha teducators with no Java experience can configure the tools to meet course requirements. A planned user-centred evaluation is intended to provide information that lays the groundwork for investigating possible educational gains resulting from the use of these tools by educators and students.",
        "title": "Supporting DSP Education using Java",
        "keywords": "",
        "authors": [
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "1f908f03-39d1-4aa1-a839-43daa3705001": {
        "id": "1f908f03-39d1-4aa1-a839-43daa3705001",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/developing-and-evaluating-javabased-educational-tools(1f908f03-39d1-4aa1-a839-43daa3705001).html",
        "abstract": "",
        "title": "Developing and evaluating Java-based educational tools",
        "keywords": "",
        "authors": [
            {
                "name": "Michael Jackson",
                "uuid": "43b4b161-fa22-4acb-969e-835ae12eeefa"
            }
        ]
    },
    "968eb24d-571f-4865-851e-67da833cef6d": {
        "id": "968eb24d-571f-4865-851e-67da833cef6d",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/using-simulation-for-decision-support-lessons-learned-from-the-firegrid-project(968eb24d-571f-4865-851e-67da833cef6d).html",
        "abstract": "This paper describes some of the lessons learned from the FireGrid project. It starts with a brief overview of the project. The discussion of the lessons learned that follows is intended for others attempting to develop a similar system, where sensor data is used to steer a super-real time simulation in order to generate predictions that will provide decision support for emergency responders.",
        "title": "Using Simulation for Decision Support: Lessons Learned from the FireGrid Project",
        "keywords": "",
        "authors": [
            {
                "name": "Gavin Pringle",
                "uuid": "66f4ae16-ad0a-4ab4-ae37-5f844ed07fae"
            }
        ]
    },
    "0d28361f-85d1-4ad0-a5cd-4ced4088a118": {
        "id": "0d28361f-85d1-4ad0-a5cd-4ced4088a118",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/magnetic-field-fossilization-and-tail-reconfiguration-in-titans-plasma-environment-during-a-magnetopause-passage-3d-adaptive-hybrid-code-simulations(0d28361f-85d1-4ad0-a5cd-4ced4088a118).html",
        "abstract": "<p>We present a hybrid simulation study (kinetic ions, fluid electrons) of Titan's plasma interaction during an excursion of this moon from Saturn's magnetosphere into its magnetosheath, as observed for the first time during Cassini's T32 flyby on 13 June 2007. In contrast to earlier simulations of Titan's plasma environment under non-stationary upstream conditions, our model considers a difference in the flow directions of magnetospheric and magnetosheath plasma. Two complementary scenarios are investigated, with the flow directions of the impinging magnetospheric/magnetosheath plasmas being (A) antiparallel and (B) parallel. In both cases, our simulations show that due to the drastically reduced convection speed in the slow and dense heavy ion plasma near Titan, the satellite carries a bundle of \"fossilized\" magnetic field lines from the magnetosphere in the magnetosheath. Furthermore, the passage through Saturn's magnetopause goes along with a disruption of Titan's pick-up tail. Although the tail is not detached from the satellite, large clouds of heavy ion plasma are stripped of its outer flank, featuring a wave-like pattern. Whereas in case (B) under parallel flow conditions there is only a small retardation of about 5 min between the passage of Titan through the magnetopause and the reconfiguration of the pick-up tail, the tail reconfiguration in the case (A) scenario is completed not until 25 min after the magnetopause passage. The lifetime of fossil fields in the moon's ionosphere is approximately 25 min, regardless of whether parallel or antiparallel flow conditions are applied. (c) 2010 Elsevier Ltd. All rights reserved.</p>",
        "title": "Magnetic field fossilization and tail reconfiguration in Titan's plasma environment during a magnetopause passage: 3D adaptive hybrid code simulations",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Gavin Pringle",
                "uuid": "66f4ae16-ad0a-4ab4-ae37-5f844ed07fae"
            }
        ]
    },
    "9fa9ea0d-8d76-4186-8a14-f18fe5bb5aa9": {
        "id": "9fa9ea0d-8d76-4186-8a14-f18fe5bb5aa9",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/aikef-adaptive-hybrid-model-for-space-plasma-simulations(9fa9ea0d-8d76-4186-8a14-f18fe5bb5aa9).html",
        "abstract": "<p>The interaction between magnetized space plasmas and obstacles like comets, asteroids or planets is determined by a variety of physical processes that occur simultaneously on significantly different length and time scales. Frequently the dynamics of individual ions play a key role for the shape of the interaction region: strong velocity shear between light and heavy plasma constituents, non-Maxwellian particle distributions due to pick up and asymmetries in the magnetic field topology are crucial in determining this type of interaction. Covering these processes is beyond the scope of any Magnetohydrodynamic (MHD) model. In order to account for these effects we have developed a new adaptive hybrid code A.I.K.E.F. (Adaptive Ion-Kinetic Electron-Fluid). The code operates on Cartesian meshes that can adapt to the physical structures in both, space and time. To the authors' knowledge, there is no other adaptive hybrid simulation code in space plasma physics to the present day. Adaptivity is implemented by means of Hybrid-Block-AMR, that is individual octs are refined rather than entire blocks, where an oct is one eighth of a block. In order to account for a reasonable number of particles in each cell, particles are refined via splitting and merging. Both procedures conserve mass, momentum and kinetic energy. The code is implemented in C++ and efficiently parallelized for distributed systems by means of the Message Passing Interface (MPI). In order to demonstrate the validity of our newly developed code we have applied it to a series of fundamental test scenarios. On the one hand we demonstrate that the dispersion relation as well as the propagation characteristics of MHD and whistler mode waves are quantitatively reproduced by our simulation code. Wave propagation remains unaffected when traveling through regions that include different refinement levels. On the other hand we verify that the results obtained on high resolution uniform meshes are identical to the results from adaptive simulations that use coarse base meshes but include various levels of refinement. A remarkable speedup could be observed: the adaptive simulations required 71 times less CPU-hours than the uniform mesh simulations. Finally, we present a first series of global, three-dimensional simulations for the interaction of Mercury with the solar wind and a real time study of Titan's plasma interaction during a magnetosheath excursion. (C) 2010 Elsevier B.V. All rights reserved.</p>",
        "title": "AIKEF: Adaptive hybrid model for space plasma simulations",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Gavin Pringle",
                "uuid": "66f4ae16-ad0a-4ab4-ae37-5f844ed07fae"
            }
        ]
    },
    "c89e65ae-446c-4e0a-9d08-1fdec5d301d1": {
        "id": "c89e65ae-446c-4e0a-9d08-1fdec5d301d1",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/firegrid-integrated-eresponse-for-the-modern-built-environment-based-on-environmental-and-structural-monitoring(c89e65ae-446c-4e0a-9d08-1fdec5d301d1).html",
        "abstract": "<p>Sensing and monitoring devices of many kinds are gradually becoming ever more pervasive in modem buildings. The range of applications is getting broader, including environmental control for occupant comfort and energy efficiency, as well as monitoring of the environment to achieve early detection and warning of emergency situations (such as fire). Conventional actuation for environmental comfort and to mitigate the effects of an emergency (such as sprinklers) is also common place. Systems for \"smart\" early response are now being developed to provide a more robust and reliable suppression or mitigation of the emergency. The FireGrid concept is about integrating the independently developing sensing technologies with modelling tools, using distributed computing (high performance computation and Grid technologies) and achieving real-time response to mitigate the potential damage as a result of major emergencies. The first application of this concept deals with fire in buildings (hence the name), however the concept is generally applicable to most emergencies. In this work the authors will discuss the basic architecture of FireGrid and how it may be used to provide early warning of the loss of structural integrity in a typical steel frame composite structure subjected to a large fire.</p>",
        "title": "FIREGRID: INTEGRATED E-RESPONSE FOR THE MODERN BUILT ENVIRONMENT BASED ON ENVIRONMENTAL AND STRUCTURAL MONITORING",
        "keywords": "",
        "authors": [
            {
                "name": "Gavin Pringle",
                "uuid": "66f4ae16-ad0a-4ab4-ae37-5f844ed07fae"
            }
        ]
    },
    "00fe82d1-c6aa-4a03-b584-1dfac33596e5": {
        "id": "00fe82d1-c6aa-4a03-b584-1dfac33596e5",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/an-architecture-for-an-integrated-fire-emergency-response-system-for-the-built-environment(00fe82d1-c6aa-4a03-b584-1dfac33596e5).html",
        "abstract": "FireGrid is a modern concept that aims to leverage a number of modern technologies to aid fire emergency response. In this paper we provide a brief introduction to the FireGrid project. A number of different technologies such as wireless sensor networks, grid-enabled High Performance Computing (HPC) implementation of fire models, and artificial intelligence tools need to be integrated to build up a modern fire emergency response system. We propose a system architecture that provides the framework for integration of the various technologies. We describe the components of the generic FireGrid system architecture in detail. Finally we present a small-scale demonstration experiment which has been completed to highlight the concept and application of the FireGrid system to an actual fire. Although our proposed system architecture provides a versatile framework for integration, a number of new and interesting research problems need to be solved before actual deployment of the system. We outline some of the challenges involved which require significant interdisciplinary collaborations.",
        "title": "An architecture for an integrated fire emergency response system for the built environment",
        "keywords": "Keywords",
        "authors": [
            {
                "name": "Gavin Pringle",
                "uuid": "66f4ae16-ad0a-4ab4-ae37-5f844ed07fae"
            }
        ]
    },
    "019e395a-80ef-4bac-96f7-de032459757a": {
        "id": "019e395a-80ef-4bac-96f7-de032459757a",
        "url": "https://www.research.ed.ac.uk/portal/en/publications/firegrid-an-einfrastructure-for-nextgeneration-emergency-response-support(019e395a-80ef-4bac-96f7-de032459757a).html",
        "abstract": "<p>The FireGrid project aims to harness the potential of advanced forms of computation to support the response to large-scale emergencies (with an initial focus on the response to fires in the built environment). Computational models of physical phenomena are developed, and then deployed and computed on High Performance Computing resources to infer incident conditions by assimilating live sensor data from an emergency in real time or, in the case of predictive models, faster-than-real time. The results of these models are then interpreted by a knowledge-based reasoning scheme to provide decision support information in appropriate terms for the emergency responder. These models are accessed over a Grid from an agent-based system, of which the human responders form an integral part. This paper proposes a novel FireGrid architecture, and describes the rationale behind this architecture and the research results of its application to a large-scale fire experiment. (c) 2010 Elsevier Inc. All rights reserved.</p>",
        "title": "FireGrid: An e-infrastructure for next-generation emergency response support",
        "keywords": "ASJC Scopus subject areas",
        "authors": [
            {
                "name": "Gavin Pringle",
                "uuid": "66f4ae16-ad0a-4ab4-ae37-5f844ed07fae"
            }
        ]
    }
}